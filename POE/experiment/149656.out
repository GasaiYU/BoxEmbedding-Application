Job start at 2023-04-05 15:39:19
Job run at:
   Static hostname: localhost.localdomain
Transient hostname: gpu-a13
         Icon name: computer-server
           Chassis: server
        Machine ID: 5284a7361474481dad97e247a5efb17a
           Boot ID: faf5914b871c4e61827d55c6cc4b8a84
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-1127.13.1.el7.x86_64
      Architecture: x86-64
Have already added /tools/cluster-modulefiles into $MODULEPATH

/usr/bin/gcc
/lustre/S/gaomj/miniconda3/envs/bachelor/bin/python
/tools/cluster-software/python3/python3-3.6.8/bin/python3
############### /home : /home/S/gaomj
Disk quotas for user gaomj (uid 6156): 
     Filesystem   space   quota   limit   grace   files   quota   limit   grace
          /home   4986M  16384M  20480M           24350       0       0        

############### /workspace
Disk quotas for user gaomj (uid 6156): 
     Filesystem   space   quota   limit   grace   files   quota   limit   grace
     /workspace      0K    400G    500G               1       0       0        

############### /lustre
Disk quotas for usr gaomj (uid 6156):
     Filesystem    used   quota   limit   grace   files   quota   limit   grace
        /lustre  9.656G      8T     10T       -  121306  3000000 36000000       -
uid 6156 is using default block quota setting
uid 6156 is using default file quota setting
name, driver_version, power.limit [W]
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
Use GPU 0,1,2,3,4,5,6,7
[TEST] epoch 0 Loss 6.164695001517733
[Train] epoch 0 Batch 1 Loss 0.16005088947713375
[Train] epoch 0 Batch 3 Loss 5.795828223228455
[Train] epoch 0 Batch 5 Loss 2.4114712476730347
[Train] epoch 0 Batch 7 Loss 1.975232183933258
[Train] epoch 0 Batch 9 Loss 1.9000834822654724
[Train] epoch 0 Batch 11 Loss 1.34549081325531
[Train] epoch 1 Batch 1 Loss 1.1285530924797058
[Train] epoch 1 Batch 3 Loss 1.1014021039009094
[Train] epoch 1 Batch 5 Loss 1.6149353384971619
[Train] epoch 1 Batch 7 Loss 2.141897052526474
[Train] epoch 1 Batch 9 Loss 1.0181662440299988
[Train] epoch 1 Batch 11 Loss 1.946019470691681
[Train] epoch 2 Batch 1 Loss 1.1131929755210876
[Train] epoch 2 Batch 3 Loss 1.1552792191505432
[Train] epoch 2 Batch 5 Loss 1.7690284848213196
[Train] epoch 2 Batch 7 Loss 1.5825579762458801
[Train] epoch 2 Batch 9 Loss 1.391055703163147
[Train] epoch 2 Batch 11 Loss 1.3710541725158691
[Train] epoch 3 Batch 1 Loss 0.9153822064399719
[Train] epoch 3 Batch 3 Loss 1.3854692578315735
[Train] epoch 3 Batch 5 Loss 1.8809671998023987
[Train] epoch 3 Batch 7 Loss 1.6710757315158844
[Train] epoch 3 Batch 9 Loss 1.3500561118125916
[Train] epoch 3 Batch 11 Loss 1.3789132237434387
[Train] epoch 4 Batch 1 Loss 1.573733389377594
[Train] epoch 4 Batch 3 Loss 1.4188497066497803
[Train] epoch 4 Batch 5 Loss 1.4364134073257446
[Train] epoch 4 Batch 7 Loss 1.086019366979599
[Train] epoch 4 Batch 9 Loss 1.3921841979026794
[Train] epoch 4 Batch 11 Loss 1.2062824368476868
[TEST] epoch 5 Loss 1.2689201434453328
[Train] epoch 5 Batch 1 Loss 1.4354454278945923
[Train] epoch 5 Batch 3 Loss 0.9753828644752502
[Train] epoch 5 Batch 5 Loss 1.547853708267212
[Train] epoch 5 Batch 7 Loss 1.45879328250885
[Train] epoch 5 Batch 9 Loss 1.3416211605072021
[Train] epoch 5 Batch 11 Loss 1.112977147102356
[Train] epoch 6 Batch 1 Loss 1.0579236149787903
[Train] epoch 6 Batch 3 Loss 1.577724575996399
[Train] epoch 6 Batch 5 Loss 0.8797574639320374
[Train] epoch 6 Batch 7 Loss 1.4170105457305908
[Train] epoch 6 Batch 9 Loss 1.0804719924926758
[Train] epoch 6 Batch 11 Loss 1.3663334846496582
[Train] epoch 7 Batch 1 Loss 0.7620857357978821
[Train] epoch 7 Batch 3 Loss 0.7786698341369629
[Train] epoch 7 Batch 5 Loss 2.2000724971294403
[Train] epoch 7 Batch 7 Loss 1.6166436672210693
[Train] epoch 7 Batch 9 Loss 0.8272902518510818
[Train] epoch 7 Batch 11 Loss 1.7843763530254364
[Train] epoch 8 Batch 1 Loss 0.5342502444982529
[Train] epoch 8 Batch 3 Loss 1.1786890029907227
[Train] epoch 8 Batch 5 Loss 1.3595157861709595
[Train] epoch 8 Batch 7 Loss 1.6391893029212952
[Train] epoch 8 Batch 9 Loss 0.8316332101821899
[Train] epoch 8 Batch 11 Loss 1.5249010920524597
[Train] epoch 9 Batch 1 Loss 0.4205024391412735
[Train] epoch 9 Batch 3 Loss 1.191758155822754
[Train] epoch 9 Batch 5 Loss 1.04266357421875
[Train] epoch 9 Batch 7 Loss 0.4846164882183075
[Train] epoch 9 Batch 9 Loss 1.8915884494781494
[Train] epoch 9 Batch 11 Loss 1.5352244973182678
[TEST] epoch 10 Loss 1.85507067044576
[Train] epoch 10 Batch 1 Loss 0.30226001143455505
[Train] epoch 10 Batch 3 Loss 2.1505849361419678
[Train] epoch 10 Batch 5 Loss 1.2702632546424866
[Train] epoch 10 Batch 7 Loss 0.41097159683704376
[Train] epoch 10 Batch 9 Loss 1.069239318370819
[Train] epoch 10 Batch 11 Loss 1.537528932094574
[Train] epoch 11 Batch 1 Loss 0.9846284687519073
[Train] epoch 11 Batch 3 Loss 0.9828046262264252
[Train] epoch 11 Batch 5 Loss 1.271322786808014
[Train] epoch 11 Batch 7 Loss 0.7227049171924591
[Train] epoch 11 Batch 9 Loss 0.7416772544384003
[Train] epoch 11 Batch 11 Loss 0.7197777628898621
[Train] epoch 12 Batch 1 Loss 0.9327004551887512
[Train] epoch 12 Batch 3 Loss 0.6247851550579071
[Train] epoch 12 Batch 5 Loss 1.1882360577583313
[Train] epoch 12 Batch 7 Loss 0.44660018384456635
[Train] epoch 12 Batch 9 Loss 1.6745337843894958
[Train] epoch 12 Batch 11 Loss 0.6632894277572632
[Train] epoch 13 Batch 1 Loss 0.8516039550304413
[Train] epoch 13 Batch 3 Loss 1.0922882854938507
[Train] epoch 13 Batch 5 Loss 1.2229402363300323
[Train] epoch 13 Batch 7 Loss 0.838340163230896
[Train] epoch 13 Batch 9 Loss 0.6464912295341492
[Train] epoch 13 Batch 11 Loss 0.6811520457267761
[Train] epoch 14 Batch 1 Loss 0.4217198044061661
[Train] epoch 14 Batch 3 Loss 0.6405066549777985
[Train] epoch 14 Batch 5 Loss 1.4777872562408447
[Train] epoch 14 Batch 7 Loss 0.8853465914726257
[Train] epoch 14 Batch 9 Loss 0.785478949546814
[Train] epoch 14 Batch 11 Loss 0.9049968421459198
[TEST] epoch 15 Loss 1.8849633534749348
[Train] epoch 15 Batch 1 Loss 1.0832107365131378
[Train] epoch 15 Batch 3 Loss 0.4996647536754608
[Train] epoch 15 Batch 5 Loss 0.899565726518631
[Train] epoch 15 Batch 7 Loss 0.7376677393913269
[Train] epoch 15 Batch 9 Loss 0.9475721716880798
[Train] epoch 15 Batch 11 Loss 0.7779741883277893
[Train] epoch 16 Batch 1 Loss 0.38505788147449493
[Train] epoch 16 Batch 3 Loss 0.8212917149066925
[Train] epoch 16 Batch 5 Loss 2.3077361583709717
[Train] epoch 16 Batch 7 Loss 1.6319013833999634
[Train] epoch 16 Batch 9 Loss 2.19588840007782
[Train] epoch 16 Batch 11 Loss 2.268925726413727
[Train] epoch 17 Batch 1 Loss 2.7979042530059814
[Train] epoch 17 Batch 3 Loss 1.120758980512619
[Train] epoch 17 Batch 5 Loss 0.8120371699333191
[Train] epoch 17 Batch 7 Loss 1.7922618389129639
[Train] epoch 17 Batch 9 Loss 1.3780649304389954
[Train] epoch 17 Batch 11 Loss 1.5278263092041016
[Train] epoch 18 Batch 1 Loss 1.4388207793235779
[Train] epoch 18 Batch 3 Loss 1.367135226726532
[Train] epoch 18 Batch 5 Loss 1.4502722024917603
[Train] epoch 18 Batch 7 Loss 1.7236418724060059
[Train] epoch 18 Batch 9 Loss 0.7273073792457581
[Train] epoch 18 Batch 11 Loss 1.0708334147930145
[Train] epoch 19 Batch 1 Loss 1.6417060494422913
[Train] epoch 19 Batch 3 Loss 1.487973153591156
[Train] epoch 19 Batch 5 Loss 1.3853386044502258
[Train] epoch 19 Batch 7 Loss 1.526984691619873
[Train] epoch 19 Batch 9 Loss 0.9928816556930542
[Train] epoch 19 Batch 11 Loss 1.052086055278778
[TEST] epoch 20 Loss 0.9529217481613159
[Train] epoch 20 Batch 1 Loss 1.2189905047416687
[Train] epoch 20 Batch 3 Loss 1.2584007382392883
[Train] epoch 20 Batch 5 Loss 1.2029269635677338
[Train] epoch 20 Batch 7 Loss 1.2873855829238892
[Train] epoch 20 Batch 9 Loss 1.4171340763568878
[Train] epoch 20 Batch 11 Loss 1.358306646347046
[Train] epoch 21 Batch 1 Loss 1.4738853573799133
[Train] epoch 21 Batch 3 Loss 0.6934636235237122
[Train] epoch 21 Batch 5 Loss 1.500178039073944
[Train] epoch 21 Batch 7 Loss 1.157505750656128
[Train] epoch 21 Batch 9 Loss 1.40774267911911
[Train] epoch 21 Batch 11 Loss 1.4411081671714783
[Train] epoch 22 Batch 1 Loss 1.2812941074371338
[Train] epoch 22 Batch 3 Loss 1.1408385038375854
[Train] epoch 22 Batch 5 Loss 1.4146444201469421
[Train] epoch 22 Batch 7 Loss 0.992749810218811
[Train] epoch 22 Batch 9 Loss 1.2832465767860413
[Train] epoch 22 Batch 11 Loss 1.5121685862541199
[Train] epoch 23 Batch 1 Loss 1.2445573806762695
[Train] epoch 23 Batch 3 Loss 1.3139819502830505
[Train] epoch 23 Batch 5 Loss 1.2886138558387756
[Train] epoch 23 Batch 7 Loss 1.302363634109497
[Train] epoch 23 Batch 9 Loss 1.238810956478119
[Train] epoch 23 Batch 11 Loss 1.2354743480682373
[Train] epoch 24 Batch 1 Loss 1.2039132118225098
[Train] epoch 24 Batch 3 Loss 1.437590777873993
[Train] epoch 24 Batch 5 Loss 0.996027410030365
[Train] epoch 24 Batch 7 Loss 1.4837906956672668
[Train] epoch 24 Batch 9 Loss 1.5644198656082153
[Train] epoch 24 Batch 11 Loss 1.1007902026176453
[TEST] epoch 25 Loss 1.0987084309260051
[Train] epoch 25 Batch 1 Loss 1.2513198852539062
[Train] epoch 25 Batch 3 Loss 1.3756446242332458
[Train] epoch 25 Batch 5 Loss 1.316546082496643
[Train] epoch 25 Batch 7 Loss 0.7664121389389038
[Train] epoch 25 Batch 9 Loss 1.3821310997009277
[Train] epoch 25 Batch 11 Loss 1.5049333572387695
[Train] epoch 26 Batch 1 Loss 0.9817683398723602
[Train] epoch 26 Batch 3 Loss 1.246315062046051
[Train] epoch 26 Batch 5 Loss 1.4122366309165955
[Train] epoch 26 Batch 7 Loss 1.3675269484519958
[Train] epoch 26 Batch 9 Loss 1.266474187374115
[Train] epoch 26 Batch 11 Loss 1.3587027788162231
[Train] epoch 27 Batch 1 Loss 1.2390882968902588
[Train] epoch 27 Batch 3 Loss 1.4927430152893066
[Train] epoch 27 Batch 5 Loss 0.9462454319000244
[Train] epoch 27 Batch 7 Loss 1.5680387020111084
[Train] epoch 27 Batch 9 Loss 1.2061640620231628
[Train] epoch 27 Batch 11 Loss 1.2006896138191223
[Train] epoch 28 Batch 1 Loss 1.1389694213867188
[Train] epoch 28 Batch 3 Loss 1.4626387357711792
[Train] epoch 28 Batch 5 Loss 0.8584215939044952
[Train] epoch 28 Batch 7 Loss 1.2870082557201385
[Train] epoch 28 Batch 9 Loss 1.5078117847442627
[Train] epoch 28 Batch 11 Loss 1.5374029278755188
[Train] epoch 29 Batch 1 Loss 1.2807011604309082
[Train] epoch 29 Batch 3 Loss 1.2766022682189941
[Train] epoch 29 Batch 5 Loss 1.1190598905086517
[Train] epoch 29 Batch 7 Loss 1.2737184166908264
[Train] epoch 29 Batch 9 Loss 1.2684425115585327
[Train] epoch 29 Batch 11 Loss 1.3661224842071533
[TEST] epoch 30 Loss 1.0719600319862366
[Train] epoch 30 Batch 1 Loss 1.0526095032691956
[Train] epoch 30 Batch 3 Loss 0.7787527441978455
[Train] epoch 30 Batch 5 Loss 1.2375553250312805
[Train] epoch 30 Batch 7 Loss 1.6098882555961609
[Train] epoch 30 Batch 9 Loss 1.512730062007904
[Train] epoch 30 Batch 11 Loss 1.561814546585083
[Train] epoch 31 Batch 1 Loss 1.5485552549362183
[Train] epoch 31 Batch 3 Loss 0.9472393989562988
[Train] epoch 31 Batch 5 Loss 1.25894033908844
[Train] epoch 31 Batch 7 Loss 1.3596758246421814
[Train] epoch 31 Batch 9 Loss 1.2408719658851624
[Train] epoch 31 Batch 11 Loss 1.439553439617157
[Train] epoch 32 Batch 1 Loss 1.389513909816742
[Train] epoch 32 Batch 3 Loss 1.2528489232063293
[Train] epoch 32 Batch 5 Loss 0.9466612935066223
[Train] epoch 32 Batch 7 Loss 1.7676326632499695
[Train] epoch 32 Batch 9 Loss 0.9977431893348694
[Train] epoch 32 Batch 11 Loss 1.7716447710990906
[Train] epoch 33 Batch 1 Loss 1.21507066488266
[Train] epoch 33 Batch 3 Loss 1.6464478373527527
[Train] epoch 33 Batch 5 Loss 1.1632188260555267
[Train] epoch 33 Batch 7 Loss 1.3551942706108093
[Train] epoch 33 Batch 9 Loss 1.5244266986846924
[Train] epoch 33 Batch 11 Loss 1.3256124258041382
[Train] epoch 34 Batch 1 Loss 1.045402467250824
[Train] epoch 34 Batch 3 Loss 1.1613368391990662
[Train] epoch 34 Batch 5 Loss 1.4235473275184631
[Train] epoch 34 Batch 7 Loss 1.2630591988563538
[Train] epoch 34 Batch 9 Loss 1.3267630338668823
[Train] epoch 34 Batch 11 Loss 1.4209717512130737
[TEST] epoch 35 Loss 1.0957653323809307
[Train] epoch 35 Batch 1 Loss 1.1009172201156616
[Train] epoch 35 Batch 3 Loss 1.2817342281341553
[Train] epoch 35 Batch 5 Loss 1.6240147948265076
[Train] epoch 35 Batch 7 Loss 1.0244679301977158
[Train] epoch 35 Batch 9 Loss 1.3135020732879639
[Train] epoch 35 Batch 11 Loss 1.24516099691391
[Train] epoch 36 Batch 1 Loss 1.243952751159668
[Train] epoch 36 Batch 3 Loss 1.4010186195373535
[Train] epoch 36 Batch 5 Loss 1.2300571501255035
[Train] epoch 36 Batch 7 Loss 1.088476538658142
[Train] epoch 36 Batch 9 Loss 1.1960715651512146
[Train] epoch 36 Batch 11 Loss 1.6577569842338562
[Train] epoch 37 Batch 1 Loss 1.405224621295929
[Train] epoch 37 Batch 3 Loss 1.2920304536819458
[Train] epoch 37 Batch 5 Loss 1.294216513633728
[Train] epoch 37 Batch 7 Loss 1.0047837495803833
[Train] epoch 37 Batch 9 Loss 1.2496405243873596
[Train] epoch 37 Batch 11 Loss 1.3505527973175049
[Train] epoch 38 Batch 1 Loss 0.8585337400436401
[Train] epoch 38 Batch 3 Loss 1.2509088516235352
[Train] epoch 38 Batch 5 Loss 1.1365885734558105
[Train] epoch 38 Batch 7 Loss 1.8303401470184326
[Train] epoch 38 Batch 9 Loss 0.8846936225891113
[Train] epoch 38 Batch 11 Loss 1.822459638118744
[Train] epoch 39 Batch 1 Loss 1.5813676118850708
[Train] epoch 39 Batch 3 Loss 1.2893405556678772
[Train] epoch 39 Batch 5 Loss 1.1995190382003784
[Train] epoch 39 Batch 7 Loss 1.035107582807541
[Train] epoch 39 Batch 9 Loss 1.4590792059898376
[Train] epoch 39 Batch 11 Loss 1.3800077438354492
[TEST] epoch 40 Loss 1.0377732515335083
[Train] epoch 40 Batch 1 Loss 1.1839182376861572
[Train] epoch 40 Batch 3 Loss 1.1447283029556274
[Train] epoch 40 Batch 5 Loss 1.286921888589859
[Train] epoch 40 Batch 7 Loss 1.667665183544159
[Train] epoch 40 Batch 9 Loss 1.2849791049957275
[Train] epoch 40 Batch 11 Loss 1.3154312372207642
[Train] epoch 41 Batch 1 Loss 0.988883912563324
[Train] epoch 41 Batch 3 Loss 1.26118803024292
[Train] epoch 41 Batch 5 Loss 1.2760149836540222
[Train] epoch 41 Batch 7 Loss 1.4403366446495056
[Train] epoch 41 Batch 9 Loss 1.2380571961402893
[Train] epoch 41 Batch 11 Loss 1.2684070467948914
[Train] epoch 42 Batch 1 Loss 1.2845970392227173
[Train] epoch 42 Batch 3 Loss 1.3386496305465698
[Train] epoch 42 Batch 5 Loss 1.3501918315887451
[Train] epoch 42 Batch 7 Loss 1.0393933355808258
[Train] epoch 42 Batch 9 Loss 1.2931314706802368
[Train] epoch 42 Batch 11 Loss 1.376308023929596
[Train] epoch 43 Batch 1 Loss 1.1361212730407715
[Train] epoch 43 Batch 3 Loss 1.4431512951850891
[Train] epoch 43 Batch 5 Loss 1.4377936124801636
[Train] epoch 43 Batch 7 Loss 0.961363822221756
[Train] epoch 43 Batch 9 Loss 1.1906577944755554
[Train] epoch 43 Batch 11 Loss 1.4331303834915161
[Train] epoch 44 Batch 1 Loss 1.2704527378082275
[Train] epoch 44 Batch 3 Loss 1.4544075727462769
[Train] epoch 44 Batch 5 Loss 1.189907729625702
[Train] epoch 44 Batch 7 Loss 1.3501694798469543
[Train] epoch 44 Batch 9 Loss 1.3785808086395264
[Train] epoch 44 Batch 11 Loss 1.4980295300483704
[TEST] epoch 45 Loss 0.9811808069547018
[Train] epoch 45 Batch 1 Loss 1.3474556803703308
[Train] epoch 45 Batch 3 Loss 1.1650696992874146
[Train] epoch 45 Batch 5 Loss 1.4958544373512268
[Train] epoch 45 Batch 7 Loss 0.9495947957038879
[Train] epoch 45 Batch 9 Loss 1.449863076210022
[Train] epoch 45 Batch 11 Loss 1.799405813217163
[Train] epoch 46 Batch 1 Loss 1.5070687532424927
[Train] epoch 46 Batch 3 Loss 0.8501491844654083
[Train] epoch 46 Batch 5 Loss 1.1064800024032593
[Train] epoch 46 Batch 7 Loss 1.670951008796692
[Train] epoch 46 Batch 9 Loss 1.3572363257408142
[Train] epoch 46 Batch 11 Loss 1.287954643368721
[Train] epoch 47 Batch 1 Loss 1.1374264359474182
[Train] epoch 47 Batch 3 Loss 1.174640268087387
[Train] epoch 47 Batch 5 Loss 1.1296179294586182
[Train] epoch 47 Batch 7 Loss 1.3396897315979004
[Train] epoch 47 Batch 9 Loss 1.3891903162002563
[Train] epoch 47 Batch 11 Loss 1.2445345222949982
[Train] epoch 48 Batch 1 Loss 1.2665309309959412
[Train] epoch 48 Batch 3 Loss 0.9654544293880463
[Train] epoch 48 Batch 5 Loss 1.239520251750946
[Train] epoch 48 Batch 7 Loss 1.3824864029884338
[Train] epoch 48 Batch 9 Loss 1.3507893085479736
[Train] epoch 48 Batch 11 Loss 1.4528904557228088
[Train] epoch 49 Batch 1 Loss 1.2391151189804077
[Train] epoch 49 Batch 3 Loss 1.1433406174182892
[Train] epoch 49 Batch 5 Loss 1.4381881952285767
[Train] epoch 49 Batch 7 Loss 0.9968056678771973
[Train] epoch 49 Batch 9 Loss 1.2975399494171143
[Train] epoch 49 Batch 11 Loss 1.5584728717803955
[TEST] epoch 50 Loss 1.1268808643023174
[Train] epoch 50 Batch 1 Loss 1.2233508825302124
[Train] epoch 50 Batch 3 Loss 1.4813600778579712
[Train] epoch 50 Batch 5 Loss 1.5766013264656067
[Train] epoch 50 Batch 7 Loss 0.9816117286682129
[Train] epoch 50 Batch 9 Loss 1.26404869556427
[Train] epoch 50 Batch 11 Loss 1.0201542377471924
[Train] epoch 51 Batch 1 Loss 1.2028372287750244
[Train] epoch 51 Batch 3 Loss 1.4055866599082947
[Train] epoch 51 Batch 5 Loss 0.9326774030923843
[Train] epoch 51 Batch 7 Loss 1.7460142374038696
[Train] epoch 51 Batch 9 Loss 1.1323645412921906
[Train] epoch 51 Batch 11 Loss 1.2369775176048279
[Train] epoch 52 Batch 1 Loss 1.3389844298362732
[Train] epoch 52 Batch 3 Loss 1.2669621706008911
[Train] epoch 52 Batch 5 Loss 1.4033308029174805
[Train] epoch 52 Batch 7 Loss 1.3188755214214325
[Train] epoch 52 Batch 9 Loss 1.1691434979438782
[Train] epoch 52 Batch 11 Loss 1.1843130588531494
[Train] epoch 53 Batch 1 Loss 1.1893617510795593
[Train] epoch 53 Batch 3 Loss 1.3161062002182007
[Train] epoch 53 Batch 5 Loss 1.1769710183143616
[Train] epoch 53 Batch 7 Loss 1.4358863234519958
[Train] epoch 53 Batch 9 Loss 1.573399007320404
[Train] epoch 53 Batch 11 Loss 0.9045121073722839
[Train] epoch 54 Batch 1 Loss 1.47396582365036
[Train] epoch 54 Batch 3 Loss 1.0056821554899216
[Train] epoch 54 Batch 5 Loss 1.4407759308815002
[Train] epoch 54 Batch 7 Loss 1.1840559244155884
[Train] epoch 54 Batch 9 Loss 1.3697707653045654
[Train] epoch 54 Batch 11 Loss 1.1750012040138245
[TEST] epoch 55 Loss 0.9597864548365275
[Train] epoch 55 Batch 1 Loss 1.081431806087494
[Train] epoch 55 Batch 3 Loss 1.192361742258072
[Train] epoch 55 Batch 5 Loss 0.9898035824298859
[Train] epoch 55 Batch 7 Loss 1.37692129611969
[Train] epoch 55 Batch 9 Loss 1.5209743976593018
[Train] epoch 55 Batch 11 Loss 1.498580276966095
[Train] epoch 56 Batch 1 Loss 1.3220767974853516
[Train] epoch 56 Batch 3 Loss 1.6333430409431458
[Train] epoch 56 Batch 5 Loss 0.974950909614563
[Train] epoch 56 Batch 7 Loss 1.24198716878891
[Train] epoch 56 Batch 9 Loss 1.1963116526603699
[Train] epoch 56 Batch 11 Loss 1.2267399430274963
[Train] epoch 57 Batch 1 Loss 1.367104709148407
[Train] epoch 57 Batch 3 Loss 1.219908356666565
[Train] epoch 57 Batch 5 Loss 0.9905158579349518
[Train] epoch 57 Batch 7 Loss 1.421768307685852
[Train] epoch 57 Batch 9 Loss 1.1812813878059387
[Train] epoch 57 Batch 11 Loss 1.4937278628349304
[Train] epoch 58 Batch 1 Loss 1.5832955837249756
[Train] epoch 58 Batch 3 Loss 1.1592506766319275
[Train] epoch 58 Batch 5 Loss 1.2031640410423279
[Train] epoch 58 Batch 7 Loss 0.9521507024765015
[Train] epoch 58 Batch 9 Loss 1.5052838325500488
[Train] epoch 58 Batch 11 Loss 1.2782241702079773
[Train] epoch 59 Batch 1 Loss 1.4358716011047363
[Train] epoch 59 Batch 3 Loss 1.1520085036754608
[Train] epoch 59 Batch 5 Loss 0.7279273271560669
[Train] epoch 59 Batch 7 Loss 1.4727604985237122
[Train] epoch 59 Batch 9 Loss 1.2307957410812378
[Train] epoch 59 Batch 11 Loss 1.5293312072753906
[TEST] epoch 60 Loss 0.9977042973041534
[Train] epoch 60 Batch 1 Loss 1.3305711150169373
[Train] epoch 60 Batch 3 Loss 1.2649112343788147
[Train] epoch 60 Batch 5 Loss 1.1225880980491638
[Train] epoch 60 Batch 7 Loss 1.2081948518753052
[Train] epoch 60 Batch 9 Loss 1.2760637998580933
[Train] epoch 60 Batch 11 Loss 1.5786786675453186
[Train] epoch 61 Batch 1 Loss 1.5141427516937256
[Train] epoch 61 Batch 3 Loss 1.2750683426856995
[Train] epoch 61 Batch 5 Loss 1.0341856777668
[Train] epoch 61 Batch 7 Loss 1.3762248754501343
[Train] epoch 61 Batch 9 Loss 1.1991606950759888
[Train] epoch 61 Batch 11 Loss 1.2113440930843353
[Train] epoch 62 Batch 1 Loss 1.188129872083664
[Train] epoch 62 Batch 3 Loss 1.3241727948188782
[Train] epoch 62 Batch 5 Loss 1.1760338246822357
[Train] epoch 62 Batch 7 Loss 1.5003899931907654
[Train] epoch 62 Batch 9 Loss 1.1731694340705872
[Train] epoch 62 Batch 11 Loss 1.286162793636322
[Train] epoch 63 Batch 1 Loss 1.353290855884552
[Train] epoch 63 Batch 3 Loss 1.1720172464847565
[Train] epoch 63 Batch 5 Loss 1.0367873907089233
[Train] epoch 63 Batch 7 Loss 1.3180084824562073
[Train] epoch 63 Batch 9 Loss 1.2726498246192932
[Train] epoch 63 Batch 11 Loss 1.446521520614624
[Train] epoch 64 Batch 1 Loss 1.0845929086208344
[Train] epoch 64 Batch 3 Loss 1.4508308172225952
[Train] epoch 64 Batch 5 Loss 0.9386812150478363
[Train] epoch 64 Batch 7 Loss 1.1826027631759644
[Train] epoch 64 Batch 9 Loss 1.4556912183761597
[Train] epoch 64 Batch 11 Loss 1.434981644153595
[TEST] epoch 65 Loss 0.9937509298324585
[Train] epoch 65 Batch 1 Loss 1.4931329488754272
[Train] epoch 65 Batch 3 Loss 1.0162422955036163
[Train] epoch 65 Batch 5 Loss 1.0003226399421692
[Train] epoch 65 Batch 7 Loss 1.1689367294311523
[Train] epoch 65 Batch 9 Loss 1.3717845678329468
[Train] epoch 65 Batch 11 Loss 1.5835126042366028
[Train] epoch 66 Batch 1 Loss 1.1147206723690033
[Train] epoch 66 Batch 3 Loss 1.183125913143158
[Train] epoch 66 Batch 5 Loss 1.3007293343544006
[Train] epoch 66 Batch 7 Loss 1.667912244796753
[Train] epoch 66 Batch 9 Loss 1.3062087297439575
[Train] epoch 66 Batch 11 Loss 1.03542098402977
[Train] epoch 67 Batch 1 Loss 1.3357447981834412
[Train] epoch 67 Batch 3 Loss 1.2047797441482544
[Train] epoch 67 Batch 5 Loss 0.977188229560852
[Train] epoch 67 Batch 7 Loss 1.2490643560886383
[Train] epoch 67 Batch 9 Loss 1.3538233041763306
[Train] epoch 67 Batch 11 Loss 1.465490996837616
[Train] epoch 68 Batch 1 Loss 1.1232805848121643
[Train] epoch 68 Batch 3 Loss 1.3427947163581848
[Train] epoch 68 Batch 5 Loss 1.1995514631271362
[Train] epoch 68 Batch 7 Loss 1.1907309293746948
[Train] epoch 68 Batch 9 Loss 1.4750062823295593
[Train] epoch 68 Batch 11 Loss 1.15706205368042
[Train] epoch 69 Batch 1 Loss 1.2863717675209045
[Train] epoch 69 Batch 3 Loss 1.4530396461486816
[Train] epoch 69 Batch 5 Loss 1.0035838782787323
[Train] epoch 69 Batch 7 Loss 1.2140065133571625
[Train] epoch 69 Batch 9 Loss 1.2138506174087524
[Train] epoch 69 Batch 11 Loss 1.4797211289405823
[TEST] epoch 70 Loss 0.9746539990107218
[Train] epoch 70 Batch 1 Loss 1.1925889253616333
[Train] epoch 70 Batch 3 Loss 1.2371171712875366
[Train] epoch 70 Batch 5 Loss 1.2204519510269165
[Train] epoch 70 Batch 7 Loss 1.2394044697284698
[Train] epoch 70 Batch 9 Loss 1.3488441109657288
[Train] epoch 70 Batch 11 Loss 1.2761247158050537
[Train] epoch 71 Batch 1 Loss 1.1682503819465637
[Train] epoch 71 Batch 3 Loss 1.3017443716526031
[Train] epoch 71 Batch 5 Loss 1.473602056503296
[Train] epoch 71 Batch 7 Loss 1.4096643924713135
[Train] epoch 71 Batch 9 Loss 1.2603439390659332
[Train] epoch 71 Batch 11 Loss 1.2391808927059174
[Train] epoch 72 Batch 1 Loss 1.4000375866889954
[Train] epoch 72 Batch 3 Loss 0.8179045021533966
[Train] epoch 72 Batch 5 Loss 1.1458149254322052
[Train] epoch 72 Batch 7 Loss 1.7448346018791199
[Train] epoch 72 Batch 9 Loss 1.0786800384521484
[Train] epoch 72 Batch 11 Loss 1.3743627071380615
[Train] epoch 73 Batch 1 Loss 1.467469036579132
[Train] epoch 73 Batch 3 Loss 1.263177514076233
[Train] epoch 73 Batch 5 Loss 1.2268882989883423
[Train] epoch 73 Batch 7 Loss 1.2425490617752075
[Train] epoch 73 Batch 9 Loss 1.2238128185272217
[Train] epoch 73 Batch 11 Loss 1.1760052144527435
[Train] epoch 74 Batch 1 Loss 1.3919792175292969
[Train] epoch 74 Batch 3 Loss 1.3950299620628357
[Train] epoch 74 Batch 5 Loss 1.1978813409805298
[Train] epoch 74 Batch 7 Loss 0.8218032717704773
[Train] epoch 74 Batch 9 Loss 1.3575834035873413
[Train] epoch 74 Batch 11 Loss 2.0032527446746826
[TEST] epoch 75 Loss 1.5800529023011525
[Train] epoch 75 Batch 1 Loss 2.2577090859413147
[Train] epoch 75 Batch 3 Loss 1.014857918024063
[Train] epoch 75 Batch 5 Loss 0.9541191756725311
[Train] epoch 75 Batch 7 Loss 1.6700027585029602
[Train] epoch 75 Batch 9 Loss 1.1690033674240112
[Train] epoch 75 Batch 11 Loss 1.3104895949363708
[Train] epoch 76 Batch 1 Loss 1.0218341052532196
[Train] epoch 76 Batch 3 Loss 1.2888620495796204
[Train] epoch 76 Batch 5 Loss 1.369964361190796
[Train] epoch 76 Batch 7 Loss 1.3533194065093994
[Train] epoch 76 Batch 9 Loss 1.330111801624298
[Train] epoch 76 Batch 11 Loss 1.2908419966697693
[Train] epoch 77 Batch 1 Loss 1.5513636469841003
[Train] epoch 77 Batch 3 Loss 1.1556814908981323
[Train] epoch 77 Batch 5 Loss 1.5375615954399109
[Train] epoch 77 Batch 7 Loss 1.1451020240783691
[Train] epoch 77 Batch 9 Loss 1.3751285076141357
[Train] epoch 77 Batch 11 Loss 0.9149763584136963
[Train] epoch 78 Batch 1 Loss 1.4350659847259521
[Train] epoch 78 Batch 3 Loss 1.1875937581062317
[Train] epoch 78 Batch 5 Loss 1.3577030301094055
[Train] epoch 78 Batch 7 Loss 1.2575210332870483
[Train] epoch 78 Batch 9 Loss 1.022280514240265
[Train] epoch 78 Batch 11 Loss 1.2431802153587341
[Train] epoch 79 Batch 1 Loss 1.0489135384559631
[Train] epoch 79 Batch 3 Loss 1.197832852602005
[Train] epoch 79 Batch 5 Loss 1.4384432435035706
[Train] epoch 79 Batch 7 Loss 1.2018963098526
[Train] epoch 79 Batch 9 Loss 1.1790956854820251
[Train] epoch 79 Batch 11 Loss 1.4964345693588257
[TEST] epoch 80 Loss 0.9451300501823425
[Train] epoch 80 Batch 1 Loss 1.2495900988578796
[Train] epoch 80 Batch 3 Loss 1.2038314938545227
[Train] epoch 80 Batch 5 Loss 1.6900421977043152
[Train] epoch 80 Batch 7 Loss 1.3398075103759766
[Train] epoch 80 Batch 9 Loss 1.357830822467804
[Train] epoch 80 Batch 11 Loss 0.7155132293701172
[Train] epoch 81 Batch 1 Loss 1.1736599802970886
[Train] epoch 81 Batch 3 Loss 1.1660124063491821
[Train] epoch 81 Batch 5 Loss 1.5774717926979065
[Train] epoch 81 Batch 7 Loss 1.5418528318405151
[Train] epoch 81 Batch 9 Loss 1.0209123194217682
[Train] epoch 81 Batch 11 Loss 1.040559709072113
[Train] epoch 82 Batch 1 Loss 1.6000497341156006
[Train] epoch 82 Batch 3 Loss 1.1649814546108246
[Train] epoch 82 Batch 5 Loss 1.3074634671211243
[Train] epoch 82 Batch 7 Loss 1.2287397384643555
[Train] epoch 82 Batch 9 Loss 1.0653289556503296
[Train] epoch 82 Batch 11 Loss 1.1605429649353027
[Train] epoch 83 Batch 1 Loss 1.4261695742607117
[Train] epoch 83 Batch 3 Loss 1.5801713466644287
[Train] epoch 83 Batch 5 Loss 1.0841098427772522
[Train] epoch 83 Batch 7 Loss 1.0746820569038391
[Train] epoch 83 Batch 9 Loss 0.9192267954349518
[Train] epoch 83 Batch 11 Loss 1.431173324584961
[Train] epoch 84 Batch 1 Loss 1.0609304904937744
[Train] epoch 84 Batch 3 Loss 1.0701096057891846
[Train] epoch 84 Batch 5 Loss 1.6072810292243958
[Train] epoch 84 Batch 7 Loss 0.9831644296646118
[Train] epoch 84 Batch 9 Loss 1.7052648067474365
[Train] epoch 84 Batch 11 Loss 1.3201475143432617
[TEST] epoch 85 Loss 1.0871432324250538
[Train] epoch 85 Batch 1 Loss 1.4711195230484009
[Train] epoch 85 Batch 3 Loss 1.5327279567718506
[Train] epoch 85 Batch 5 Loss 1.2425192594528198
[Train] epoch 85 Batch 7 Loss 0.9838992357254028
[Train] epoch 85 Batch 9 Loss 1.106864869594574
[Train] epoch 85 Batch 11 Loss 1.2729551792144775
[Train] epoch 86 Batch 1 Loss 1.3785991668701172
[Train] epoch 86 Batch 3 Loss 1.353209376335144
[Train] epoch 86 Batch 5 Loss 1.386343002319336
[Train] epoch 86 Batch 7 Loss 1.0471025705337524
[Train] epoch 86 Batch 9 Loss 1.1408917307853699
[Train] epoch 86 Batch 11 Loss 1.1870200634002686
[Train] epoch 87 Batch 1 Loss 1.128764271736145
[Train] epoch 87 Batch 3 Loss 1.2044089436531067
[Train] epoch 87 Batch 5 Loss 0.8791273534297943
[Train] epoch 87 Batch 7 Loss 1.2393180131912231
[Train] epoch 87 Batch 9 Loss 1.5489290356636047
[Train] epoch 87 Batch 11 Loss 1.6101415157318115
[Train] epoch 88 Batch 1 Loss 1.2107532024383545
[Train] epoch 88 Batch 3 Loss 1.4945021867752075
[Train] epoch 88 Batch 5 Loss 0.9548141956329346
[Train] epoch 88 Batch 7 Loss 0.994795560836792
[Train] epoch 88 Batch 9 Loss 1.439133882522583
[Train] epoch 88 Batch 11 Loss 1.3498469293117523
[Train] epoch 89 Batch 1 Loss 1.0842191874980927
[Train] epoch 89 Batch 3 Loss 1.3980740308761597
[Train] epoch 89 Batch 5 Loss 1.3363332748413086
[Train] epoch 89 Batch 7 Loss 1.102002203464508
[Train] epoch 89 Batch 9 Loss 1.411767601966858
[Train] epoch 89 Batch 11 Loss 1.1495825052261353
[TEST] epoch 90 Loss 0.984005888303121
[Train] epoch 90 Batch 1 Loss 1.0884559452533722
[Train] epoch 90 Batch 3 Loss 1.55863356590271
[Train] epoch 90 Batch 5 Loss 1.0396958589553833
[Train] epoch 90 Batch 7 Loss 1.2275426983833313
[Train] epoch 90 Batch 9 Loss 1.1578269600868225
[Train] epoch 90 Batch 11 Loss 1.603391408920288
[Train] epoch 91 Batch 1 Loss 1.2303019165992737
[Train] epoch 91 Batch 3 Loss 1.326686143875122
[Train] epoch 91 Batch 5 Loss 1.5220381617546082
[Train] epoch 91 Batch 7 Loss 1.0012147128582
[Train] epoch 91 Batch 9 Loss 1.1529197990894318
[Train] epoch 91 Batch 11 Loss 1.2822591662406921
[Train] epoch 92 Batch 1 Loss 0.6782379597425461
[Train] epoch 92 Batch 3 Loss 1.1475406289100647
[Train] epoch 92 Batch 5 Loss 1.6276629567146301
[Train] epoch 92 Batch 7 Loss 1.6521339416503906
[Train] epoch 92 Batch 9 Loss 1.2838793396949768
[Train] epoch 92 Batch 11 Loss 1.315520703792572
[Train] epoch 93 Batch 1 Loss 1.194094479084015
[Train] epoch 93 Batch 3 Loss 1.19769948720932
[Train] epoch 93 Batch 5 Loss 1.374501883983612
[Train] epoch 93 Batch 7 Loss 1.2913903594017029
[Train] epoch 93 Batch 9 Loss 1.2663146257400513
[Train] epoch 93 Batch 11 Loss 1.306198000907898
[Train] epoch 94 Batch 1 Loss 1.3543871641159058
[Train] epoch 94 Batch 3 Loss 1.2968990802764893
[Train] epoch 94 Batch 5 Loss 1.144374430179596
[Train] epoch 94 Batch 7 Loss 1.1524878144264221
[Train] epoch 94 Batch 9 Loss 1.388329803943634
[Train] epoch 94 Batch 11 Loss 1.3005166053771973
[TEST] epoch 95 Loss 0.9633797605832418
[Train] epoch 95 Batch 1 Loss 1.2110863327980042
[Train] epoch 95 Batch 3 Loss 1.2645981311798096
[Train] epoch 95 Batch 5 Loss 1.3401044011116028
[Train] epoch 95 Batch 7 Loss 1.1737734377384186
[Train] epoch 95 Batch 9 Loss 1.4381913542747498
[Train] epoch 95 Batch 11 Loss 0.9865208268165588
[Train] epoch 96 Batch 1 Loss 0.8908059597015381
[Train] epoch 96 Batch 3 Loss 1.249659776687622
[Train] epoch 96 Batch 5 Loss 1.2756219506263733
[Train] epoch 96 Batch 7 Loss 1.4738200902938843
[Train] epoch 96 Batch 9 Loss 1.4379302859306335
[Train] epoch 96 Batch 11 Loss 1.3711957335472107
[Train] epoch 97 Batch 1 Loss 1.5647093653678894
[Train] epoch 97 Batch 3 Loss 1.2483221292495728
[Train] epoch 97 Batch 5 Loss 1.326963186264038
[Train] epoch 97 Batch 7 Loss 1.1240918636322021
[Train] epoch 97 Batch 9 Loss 1.0580080151557922
[Train] epoch 97 Batch 11 Loss 1.194588541984558
[Train] epoch 98 Batch 1 Loss 1.4618676900863647
[Train] epoch 98 Batch 3 Loss 0.9339724481105804
[Train] epoch 98 Batch 5 Loss 1.1052899360656738
[Train] epoch 98 Batch 7 Loss 1.3524123430252075
[Train] epoch 98 Batch 9 Loss 1.382681667804718
[Train] epoch 98 Batch 11 Loss 1.2718251943588257
[Train] epoch 99 Batch 1 Loss 0.9409044682979584
[Train] epoch 99 Batch 3 Loss 1.4447916746139526
[Train] epoch 99 Batch 5 Loss 1.1800317764282227
[Train] epoch 99 Batch 7 Loss 1.443665325641632
[Train] epoch 99 Batch 9 Loss 1.4914464950561523
[Train] epoch 99 Batch 11 Loss 0.9718655347824097
[TEST] epoch 100 Loss 1.0054864684740703
[Train] epoch 100 Batch 1 Loss 1.1648470759391785
[Train] epoch 100 Batch 3 Loss 1.4695444107055664
[Train] epoch 100 Batch 5 Loss 1.2556065022945404
[Train] epoch 100 Batch 7 Loss 1.1263521313667297
[Train] epoch 100 Batch 9 Loss 1.4817771911621094
[Train] epoch 100 Batch 11 Loss 1.1666780710220337
[Train] epoch 101 Batch 1 Loss 1.1212512254714966
[Train] epoch 101 Batch 3 Loss 1.4394755363464355
[Train] epoch 101 Batch 5 Loss 1.2710040807724
[Train] epoch 101 Batch 7 Loss 1.0488665401935577
[Train] epoch 101 Batch 9 Loss 1.4703789949417114
[Train] epoch 101 Batch 11 Loss 1.3701789379119873
[Train] epoch 102 Batch 1 Loss 1.067325234413147
[Train] epoch 102 Batch 3 Loss 1.6676688194274902
[Train] epoch 102 Batch 5 Loss 0.866521954536438
[Train] epoch 102 Batch 7 Loss 0.9959670305252075
[Train] epoch 102 Batch 9 Loss 1.6410623788833618
[Train] epoch 102 Batch 11 Loss 1.2789074182510376
[Train] epoch 103 Batch 1 Loss 1.1933012008666992
[Train] epoch 103 Batch 3 Loss 1.3073285818099976
[Train] epoch 103 Batch 5 Loss 1.1139432787895203
[Train] epoch 103 Batch 7 Loss 1.0441206693649292
[Train] epoch 103 Batch 9 Loss 1.438883364200592
[Train] epoch 103 Batch 11 Loss 1.4437341690063477
[Train] epoch 104 Batch 1 Loss 1.2636403143405914
[Train] epoch 104 Batch 3 Loss 1.2359302043914795
[Train] epoch 104 Batch 5 Loss 0.9113896489143372
[Train] epoch 104 Batch 7 Loss 1.3007936477661133
[Train] epoch 104 Batch 9 Loss 1.270220160484314
[Train] epoch 104 Batch 11 Loss 1.6407473683357239
[TEST] epoch 105 Loss 0.9236119588216146
[Train] epoch 105 Batch 1 Loss 1.4428337812423706
[Train] epoch 105 Batch 3 Loss 0.8018132150173187
[Train] epoch 105 Batch 5 Loss 1.3463351726531982
[Train] epoch 105 Batch 7 Loss 0.9909629225730896
[Train] epoch 105 Batch 9 Loss 1.5288766026496887
[Train] epoch 105 Batch 11 Loss 1.4201212525367737
[Train] epoch 106 Batch 1 Loss 1.0461004376411438
[Train] epoch 106 Batch 3 Loss 1.1348040103912354
[Train] epoch 106 Batch 5 Loss 1.4536834955215454
[Train] epoch 106 Batch 7 Loss 1.0589938163757324
[Train] epoch 106 Batch 9 Loss 1.133706271648407
[Train] epoch 106 Batch 11 Loss 1.685874581336975
[Train] epoch 107 Batch 1 Loss 1.5604617595672607
[Train] epoch 107 Batch 3 Loss 0.9553278386592865
[Train] epoch 107 Batch 5 Loss 1.2257364392280579
[Train] epoch 107 Batch 7 Loss 1.4341064095497131
[Train] epoch 107 Batch 9 Loss 1.34995037317276
[Train] epoch 107 Batch 11 Loss 1.0273533463478088
[Train] epoch 108 Batch 1 Loss 1.1749987304210663
[Train] epoch 108 Batch 3 Loss 0.9468933641910553
[Train] epoch 108 Batch 5 Loss 1.3172866106033325
[Train] epoch 108 Batch 7 Loss 1.481918752193451
[Train] epoch 108 Batch 9 Loss 1.1643583476543427
[Train] epoch 108 Batch 11 Loss 1.43839430809021
[Train] epoch 109 Batch 1 Loss 1.1747060120105743
[Train] epoch 109 Batch 3 Loss 1.422373652458191
[Train] epoch 109 Batch 5 Loss 0.9099559187889099
[Train] epoch 109 Batch 7 Loss 1.1406182646751404
[Train] epoch 109 Batch 9 Loss 1.432928204536438
[Train] epoch 109 Batch 11 Loss 1.5540823340415955
[TEST] epoch 110 Loss 1.0516090393066406
[Train] epoch 110 Batch 1 Loss 1.3812756538391113
[Train] epoch 110 Batch 3 Loss 1.4232044219970703
[Train] epoch 110 Batch 5 Loss 0.9932940006256104
[Train] epoch 110 Batch 7 Loss 1.4785205721855164
[Train] epoch 110 Batch 9 Loss 0.9470106065273285
[Train] epoch 110 Batch 11 Loss 1.258887767791748
[Train] epoch 111 Batch 1 Loss 1.316325604915619
[Train] epoch 111 Batch 3 Loss 1.2262970805168152
[Train] epoch 111 Batch 5 Loss 1.2589010000228882
[Train] epoch 111 Batch 7 Loss 1.0176465809345245
[Train] epoch 111 Batch 9 Loss 1.500403881072998
[Train] epoch 111 Batch 11 Loss 1.3816750049591064
[Train] epoch 112 Batch 1 Loss 1.2092466354370117
[Train] epoch 112 Batch 3 Loss 1.1948706805706024
[Train] epoch 112 Batch 5 Loss 1.400880217552185
[Train] epoch 112 Batch 7 Loss 1.5813379883766174
[Train] epoch 112 Batch 9 Loss 0.9168318510055542
[Train] epoch 112 Batch 11 Loss 1.2809576988220215
[Train] epoch 113 Batch 1 Loss 1.5492467880249023
[Train] epoch 113 Batch 3 Loss 1.5642426013946533
[Train] epoch 113 Batch 5 Loss 1.3955339193344116
[Train] epoch 113 Batch 7 Loss 1.01947483420372
[Train] epoch 113 Batch 9 Loss 0.9845757186412811
[Train] epoch 113 Batch 11 Loss 1.187466561794281
[Train] epoch 114 Batch 1 Loss 1.0127865970134735
[Train] epoch 114 Batch 3 Loss 1.303833544254303
[Train] epoch 114 Batch 5 Loss 1.3731342554092407
[Train] epoch 114 Batch 7 Loss 1.0277548432350159
[Train] epoch 114 Batch 9 Loss 1.3828465342521667
[Train] epoch 114 Batch 11 Loss 1.5480352640151978
[TEST] epoch 115 Loss 1.071459412574768
[Train] epoch 115 Batch 1 Loss 1.2962181568145752
[Train] epoch 115 Batch 3 Loss 1.1538838744163513
[Train] epoch 115 Batch 5 Loss 1.7381311058998108
[Train] epoch 115 Batch 7 Loss 1.391161859035492
[Train] epoch 115 Batch 9 Loss 1.213630497455597
[Train] epoch 115 Batch 11 Loss 0.784551203250885
[Train] epoch 116 Batch 1 Loss 1.2184768319129944
[Train] epoch 116 Batch 3 Loss 1.036251425743103
[Train] epoch 116 Batch 5 Loss 1.1716407537460327
[Train] epoch 116 Batch 7 Loss 1.5675466060638428
[Train] epoch 116 Batch 9 Loss 1.3700060844421387
[Train] epoch 116 Batch 11 Loss 1.1353825330734253
[Train] epoch 117 Batch 1 Loss 1.0910017490386963
[Train] epoch 117 Batch 3 Loss 1.2922945618629456
[Train] epoch 117 Batch 5 Loss 1.3787979483604431
[Train] epoch 117 Batch 7 Loss 1.1221602857112885
[Train] epoch 117 Batch 9 Loss 1.4298267364501953
[Train] epoch 117 Batch 11 Loss 1.1741414666175842
[Train] epoch 118 Batch 1 Loss 1.3969380259513855
[Train] epoch 118 Batch 3 Loss 0.9951095581054688
[Train] epoch 118 Batch 5 Loss 1.464213490486145
[Train] epoch 118 Batch 7 Loss 0.7507939040660858
[Train] epoch 118 Batch 9 Loss 1.3380413055419922
[Train] epoch 118 Batch 11 Loss 1.5025036334991455
[Train] epoch 119 Batch 1 Loss 1.2023658156394958
[Train] epoch 119 Batch 3 Loss 1.1759654879570007
[Train] epoch 119 Batch 5 Loss 1.2948740720748901
[Train] epoch 119 Batch 7 Loss 1.3626269698143005
[Train] epoch 119 Batch 9 Loss 1.3187521696090698
[Train] epoch 119 Batch 11 Loss 1.269206941127777
[TEST] epoch 120 Loss 1.0389575163523357
[Train] epoch 120 Batch 1 Loss 1.1001518964767456
[Train] epoch 120 Batch 3 Loss 1.5242056250572205
[Train] epoch 120 Batch 5 Loss 1.4846883416175842
[Train] epoch 120 Batch 7 Loss 1.124111533164978
[Train] epoch 120 Batch 9 Loss 0.9610346555709839
[Train] epoch 120 Batch 11 Loss 1.2604897618293762
[Train] epoch 121 Batch 1 Loss 1.324796199798584
[Train] epoch 121 Batch 3 Loss 1.249645173549652
[Train] epoch 121 Batch 5 Loss 1.2214107513427734
[Train] epoch 121 Batch 7 Loss 1.2175180912017822
[Train] epoch 121 Batch 9 Loss 0.9977381229400635
[Train] epoch 121 Batch 11 Loss 1.4324663877487183
[Train] epoch 122 Batch 1 Loss 0.9721284806728363
[Train] epoch 122 Batch 3 Loss 1.4033493995666504
[Train] epoch 122 Batch 5 Loss 1.2401137351989746
[Train] epoch 122 Batch 7 Loss 0.9947748780250549
[Train] epoch 122 Batch 9 Loss 1.4527140259742737
[Train] epoch 122 Batch 11 Loss 1.378713071346283
[Train] epoch 123 Batch 1 Loss 1.4941759705543518
[Train] epoch 123 Batch 3 Loss 1.169191062450409
[Train] epoch 123 Batch 5 Loss 0.7001351118087769
[Train] epoch 123 Batch 7 Loss 1.5379899144172668
[Train] epoch 123 Batch 9 Loss 1.0374129712581635
[Train] epoch 123 Batch 11 Loss 1.6594074368476868
[Train] epoch 124 Batch 1 Loss 1.1735270619392395
[Train] epoch 124 Batch 3 Loss 1.4115630388259888
[Train] epoch 124 Batch 5 Loss 1.386309266090393
[Train] epoch 124 Batch 7 Loss 1.1834094524383545
[Train] epoch 124 Batch 9 Loss 1.324700951576233
[Train] epoch 124 Batch 11 Loss 0.975376546382904
[TEST] epoch 125 Loss 1.0103861689567566
[Train] epoch 125 Batch 1 Loss 1.154307246208191
[Train] epoch 125 Batch 3 Loss 1.0295469760894775
[Train] epoch 125 Batch 5 Loss 0.9459148645401001
[Train] epoch 125 Batch 7 Loss 1.6972538232803345
[Train] epoch 125 Batch 9 Loss 1.2837658524513245
[Train] epoch 125 Batch 11 Loss 1.4143806099891663
[Train] epoch 126 Batch 1 Loss 0.7398703992366791
[Train] epoch 126 Batch 3 Loss 1.2279735803604126
[Train] epoch 126 Batch 5 Loss 1.2142688632011414
[Train] epoch 126 Batch 7 Loss 1.4997098445892334
[Train] epoch 126 Batch 9 Loss 1.3725441694259644
[Train] epoch 126 Batch 11 Loss 1.4610590934753418
[Train] epoch 127 Batch 1 Loss 1.1050183773040771
[Train] epoch 127 Batch 3 Loss 1.2544037699699402
[Train] epoch 127 Batch 5 Loss 1.2472133040428162
[Train] epoch 127 Batch 7 Loss 1.523111343383789
[Train] epoch 127 Batch 9 Loss 1.2630212903022766
[Train] epoch 127 Batch 11 Loss 1.2432763576507568
[Train] epoch 128 Batch 1 Loss 1.3256217241287231
[Train] epoch 128 Batch 3 Loss 0.8523956537246704
[Train] epoch 128 Batch 5 Loss 1.2019357085227966
[Train] epoch 128 Batch 7 Loss 1.2870274782180786
[Train] epoch 128 Batch 9 Loss 1.2977769374847412
[Train] epoch 128 Batch 11 Loss 1.535632073879242
[Train] epoch 129 Batch 1 Loss 1.493583858013153
[Train] epoch 129 Batch 3 Loss 1.019299864768982
[Train] epoch 129 Batch 5 Loss 1.204549789428711
[Train] epoch 129 Batch 7 Loss 1.2730702757835388
[Train] epoch 129 Batch 9 Loss 1.2065976560115814
[Train] epoch 129 Batch 11 Loss 1.4802254438400269
[TEST] epoch 130 Loss 0.997550348440806
[Train] epoch 130 Batch 1 Loss 1.4041017293930054
[Train] epoch 130 Batch 3 Loss 1.3644115924835205
[Train] epoch 130 Batch 5 Loss 1.0688322186470032
[Train] epoch 130 Batch 7 Loss 1.2182831168174744
[Train] epoch 130 Batch 9 Loss 1.2846653461456299
[Train] epoch 130 Batch 11 Loss 1.1715354323387146
[Train] epoch 131 Batch 1 Loss 1.1094819903373718
[Train] epoch 131 Batch 3 Loss 0.8654751181602478
[Train] epoch 131 Batch 5 Loss 1.4709002375602722
[Train] epoch 131 Batch 7 Loss 1.1113104224205017
[Train] epoch 131 Batch 9 Loss 1.4764944314956665
[Train] epoch 131 Batch 11 Loss 1.4728004932403564
[Train] epoch 132 Batch 1 Loss 1.403857171535492
[Train] epoch 132 Batch 3 Loss 1.3793801665306091
[Train] epoch 132 Batch 5 Loss 1.2557626962661743
[Train] epoch 132 Batch 7 Loss 1.2183123230934143
[Train] epoch 132 Batch 9 Loss 0.9959543943405151
[Train] epoch 132 Batch 11 Loss 1.2544378638267517
[Train] epoch 133 Batch 1 Loss 1.4487443566322327
[Train] epoch 133 Batch 3 Loss 1.1413870453834534
[Train] epoch 133 Batch 5 Loss 1.3434112071990967
[Train] epoch 133 Batch 7 Loss 0.8341533690690994
[Train] epoch 133 Batch 9 Loss 1.18026202917099
[Train] epoch 133 Batch 11 Loss 1.525834321975708
[Train] epoch 134 Batch 1 Loss 1.0907313823699951
[Train] epoch 134 Batch 3 Loss 1.2437233328819275
[Train] epoch 134 Batch 5 Loss 1.2703667283058167
[Train] epoch 134 Batch 7 Loss 1.356389582157135
[Train] epoch 134 Batch 9 Loss 1.2684631943702698
[Train] epoch 134 Batch 11 Loss 1.2535931468009949
[TEST] epoch 135 Loss 1.0144327680269878
[Train] epoch 135 Batch 1 Loss 1.4798126220703125
[Train] epoch 135 Batch 3 Loss 1.206926167011261
[Train] epoch 135 Batch 5 Loss 0.9024414420127869
[Train] epoch 135 Batch 7 Loss 1.2686901092529297
[Train] epoch 135 Batch 9 Loss 1.4000560641288757
[Train] epoch 135 Batch 11 Loss 1.2039371132850647
[Train] epoch 136 Batch 1 Loss 0.923418253660202
[Train] epoch 136 Batch 3 Loss 1.504372477531433
[Train] epoch 136 Batch 5 Loss 1.2959198355674744
[Train] epoch 136 Batch 7 Loss 1.3245015144348145
[Train] epoch 136 Batch 9 Loss 1.2510563731193542
[Train] epoch 136 Batch 11 Loss 1.5882195234298706
[Train] epoch 137 Batch 1 Loss 1.1536282896995544
[Train] epoch 137 Batch 3 Loss 1.2067763209342957
[Train] epoch 137 Batch 5 Loss 1.2479497194290161
[Train] epoch 137 Batch 7 Loss 1.3161776065826416
[Train] epoch 137 Batch 9 Loss 1.2750288248062134
[Train] epoch 137 Batch 11 Loss 1.3344008326530457
[Train] epoch 138 Batch 1 Loss 1.2723060250282288
[Train] epoch 138 Batch 3 Loss 1.4489745497703552
[Train] epoch 138 Batch 5 Loss 0.8195109069347382
[Train] epoch 138 Batch 7 Loss 1.2654010653495789
[Train] epoch 138 Batch 9 Loss 1.119194507598877
[Train] epoch 138 Batch 11 Loss 1.5915627479553223
[Train] epoch 139 Batch 1 Loss 1.1085470914840698
[Train] epoch 139 Batch 3 Loss 1.2481211423873901
[Train] epoch 139 Batch 5 Loss 1.2680752277374268
[Train] epoch 139 Batch 7 Loss 1.436207890510559
[Train] epoch 139 Batch 9 Loss 1.2396481037139893
[Train] epoch 139 Batch 11 Loss 1.2295001745224
[TEST] epoch 140 Loss 1.0200233856836955
[Train] epoch 140 Batch 1 Loss 1.2267004251480103
[Train] epoch 140 Batch 3 Loss 1.20458322763443
[Train] epoch 140 Batch 5 Loss 1.2993807196617126
[Train] epoch 140 Batch 7 Loss 1.2824398279190063
[Train] epoch 140 Batch 9 Loss 1.2598393559455872
[Train] epoch 140 Batch 11 Loss 1.2093002796173096
[Train] epoch 141 Batch 1 Loss 1.1830721497535706
[Train] epoch 141 Batch 3 Loss 1.435643196105957
[Train] epoch 141 Batch 5 Loss 1.415170431137085
[Train] epoch 141 Batch 7 Loss 0.7225309312343597
[Train] epoch 141 Batch 9 Loss 1.2390782237052917
[Train] epoch 141 Batch 11 Loss 1.4991613626480103
[Train] epoch 142 Batch 1 Loss 0.8138072639703751
[Train] epoch 142 Batch 3 Loss 1.3875512480735779
[Train] epoch 142 Batch 5 Loss 1.1504742503166199
[Train] epoch 142 Batch 7 Loss 1.1259453892707825
[Train] epoch 142 Batch 9 Loss 1.4147956371307373
[Train] epoch 142 Batch 11 Loss 1.5742110013961792
[Train] epoch 143 Batch 1 Loss 1.0855635404586792
[Train] epoch 143 Batch 3 Loss 1.349439024925232
[Train] epoch 143 Batch 5 Loss 1.271763265132904
[Train] epoch 143 Batch 7 Loss 1.2377382516860962
[Train] epoch 143 Batch 9 Loss 1.3117136359214783
[Train] epoch 143 Batch 11 Loss 1.2428786754608154
[Train] epoch 144 Batch 1 Loss 1.0745143592357635
[Train] epoch 144 Batch 3 Loss 1.4387345910072327
[Train] epoch 144 Batch 5 Loss 1.5498886704444885
[Train] epoch 144 Batch 7 Loss 1.3439670205116272
[Train] epoch 144 Batch 9 Loss 1.044414222240448
[Train] epoch 144 Batch 11 Loss 1.0590507984161377
[TEST] epoch 145 Loss 0.9697615702946981
[Train] epoch 145 Batch 1 Loss 1.3769006729125977
[Train] epoch 145 Batch 3 Loss 1.442408800125122
[Train] epoch 145 Batch 5 Loss 1.4471309185028076
[Train] epoch 145 Batch 7 Loss 0.974657267332077
[Train] epoch 145 Batch 9 Loss 1.3441567420959473
[Train] epoch 145 Batch 11 Loss 0.9145534038543701
[Train] epoch 146 Batch 1 Loss 1.2029196619987488
[Train] epoch 146 Batch 3 Loss 1.465139925479889
[Train] epoch 146 Batch 5 Loss 0.8408437371253967
[Train] epoch 146 Batch 7 Loss 1.155031979084015
[Train] epoch 146 Batch 9 Loss 1.511933982372284
[Train] epoch 146 Batch 11 Loss 1.381223976612091
[Train] epoch 147 Batch 1 Loss 1.3383864164352417
[Train] epoch 147 Batch 3 Loss 0.8447370529174805
[Train] epoch 147 Batch 5 Loss 1.4594866037368774
[Train] epoch 147 Batch 7 Loss 1.4806034564971924
[Train] epoch 147 Batch 9 Loss 1.130293369293213
[Train] epoch 147 Batch 11 Loss 1.2336077690124512
[Train] epoch 148 Batch 1 Loss 1.2458415627479553
[Train] epoch 148 Batch 3 Loss 1.4327039122581482
[Train] epoch 148 Batch 5 Loss 0.9818228185176849
[Train] epoch 148 Batch 7 Loss 1.2095555067062378
[Train] epoch 148 Batch 9 Loss 1.1964452862739563
[Train] epoch 148 Batch 11 Loss 1.4013316631317139
[Train] epoch 149 Batch 1 Loss 1.5272769927978516
[Train] epoch 149 Batch 3 Loss 1.3866345882415771
[Train] epoch 149 Batch 5 Loss 1.4342128038406372
[Train] epoch 149 Batch 7 Loss 1.019583284854889
[Train] epoch 149 Batch 9 Loss 1.2031239867210388
[Train] epoch 149 Batch 11 Loss 1.042948603630066
[TEST] epoch 150 Loss 0.987626870473226
[Train] epoch 150 Batch 1 Loss 1.3353313207626343
[Train] epoch 150 Batch 3 Loss 1.2583740949630737
[Train] epoch 150 Batch 5 Loss 1.1119828820228577
[Train] epoch 150 Batch 7 Loss 1.6455934047698975
[Train] epoch 150 Batch 9 Loss 1.1277246475219727
[Train] epoch 150 Batch 11 Loss 1.2009307742118835
[Train] epoch 151 Batch 1 Loss 1.1212508976459503
[Train] epoch 151 Batch 3 Loss 1.3649015426635742
[Train] epoch 151 Batch 5 Loss 0.9487753808498383
[Train] epoch 151 Batch 7 Loss 1.4899908900260925
[Train] epoch 151 Batch 9 Loss 1.1271546185016632
[Train] epoch 151 Batch 11 Loss 1.422428011894226
[Train] epoch 152 Batch 1 Loss 0.963493824005127
[Train] epoch 152 Batch 3 Loss 1.2461740970611572
[Train] epoch 152 Batch 5 Loss 1.254453718662262
[Train] epoch 152 Batch 7 Loss 1.3745189905166626
[Train] epoch 152 Batch 9 Loss 1.3680917024612427
[Train] epoch 152 Batch 11 Loss 1.2934455871582031
[Train] epoch 153 Batch 1 Loss 1.1715669929981232
[Train] epoch 153 Batch 3 Loss 1.2646759152412415
[Train] epoch 153 Batch 5 Loss 1.392814576625824
[Train] epoch 153 Batch 7 Loss 1.1157615780830383
[Train] epoch 153 Batch 9 Loss 0.9341833591461182
[Train] epoch 153 Batch 11 Loss 1.6247010231018066
[Train] epoch 154 Batch 1 Loss 1.1891428232192993
[Train] epoch 154 Batch 3 Loss 1.1041765660047531
[Train] epoch 154 Batch 5 Loss 0.9530203342437744
[Train] epoch 154 Batch 7 Loss 1.3113957643508911
[Train] epoch 154 Batch 9 Loss 1.469997525215149
[Train] epoch 154 Batch 11 Loss 1.6301923394203186
[TEST] epoch 155 Loss 1.130036363999049
[Train] epoch 155 Batch 1 Loss 1.2601605653762817
[Train] epoch 155 Batch 3 Loss 0.8266996145248413
[Train] epoch 155 Batch 5 Loss 1.137900710105896
[Train] epoch 155 Batch 7 Loss 1.4199671745300293
[Train] epoch 155 Batch 9 Loss 1.4572710990905762
[Train] epoch 155 Batch 11 Loss 1.3677582740783691
[Train] epoch 156 Batch 1 Loss 1.2041751742362976
[Train] epoch 156 Batch 3 Loss 0.8275483846664429
[Train] epoch 156 Batch 5 Loss 1.2678548395633698
[Train] epoch 156 Batch 7 Loss 1.5510869026184082
[Train] epoch 156 Batch 9 Loss 1.4268928170204163
[Train] epoch 156 Batch 11 Loss 1.1702066659927368
[Train] epoch 157 Batch 1 Loss 1.440409004688263
[Train] epoch 157 Batch 3 Loss 1.159127652645111
[Train] epoch 157 Batch 5 Loss 1.328803300857544
[Train] epoch 157 Batch 7 Loss 1.0265620946884155
[Train] epoch 157 Batch 9 Loss 1.1966491639614105
[Train] epoch 157 Batch 11 Loss 1.4651477932929993
[Train] epoch 158 Batch 1 Loss 1.245958685874939
[Train] epoch 158 Batch 3 Loss 1.4453486800193787
[Train] epoch 158 Batch 5 Loss 1.1532464623451233
[Train] epoch 158 Batch 7 Loss 1.1325453519821167
[Train] epoch 158 Batch 9 Loss 1.6018540859222412
[Train] epoch 158 Batch 11 Loss 0.9137036502361298
[Train] epoch 159 Batch 1 Loss 0.9637863039970398
[Train] epoch 159 Batch 3 Loss 1.4989328384399414
[Train] epoch 159 Batch 5 Loss 1.1736270189285278
[Train] epoch 159 Batch 7 Loss 1.2066324055194855
[Train] epoch 159 Batch 9 Loss 1.4622533917427063
[Train] epoch 159 Batch 11 Loss 1.174814522266388
[TEST] epoch 160 Loss 0.9888063271840414
[Train] epoch 160 Batch 1 Loss 1.4085360169410706
[Train] epoch 160 Batch 3 Loss 1.2232263088226318
[Train] epoch 160 Batch 5 Loss 0.9068623483181
[Train] epoch 160 Batch 7 Loss 1.4038496017456055
[Train] epoch 160 Batch 9 Loss 1.4178706407546997
[Train] epoch 160 Batch 11 Loss 1.0645825862884521
[Train] epoch 161 Batch 1 Loss 1.2192810475826263
[Train] epoch 161 Batch 3 Loss 1.1104546785354614
[Train] epoch 161 Batch 5 Loss 1.342049479484558
[Train] epoch 161 Batch 7 Loss 1.421184480190277
[Train] epoch 161 Batch 9 Loss 1.037983000278473
[Train] epoch 161 Batch 11 Loss 1.369024395942688
[Train] epoch 162 Batch 1 Loss 1.4569903016090393
[Train] epoch 162 Batch 3 Loss 1.2384430766105652
[Train] epoch 162 Batch 5 Loss 1.5571449995040894
[Train] epoch 162 Batch 7 Loss 1.2366440892219543
[Train] epoch 162 Batch 9 Loss 1.2535969018936157
[Train] epoch 162 Batch 11 Loss 0.9761683940887451
[Train] epoch 163 Batch 1 Loss 1.4071771502494812
[Train] epoch 163 Batch 3 Loss 1.1842834651470184
[Train] epoch 163 Batch 5 Loss 1.544093668460846
[Train] epoch 163 Batch 7 Loss 0.9639921486377716
[Train] epoch 163 Batch 9 Loss 1.1668581366539001
[Train] epoch 163 Batch 11 Loss 1.1913792788982391
[Train] epoch 164 Batch 1 Loss 1.1481614708900452
[Train] epoch 164 Batch 3 Loss 1.0749412775039673
[Train] epoch 164 Batch 5 Loss 1.1345320343971252
[Train] epoch 164 Batch 7 Loss 1.2752520442008972
[Train] epoch 164 Batch 9 Loss 1.4626222252845764
[Train] epoch 164 Batch 11 Loss 1.5034465789794922
[TEST] epoch 165 Loss 1.0497936805089314
[Train] epoch 165 Batch 1 Loss 1.2050555646419525
[Train] epoch 165 Batch 3 Loss 1.0528534054756165
[Train] epoch 165 Batch 5 Loss 1.4072980284690857
[Train] epoch 165 Batch 7 Loss 1.2447027564048767
[Train] epoch 165 Batch 9 Loss 1.1571887731552124
[Train] epoch 165 Batch 11 Loss 1.3691456317901611
[Train] epoch 166 Batch 1 Loss 0.803246796131134
[Train] epoch 166 Batch 3 Loss 1.3028902411460876
[Train] epoch 166 Batch 5 Loss 1.5554795265197754
[Train] epoch 166 Batch 7 Loss 1.37721586227417
[Train] epoch 166 Batch 9 Loss 1.3829272389411926
[Train] epoch 166 Batch 11 Loss 0.9894377589225769
[Train] epoch 167 Batch 1 Loss 1.198690116405487
[Train] epoch 167 Batch 3 Loss 1.4936360716819763
[Train] epoch 167 Batch 5 Loss 1.3725277185440063
[Train] epoch 167 Batch 7 Loss 1.0301171839237213
[Train] epoch 167 Batch 9 Loss 1.4035964012145996
[Train] epoch 167 Batch 11 Loss 1.0377283096313477
[Train] epoch 168 Batch 1 Loss 1.1250738501548767
[Train] epoch 168 Batch 3 Loss 1.4256929159164429
[Train] epoch 168 Batch 5 Loss 1.2027447819709778
[Train] epoch 168 Batch 7 Loss 1.4600146412849426
[Train] epoch 168 Batch 9 Loss 0.9885150790214539
[Train] epoch 168 Batch 11 Loss 1.2672354578971863
[Train] epoch 169 Batch 1 Loss 1.21502286195755
[Train] epoch 169 Batch 3 Loss 1.0345281958580017
[Train] epoch 169 Batch 5 Loss 1.331720769405365
[Train] epoch 169 Batch 7 Loss 1.6367058753967285
[Train] epoch 169 Batch 9 Loss 1.1567174196243286
[Train] epoch 169 Batch 11 Loss 1.2082695364952087
[TEST] epoch 170 Loss 1.0380095442136128
[Train] epoch 170 Batch 1 Loss 1.3095735907554626
[Train] epoch 170 Batch 3 Loss 1.0072590112686157
[Train] epoch 170 Batch 5 Loss 1.3140226006507874
[Train] epoch 170 Batch 7 Loss 1.1668032109737396
[Train] epoch 170 Batch 9 Loss 1.2351425290107727
[Train] epoch 170 Batch 11 Loss 1.485681176185608
[Train] epoch 171 Batch 1 Loss 1.2038782835006714
[Train] epoch 171 Batch 3 Loss 1.2909507155418396
[Train] epoch 171 Batch 5 Loss 1.151463359594345
[Train] epoch 171 Batch 7 Loss 0.901118665933609
[Train] epoch 171 Batch 9 Loss 1.4425049424171448
[Train] epoch 171 Batch 11 Loss 1.4836864471435547
[Train] epoch 172 Batch 1 Loss 1.3496089577674866
[Train] epoch 172 Batch 3 Loss 1.4179267287254333
[Train] epoch 172 Batch 5 Loss 0.9706069231033325
[Train] epoch 172 Batch 7 Loss 1.1463016271591187
[Train] epoch 172 Batch 9 Loss 1.5629178881645203
[Train] epoch 172 Batch 11 Loss 1.001940906047821
[Train] epoch 173 Batch 1 Loss 1.2494943737983704
[Train] epoch 173 Batch 3 Loss 1.1585177183151245
[Train] epoch 173 Batch 5 Loss 1.405353605747223
[Train] epoch 173 Batch 7 Loss 1.2458452582359314
[Train] epoch 173 Batch 9 Loss 1.4007394313812256
[Train] epoch 173 Batch 11 Loss 1.0034824013710022
[Train] epoch 174 Batch 1 Loss 1.0566877126693726
[Train] epoch 174 Batch 3 Loss 1.2666746377944946
[Train] epoch 174 Batch 5 Loss 1.0984580516815186
[Train] epoch 174 Batch 7 Loss 1.4501302242279053
[Train] epoch 174 Batch 9 Loss 1.3364675045013428
[Train] epoch 174 Batch 11 Loss 1.2732449173927307
[TEST] epoch 175 Loss 1.0197516083717346
[Train] epoch 175 Batch 1 Loss 1.4282575249671936
[Train] epoch 175 Batch 3 Loss 1.1713184714317322
[Train] epoch 175 Batch 5 Loss 1.2717920541763306
[Train] epoch 175 Batch 7 Loss 1.103683590888977
[Train] epoch 175 Batch 9 Loss 1.453331708908081
[Train] epoch 175 Batch 11 Loss 1.208604097366333
[Train] epoch 176 Batch 1 Loss 1.4392768144607544
[Train] epoch 176 Batch 3 Loss 1.146311342716217
[Train] epoch 176 Batch 5 Loss 1.1348878145217896
[Train] epoch 176 Batch 7 Loss 1.4685568809509277
[Train] epoch 176 Batch 9 Loss 1.5446916818618774
[Train] epoch 176 Batch 11 Loss 0.7604734003543854
[Train] epoch 177 Batch 1 Loss 1.4414327144622803
[Train] epoch 177 Batch 3 Loss 1.162615716457367
[Train] epoch 177 Batch 5 Loss 1.1494131088256836
[Train] epoch 177 Batch 7 Loss 1.5862081050872803
[Train] epoch 177 Batch 9 Loss 1.0860612988471985
[Train] epoch 177 Batch 11 Loss 1.0250994563102722
[Train] epoch 178 Batch 1 Loss 1.4250091314315796
[Train] epoch 178 Batch 3 Loss 1.4295870065689087
[Train] epoch 178 Batch 5 Loss 1.0169099867343903
[Train] epoch 178 Batch 7 Loss 0.9756472110748291
[Train] epoch 178 Batch 9 Loss 1.4084985256195068
[Train] epoch 178 Batch 11 Loss 1.26961088180542
[Train] epoch 179 Batch 1 Loss 1.3969458937644958
[Train] epoch 179 Batch 3 Loss 1.1668162643909454
[Train] epoch 179 Batch 5 Loss 1.1612772345542908
[Train] epoch 179 Batch 7 Loss 1.2325136065483093
[Train] epoch 179 Batch 9 Loss 1.2972787618637085
[Train] epoch 179 Batch 11 Loss 1.197031319141388
[TEST] epoch 180 Loss 0.9786855975786845
[Train] epoch 180 Batch 1 Loss 1.1998883485794067
[Train] epoch 180 Batch 3 Loss 1.435496211051941
[Train] epoch 180 Batch 5 Loss 1.2243144512176514
[Train] epoch 180 Batch 7 Loss 1.1186094880104065
[Train] epoch 180 Batch 9 Loss 1.2164770364761353
[Train] epoch 180 Batch 11 Loss 1.3555887341499329
[Train] epoch 181 Batch 1 Loss 0.9953334927558899
[Train] epoch 181 Batch 3 Loss 1.321628898382187
[Train] epoch 181 Batch 5 Loss 1.2324295043945312
[Train] epoch 181 Batch 7 Loss 1.1992392539978027
[Train] epoch 181 Batch 9 Loss 1.4005448818206787
[Train] epoch 181 Batch 11 Loss 1.3272212743759155
[Train] epoch 182 Batch 1 Loss 1.4057145714759827
[Train] epoch 182 Batch 3 Loss 1.097409963607788
[Train] epoch 182 Batch 5 Loss 1.4042710661888123
[Train] epoch 182 Batch 7 Loss 1.3204891681671143
[Train] epoch 182 Batch 9 Loss 1.5290737748146057
[Train] epoch 182 Batch 11 Loss 0.7550700306892395
[Train] epoch 183 Batch 1 Loss 1.6019989252090454
[Train] epoch 183 Batch 3 Loss 1.069298803806305
[Train] epoch 183 Batch 5 Loss 1.362356185913086
[Train] epoch 183 Batch 7 Loss 1.2650083303451538
[Train] epoch 183 Batch 9 Loss 1.1808792352676392
[Train] epoch 183 Batch 11 Loss 1.1931306719779968
[Train] epoch 184 Batch 1 Loss 1.177684336900711
[Train] epoch 184 Batch 3 Loss 1.1510857939720154
[Train] epoch 184 Batch 5 Loss 1.164001315832138
[Train] epoch 184 Batch 7 Loss 1.4690186381340027
[Train] epoch 184 Batch 9 Loss 1.2423461079597473
[Train] epoch 184 Batch 11 Loss 1.2730176448822021
[TEST] epoch 185 Loss 1.0280099312464397
[Train] epoch 185 Batch 1 Loss 1.4231606125831604
[Train] epoch 185 Batch 3 Loss 1.2788790464401245
[Train] epoch 185 Batch 5 Loss 1.2962347269058228
[Train] epoch 185 Batch 7 Loss 1.0284115970134735
[Train] epoch 185 Batch 9 Loss 1.4810843467712402
[Train] epoch 185 Batch 11 Loss 0.9765541553497314
[Train] epoch 186 Batch 1 Loss 0.8272069096565247
[Train] epoch 186 Batch 3 Loss 1.362231194972992
[Train] epoch 186 Batch 5 Loss 1.4138147830963135
[Train] epoch 186 Batch 7 Loss 1.3082727789878845
[Train] epoch 186 Batch 9 Loss 1.3855701088905334
[Train] epoch 186 Batch 11 Loss 1.1757362484931946
[Train] epoch 187 Batch 1 Loss 1.265740156173706
[Train] epoch 187 Batch 3 Loss 1.2411185503005981
[Train] epoch 187 Batch 5 Loss 0.817229151725769
[Train] epoch 187 Batch 7 Loss 1.4092055559158325
[Train] epoch 187 Batch 9 Loss 1.158387303352356
[Train] epoch 187 Batch 11 Loss 1.5326598286628723
[Train] epoch 188 Batch 1 Loss 1.09971421957016
[Train] epoch 188 Batch 3 Loss 1.5207292437553406
[Train] epoch 188 Batch 5 Loss 1.0076037645339966
[Train] epoch 188 Batch 7 Loss 1.268622636795044
[Train] epoch 188 Batch 9 Loss 1.3705013990402222
[Train] epoch 188 Batch 11 Loss 1.2674720883369446
[Train] epoch 189 Batch 1 Loss 1.4922763109207153
[Train] epoch 189 Batch 3 Loss 1.26492440700531
[Train] epoch 189 Batch 5 Loss 1.270282804965973
[Train] epoch 189 Batch 7 Loss 0.9995622634887695
[Train] epoch 189 Batch 9 Loss 1.1510010957717896
[Train] epoch 189 Batch 11 Loss 1.2742915451526642
[TEST] epoch 190 Loss 1.0283861955006917
[Train] epoch 190 Batch 1 Loss 1.3720107674598694
[Train] epoch 190 Batch 3 Loss 0.9930786490440369
[Train] epoch 190 Batch 5 Loss 1.4354800581932068
[Train] epoch 190 Batch 7 Loss 1.175207793712616
[Train] epoch 190 Batch 9 Loss 1.284738004207611
[Train] epoch 190 Batch 11 Loss 1.1590027213096619
[Train] epoch 191 Batch 1 Loss 1.1977136135101318
[Train] epoch 191 Batch 3 Loss 1.2669743299484253
[Train] epoch 191 Batch 5 Loss 1.4018673300743103
[Train] epoch 191 Batch 7 Loss 0.9717685878276825
[Train] epoch 191 Batch 9 Loss 1.189354807138443
[Train] epoch 191 Batch 11 Loss 1.4108275771141052
[Train] epoch 192 Batch 1 Loss 1.334345281124115
[Train] epoch 192 Batch 3 Loss 1.0168206691741943
[Train] epoch 192 Batch 5 Loss 1.4277973771095276
[Train] epoch 192 Batch 7 Loss 1.1085781753063202
[Train] epoch 192 Batch 9 Loss 1.148902416229248
[Train] epoch 192 Batch 11 Loss 1.482920527458191
[Train] epoch 193 Batch 1 Loss 1.1190289855003357
[Train] epoch 193 Batch 3 Loss 1.1003957390785217
[Train] epoch 193 Batch 5 Loss 1.292333722114563
[Train] epoch 193 Batch 7 Loss 1.4053435325622559
[Train] epoch 193 Batch 9 Loss 1.3789657652378082
[Train] epoch 193 Batch 11 Loss 1.0452176630496979
[Train] epoch 194 Batch 1 Loss 1.0167703330516815
[Train] epoch 194 Batch 3 Loss 1.2552307546138763
[Train] epoch 194 Batch 5 Loss 1.2716310024261475
[Train] epoch 194 Batch 7 Loss 1.3747721910476685
[Train] epoch 194 Batch 9 Loss 1.144605427980423
[Train] epoch 194 Batch 11 Loss 1.146741509437561
[TEST] epoch 195 Loss 1.059416135152181
[Train] epoch 195 Batch 1 Loss 1.2375335097312927
[Train] epoch 195 Batch 3 Loss 0.8887156844139099
[Train] epoch 195 Batch 5 Loss 1.001745581626892
[Train] epoch 195 Batch 7 Loss 1.0888186693191528
[Train] epoch 195 Batch 9 Loss 1.1790738701820374
[Train] epoch 195 Batch 11 Loss 0.797774463891983
[Train] epoch 196 Batch 1 Loss 0.5726891160011292
[Train] epoch 196 Batch 3 Loss 0.7919222712516785
[Train] epoch 196 Batch 5 Loss 0.7865722477436066
[Train] epoch 196 Batch 7 Loss 1.2394074201583862
[Train] epoch 196 Batch 9 Loss 1.8695494532585144
[Train] epoch 196 Batch 11 Loss 1.1444458067417145
[Train] epoch 197 Batch 1 Loss 1.2217347025871277
[Train] epoch 197 Batch 3 Loss 1.081843614578247
[Train] epoch 197 Batch 5 Loss 1.576185703277588
[Train] epoch 197 Batch 7 Loss 0.9027278423309326
[Train] epoch 197 Batch 9 Loss 1.200046956539154
[Train] epoch 197 Batch 11 Loss 1.9995834827423096
[Train] epoch 198 Batch 1 Loss 1.73470801115036
[Train] epoch 198 Batch 3 Loss 1.1340096592903137
[Train] epoch 198 Batch 5 Loss 1.0514662861824036
[Train] epoch 198 Batch 7 Loss 1.367713302373886
[Train] epoch 198 Batch 9 Loss 1.268536925315857
[Train] epoch 198 Batch 11 Loss 1.2410897016525269
[Train] epoch 199 Batch 1 Loss 1.4385511875152588
[Train] epoch 199 Batch 3 Loss 0.8780409097671509
[Train] epoch 199 Batch 5 Loss 1.1602258682250977
[Train] epoch 199 Batch 7 Loss 1.1026103645563126
[Train] epoch 199 Batch 9 Loss 1.3459064960479736
[Train] epoch 199 Batch 11 Loss 1.7370222806930542
Job end at 2023-04-05 15:40:17
