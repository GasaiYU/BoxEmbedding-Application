Job start at 2023-04-05 15:41:56
Job run at:
   Static hostname: localhost.localdomain
Transient hostname: gpu-a13
         Icon name: computer-server
           Chassis: server
        Machine ID: 5284a7361474481dad97e247a5efb17a
           Boot ID: faf5914b871c4e61827d55c6cc4b8a84
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-1127.13.1.el7.x86_64
      Architecture: x86-64
Have already added /tools/cluster-modulefiles into $MODULEPATH

/usr/bin/gcc
/lustre/S/gaomj/miniconda3/envs/bachelor/bin/python
/tools/cluster-software/python3/python3-3.6.8/bin/python3
############### /home : /home/S/gaomj
Disk quotas for user gaomj (uid 6156): 
     Filesystem   space   quota   limit   grace   files   quota   limit   grace
          /home   4986M  16384M  20480M           24350       0       0        

############### /workspace
Disk quotas for user gaomj (uid 6156): 
     Filesystem   space   quota   limit   grace   files   quota   limit   grace
     /workspace      0K    400G    500G               1       0       0        

############### /lustre
Disk quotas for usr gaomj (uid 6156):
     Filesystem    used   quota   limit   grace   files   quota   limit   grace
        /lustre  9.656G      8T     10T       -  121308  3000000 36000000       -
uid 6156 is using default block quota setting
uid 6156 is using default file quota setting
name, driver_version, power.limit [W]
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
NVIDIA A100-SXM4-40GB, 465.19.01, 300.00 W
Use GPU 0,1,2,3,4,5,6,7
[TEST] epoch 0 Loss 4.894523993134499
[Train] epoch 0 Batch 1 Loss 8.123357772827148
[Train] epoch 0 Batch 3 Loss 0.356770783662796
[Train] epoch 0 Batch 5 Loss 3.2555688619613647
[Train] epoch 0 Batch 7 Loss 1.2043302059173584
[Train] epoch 0 Batch 9 Loss 2.01390278339386
[Train] epoch 0 Batch 11 Loss 1.835720419883728
[Train] epoch 1 Batch 1 Loss 1.260340303182602
[Train] epoch 1 Batch 3 Loss 0.5792677998542786
[Train] epoch 1 Batch 5 Loss 1.9732362627983093
[Train] epoch 1 Batch 7 Loss 1.0713239312171936
[Train] epoch 1 Batch 9 Loss 2.957098960876465
[Train] epoch 1 Batch 11 Loss 1.6758118271827698
[Train] epoch 2 Batch 1 Loss 1.5627145171165466
[Train] epoch 2 Batch 3 Loss 1.0793559849262238
[Train] epoch 2 Batch 5 Loss 1.5945205092430115
[Train] epoch 2 Batch 7 Loss 1.523500144481659
[Train] epoch 2 Batch 9 Loss 0.6605360805988312
[Train] epoch 2 Batch 11 Loss 3.09396231174469
[Train] epoch 3 Batch 1 Loss 1.6022359132766724
[Train] epoch 3 Batch 3 Loss 1.210517406463623
[Train] epoch 3 Batch 5 Loss 1.7449172735214233
[Train] epoch 3 Batch 7 Loss 1.0876476466655731
[Train] epoch 3 Batch 9 Loss 1.8937856554985046
[Train] epoch 3 Batch 11 Loss 1.305614173412323
[Train] epoch 4 Batch 1 Loss 1.5916099846363068
[Train] epoch 4 Batch 3 Loss 1.2311407327651978
[Train] epoch 4 Batch 5 Loss 1.257728934288025
[Train] epoch 4 Batch 7 Loss 1.5250517129898071
[Train] epoch 4 Batch 9 Loss 1.3084444403648376
[Train] epoch 4 Batch 11 Loss 2.045767307281494
[TEST] epoch 5 Loss 1.3681047757466633
[Train] epoch 5 Batch 1 Loss 1.1132852435112
[Train] epoch 5 Batch 3 Loss 1.7871392369270325
[Train] epoch 5 Batch 5 Loss 2.1425695419311523
[Train] epoch 5 Batch 7 Loss 1.5584443807601929
[Train] epoch 5 Batch 9 Loss 1.1544353365898132
[Train] epoch 5 Batch 11 Loss 0.9034743010997772
[Train] epoch 6 Batch 1 Loss 1.122320532798767
[Train] epoch 6 Batch 3 Loss 1.2475157678127289
[Train] epoch 6 Batch 5 Loss 0.8245549947023392
[Train] epoch 6 Batch 7 Loss 2.1487892270088196
[Train] epoch 6 Batch 9 Loss 1.7163618803024292
[Train] epoch 6 Batch 11 Loss 2.4866195917129517
[Train] epoch 7 Batch 1 Loss 1.5700730085372925
[Train] epoch 7 Batch 3 Loss 1.6711816191673279
[Train] epoch 7 Batch 5 Loss 1.3724602460861206
[Train] epoch 7 Batch 7 Loss 1.7428449988365173
[Train] epoch 7 Batch 9 Loss 1.4602128267288208
[Train] epoch 7 Batch 11 Loss 1.1294869184494019
[Train] epoch 8 Batch 1 Loss 1.3355006575584412
[Train] epoch 8 Batch 3 Loss 1.2656122744083405
[Train] epoch 8 Batch 5 Loss 1.2774165868759155
[Train] epoch 8 Batch 7 Loss 1.1408389806747437
[Train] epoch 8 Batch 9 Loss 3.613097667694092
[Train] epoch 8 Batch 11 Loss 1.2847298085689545
[Train] epoch 9 Batch 1 Loss 1.5605928003787994
[Train] epoch 9 Batch 3 Loss 1.2283769249916077
[Train] epoch 9 Batch 5 Loss 1.7788417637348175
[Train] epoch 9 Batch 7 Loss 1.5161653757095337
[Train] epoch 9 Batch 9 Loss 1.0666202008724213
[Train] epoch 9 Batch 11 Loss 2.013117253780365
[TEST] epoch 10 Loss 1.3157999515533447
[Train] epoch 10 Batch 1 Loss 1.881624460220337
[Train] epoch 10 Batch 3 Loss 1.457662284374237
[Train] epoch 10 Batch 5 Loss 1.0694136023521423
[Train] epoch 10 Batch 7 Loss 1.6496211290359497
[Train] epoch 10 Batch 9 Loss 1.1180322766304016
[Train] epoch 10 Batch 11 Loss 1.5158368349075317
[Train] epoch 11 Batch 1 Loss 1.1387551724910736
[Train] epoch 11 Batch 3 Loss 1.2272780239582062
[Train] epoch 11 Batch 5 Loss 1.0741164088249207
[Train] epoch 11 Batch 7 Loss 3.046570062637329
[Train] epoch 11 Batch 9 Loss 1.493354320526123
[Train] epoch 11 Batch 11 Loss 1.1783271431922913
[Train] epoch 12 Batch 1 Loss 1.0616453886032104
[Train] epoch 12 Batch 3 Loss 1.1705814003944397
[Train] epoch 12 Batch 5 Loss 1.389771580696106
[Train] epoch 12 Batch 7 Loss 1.8706828355789185
[Train] epoch 12 Batch 9 Loss 1.9794400334358215
[Train] epoch 12 Batch 11 Loss 1.2665976285934448
[Train] epoch 13 Batch 1 Loss 1.1120900511741638
[Train] epoch 13 Batch 3 Loss 1.2334820628166199
[Train] epoch 13 Batch 5 Loss 1.7952951788902283
[Train] epoch 13 Batch 7 Loss 1.2879512310028076
[Train] epoch 13 Batch 9 Loss 1.3101880550384521
[Train] epoch 13 Batch 11 Loss 1.7210863828659058
[Train] epoch 14 Batch 1 Loss 1.763364315032959
[Train] epoch 14 Batch 3 Loss 1.088317096233368
[Train] epoch 14 Batch 5 Loss 1.7257937788963318
[Train] epoch 14 Batch 7 Loss 1.7954830527305603
[Train] epoch 14 Batch 9 Loss 1.2286310195922852
[Train] epoch 14 Batch 11 Loss 1.0097056329250336
[TEST] epoch 15 Loss 1.3250867525736492
[Train] epoch 15 Batch 1 Loss 1.4847623109817505
[Train] epoch 15 Batch 3 Loss 1.3617500066757202
[Train] epoch 15 Batch 5 Loss 1.281342089176178
[Train] epoch 15 Batch 7 Loss 1.5702131986618042
[Train] epoch 15 Batch 9 Loss 1.4725596606731415
[Train] epoch 15 Batch 11 Loss 1.1449204087257385
[Train] epoch 16 Batch 1 Loss 1.4245989322662354
[Train] epoch 16 Batch 3 Loss 0.8570311665534973
[Train] epoch 16 Batch 5 Loss 1.9492895603179932
[Train] epoch 16 Batch 7 Loss 1.0118282735347748
[Train] epoch 16 Batch 9 Loss 0.6935403347015381
[Train] epoch 16 Batch 11 Loss 2.3752121925354004
[Train] epoch 17 Batch 1 Loss 1.092024028301239
[Train] epoch 17 Batch 3 Loss 1.5093669891357422
[Train] epoch 17 Batch 5 Loss 1.4019557237625122
[Train] epoch 17 Batch 7 Loss 1.6680993437767029
[Train] epoch 17 Batch 9 Loss 1.2932234406471252
[Train] epoch 17 Batch 11 Loss 1.2313244044780731
[Train] epoch 18 Batch 1 Loss 1.2127811908721924
[Train] epoch 18 Batch 3 Loss 1.379095196723938
[Train] epoch 18 Batch 5 Loss 1.283524751663208
[Train] epoch 18 Batch 7 Loss 1.6597706079483032
[Train] epoch 18 Batch 9 Loss 1.4747647643089294
[Train] epoch 18 Batch 11 Loss 1.4072969555854797
[Train] epoch 19 Batch 1 Loss 1.7323631644248962
[Train] epoch 19 Batch 3 Loss 1.4518596231937408
[Train] epoch 19 Batch 5 Loss 1.6399712562561035
[Train] epoch 19 Batch 7 Loss 0.9734034240245819
[Train] epoch 19 Batch 9 Loss 1.0837323665618896
[Train] epoch 19 Batch 11 Loss 1.1828539371490479
[TEST] epoch 20 Loss 1.1703534921010335
[Train] epoch 20 Batch 1 Loss 1.3329116106033325
[Train] epoch 20 Batch 3 Loss 1.15562704205513
[Train] epoch 20 Batch 5 Loss 1.4117796421051025
[Train] epoch 20 Batch 7 Loss 1.0473716855049133
[Train] epoch 20 Batch 9 Loss 1.6161649823188782
[Train] epoch 20 Batch 11 Loss 1.7183732688426971
[Train] epoch 21 Batch 1 Loss 1.1114689111709595
[Train] epoch 21 Batch 3 Loss 1.2771410942077637
[Train] epoch 21 Batch 5 Loss 0.6528392136096954
[Train] epoch 21 Batch 7 Loss 1.9895194172859192
[Train] epoch 21 Batch 9 Loss 1.5764131546020508
[Train] epoch 21 Batch 11 Loss 1.952073335647583
[Train] epoch 22 Batch 1 Loss 1.1768391132354736
[Train] epoch 22 Batch 3 Loss 1.0170207917690277
[Train] epoch 22 Batch 5 Loss 1.4958730340003967
[Train] epoch 22 Batch 7 Loss 1.3911789655685425
[Train] epoch 22 Batch 9 Loss 1.4070192575454712
[Train] epoch 22 Batch 11 Loss 1.7820682525634766
[Train] epoch 23 Batch 1 Loss 1.1589590311050415
[Train] epoch 23 Batch 3 Loss 1.1529298424720764
[Train] epoch 23 Batch 5 Loss 1.5827810764312744
[Train] epoch 23 Batch 7 Loss 1.7554458379745483
[Train] epoch 23 Batch 9 Loss 1.2575267553329468
[Train] epoch 23 Batch 11 Loss 1.3778796792030334
[Train] epoch 24 Batch 1 Loss 1.2893831729888916
[Train] epoch 24 Batch 3 Loss 1.2287220358848572
[Train] epoch 24 Batch 5 Loss 1.0013313293457031
[Train] epoch 24 Batch 7 Loss 1.3837104439735413
[Train] epoch 24 Batch 9 Loss 1.6426673233509064
[Train] epoch 24 Batch 11 Loss 2.0642576813697815
[TEST] epoch 25 Loss 1.2228503227233887
[Train] epoch 25 Batch 1 Loss 1.9523885250091553
[Train] epoch 25 Batch 3 Loss 1.5882047414779663
[Train] epoch 25 Batch 5 Loss 1.1921234726905823
[Train] epoch 25 Batch 7 Loss 1.0330358147621155
[Train] epoch 25 Batch 9 Loss 1.0920653343200684
[Train] epoch 25 Batch 11 Loss 1.5564725399017334
[Train] epoch 26 Batch 1 Loss 0.9366437196731567
[Train] epoch 26 Batch 3 Loss 1.3691430687904358
[Train] epoch 26 Batch 5 Loss 1.2533972263336182
[Train] epoch 26 Batch 7 Loss 2.10071724653244
[Train] epoch 26 Batch 9 Loss 1.6163620948791504
[Train] epoch 26 Batch 11 Loss 1.4313357472419739
[Train] epoch 27 Batch 1 Loss 1.1023818850517273
[Train] epoch 27 Batch 3 Loss 1.4357292652130127
[Train] epoch 27 Batch 5 Loss 1.260420799255371
[Train] epoch 27 Batch 7 Loss 1.9726976156234741
[Train] epoch 27 Batch 9 Loss 1.1646577715873718
[Train] epoch 27 Batch 11 Loss 1.067812442779541
[Train] epoch 28 Batch 1 Loss 0.9096323847770691
[Train] epoch 28 Batch 3 Loss 1.7718995213508606
[Train] epoch 28 Batch 5 Loss 1.4734944701194763
[Train] epoch 28 Batch 7 Loss 1.4796611070632935
[Train] epoch 28 Batch 9 Loss 1.276037722826004
[Train] epoch 28 Batch 11 Loss 1.0300521850585938
[Train] epoch 29 Batch 1 Loss 1.4838949143886566
[Train] epoch 29 Batch 3 Loss 1.1497076153755188
[Train] epoch 29 Batch 5 Loss 1.1968565583229065
[Train] epoch 29 Batch 7 Loss 1.325735628604889
[Train] epoch 29 Batch 9 Loss 1.4294326901435852
[Train] epoch 29 Batch 11 Loss 1.3045298755168915
[TEST] epoch 30 Loss 1.191385825475057
[Train] epoch 30 Batch 1 Loss 1.2266694009304047
[Train] epoch 30 Batch 3 Loss 0.9467656314373016
[Train] epoch 30 Batch 5 Loss 1.3161338567733765
[Train] epoch 30 Batch 7 Loss 1.2684406638145447
[Train] epoch 30 Batch 9 Loss 1.1728456020355225
[Train] epoch 30 Batch 11 Loss 1.5396350026130676
[Train] epoch 31 Batch 1 Loss 1.6429393291473389
[Train] epoch 31 Batch 3 Loss 0.6058945953845978
[Train] epoch 31 Batch 5 Loss 1.3015036582946777
[Train] epoch 31 Batch 7 Loss 0.5120137631893158
[Train] epoch 31 Batch 9 Loss 0.7245790660381317
[Train] epoch 31 Batch 11 Loss 2.0310696363449097
[Train] epoch 32 Batch 1 Loss 1.127633273601532
[Train] epoch 32 Batch 3 Loss 0.7777717709541321
[Train] epoch 32 Batch 5 Loss 1.1648470163345337
[Train] epoch 32 Batch 7 Loss 1.241718053817749
[Train] epoch 32 Batch 9 Loss 1.1695001721382141
[Train] epoch 32 Batch 11 Loss 0.993937075138092
[Train] epoch 33 Batch 1 Loss 0.748629093170166
[Train] epoch 33 Batch 3 Loss 1.0308879613876343
[Train] epoch 33 Batch 5 Loss 1.2734409868717194
[Train] epoch 33 Batch 7 Loss 0.6635167002677917
[Train] epoch 33 Batch 9 Loss 0.817128986120224
[Train] epoch 33 Batch 11 Loss 1.190259039402008
[Train] epoch 34 Batch 1 Loss 0.29686684906482697
[Train] epoch 34 Batch 3 Loss 0.912927120923996
[Train] epoch 34 Batch 5 Loss 0.5611619651317596
[Train] epoch 34 Batch 7 Loss 1.262728214263916
[Train] epoch 34 Batch 9 Loss 1.5817405581474304
[Train] epoch 34 Batch 11 Loss 0.978906661272049
[TEST] epoch 35 Loss 1.9041698376337688
[Train] epoch 35 Batch 1 Loss 1.006623387336731
[Train] epoch 35 Batch 3 Loss 0.9302288889884949
[Train] epoch 35 Batch 5 Loss 0.7304311096668243
[Train] epoch 35 Batch 7 Loss 0.6296650171279907
[Train] epoch 35 Batch 9 Loss 1.3141038417816162
[Train] epoch 35 Batch 11 Loss 0.9791145324707031
[Train] epoch 36 Batch 1 Loss 0.6440068781375885
[Train] epoch 36 Batch 3 Loss 0.6925264894962311
[Train] epoch 36 Batch 5 Loss 0.8261876702308655
[Train] epoch 36 Batch 7 Loss 1.15006023645401
[Train] epoch 36 Batch 9 Loss 0.5781927108764648
[Train] epoch 36 Batch 11 Loss 1.4759603142738342
[Train] epoch 37 Batch 1 Loss 0.9075593054294586
[Train] epoch 37 Batch 3 Loss 0.7229525148868561
[Train] epoch 37 Batch 5 Loss 0.8050891607999802
[Train] epoch 37 Batch 7 Loss 1.0564270317554474
[Train] epoch 37 Batch 9 Loss 0.86153644323349
[Train] epoch 37 Batch 11 Loss 1.1604313254356384
[Train] epoch 38 Batch 1 Loss 0.6769708395004272
[Train] epoch 38 Batch 3 Loss 0.7659816145896912
[Train] epoch 38 Batch 5 Loss 1.0724459886550903
[Train] epoch 38 Batch 7 Loss 1.2901894748210907
[Train] epoch 38 Batch 9 Loss 0.9534253180027008
[Train] epoch 38 Batch 11 Loss 0.55079784989357
[Train] epoch 39 Batch 1 Loss 1.0340325236320496
[Train] epoch 39 Batch 3 Loss 0.7728217840194702
[Train] epoch 39 Batch 5 Loss 0.844456136226654
[Train] epoch 39 Batch 7 Loss 0.9411674737930298
[Train] epoch 39 Batch 9 Loss 0.8080014586448669
[Train] epoch 39 Batch 11 Loss 0.9302346110343933
[TEST] epoch 40 Loss 1.6935657858848572
[Train] epoch 40 Batch 1 Loss 1.4617072343826294
[Train] epoch 40 Batch 3 Loss 0.677762508392334
[Train] epoch 40 Batch 5 Loss 0.6541749536991119
[Train] epoch 40 Batch 7 Loss 0.8479132354259491
[Train] epoch 40 Batch 9 Loss 0.8211091160774231
[Train] epoch 40 Batch 11 Loss 0.9240836799144745
[Train] epoch 41 Batch 1 Loss 0.6934115290641785
[Train] epoch 41 Batch 3 Loss 0.618256539106369
[Train] epoch 41 Batch 5 Loss 1.1052207350730896
[Train] epoch 41 Batch 7 Loss 1.3928163945674896
[Train] epoch 41 Batch 9 Loss 0.715756744146347
[Train] epoch 41 Batch 11 Loss 0.7694481611251831
[Train] epoch 42 Batch 1 Loss 0.6412391364574432
[Train] epoch 42 Batch 3 Loss 1.222499966621399
[Train] epoch 42 Batch 5 Loss 0.6233154237270355
[Train] epoch 42 Batch 7 Loss 0.9057706296443939
[Train] epoch 42 Batch 9 Loss 0.8639586269855499
[Train] epoch 42 Batch 11 Loss 0.7864596247673035
[Train] epoch 43 Batch 1 Loss 0.6714339405298233
[Train] epoch 43 Batch 3 Loss 0.6083256304264069
[Train] epoch 43 Batch 5 Loss 0.734485924243927
[Train] epoch 43 Batch 7 Loss 1.161346584558487
[Train] epoch 43 Batch 9 Loss 1.0211490392684937
[Train] epoch 43 Batch 11 Loss 0.7952756583690643
[Train] epoch 44 Batch 1 Loss 1.0445627570152283
[Train] epoch 44 Batch 3 Loss 1.1055508255958557
[Train] epoch 44 Batch 5 Loss 0.7620740830898285
[Train] epoch 44 Batch 7 Loss 0.7441859543323517
[Train] epoch 44 Batch 9 Loss 0.6880189776420593
[Train] epoch 44 Batch 11 Loss 0.6311710476875305
[TEST] epoch 45 Loss 1.6783986886342366
[Train] epoch 45 Batch 1 Loss 0.669314980506897
[Train] epoch 45 Batch 3 Loss 0.7612389028072357
[Train] epoch 45 Batch 5 Loss 0.759952038526535
[Train] epoch 45 Batch 7 Loss 1.2197984457015991
[Train] epoch 45 Batch 9 Loss 0.8624916672706604
[Train] epoch 45 Batch 11 Loss 0.5720371454954147
[Train] epoch 46 Batch 1 Loss 0.8780003488063812
[Train] epoch 46 Batch 3 Loss 0.8056049644947052
[Train] epoch 46 Batch 5 Loss 0.4914989024400711
[Train] epoch 46 Batch 7 Loss 0.6892299056053162
[Train] epoch 46 Batch 9 Loss 1.2064839899539948
[Train] epoch 46 Batch 11 Loss 0.724744975566864
[Train] epoch 47 Batch 1 Loss 0.6385725140571594
[Train] epoch 47 Batch 3 Loss 0.5840051770210266
[Train] epoch 47 Batch 5 Loss 0.9066148996353149
[Train] epoch 47 Batch 7 Loss 0.9422627687454224
[Train] epoch 47 Batch 9 Loss 0.7907509803771973
[Train] epoch 47 Batch 11 Loss 0.8671900033950806
[Train] epoch 48 Batch 1 Loss 0.6798495352268219
[Train] epoch 48 Batch 3 Loss 0.6576428264379501
[Train] epoch 48 Batch 5 Loss 1.400667428970337
[Train] epoch 48 Batch 7 Loss 0.595310240983963
[Train] epoch 48 Batch 9 Loss 0.8669415712356567
[Train] epoch 48 Batch 11 Loss 0.6574680805206299
[Train] epoch 49 Batch 1 Loss 0.5353703200817108
[Train] epoch 49 Batch 3 Loss 0.7326348721981049
[Train] epoch 49 Batch 5 Loss 0.8608386218547821
[Train] epoch 49 Batch 7 Loss 0.486849308013916
[Train] epoch 49 Batch 9 Loss 1.3501411974430084
[Train] epoch 49 Batch 11 Loss 1.0363340377807617
[TEST] epoch 50 Loss 1.8207061290740967
[Train] epoch 50 Batch 1 Loss 0.5744410753250122
[Train] epoch 50 Batch 3 Loss 1.169805258512497
[Train] epoch 50 Batch 5 Loss 0.5985647737979889
[Train] epoch 50 Batch 7 Loss 1.0383453369140625
[Train] epoch 50 Batch 9 Loss 0.823164701461792
[Train] epoch 50 Batch 11 Loss 0.72128626704216
[Train] epoch 51 Batch 1 Loss 0.6583919525146484
[Train] epoch 51 Batch 3 Loss 1.08534637093544
[Train] epoch 51 Batch 5 Loss 0.6195442080497742
[Train] epoch 51 Batch 7 Loss 1.0037937760353088
[Train] epoch 51 Batch 9 Loss 0.6629461050033569
[Train] epoch 51 Batch 11 Loss 0.5957372188568115
[Train] epoch 52 Batch 1 Loss 0.5703116953372955
[Train] epoch 52 Batch 3 Loss 0.6613548398017883
[Train] epoch 52 Batch 5 Loss 1.105364739894867
[Train] epoch 52 Batch 7 Loss 0.8184172511100769
[Train] epoch 52 Batch 9 Loss 0.6871454119682312
[Train] epoch 52 Batch 11 Loss 1.2960960566997528
[Train] epoch 53 Batch 1 Loss 0.9242227971553802
[Train] epoch 53 Batch 3 Loss 0.49688562750816345
[Train] epoch 53 Batch 5 Loss 1.1049959361553192
[Train] epoch 53 Batch 7 Loss 0.805207759141922
[Train] epoch 53 Batch 9 Loss 0.7433953583240509
[Train] epoch 53 Batch 11 Loss 0.8956065773963928
[Train] epoch 54 Batch 1 Loss 0.8994311392307281
[Train] epoch 54 Batch 3 Loss 0.6436710953712463
[Train] epoch 54 Batch 5 Loss 0.6971398591995239
[Train] epoch 54 Batch 7 Loss 0.8646012544631958
[Train] epoch 54 Batch 9 Loss 0.881606251001358
[Train] epoch 54 Batch 11 Loss 0.9321442246437073
[TEST] epoch 55 Loss 1.809762676556905
[Train] epoch 55 Batch 1 Loss 0.8898316621780396
[Train] epoch 55 Batch 3 Loss 0.7682920694351196
[Train] epoch 55 Batch 5 Loss 0.8384951651096344
[Train] epoch 55 Batch 7 Loss 0.5918628722429276
[Train] epoch 55 Batch 9 Loss 0.688210666179657
[Train] epoch 55 Batch 11 Loss 0.8565209656953812
[Train] epoch 56 Batch 1 Loss 0.654535174369812
[Train] epoch 56 Batch 3 Loss 0.700744241476059
[Train] epoch 56 Batch 5 Loss 0.7736695110797882
[Train] epoch 56 Batch 7 Loss 0.6135461926460266
[Train] epoch 56 Batch 9 Loss 0.8904474675655365
[Train] epoch 56 Batch 11 Loss 1.0123071372509003
[Train] epoch 57 Batch 1 Loss 0.6834229528903961
[Train] epoch 57 Batch 3 Loss 0.6009867191314697
[Train] epoch 57 Batch 5 Loss 0.8866122364997864
[Train] epoch 57 Batch 7 Loss 0.5918115824460983
[Train] epoch 57 Batch 9 Loss 0.6484995484352112
[Train] epoch 57 Batch 11 Loss 1.2519465386867523
[Train] epoch 58 Batch 1 Loss 0.6126722097396851
[Train] epoch 58 Batch 3 Loss 0.7700627148151398
[Train] epoch 58 Batch 5 Loss 0.7963904142379761
[Train] epoch 58 Batch 7 Loss 0.7441177070140839
[Train] epoch 58 Batch 9 Loss 0.6791678965091705
[Train] epoch 58 Batch 11 Loss 0.9894775450229645
[Train] epoch 59 Batch 1 Loss 0.634609043598175
[Train] epoch 59 Batch 3 Loss 0.9220903515815735
[Train] epoch 59 Batch 5 Loss 0.6980634331703186
[Train] epoch 59 Batch 7 Loss 0.6749758124351501
[Train] epoch 59 Batch 9 Loss 0.8558510839939117
[Train] epoch 59 Batch 11 Loss 0.7633926868438721
[TEST] epoch 60 Loss 1.8513102531433105
[Train] epoch 60 Batch 1 Loss 0.9613929986953735
[Train] epoch 60 Batch 3 Loss 0.9888819754123688
[Train] epoch 60 Batch 5 Loss 0.6725136935710907
[Train] epoch 60 Batch 7 Loss 0.6836456656455994
[Train] epoch 60 Batch 9 Loss 0.5793114304542542
[Train] epoch 60 Batch 11 Loss 0.7065333724021912
[Train] epoch 61 Batch 1 Loss 1.1255487203598022
[Train] epoch 61 Batch 3 Loss 0.8569897711277008
[Train] epoch 61 Batch 5 Loss 0.8352712690830231
[Train] epoch 61 Batch 7 Loss 0.610389307141304
[Train] epoch 61 Batch 9 Loss 0.502254530787468
[Train] epoch 61 Batch 11 Loss 0.673945963382721
[Train] epoch 62 Batch 1 Loss 0.7173200249671936
[Train] epoch 62 Batch 3 Loss 0.6954379081726074
[Train] epoch 62 Batch 5 Loss 0.5907348692417145
[Train] epoch 62 Batch 7 Loss 1.0729379951953888
[Train] epoch 62 Batch 9 Loss 0.7561486065387726
[Train] epoch 62 Batch 11 Loss 0.7245927453041077
[Train] epoch 63 Batch 1 Loss 0.6310363709926605
[Train] epoch 63 Batch 3 Loss 0.5074807703495026
[Train] epoch 63 Batch 5 Loss 0.52140873670578
[Train] epoch 63 Batch 7 Loss 1.0880346596240997
[Train] epoch 63 Batch 9 Loss 1.1879981756210327
[Train] epoch 63 Batch 11 Loss 0.7729357182979584
[Train] epoch 64 Batch 1 Loss 1.1255951821804047
[Train] epoch 64 Batch 3 Loss 0.9275195598602295
[Train] epoch 64 Batch 5 Loss 0.536426231265068
[Train] epoch 64 Batch 7 Loss 0.716372162103653
[Train] epoch 64 Batch 9 Loss 0.7435320019721985
[Train] epoch 64 Batch 11 Loss 0.8503165543079376
[TEST] epoch 65 Loss 1.9379316568374634
[Train] epoch 65 Batch 1 Loss 0.7510071694850922
[Train] epoch 65 Batch 3 Loss 1.1499770283699036
[Train] epoch 65 Batch 5 Loss 0.8582449853420258
[Train] epoch 65 Batch 7 Loss 0.5685132145881653
[Train] epoch 65 Batch 9 Loss 0.8039439916610718
[Train] epoch 65 Batch 11 Loss 0.5436761975288391
[Train] epoch 66 Batch 1 Loss 0.6586019992828369
[Train] epoch 66 Batch 3 Loss 0.8528266847133636
[Train] epoch 66 Batch 5 Loss 0.9901506304740906
[Train] epoch 66 Batch 7 Loss 0.5608786195516586
[Train] epoch 66 Batch 9 Loss 1.0066376030445099
[Train] epoch 66 Batch 11 Loss 0.6315373331308365
[Train] epoch 67 Batch 1 Loss 0.7544228136539459
[Train] epoch 67 Batch 3 Loss 1.3042236268520355
[Train] epoch 67 Batch 5 Loss 0.5803419798612595
[Train] epoch 67 Batch 7 Loss 0.9676468074321747
[Train] epoch 67 Batch 9 Loss 0.701550155878067
[Train] epoch 67 Batch 11 Loss 0.49335870146751404
[Train] epoch 68 Batch 1 Loss 1.1504038870334625
[Train] epoch 68 Batch 3 Loss 0.49599453806877136
[Train] epoch 68 Batch 5 Loss 0.5627236068248749
[Train] epoch 68 Batch 7 Loss 0.7087197303771973
[Train] epoch 68 Batch 9 Loss 0.7252566516399384
[Train] epoch 68 Batch 11 Loss 0.921602725982666
[Train] epoch 69 Batch 1 Loss 0.7358694672584534
[Train] epoch 69 Batch 3 Loss 0.9938636869192123
[Train] epoch 69 Batch 5 Loss 0.5956069231033325
[Train] epoch 69 Batch 7 Loss 0.6238700151443481
[Train] epoch 69 Batch 9 Loss 0.7526280581951141
[Train] epoch 69 Batch 11 Loss 0.7552625834941864
[TEST] epoch 70 Loss 1.9052303433418274
[Train] epoch 70 Batch 1 Loss 0.5751370191574097
[Train] epoch 70 Batch 3 Loss 0.6656972020864487
[Train] epoch 70 Batch 5 Loss 1.0080205798149109
[Train] epoch 70 Batch 7 Loss 0.422411173582077
[Train] epoch 70 Batch 9 Loss 1.0501226484775543
[Train] epoch 70 Batch 11 Loss 0.7929265201091766
[Train] epoch 71 Batch 1 Loss 0.7337620109319687
[Train] epoch 71 Batch 3 Loss 0.9843087196350098
[Train] epoch 71 Batch 5 Loss 0.4598681628704071
[Train] epoch 71 Batch 7 Loss 0.6695260107517242
[Train] epoch 71 Batch 9 Loss 0.8958801627159119
[Train] epoch 71 Batch 11 Loss 0.9774511456489563
[Train] epoch 72 Batch 1 Loss 0.4876963496208191
[Train] epoch 72 Batch 3 Loss 0.4904038608074188
[Train] epoch 72 Batch 5 Loss 1.1573452949523926
[Train] epoch 72 Batch 7 Loss 0.7643320858478546
[Train] epoch 72 Batch 9 Loss 0.49889877438545227
[Train] epoch 72 Batch 11 Loss 1.3266265392303467
[Train] epoch 73 Batch 1 Loss 0.5775614976882935
[Train] epoch 73 Batch 3 Loss 1.1288591623306274
[Train] epoch 73 Batch 5 Loss 1.0347592532634735
[Train] epoch 73 Batch 7 Loss 0.4717787802219391
[Train] epoch 73 Batch 9 Loss 0.8985490798950195
[Train] epoch 73 Batch 11 Loss 0.7424708604812622
[Train] epoch 74 Batch 1 Loss 0.8569217026233673
[Train] epoch 74 Batch 3 Loss 0.7704265415668488
[Train] epoch 74 Batch 5 Loss 0.9678920805454254
[Train] epoch 74 Batch 7 Loss 0.7688429653644562
[Train] epoch 74 Batch 9 Loss 0.5598861277103424
[Train] epoch 74 Batch 11 Loss 0.6640430688858032
[TEST] epoch 75 Loss 1.9316324790318806
[Train] epoch 75 Batch 1 Loss 0.762128472328186
[Train] epoch 75 Batch 3 Loss 0.6855075061321259
[Train] epoch 75 Batch 5 Loss 0.7783740162849426
[Train] epoch 75 Batch 7 Loss 0.30757370591163635
[Train] epoch 75 Batch 9 Loss 0.9149863719940186
[Train] epoch 75 Batch 11 Loss 1.1727398037910461
[Train] epoch 76 Batch 1 Loss 0.5891369879245758
[Train] epoch 76 Batch 3 Loss 0.8716908991336823
[Train] epoch 76 Batch 5 Loss 0.48587870597839355
[Train] epoch 76 Batch 7 Loss 0.7424836754798889
[Train] epoch 76 Batch 9 Loss 0.905489981174469
[Train] epoch 76 Batch 11 Loss 0.8807032406330109
[Train] epoch 77 Batch 1 Loss 0.6245617419481277
[Train] epoch 77 Batch 3 Loss 0.7475343942642212
[Train] epoch 77 Batch 5 Loss 0.9487644731998444
[Train] epoch 77 Batch 7 Loss 1.0554766654968262
[Train] epoch 77 Batch 9 Loss 0.3398904800415039
[Train] epoch 77 Batch 11 Loss 0.7669675648212433
[Train] epoch 78 Batch 1 Loss 0.6387934237718582
[Train] epoch 78 Batch 3 Loss 0.9302480220794678
[Train] epoch 78 Batch 5 Loss 0.5749024599790573
[Train] epoch 78 Batch 7 Loss 0.8116096556186676
[Train] epoch 78 Batch 9 Loss 0.8075057566165924
[Train] epoch 78 Batch 11 Loss 0.6114723086357117
[Train] epoch 79 Batch 1 Loss 0.613803431391716
[Train] epoch 79 Batch 3 Loss 0.9282917678356171
[Train] epoch 79 Batch 5 Loss 0.4952298700809479
[Train] epoch 79 Batch 7 Loss 1.030665397644043
[Train] epoch 79 Batch 9 Loss 0.6319599449634552
[Train] epoch 79 Batch 11 Loss 0.6259958744049072
[TEST] epoch 80 Loss 2.0510087410608926
[Train] epoch 80 Batch 1 Loss 0.5709042549133301
[Train] epoch 80 Batch 3 Loss 0.48534736037254333
[Train] epoch 80 Batch 5 Loss 1.0786362290382385
[Train] epoch 80 Batch 7 Loss 0.7803359925746918
[Train] epoch 80 Batch 9 Loss 0.46345314383506775
[Train] epoch 80 Batch 11 Loss 0.9100856781005859
[Train] epoch 81 Batch 1 Loss 0.6974723637104034
[Train] epoch 81 Batch 3 Loss 0.9293348789215088
[Train] epoch 81 Batch 5 Loss 0.6951570808887482
[Train] epoch 81 Batch 7 Loss 0.41105593740940094
[Train] epoch 81 Batch 9 Loss 0.8255816549062729
[Train] epoch 81 Batch 11 Loss 0.7857678532600403
[Train] epoch 82 Batch 1 Loss 0.46752960979938507
[Train] epoch 82 Batch 3 Loss 0.6201850175857544
[Train] epoch 82 Batch 5 Loss 0.5518973171710968
[Train] epoch 82 Batch 7 Loss 0.9756678640842438
[Train] epoch 82 Batch 9 Loss 0.8106669187545776
[Train] epoch 82 Batch 11 Loss 0.8600446283817291
[Train] epoch 83 Batch 1 Loss 0.8953281939029694
[Train] epoch 83 Batch 3 Loss 0.7598060965538025
[Train] epoch 83 Batch 5 Loss 0.6292986422777176
[Train] epoch 83 Batch 7 Loss 0.6441459059715271
[Train] epoch 83 Batch 9 Loss 0.6158457398414612
[Train] epoch 83 Batch 11 Loss 0.6962120532989502
[Train] epoch 84 Batch 1 Loss 0.7200018912553787
[Train] epoch 84 Batch 3 Loss 0.6910957992076874
[Train] epoch 84 Batch 5 Loss 0.7425277233123779
[Train] epoch 84 Batch 7 Loss 0.6959773302078247
[Train] epoch 84 Batch 9 Loss 0.7047743797302246
[Train] epoch 84 Batch 11 Loss 0.6786023676395416
[TEST] epoch 85 Loss 1.7646547158559163
[Train] epoch 85 Batch 1 Loss 0.9369595348834991
[Train] epoch 85 Batch 3 Loss 0.7148237824440002
[Train] epoch 85 Batch 5 Loss 0.5945080071687698
[Train] epoch 85 Batch 7 Loss 0.43305883556604385
[Train] epoch 85 Batch 9 Loss 0.7693774104118347
[Train] epoch 85 Batch 11 Loss 0.7956497073173523
[Train] epoch 86 Batch 1 Loss 0.7391667068004608
[Train] epoch 86 Batch 3 Loss 0.808821439743042
[Train] epoch 86 Batch 5 Loss 0.419951930642128
[Train] epoch 86 Batch 7 Loss 0.41288794577121735
[Train] epoch 86 Batch 9 Loss 1.1242051720619202
[Train] epoch 86 Batch 11 Loss 0.5547148585319519
[Train] epoch 87 Batch 1 Loss 0.35884250700473785
[Train] epoch 87 Batch 3 Loss 0.6814887672662735
[Train] epoch 87 Batch 5 Loss 0.839587390422821
[Train] epoch 87 Batch 7 Loss 0.3093112111091614
[Train] epoch 87 Batch 9 Loss 1.004946768283844
[Train] epoch 87 Batch 11 Loss 1.0289979577064514
[Train] epoch 88 Batch 1 Loss 0.42458653450012207
[Train] epoch 88 Batch 3 Loss 0.9026398062705994
[Train] epoch 88 Batch 5 Loss 0.9747258126735687
[Train] epoch 88 Batch 7 Loss 0.47695060074329376
[Train] epoch 88 Batch 9 Loss 0.6166776865720749
[Train] epoch 88 Batch 11 Loss 0.670194685459137
[Train] epoch 89 Batch 1 Loss 0.4906960725784302
[Train] epoch 89 Batch 3 Loss 0.5523484200239182
[Train] epoch 89 Batch 5 Loss 0.8597522974014282
[Train] epoch 89 Batch 7 Loss 0.5763601511716843
[Train] epoch 89 Batch 9 Loss 0.7813850045204163
[Train] epoch 89 Batch 11 Loss 0.7114889025688171
[TEST] epoch 90 Loss 2.00246795018514
[Train] epoch 90 Batch 1 Loss 0.5704674422740936
[Train] epoch 90 Batch 3 Loss 0.8059311211109161
[Train] epoch 90 Batch 5 Loss 0.507291853427887
[Train] epoch 90 Batch 7 Loss 0.8640445172786713
[Train] epoch 90 Batch 9 Loss 0.7726818025112152
[Train] epoch 90 Batch 11 Loss 0.62073914706707
[Train] epoch 91 Batch 1 Loss 0.8747280836105347
[Train] epoch 91 Batch 3 Loss 0.5319420099258423
[Train] epoch 91 Batch 5 Loss 0.5981734395027161
[Train] epoch 91 Batch 7 Loss 0.797957569360733
[Train] epoch 91 Batch 9 Loss 0.4757886677980423
[Train] epoch 91 Batch 11 Loss 0.8057491481304169
[Train] epoch 92 Batch 1 Loss 0.747795820236206
[Train] epoch 92 Batch 3 Loss 1.0705150067806244
[Train] epoch 92 Batch 5 Loss 0.6772413551807404
[Train] epoch 92 Batch 7 Loss 0.3125685676932335
[Train] epoch 92 Batch 9 Loss 0.3811172544956207
[Train] epoch 92 Batch 11 Loss 0.7920985221862793
[Train] epoch 93 Batch 1 Loss 0.4492681473493576
[Train] epoch 93 Batch 3 Loss 0.5627395510673523
[Train] epoch 93 Batch 5 Loss 0.4983769580721855
[Train] epoch 93 Batch 7 Loss 0.8158634901046753
[Train] epoch 93 Batch 9 Loss 0.6845536679029465
[Train] epoch 93 Batch 11 Loss 1.0414510071277618
[Train] epoch 94 Batch 1 Loss 0.719070315361023
[Train] epoch 94 Batch 3 Loss 0.504993200302124
[Train] epoch 94 Batch 5 Loss 0.7410875558853149
[Train] epoch 94 Batch 7 Loss 1.0074074864387512
[Train] epoch 94 Batch 9 Loss 0.8415710926055908
[Train] epoch 94 Batch 11 Loss 0.37571071088314056
[TEST] epoch 95 Loss 2.2131905555725098
[Train] epoch 95 Batch 1 Loss 0.646101325750351
[Train] epoch 95 Batch 3 Loss 0.2827680706977844
[Train] epoch 95 Batch 5 Loss 0.6121864467859268
[Train] epoch 95 Batch 7 Loss 0.7442846298217773
[Train] epoch 95 Batch 9 Loss 0.9444857835769653
[Train] epoch 95 Batch 11 Loss 0.7022239714860916
[Train] epoch 96 Batch 1 Loss 0.6119909286499023
[Train] epoch 96 Batch 3 Loss 0.7588715255260468
[Train] epoch 96 Batch 5 Loss 0.49510283023118973
[Train] epoch 96 Batch 7 Loss 0.5591936111450195
[Train] epoch 96 Batch 9 Loss 0.3999510258436203
[Train] epoch 96 Batch 11 Loss 1.191886842250824
[Train] epoch 97 Batch 1 Loss 0.595174640417099
[Train] epoch 97 Batch 3 Loss 0.5920496135950089
[Train] epoch 97 Batch 5 Loss 0.6529881060123444
[Train] epoch 97 Batch 7 Loss 0.8956936001777649
[Train] epoch 97 Batch 9 Loss 0.8660245537757874
[Train] epoch 97 Batch 11 Loss 0.7689065635204315
[Train] epoch 98 Batch 1 Loss 0.6617776453495026
[Train] epoch 98 Batch 3 Loss 0.9118547737598419
[Train] epoch 98 Batch 5 Loss 0.3367001414299011
[Train] epoch 98 Batch 7 Loss 0.6846850514411926
[Train] epoch 98 Batch 9 Loss 0.48431216180324554
[Train] epoch 98 Batch 11 Loss 0.8481004238128662
[Train] epoch 99 Batch 1 Loss 0.35579144954681396
[Train] epoch 99 Batch 3 Loss 1.1022330522537231
[Train] epoch 99 Batch 5 Loss 0.3774385303258896
[Train] epoch 99 Batch 7 Loss 0.6206105798482895
[Train] epoch 99 Batch 9 Loss 0.7701188027858734
[Train] epoch 99 Batch 11 Loss 0.6991250216960907
[TEST] epoch 100 Loss 3.1152597268422446
[Train] epoch 100 Batch 1 Loss 0.2290145456790924
[Train] epoch 100 Batch 3 Loss 0.5906966328620911
[Train] epoch 100 Batch 5 Loss 0.7104630470275879
[Train] epoch 100 Batch 7 Loss 0.7448558211326599
[Train] epoch 100 Batch 9 Loss 0.8732800185680389
[Train] epoch 100 Batch 11 Loss 0.7608255445957184
[Train] epoch 101 Batch 1 Loss 0.687002494931221
[Train] epoch 101 Batch 3 Loss 0.3981121629476547
[Train] epoch 101 Batch 5 Loss 0.9354275763034821
[Train] epoch 101 Batch 7 Loss 0.7640113532543182
[Train] epoch 101 Batch 9 Loss 0.8231149315834045
[Train] epoch 101 Batch 11 Loss 0.4652976393699646
[Train] epoch 102 Batch 1 Loss 0.48465846478939056
[Train] epoch 102 Batch 3 Loss 0.909172773361206
[Train] epoch 102 Batch 5 Loss 0.7241247892379761
[Train] epoch 102 Batch 7 Loss 0.6052834391593933
[Train] epoch 102 Batch 9 Loss 0.4469998925924301
[Train] epoch 102 Batch 11 Loss 0.6877677738666534
[Train] epoch 103 Batch 1 Loss 0.6300186812877655
[Train] epoch 103 Batch 3 Loss 0.4938962161540985
[Train] epoch 103 Batch 5 Loss 0.5131662487983704
[Train] epoch 103 Batch 7 Loss 1.149812400341034
[Train] epoch 103 Batch 9 Loss 0.9296892583370209
[Train] epoch 103 Batch 11 Loss 0.3957737684249878
[Train] epoch 104 Batch 1 Loss 0.41698068380355835
[Train] epoch 104 Batch 3 Loss 1.0671546757221222
[Train] epoch 104 Batch 5 Loss 0.4960954487323761
[Train] epoch 104 Batch 7 Loss 0.47844932973384857
[Train] epoch 104 Batch 9 Loss 0.6583265960216522
[Train] epoch 104 Batch 11 Loss 0.7806479036808014
[TEST] epoch 105 Loss 2.320889194806417
[Train] epoch 105 Batch 1 Loss 0.5950625240802765
[Train] epoch 105 Batch 3 Loss 0.6022144258022308
[Train] epoch 105 Batch 5 Loss 0.6036988943815231
[Train] epoch 105 Batch 7 Loss 0.854664534330368
[Train] epoch 105 Batch 9 Loss 0.6135637164115906
[Train] epoch 105 Batch 11 Loss 0.44330817461013794
[Train] epoch 106 Batch 1 Loss 0.4647553041577339
[Train] epoch 106 Batch 3 Loss 0.4473365321755409
[Train] epoch 106 Batch 5 Loss 0.6284720301628113
[Train] epoch 106 Batch 7 Loss 0.4268111288547516
[Train] epoch 106 Batch 9 Loss 0.9806271195411682
[Train] epoch 106 Batch 11 Loss 0.6706334352493286
[Train] epoch 107 Batch 1 Loss 0.4825685918331146
[Train] epoch 107 Batch 3 Loss 0.5972923189401627
[Train] epoch 107 Batch 5 Loss 0.6041988581418991
[Train] epoch 107 Batch 7 Loss 0.6995759904384613
[Train] epoch 107 Batch 9 Loss 0.8264296650886536
[Train] epoch 107 Batch 11 Loss 0.439435139298439
[Train] epoch 108 Batch 1 Loss 0.6178303062915802
[Train] epoch 108 Batch 3 Loss 0.6897198557853699
[Train] epoch 108 Batch 5 Loss 0.4903855621814728
[Train] epoch 108 Batch 7 Loss 0.63149693608284
[Train] epoch 108 Batch 9 Loss 0.5420731157064438
[Train] epoch 108 Batch 11 Loss 0.5657551288604736
[Train] epoch 109 Batch 1 Loss 0.8599320501089096
[Train] epoch 109 Batch 3 Loss 0.6837209463119507
[Train] epoch 109 Batch 5 Loss 0.5557311475276947
[Train] epoch 109 Batch 7 Loss 0.4808329641819
[Train] epoch 109 Batch 9 Loss 0.6033718585968018
[Train] epoch 109 Batch 11 Loss 0.332080215215683
[TEST] epoch 110 Loss 2.632293224334717
[Train] epoch 110 Batch 1 Loss 0.37911854684352875
[Train] epoch 110 Batch 3 Loss 0.6033914238214493
[Train] epoch 110 Batch 5 Loss 0.9849079847335815
[Train] epoch 110 Batch 7 Loss 0.29592573642730713
[Train] epoch 110 Batch 9 Loss 0.7930070161819458
[Train] epoch 110 Batch 11 Loss 0.6735061407089233
[Train] epoch 111 Batch 1 Loss 0.44861243665218353
[Train] epoch 111 Batch 3 Loss 0.2684333100914955
[Train] epoch 111 Batch 5 Loss 0.500768169760704
[Train] epoch 111 Batch 7 Loss 1.1611743569374084
[Train] epoch 111 Batch 9 Loss 0.7283695340156555
[Train] epoch 111 Batch 11 Loss 0.575749933719635
[Train] epoch 112 Batch 1 Loss 0.8325889110565186
[Train] epoch 112 Batch 3 Loss 0.7318200469017029
[Train] epoch 112 Batch 5 Loss 0.7770764231681824
[Train] epoch 112 Batch 7 Loss 0.6660688519477844
[Train] epoch 112 Batch 9 Loss 1.0750541985034943
[Train] epoch 112 Batch 11 Loss 0.598091259598732
[Train] epoch 113 Batch 1 Loss 0.8303435146808624
[Train] epoch 113 Batch 3 Loss 0.5853994786739349
[Train] epoch 113 Batch 5 Loss 0.595945417881012
[Train] epoch 113 Batch 7 Loss 0.8351131230592728
[Train] epoch 113 Batch 9 Loss 1.0091727077960968
[Train] epoch 113 Batch 11 Loss 0.6754595339298248
[Train] epoch 114 Batch 1 Loss 0.9768989682197571
[Train] epoch 114 Batch 3 Loss 0.7590535581111908
[Train] epoch 114 Batch 5 Loss 0.6553395986557007
[Train] epoch 114 Batch 7 Loss 0.49916747212409973
[Train] epoch 114 Batch 9 Loss 0.8161056935787201
[Train] epoch 114 Batch 11 Loss 0.9114451110363007
[TEST] epoch 115 Loss 2.031869729359945
[Train] epoch 115 Batch 1 Loss 0.6502749621868134
[Train] epoch 115 Batch 3 Loss 0.7408410608768463
[Train] epoch 115 Batch 5 Loss 0.6139926016330719
[Train] epoch 115 Batch 7 Loss 0.5569878220558167
[Train] epoch 115 Batch 9 Loss 0.7570472061634064
[Train] epoch 115 Batch 11 Loss 0.8923642635345459
[Train] epoch 116 Batch 1 Loss 0.530092790722847
[Train] epoch 116 Batch 3 Loss 0.5997436046600342
[Train] epoch 116 Batch 5 Loss 0.7721982151269913
[Train] epoch 116 Batch 7 Loss 0.4916919767856598
[Train] epoch 116 Batch 9 Loss 1.0416021645069122
[Train] epoch 116 Batch 11 Loss 0.9652511179447174
[Train] epoch 117 Batch 1 Loss 0.6307764947414398
[Train] epoch 117 Batch 3 Loss 1.064464956521988
[Train] epoch 117 Batch 5 Loss 0.732404500246048
[Train] epoch 117 Batch 7 Loss 0.869499146938324
[Train] epoch 117 Batch 9 Loss 0.5551021695137024
[Train] epoch 117 Batch 11 Loss 0.4968886077404022
[Train] epoch 118 Batch 1 Loss 0.5039609670639038
[Train] epoch 118 Batch 3 Loss 0.7607807219028473
[Train] epoch 118 Batch 5 Loss 0.5624841749668121
[Train] epoch 118 Batch 7 Loss 0.8518393635749817
[Train] epoch 118 Batch 9 Loss 0.8298623263835907
[Train] epoch 118 Batch 11 Loss 0.8752304017543793
[Train] epoch 119 Batch 1 Loss 0.6644492447376251
[Train] epoch 119 Batch 3 Loss 0.7174172699451447
[Train] epoch 119 Batch 5 Loss 0.7719963490962982
[Train] epoch 119 Batch 7 Loss 0.5079372748732567
[Train] epoch 119 Batch 9 Loss 0.8961718082427979
[Train] epoch 119 Batch 11 Loss 0.7387059032917023
[TEST] epoch 120 Loss 2.3419727881749473
[Train] epoch 120 Batch 1 Loss 0.5734056979417801
[Train] epoch 120 Batch 3 Loss 1.2263900637626648
[Train] epoch 120 Batch 5 Loss 0.6767612099647522
[Train] epoch 120 Batch 7 Loss 0.6959846317768097
[Train] epoch 120 Batch 9 Loss 0.7831701636314392
[Train] epoch 120 Batch 11 Loss 0.6036143004894257
[Train] epoch 121 Batch 1 Loss 0.7433132231235504
[Train] epoch 121 Batch 3 Loss 0.7115974128246307
[Train] epoch 121 Batch 5 Loss 0.8157237470149994
[Train] epoch 121 Batch 7 Loss 0.6359356939792633
[Train] epoch 121 Batch 9 Loss 0.8195099830627441
[Train] epoch 121 Batch 11 Loss 0.4817664921283722
[Train] epoch 122 Batch 1 Loss 0.6034245193004608
[Train] epoch 122 Batch 3 Loss 0.6005207151174545
[Train] epoch 122 Batch 5 Loss 0.9142794013023376
[Train] epoch 122 Batch 7 Loss 0.49657075107097626
[Train] epoch 122 Batch 9 Loss 0.6992512345314026
[Train] epoch 122 Batch 11 Loss 1.058907687664032
[Train] epoch 123 Batch 1 Loss 0.7681454420089722
[Train] epoch 123 Batch 3 Loss 0.5062507688999176
[Train] epoch 123 Batch 5 Loss 1.0800230205059052
[Train] epoch 123 Batch 7 Loss 0.7361050546169281
[Train] epoch 123 Batch 9 Loss 0.5583988130092621
[Train] epoch 123 Batch 11 Loss 0.7063998579978943
[Train] epoch 124 Batch 1 Loss 0.7769111096858978
[Train] epoch 124 Batch 3 Loss 0.9206276535987854
[Train] epoch 124 Batch 5 Loss 0.8113043904304504
[Train] epoch 124 Batch 7 Loss 0.6436766386032104
[Train] epoch 124 Batch 9 Loss 0.6109477281570435
[Train] epoch 124 Batch 11 Loss 0.5736817121505737
[TEST] epoch 125 Loss 2.628877282142639
[Train] epoch 125 Batch 1 Loss 0.7964953780174255
[Train] epoch 125 Batch 3 Loss 0.6268259286880493
[Train] epoch 125 Batch 5 Loss 0.7453416883945465
[Train] epoch 125 Batch 7 Loss 0.5169501006603241
[Train] epoch 125 Batch 9 Loss 0.6677349209785461
[Train] epoch 125 Batch 11 Loss 0.9349349439144135
[Train] epoch 126 Batch 1 Loss 0.8558143377304077
[Train] epoch 126 Batch 3 Loss 0.4112579822540283
[Train] epoch 126 Batch 5 Loss 0.9847685694694519
[Train] epoch 126 Batch 7 Loss 1.041688859462738
[Train] epoch 126 Batch 9 Loss 0.6250369250774384
[Train] epoch 126 Batch 11 Loss 0.651702880859375
[Train] epoch 127 Batch 1 Loss 0.5550466775894165
[Train] epoch 127 Batch 3 Loss 1.0081791877746582
[Train] epoch 127 Batch 5 Loss 0.6470373272895813
[Train] epoch 127 Batch 7 Loss 0.5170117318630219
[Train] epoch 127 Batch 9 Loss 0.6356933116912842
[Train] epoch 127 Batch 11 Loss 0.9882130920886993
[Train] epoch 128 Batch 1 Loss 0.7685631513595581
[Train] epoch 128 Batch 3 Loss 0.6400472819805145
[Train] epoch 128 Batch 5 Loss 0.6902013421058655
[Train] epoch 128 Batch 7 Loss 0.4454222470521927
[Train] epoch 128 Batch 9 Loss 0.8823784291744232
[Train] epoch 128 Batch 11 Loss 0.8859789371490479
[Train] epoch 129 Batch 1 Loss 0.5793090611696243
[Train] epoch 129 Batch 3 Loss 0.5959000885486603
[Train] epoch 129 Batch 5 Loss 0.713111162185669
[Train] epoch 129 Batch 7 Loss 0.5472874939441681
[Train] epoch 129 Batch 9 Loss 0.9171896874904633
[Train] epoch 129 Batch 11 Loss 0.840780109167099
[TEST] epoch 130 Loss 2.5116666555404663
[Train] epoch 130 Batch 1 Loss 0.5784480273723602
[Train] epoch 130 Batch 3 Loss 0.6100517362356186
[Train] epoch 130 Batch 5 Loss 0.8905147016048431
[Train] epoch 130 Batch 7 Loss 0.6389240026473999
[Train] epoch 130 Batch 9 Loss 0.8540494441986084
[Train] epoch 130 Batch 11 Loss 0.6710872054100037
[Train] epoch 131 Batch 1 Loss 0.5382489860057831
[Train] epoch 131 Batch 3 Loss 0.6443945169448853
[Train] epoch 131 Batch 5 Loss 0.984715610742569
[Train] epoch 131 Batch 7 Loss 0.8296463489532471
[Train] epoch 131 Batch 9 Loss 0.4640260860323906
[Train] epoch 131 Batch 11 Loss 0.8146536946296692
[Train] epoch 132 Batch 1 Loss 0.7601149082183838
[Train] epoch 132 Batch 3 Loss 0.62709841132164
[Train] epoch 132 Batch 5 Loss 0.46141432225704193
[Train] epoch 132 Batch 7 Loss 0.8216837644577026
[Train] epoch 132 Batch 9 Loss 0.8931659460067749
[Train] epoch 132 Batch 11 Loss 0.624945729970932
[Train] epoch 133 Batch 1 Loss 0.6770007610321045
[Train] epoch 133 Batch 3 Loss 0.4623218923807144
[Train] epoch 133 Batch 5 Loss 0.6620416939258575
[Train] epoch 133 Batch 7 Loss 0.8712897300720215
[Train] epoch 133 Batch 9 Loss 0.768314927816391
[Train] epoch 133 Batch 11 Loss 0.8567315936088562
[Train] epoch 134 Batch 1 Loss 0.45354241132736206
[Train] epoch 134 Batch 3 Loss 0.8400047123432159
[Train] epoch 134 Batch 5 Loss 0.7219148874282837
[Train] epoch 134 Batch 7 Loss 0.762312263250351
[Train] epoch 134 Batch 9 Loss 0.9442195892333984
[Train] epoch 134 Batch 11 Loss 0.5296794772148132
[TEST] epoch 135 Loss 2.262127081553141
[Train] epoch 135 Batch 1 Loss 0.7844640910625458
[Train] epoch 135 Batch 3 Loss 0.8563096523284912
[Train] epoch 135 Batch 5 Loss 0.6199059188365936
[Train] epoch 135 Batch 7 Loss 0.5923466980457306
[Train] epoch 135 Batch 9 Loss 0.7246324419975281
[Train] epoch 135 Batch 11 Loss 0.7314870357513428
[Train] epoch 136 Batch 1 Loss 0.7097170054912567
[Train] epoch 136 Batch 3 Loss 0.764830082654953
[Train] epoch 136 Batch 5 Loss 0.8823559284210205
[Train] epoch 136 Batch 7 Loss 0.2944650948047638
[Train] epoch 136 Batch 9 Loss 0.8100855350494385
[Train] epoch 136 Batch 11 Loss 0.7287135720252991
[Train] epoch 137 Batch 1 Loss 0.37325024604797363
[Train] epoch 137 Batch 3 Loss 0.48551349341869354
[Train] epoch 137 Batch 5 Loss 0.7014061808586121
[Train] epoch 137 Batch 7 Loss 0.7762969136238098
[Train] epoch 137 Batch 9 Loss 1.2740036249160767
[Train] epoch 137 Batch 11 Loss 0.6605913043022156
[Train] epoch 138 Batch 1 Loss 0.586811900138855
[Train] epoch 138 Batch 3 Loss 0.584908626973629
[Train] epoch 138 Batch 5 Loss 0.37851111590862274
[Train] epoch 138 Batch 7 Loss 0.903369277715683
[Train] epoch 138 Batch 9 Loss 0.5759393125772476
[Train] epoch 138 Batch 11 Loss 1.1853770315647125
[Train] epoch 139 Batch 1 Loss 0.9337987899780273
[Train] epoch 139 Batch 3 Loss 0.5944506525993347
[Train] epoch 139 Batch 5 Loss 0.515403538942337
[Train] epoch 139 Batch 7 Loss 0.6376253664493561
[Train] epoch 139 Batch 9 Loss 0.6200897991657257
[Train] epoch 139 Batch 11 Loss 0.9761076271533966
[TEST] epoch 140 Loss 2.3159549236297607
[Train] epoch 140 Batch 1 Loss 0.7928167879581451
[Train] epoch 140 Batch 3 Loss 0.7554275393486023
[Train] epoch 140 Batch 5 Loss 0.625480979681015
[Train] epoch 140 Batch 7 Loss 0.555600568652153
[Train] epoch 140 Batch 9 Loss 0.7158340513706207
[Train] epoch 140 Batch 11 Loss 0.8223179280757904
[Train] epoch 141 Batch 1 Loss 0.8588981926441193
[Train] epoch 141 Batch 3 Loss 0.7570204734802246
[Train] epoch 141 Batch 5 Loss 0.693787157535553
[Train] epoch 141 Batch 7 Loss 0.6299723982810974
[Train] epoch 141 Batch 9 Loss 0.6295590400695801
[Train] epoch 141 Batch 11 Loss 0.673124372959137
[Train] epoch 142 Batch 1 Loss 0.570316344499588
[Train] epoch 142 Batch 3 Loss 0.976018488407135
[Train] epoch 142 Batch 5 Loss 0.7120873183012009
[Train] epoch 142 Batch 7 Loss 0.4219234585762024
[Train] epoch 142 Batch 9 Loss 0.6326645910739899
[Train] epoch 142 Batch 11 Loss 0.9511661231517792
[Train] epoch 143 Batch 1 Loss 0.6447255313396454
[Train] epoch 143 Batch 3 Loss 0.7163967788219452
[Train] epoch 143 Batch 5 Loss 1.0275002121925354
[Train] epoch 143 Batch 7 Loss 0.8493613302707672
[Train] epoch 143 Batch 9 Loss 0.4772745370864868
[Train] epoch 143 Batch 11 Loss 0.5448095798492432
[Train] epoch 144 Batch 1 Loss 0.8174232840538025
[Train] epoch 144 Batch 3 Loss 0.34701472520828247
[Train] epoch 144 Batch 5 Loss 0.6794615089893341
[Train] epoch 144 Batch 7 Loss 0.9617623686790466
[Train] epoch 144 Batch 9 Loss 0.6216374337673187
[Train] epoch 144 Batch 11 Loss 0.7998514473438263
[TEST] epoch 145 Loss 2.5526532729466758
[Train] epoch 145 Batch 1 Loss 0.5138691663742065
[Train] epoch 145 Batch 3 Loss 0.6874979734420776
[Train] epoch 145 Batch 5 Loss 0.7750272154808044
[Train] epoch 145 Batch 7 Loss 0.5867116451263428
[Train] epoch 145 Batch 9 Loss 0.8318834900856018
[Train] epoch 145 Batch 11 Loss 0.8581863045692444
[Train] epoch 146 Batch 1 Loss 0.6113686114549637
[Train] epoch 146 Batch 3 Loss 0.6391369998455048
[Train] epoch 146 Batch 5 Loss 0.5349674224853516
[Train] epoch 146 Batch 7 Loss 0.8527578413486481
[Train] epoch 146 Batch 9 Loss 0.8020247891545296
[Train] epoch 146 Batch 11 Loss 0.7112629115581512
[Train] epoch 147 Batch 1 Loss 0.6715733408927917
[Train] epoch 147 Batch 3 Loss 0.614738255739212
[Train] epoch 147 Batch 5 Loss 0.6482508480548859
[Train] epoch 147 Batch 7 Loss 0.9370467662811279
[Train] epoch 147 Batch 9 Loss 0.7831040620803833
[Train] epoch 147 Batch 11 Loss 0.5279705375432968
[Train] epoch 148 Batch 1 Loss 0.9594901204109192
[Train] epoch 148 Batch 3 Loss 0.5142431855201721
[Train] epoch 148 Batch 5 Loss 0.5716438740491867
[Train] epoch 148 Batch 7 Loss 0.7293461561203003
[Train] epoch 148 Batch 9 Loss 0.7271781265735626
[Train] epoch 148 Batch 11 Loss 0.7587676048278809
[Train] epoch 149 Batch 1 Loss 0.7526279538869858
[Train] epoch 149 Batch 3 Loss 0.6604167520999908
[Train] epoch 149 Batch 5 Loss 0.5892770886421204
[Train] epoch 149 Batch 7 Loss 0.6229840517044067
[Train] epoch 149 Batch 9 Loss 0.7683829367160797
[Train] epoch 149 Batch 11 Loss 0.7757585644721985
[TEST] epoch 150 Loss 2.4180249770482383
[Train] epoch 150 Batch 1 Loss 0.7184388637542725
[Train] epoch 150 Batch 3 Loss 1.01946622133255
[Train] epoch 150 Batch 5 Loss 0.3548278212547302
[Train] epoch 150 Batch 7 Loss 0.8186672627925873
[Train] epoch 150 Batch 9 Loss 0.7000990808010101
[Train] epoch 150 Batch 11 Loss 0.6056457459926605
[Train] epoch 151 Batch 1 Loss 0.7347723245620728
[Train] epoch 151 Batch 3 Loss 0.4222656488418579
[Train] epoch 151 Batch 5 Loss 0.6944767832756042
[Train] epoch 151 Batch 7 Loss 0.959493488073349
[Train] epoch 151 Batch 9 Loss 0.5967058688402176
[Train] epoch 151 Batch 11 Loss 0.7633988708257675
[Train] epoch 152 Batch 1 Loss 0.39134837687015533
[Train] epoch 152 Batch 3 Loss 0.791691243648529
[Train] epoch 152 Batch 5 Loss 0.5444517582654953
[Train] epoch 152 Batch 7 Loss 0.8850511312484741
[Train] epoch 152 Batch 9 Loss 0.7324525415897369
[Train] epoch 152 Batch 11 Loss 0.8080253005027771
[Train] epoch 153 Batch 1 Loss 0.6370959877967834
[Train] epoch 153 Batch 3 Loss 0.7119211256504059
[Train] epoch 153 Batch 5 Loss 0.4446194916963577
[Train] epoch 153 Batch 7 Loss 1.0212152898311615
[Train] epoch 153 Batch 9 Loss 0.5899929702281952
[Train] epoch 153 Batch 11 Loss 0.7431558966636658
[Train] epoch 154 Batch 1 Loss 0.7313268184661865
[Train] epoch 154 Batch 3 Loss 0.6689954996109009
[Train] epoch 154 Batch 5 Loss 0.726452648639679
[Train] epoch 154 Batch 7 Loss 0.8364840447902679
[Train] epoch 154 Batch 9 Loss 0.6753527522087097
[Train] epoch 154 Batch 11 Loss 0.6019607782363892
[TEST] epoch 155 Loss 2.6148542960484824
[Train] epoch 155 Batch 1 Loss 0.5604694485664368
[Train] epoch 155 Batch 3 Loss 0.7289933860301971
[Train] epoch 155 Batch 5 Loss 0.7013570666313171
[Train] epoch 155 Batch 7 Loss 0.7911185622215271
[Train] epoch 155 Batch 9 Loss 0.8704207390546799
[Train] epoch 155 Batch 11 Loss 0.4896647483110428
[Train] epoch 156 Batch 1 Loss 0.8837645053863525
[Train] epoch 156 Batch 3 Loss 0.8153745532035828
[Train] epoch 156 Batch 5 Loss 0.5893198251724243
[Train] epoch 156 Batch 7 Loss 0.8091953694820404
[Train] epoch 156 Batch 9 Loss 0.6402169764041901
[Train] epoch 156 Batch 11 Loss 0.488222137093544
[Train] epoch 157 Batch 1 Loss 0.4772260785102844
[Train] epoch 157 Batch 3 Loss 0.658160388469696
[Train] epoch 157 Batch 5 Loss 1.140157699584961
[Train] epoch 157 Batch 7 Loss 0.26957379281520844
[Train] epoch 157 Batch 9 Loss 0.8475601375102997
[Train] epoch 157 Batch 11 Loss 0.8714521527290344
[Train] epoch 158 Batch 1 Loss 0.6643704324960709
[Train] epoch 158 Batch 3 Loss 0.4669773355126381
[Train] epoch 158 Batch 5 Loss 0.795630156993866
[Train] epoch 158 Batch 7 Loss 0.8037295043468475
[Train] epoch 158 Batch 9 Loss 0.7054996639490128
[Train] epoch 158 Batch 11 Loss 0.7472270727157593
[Train] epoch 159 Batch 1 Loss 0.5835485905408859
[Train] epoch 159 Batch 3 Loss 0.4894099831581116
[Train] epoch 159 Batch 5 Loss 0.8150123953819275
[Train] epoch 159 Batch 7 Loss 0.7879364192485809
[Train] epoch 159 Batch 9 Loss 0.585671678185463
[Train] epoch 159 Batch 11 Loss 0.9502317309379578
[TEST] epoch 160 Loss 2.7062848806381226
[Train] epoch 160 Batch 1 Loss 0.8294828236103058
[Train] epoch 160 Batch 3 Loss 0.5154557973146439
[Train] epoch 160 Batch 5 Loss 1.0690972805023193
[Train] epoch 160 Batch 7 Loss 0.6614190340042114
[Train] epoch 160 Batch 9 Loss 0.5139082074165344
[Train] epoch 160 Batch 11 Loss 0.7854022979736328
[Train] epoch 161 Batch 1 Loss 0.6853935718536377
[Train] epoch 161 Batch 3 Loss 0.7217041552066803
[Train] epoch 161 Batch 5 Loss 0.7738967537879944
[Train] epoch 161 Batch 7 Loss 0.683392196893692
[Train] epoch 161 Batch 9 Loss 0.49016672372817993
[Train] epoch 161 Batch 11 Loss 0.8143351376056671
[Train] epoch 162 Batch 1 Loss 0.5784640312194824
[Train] epoch 162 Batch 3 Loss 0.8819702565670013
[Train] epoch 162 Batch 5 Loss 0.7726459503173828
[Train] epoch 162 Batch 7 Loss 0.7039580196142197
[Train] epoch 162 Batch 9 Loss 0.5000305473804474
[Train] epoch 162 Batch 11 Loss 0.7370952069759369
[Train] epoch 163 Batch 1 Loss 0.6859905123710632
[Train] epoch 163 Batch 3 Loss 0.7824451923370361
[Train] epoch 163 Batch 5 Loss 0.9728241860866547
[Train] epoch 163 Batch 7 Loss 0.48607469350099564
[Train] epoch 163 Batch 9 Loss 0.6224221885204315
[Train] epoch 163 Batch 11 Loss 0.728855311870575
[Train] epoch 164 Batch 1 Loss 0.8363843560218811
[Train] epoch 164 Batch 3 Loss 0.6812053918838501
[Train] epoch 164 Batch 5 Loss 0.4292392432689667
[Train] epoch 164 Batch 7 Loss 0.9027712643146515
[Train] epoch 164 Batch 9 Loss 0.5460998266935349
[Train] epoch 164 Batch 11 Loss 0.7692313939332962
[TEST] epoch 165 Loss 1.9551560878753662
[Train] epoch 165 Batch 1 Loss 0.6297985017299652
[Train] epoch 165 Batch 3 Loss 0.8262320458889008
[Train] epoch 165 Batch 5 Loss 0.7677203416824341
[Train] epoch 165 Batch 7 Loss 0.9888653457164764
[Train] epoch 165 Batch 9 Loss 0.5995959341526031
[Train] epoch 165 Batch 11 Loss 0.4963001608848572
[Train] epoch 166 Batch 1 Loss 0.8160769194364548
[Train] epoch 166 Batch 3 Loss 0.6406558156013489
[Train] epoch 166 Batch 5 Loss 0.7280016243457794
[Train] epoch 166 Batch 7 Loss 0.8005569577217102
[Train] epoch 166 Batch 9 Loss 0.5251733213663101
[Train] epoch 166 Batch 11 Loss 0.6087723672389984
[Train] epoch 167 Batch 1 Loss 0.5830550938844681
[Train] epoch 167 Batch 3 Loss 0.4819851219654083
[Train] epoch 167 Batch 5 Loss 0.8299468755722046
[Train] epoch 167 Batch 7 Loss 1.1248722672462463
[Train] epoch 167 Batch 9 Loss 0.6336125433444977
[Train] epoch 167 Batch 11 Loss 0.6596772521734238
[Train] epoch 168 Batch 1 Loss 0.5956761837005615
[Train] epoch 168 Batch 3 Loss 0.8351904153823853
[Train] epoch 168 Batch 5 Loss 0.7643929123878479
[Train] epoch 168 Batch 7 Loss 0.7365889847278595
[Train] epoch 168 Batch 9 Loss 0.4998244345188141
[Train] epoch 168 Batch 11 Loss 0.7463203966617584
[Train] epoch 169 Batch 1 Loss 0.6054047644138336
[Train] epoch 169 Batch 3 Loss 0.5317214131355286
[Train] epoch 169 Batch 5 Loss 0.6207828521728516
[Train] epoch 169 Batch 7 Loss 0.6868302226066589
[Train] epoch 169 Batch 9 Loss 0.9694018065929413
[Train] epoch 169 Batch 11 Loss 0.7586928308010101
[TEST] epoch 170 Loss 2.2061391274134317
[Train] epoch 170 Batch 1 Loss 0.5380728244781494
[Train] epoch 170 Batch 3 Loss 0.5975487232208252
[Train] epoch 170 Batch 5 Loss 1.1739194989204407
[Train] epoch 170 Batch 7 Loss 0.4514176994562149
[Train] epoch 170 Batch 9 Loss 0.7402695119380951
[Train] epoch 170 Batch 11 Loss 0.7279769778251648
[Train] epoch 171 Batch 1 Loss 0.5552094727754593
[Train] epoch 171 Batch 3 Loss 0.7799329161643982
[Train] epoch 171 Batch 5 Loss 0.6662116944789886
[Train] epoch 171 Batch 7 Loss 0.842785507440567
[Train] epoch 171 Batch 9 Loss 0.7842422723770142
[Train] epoch 171 Batch 11 Loss 0.49021343886852264
[Train] epoch 172 Batch 1 Loss 0.6433071941137314
[Train] epoch 172 Batch 3 Loss 0.6069531142711639
[Train] epoch 172 Batch 5 Loss 0.3601124584674835
[Train] epoch 172 Batch 7 Loss 0.6056662201881409
[Train] epoch 172 Batch 9 Loss 0.737915426492691
[Train] epoch 172 Batch 11 Loss 1.3796309232711792
[Train] epoch 173 Batch 1 Loss 0.5884678959846497
[Train] epoch 173 Batch 3 Loss 0.7371042966842651
[Train] epoch 173 Batch 5 Loss 0.7429360747337341
[Train] epoch 173 Batch 7 Loss 0.5873216092586517
[Train] epoch 173 Batch 9 Loss 0.801496684551239
[Train] epoch 173 Batch 11 Loss 0.769085168838501
[Train] epoch 174 Batch 1 Loss 0.6204611659049988
[Train] epoch 174 Batch 3 Loss 0.5920983552932739
[Train] epoch 174 Batch 5 Loss 0.6801992356777191
[Train] epoch 174 Batch 7 Loss 0.5156021639704704
[Train] epoch 174 Batch 9 Loss 0.8225218951702118
[Train] epoch 174 Batch 11 Loss 0.9953359067440033
[TEST] epoch 175 Loss 2.7567646503448486
[Train] epoch 175 Batch 1 Loss 0.7482916712760925
[Train] epoch 175 Batch 3 Loss 0.8672946393489838
[Train] epoch 175 Batch 5 Loss 0.6272813677787781
[Train] epoch 175 Batch 7 Loss 0.621516078710556
[Train] epoch 175 Batch 9 Loss 0.7752529978752136
[Train] epoch 175 Batch 11 Loss 0.668554037809372
[Train] epoch 176 Batch 1 Loss 0.7018973231315613
[Train] epoch 176 Batch 3 Loss 0.7066364288330078
[Train] epoch 176 Batch 5 Loss 0.6000025570392609
[Train] epoch 176 Batch 7 Loss 0.8154129832983017
[Train] epoch 176 Batch 9 Loss 0.7108465284109116
[Train] epoch 176 Batch 11 Loss 0.6004451811313629
[Train] epoch 177 Batch 1 Loss 0.4893490970134735
[Train] epoch 177 Batch 3 Loss 0.513024091720581
[Train] epoch 177 Batch 5 Loss 0.9865826070308685
[Train] epoch 177 Batch 7 Loss 0.9323354959487915
[Train] epoch 177 Batch 9 Loss 0.7890883088111877
[Train] epoch 177 Batch 11 Loss 0.5066535845398903
[Train] epoch 178 Batch 1 Loss 0.5660541951656342
[Train] epoch 178 Batch 3 Loss 0.7533833682537079
[Train] epoch 178 Batch 5 Loss 1.023359328508377
[Train] epoch 178 Batch 7 Loss 0.6630344092845917
[Train] epoch 178 Batch 9 Loss 0.4770561754703522
[Train] epoch 178 Batch 11 Loss 0.7080394923686981
[Train] epoch 179 Batch 1 Loss 0.8118411302566528
[Train] epoch 179 Batch 3 Loss 0.6121518015861511
[Train] epoch 179 Batch 5 Loss 0.7858140766620636
[Train] epoch 179 Batch 7 Loss 0.5574818253517151
[Train] epoch 179 Batch 9 Loss 0.4152177944779396
[Train] epoch 179 Batch 11 Loss 0.9567157030105591
[TEST] epoch 180 Loss 2.698992292086283
[Train] epoch 180 Batch 1 Loss 0.5598571300506592
[Train] epoch 180 Batch 3 Loss 0.7232381701469421
[Train] epoch 180 Batch 5 Loss 0.4440920650959015
[Train] epoch 180 Batch 7 Loss 0.9607482552528381
[Train] epoch 180 Batch 9 Loss 0.9221538603305817
[Train] epoch 180 Batch 11 Loss 0.5936432480812073
[Train] epoch 181 Batch 1 Loss 0.6003381460905075
[Train] epoch 181 Batch 3 Loss 0.3664972186088562
[Train] epoch 181 Batch 5 Loss 0.8637939989566803
[Train] epoch 181 Batch 7 Loss 0.7772527635097504
[Train] epoch 181 Batch 9 Loss 1.0629516541957855
[Train] epoch 181 Batch 11 Loss 0.5426725596189499
[Train] epoch 182 Batch 1 Loss 0.44768843054771423
[Train] epoch 182 Batch 3 Loss 1.0302163064479828
[Train] epoch 182 Batch 5 Loss 0.35336703062057495
[Train] epoch 182 Batch 7 Loss 0.7913092076778412
[Train] epoch 182 Batch 9 Loss 0.5422750115394592
[Train] epoch 182 Batch 11 Loss 0.9519741535186768
[Train] epoch 183 Batch 1 Loss 0.49552343785762787
[Train] epoch 183 Batch 3 Loss 0.7452279925346375
[Train] epoch 183 Batch 5 Loss 0.5120804309844971
[Train] epoch 183 Batch 7 Loss 0.6585381925106049
[Train] epoch 183 Batch 9 Loss 0.8794366717338562
[Train] epoch 183 Batch 11 Loss 0.8165782690048218
[Train] epoch 184 Batch 1 Loss 0.8453473448753357
[Train] epoch 184 Batch 3 Loss 0.5581693947315216
[Train] epoch 184 Batch 5 Loss 0.6696049571037292
[Train] epoch 184 Batch 7 Loss 0.5309591144323349
[Train] epoch 184 Batch 9 Loss 0.9756056070327759
[Train] epoch 184 Batch 11 Loss 0.5234009027481079
[TEST] epoch 185 Loss 2.7056235472361245
[Train] epoch 185 Batch 1 Loss 0.5348243713378906
[Train] epoch 185 Batch 3 Loss 0.5994674563407898
[Train] epoch 185 Batch 5 Loss 0.5853560268878937
[Train] epoch 185 Batch 7 Loss 0.6415115296840668
[Train] epoch 185 Batch 9 Loss 1.0926589667797089
[Train] epoch 185 Batch 11 Loss 0.836081251502037
[Train] epoch 186 Batch 1 Loss 0.5299406200647354
[Train] epoch 186 Batch 3 Loss 0.8660842180252075
[Train] epoch 186 Batch 5 Loss 0.570387065410614
[Train] epoch 186 Batch 7 Loss 0.552793562412262
[Train] epoch 186 Batch 9 Loss 0.8040644824504852
[Train] epoch 186 Batch 11 Loss 0.769756942987442
[Train] epoch 187 Batch 1 Loss 0.5365907102823257
[Train] epoch 187 Batch 3 Loss 0.5758339315652847
[Train] epoch 187 Batch 5 Loss 0.972391277551651
[Train] epoch 187 Batch 7 Loss 0.7509375214576721
[Train] epoch 187 Batch 9 Loss 0.613683745265007
[Train] epoch 187 Batch 11 Loss 0.6686543673276901
[Train] epoch 188 Batch 1 Loss 0.441403329372406
[Train] epoch 188 Batch 3 Loss 0.48795582354068756
[Train] epoch 188 Batch 5 Loss 0.9572254717350006
[Train] epoch 188 Batch 7 Loss 0.681372195482254
[Train] epoch 188 Batch 9 Loss 0.7957150340080261
[Train] epoch 188 Batch 11 Loss 0.7683026194572449
[Train] epoch 189 Batch 1 Loss 0.8017222285270691
[Train] epoch 189 Batch 3 Loss 0.5859465301036835
[Train] epoch 189 Batch 5 Loss 0.599056214094162
[Train] epoch 189 Batch 7 Loss 0.4985060542821884
[Train] epoch 189 Batch 9 Loss 0.8333838880062103
[Train] epoch 189 Batch 11 Loss 0.8020476996898651
[TEST] epoch 190 Loss 2.4500730832417807
[Train] epoch 190 Batch 1 Loss 0.7511304020881653
[Train] epoch 190 Batch 3 Loss 0.7187908440828323
[Train] epoch 190 Batch 5 Loss 0.6036291718482971
[Train] epoch 190 Batch 7 Loss 0.605184830725193
[Train] epoch 190 Batch 9 Loss 0.724547266960144
[Train] epoch 190 Batch 11 Loss 0.8403211832046509
[Train] epoch 191 Batch 1 Loss 0.44538310170173645
[Train] epoch 191 Batch 3 Loss 0.8217884302139282
[Train] epoch 191 Batch 5 Loss 0.6863758563995361
[Train] epoch 191 Batch 7 Loss 1.127104103565216
[Train] epoch 191 Batch 9 Loss 0.440464586019516
[Train] epoch 191 Batch 11 Loss 0.6344005763530731
[Train] epoch 192 Batch 1 Loss 0.3938663974404335
[Train] epoch 192 Batch 3 Loss 0.7792671322822571
[Train] epoch 192 Batch 5 Loss 0.5200404226779938
[Train] epoch 192 Batch 7 Loss 0.7158895432949066
[Train] epoch 192 Batch 9 Loss 0.8652026951313019
[Train] epoch 192 Batch 11 Loss 1.0678281486034393
[Train] epoch 193 Batch 1 Loss 0.6388667672872543
[Train] epoch 193 Batch 3 Loss 0.555374413728714
[Train] epoch 193 Batch 5 Loss 0.6201241165399551
[Train] epoch 193 Batch 7 Loss 0.8848127722740173
[Train] epoch 193 Batch 9 Loss 0.6525977253913879
[Train] epoch 193 Batch 11 Loss 0.7497889697551727
[Train] epoch 194 Batch 1 Loss 0.6548731029033661
[Train] epoch 194 Batch 3 Loss 0.7261761128902435
[Train] epoch 194 Batch 5 Loss 0.594915896654129
[Train] epoch 194 Batch 7 Loss 0.8231622576713562
[Train] epoch 194 Batch 9 Loss 0.7318727076053619
[Train] epoch 194 Batch 11 Loss 0.6503507494926453
[TEST] epoch 195 Loss 2.6492967208226523
[Train] epoch 195 Batch 1 Loss 0.7872191667556763
[Train] epoch 195 Batch 3 Loss 0.6764492094516754
[Train] epoch 195 Batch 5 Loss 0.5487833917140961
[Train] epoch 195 Batch 7 Loss 0.5265594571828842
[Train] epoch 195 Batch 9 Loss 0.7638014256954193
[Train] epoch 195 Batch 11 Loss 0.8567580282688141
[Train] epoch 196 Batch 1 Loss 0.7336912155151367
[Train] epoch 196 Batch 3 Loss 0.7574173212051392
[Train] epoch 196 Batch 5 Loss 0.7400864958763123
[Train] epoch 196 Batch 7 Loss 0.8118578195571899
[Train] epoch 196 Batch 9 Loss 0.5077579766511917
[Train] epoch 196 Batch 11 Loss 0.554220050573349
[Train] epoch 197 Batch 1 Loss 0.4650406241416931
[Train] epoch 197 Batch 3 Loss 0.5773313641548157
[Train] epoch 197 Batch 5 Loss 1.1591573059558868
[Train] epoch 197 Batch 7 Loss 0.7284331917762756
[Train] epoch 197 Batch 9 Loss 0.6098143458366394
[Train] epoch 197 Batch 11 Loss 0.5841992199420929
[Train] epoch 198 Batch 1 Loss 0.7696679830551147
[Train] epoch 198 Batch 3 Loss 0.6607598960399628
[Train] epoch 198 Batch 5 Loss 0.8416565954685211
[Train] epoch 198 Batch 7 Loss 0.5531030297279358
[Train] epoch 198 Batch 9 Loss 0.5422336906194687
[Train] epoch 198 Batch 11 Loss 0.754903644323349
[Train] epoch 199 Batch 1 Loss 0.6074186861515045
[Train] epoch 199 Batch 3 Loss 0.7011838555335999
[Train] epoch 199 Batch 5 Loss 0.7260218262672424
[Train] epoch 199 Batch 7 Loss 0.6524735391139984
[Train] epoch 199 Batch 9 Loss 0.5617594569921494
[Train] epoch 199 Batch 11 Loss 0.8348960876464844
Job end at 2023-04-05 15:42:52
