[Train] epoch 0 Batch 0 Loss 6.0355048179626465
[Train] epoch 0 Batch 1 Loss 3.973970651626587
[Train] epoch 0 Batch 2 Loss 5.056423664093018
[Train] epoch 0 Batch 3 Loss 4.099356651306152
[Train] epoch 0 Batch 4 Loss 5.123567581176758
[Train] epoch 0 Batch 5 Loss 4.959598541259766
[Train] epoch 0 Batch 6 Loss 4.269822120666504
[Train] epoch 0 Batch 7 Loss 4.580146789550781
[Train] epoch 0 Batch 8 Loss 3.9045886993408203
[Train] epoch 0 Batch 9 Loss 4.926992893218994
[Train] epoch 0 Batch 10 Loss 4.439000129699707
[Train] epoch 0 Batch 11 Loss 2.528629779815674
[Train] epoch 0 Batch 12 Loss 4.237789154052734
[Train] epoch 0 Batch 13 Loss 3.6693196296691895
[Train] epoch 0 Batch 14 Loss 4.770779609680176
[Train] epoch 0 Batch 15 Loss 4.459198951721191
[Train] epoch 0 Batch 16 Loss 3.2531208992004395
[Train] epoch 0 Batch 17 Loss 4.697879314422607
[Train] epoch 0 Batch 18 Loss 4.740229606628418
[Train] epoch 0 Batch 19 Loss 4.928836822509766
[Train] epoch 0 Batch 20 Loss 5.160671710968018
[Train] epoch 0 Batch 21 Loss 3.528744697570801
[Train] epoch 0 Batch 22 Loss 3.3963992595672607
[Train] epoch 0 Batch 23 Loss 3.671680450439453
[Train] epoch 0 Batch 24 Loss 3.4843337535858154
[Train] epoch 0 Batch 25 Loss 5.096145153045654
[Train] epoch 0 Batch 26 Loss 5.7245774269104
[Train] epoch 0 Batch 27 Loss 3.5238125324249268
[Train] epoch 0 Batch 28 Loss 4.302033424377441
[Train] epoch 0 Batch 29 Loss 2.7135796546936035
[Train] epoch 0 Batch 30 Loss 3.2264938354492188
[Train] epoch 0 Batch 31 Loss 5.087360858917236
[Train] epoch 0 Batch 32 Loss 2.6460883617401123
[Train] epoch 0 Batch 33 Loss 3.349219799041748
[Train] epoch 0 Batch 34 Loss 4.0065507888793945
[Train] epoch 0 Batch 35 Loss 3.9493954181671143
[Train] epoch 0 Batch 36 Loss 3.095609188079834
[Train] epoch 0 Batch 37 Loss 3.5741472244262695
[Train] epoch 0 Batch 38 Loss 3.7400598526000977
[Train] epoch 0 Batch 39 Loss 3.338181257247925
[Train] epoch 0 Batch 40 Loss 3.398695945739746
[Train] epoch 0 Batch 41 Loss 3.0263752937316895
[Train] epoch 0 Batch 42 Loss 2.2726831436157227
[Train] epoch 0 Batch 43 Loss 2.2321128845214844
[Train] epoch 0 Batch 44 Loss 3.6694347858428955
[Train] epoch 0 Batch 45 Loss 2.4814682006835938
[Train] epoch 0 Batch 46 Loss 2.456378936767578
[Train] epoch 0 Batch 47 Loss 2.8387563228607178
[Train] epoch 1 Batch 0 Loss 4.1355180740356445
[Train] epoch 1 Batch 1 Loss 3.165930986404419
[Train] epoch 1 Batch 2 Loss 4.056096076965332
[Train] epoch 1 Batch 3 Loss 3.771137237548828
[Train] epoch 1 Batch 4 Loss 4.972335338592529
[Train] epoch 1 Batch 5 Loss 4.817723751068115
[Train] epoch 1 Batch 6 Loss 3.049530029296875
[Train] epoch 1 Batch 7 Loss 3.4443554878234863
[Train] epoch 1 Batch 8 Loss 3.7785708904266357
[Train] epoch 1 Batch 9 Loss 4.548216819763184
[Train] epoch 1 Batch 10 Loss 2.938690423965454
[Train] epoch 1 Batch 11 Loss 1.4861830472946167
[Train] epoch 1 Batch 12 Loss 2.627331495285034
[Train] epoch 1 Batch 13 Loss 2.3879506587982178
[Train] epoch 1 Batch 14 Loss 2.8847885131835938
[Train] epoch 1 Batch 15 Loss 3.7038471698760986
[Train] epoch 1 Batch 16 Loss 3.1736369132995605
[Train] epoch 1 Batch 17 Loss 2.6184961795806885
[Train] epoch 1 Batch 18 Loss 3.1371326446533203
[Train] epoch 1 Batch 19 Loss 2.6093196868896484
[Train] epoch 1 Batch 20 Loss 2.0642974376678467
[Train] epoch 1 Batch 21 Loss 1.904901146888733
[Train] epoch 1 Batch 22 Loss 1.8100652694702148
[Train] epoch 1 Batch 23 Loss 2.1958205699920654
[Train] epoch 1 Batch 24 Loss 2.29152512550354
[Train] epoch 1 Batch 25 Loss 2.2861735820770264
[Train] epoch 1 Batch 26 Loss 2.5337324142456055
[Train] epoch 1 Batch 27 Loss 3.09525990486145
[Train] epoch 1 Batch 28 Loss 2.167487859725952
[Train] epoch 1 Batch 29 Loss 1.8798187971115112
[Train] epoch 1 Batch 30 Loss 1.5236328840255737
[Train] epoch 1 Batch 31 Loss 2.09963059425354
[Train] epoch 1 Batch 32 Loss 1.646295428276062
[Train] epoch 1 Batch 33 Loss 2.8084280490875244
[Train] epoch 1 Batch 34 Loss 2.0171079635620117
[Train] epoch 1 Batch 35 Loss 1.8431305885314941
[Train] epoch 1 Batch 36 Loss 1.6602604389190674
[Train] epoch 1 Batch 37 Loss 1.650247573852539
[Train] epoch 1 Batch 38 Loss 1.7217011451721191
[Train] epoch 1 Batch 39 Loss 1.3811984062194824
[Train] epoch 1 Batch 40 Loss 2.7580513954162598
[Train] epoch 1 Batch 41 Loss 2.6723992824554443
[Train] epoch 1 Batch 42 Loss 2.8216652870178223
[Train] epoch 1 Batch 43 Loss 2.4669597148895264
[Train] epoch 1 Batch 44 Loss 2.289607524871826
[Train] epoch 1 Batch 45 Loss 2.1651883125305176
[Train] epoch 1 Batch 46 Loss 2.5083303451538086
[Train] epoch 1 Batch 47 Loss 2.5009095668792725
[Train] epoch 2 Batch 0 Loss 1.5908480882644653
[Train] epoch 2 Batch 1 Loss 1.612565517425537
[Train] epoch 2 Batch 2 Loss 2.531599521636963
[Train] epoch 2 Batch 3 Loss 1.421920657157898
[Train] epoch 2 Batch 4 Loss 2.0123937129974365
[Train] epoch 2 Batch 5 Loss 2.0191919803619385
[Train] epoch 2 Batch 6 Loss 1.4075860977172852
[Train] epoch 2 Batch 7 Loss 1.7914625406265259
[Train] epoch 2 Batch 8 Loss 2.666672468185425
[Train] epoch 2 Batch 9 Loss 1.27778160572052
[Train] epoch 2 Batch 10 Loss 1.5734152793884277
[Train] epoch 2 Batch 11 Loss 2.200437545776367
[Train] epoch 2 Batch 12 Loss 1.7878854274749756
[Train] epoch 2 Batch 13 Loss 1.4373613595962524
[Train] epoch 2 Batch 14 Loss 0.6663213968276978
[Train] epoch 2 Batch 15 Loss 1.4382870197296143
[Train] epoch 2 Batch 16 Loss 2.059868335723877
[Train] epoch 2 Batch 17 Loss 2.3373775482177734
[Train] epoch 2 Batch 18 Loss 1.7018017768859863
[Train] epoch 2 Batch 19 Loss 1.032638430595398
[Train] epoch 2 Batch 20 Loss 1.7967493534088135
[Train] epoch 2 Batch 21 Loss 2.1469638347625732
[Train] epoch 2 Batch 22 Loss 1.6312717199325562
[Train] epoch 2 Batch 23 Loss 2.5898468494415283
[Train] epoch 2 Batch 24 Loss 1.8004390001296997
[Train] epoch 2 Batch 25 Loss 1.343685269355774
[Train] epoch 2 Batch 26 Loss 1.2438358068466187
[Train] epoch 2 Batch 27 Loss 1.3991258144378662
[Train] epoch 2 Batch 28 Loss 1.47849440574646
[Train] epoch 2 Batch 29 Loss 1.3963496685028076
[Train] epoch 2 Batch 30 Loss 1.3276042938232422
[Train] epoch 2 Batch 31 Loss 1.214111328125
[Train] epoch 2 Batch 32 Loss 1.6145249605178833
[Train] epoch 2 Batch 33 Loss 1.1761982440948486
[Train] epoch 2 Batch 34 Loss 1.2857651710510254
[Train] epoch 2 Batch 35 Loss 1.4394563436508179
[Train] epoch 2 Batch 36 Loss 1.154248595237732
[Train] epoch 2 Batch 37 Loss 1.1577606201171875
[Train] epoch 2 Batch 38 Loss 1.5247405767440796
[Train] epoch 2 Batch 39 Loss 1.065126657485962
[Train] epoch 2 Batch 40 Loss 1.002785563468933
[Train] epoch 2 Batch 41 Loss 1.2991912364959717
[Train] epoch 2 Batch 42 Loss 1.0938749313354492
[Train] epoch 2 Batch 43 Loss 1.0345150232315063
[Train] epoch 2 Batch 44 Loss 0.91990065574646
[Train] epoch 2 Batch 45 Loss 0.8501760959625244
[Train] epoch 2 Batch 46 Loss 1.0216952562332153
[Train] epoch 2 Batch 47 Loss 0.8230301141738892
[Train] epoch 3 Batch 0 Loss 0.9244033098220825
[Train] epoch 3 Batch 1 Loss 1.1495356559753418
[Train] epoch 3 Batch 2 Loss 0.9612314701080322
[Train] epoch 3 Batch 3 Loss 1.0942351818084717
[Train] epoch 3 Batch 4 Loss 1.4099589586257935
[Train] epoch 3 Batch 5 Loss 0.9062212109565735
[Train] epoch 3 Batch 6 Loss 1.1949163675308228
[Train] epoch 3 Batch 7 Loss 1.0838676691055298
[Train] epoch 3 Batch 8 Loss 0.924543023109436
[Train] epoch 3 Batch 9 Loss 0.6112041473388672
[Train] epoch 3 Batch 10 Loss 0.8426053524017334
[Train] epoch 3 Batch 11 Loss 0.8587521314620972
[Train] epoch 3 Batch 12 Loss 0.7865611910820007
[Train] epoch 3 Batch 13 Loss 0.5901741981506348
[Train] epoch 3 Batch 14 Loss 0.43882328271865845
[Train] epoch 3 Batch 15 Loss 0.6042416095733643
[Train] epoch 3 Batch 16 Loss 1.0469266176223755
[Train] epoch 3 Batch 17 Loss 0.8101491332054138
[Train] epoch 3 Batch 18 Loss 0.7105280756950378
[Train] epoch 3 Batch 19 Loss 0.9051653146743774
[Train] epoch 3 Batch 20 Loss 0.891840398311615
[Train] epoch 3 Batch 21 Loss 0.7015953660011292
[Train] epoch 3 Batch 22 Loss 0.5160449743270874
[Train] epoch 3 Batch 23 Loss 0.5865190625190735
[Train] epoch 3 Batch 24 Loss 0.5760732889175415
[Train] epoch 3 Batch 25 Loss 0.5790222883224487
[Train] epoch 3 Batch 26 Loss 0.8673350214958191
[Train] epoch 3 Batch 27 Loss 0.39514145255088806
[Train] epoch 3 Batch 28 Loss 0.498440146446228
[Train] epoch 3 Batch 29 Loss 0.3713415861129761
[Train] epoch 3 Batch 30 Loss 0.6467140913009644
[Train] epoch 3 Batch 31 Loss 0.41574347019195557
[Train] epoch 3 Batch 32 Loss 0.37371766567230225
[Train] epoch 3 Batch 33 Loss 0.48818838596343994
[Train] epoch 3 Batch 34 Loss 0.4563518166542053
[Train] epoch 3 Batch 35 Loss 0.5474299192428589
[Train] epoch 3 Batch 36 Loss 0.24200356006622314
[Train] epoch 3 Batch 37 Loss 0.5244577527046204
[Train] epoch 3 Batch 38 Loss 0.5387559533119202
[Train] epoch 3 Batch 39 Loss 0.6416460275650024
[Train] epoch 3 Batch 40 Loss 0.35332387685775757
[Train] epoch 3 Batch 41 Loss 0.46218588948249817
[Train] epoch 3 Batch 42 Loss 0.3422553539276123
[Train] epoch 3 Batch 43 Loss 0.1785373091697693
[Train] epoch 3 Batch 44 Loss 0.49327540397644043
[Train] epoch 3 Batch 45 Loss 0.7012423276901245
[Train] epoch 3 Batch 46 Loss 0.686526894569397
[Train] epoch 3 Batch 47 Loss 0.47289687395095825
[Train] epoch 4 Batch 0 Loss 0.4906368851661682
[Train] epoch 4 Batch 1 Loss 0.371682345867157
[Train] epoch 4 Batch 2 Loss 0.5307962894439697
[Train] epoch 4 Batch 3 Loss 0.48202547430992126
[Train] epoch 4 Batch 4 Loss 0.49839386343955994
[Train] epoch 4 Batch 5 Loss 0.27187371253967285
[Train] epoch 4 Batch 6 Loss 0.708465576171875
[Train] epoch 4 Batch 7 Loss 0.42605167627334595
[Train] epoch 4 Batch 8 Loss 0.5001360177993774
[Train] epoch 4 Batch 9 Loss 0.4400883615016937
[Train] epoch 4 Batch 10 Loss 0.2446724772453308
[Train] epoch 4 Batch 11 Loss 0.35613468289375305
[Train] epoch 4 Batch 12 Loss 0.3954586088657379
[Train] epoch 4 Batch 13 Loss 0.2530374228954315
[Train] epoch 4 Batch 14 Loss 0.5806311368942261
[Train] epoch 4 Batch 15 Loss 0.27660107612609863
[Train] epoch 4 Batch 16 Loss 0.3099823594093323
[Train] epoch 4 Batch 17 Loss 0.20873813331127167
[Train] epoch 4 Batch 18 Loss 0.49812909960746765
[Train] epoch 4 Batch 19 Loss 0.45355740189552307
[Train] epoch 4 Batch 20 Loss 0.18984927237033844
[Train] epoch 4 Batch 21 Loss 0.4864461421966553
[Train] epoch 4 Batch 22 Loss 0.203456848859787
[Train] epoch 4 Batch 23 Loss 0.2543640434741974
[Train] epoch 4 Batch 24 Loss 0.240602046251297
[Train] epoch 4 Batch 25 Loss 0.2553514242172241
[Train] epoch 4 Batch 26 Loss 0.4959203600883484
[Train] epoch 4 Batch 27 Loss 0.2010209858417511
[Train] epoch 4 Batch 28 Loss 0.3125755786895752
[Train] epoch 4 Batch 29 Loss 0.30327850580215454
[Train] epoch 4 Batch 30 Loss 0.3412725329399109
[Train] epoch 4 Batch 31 Loss 0.33059126138687134
[Train] epoch 4 Batch 32 Loss 0.3236587345600128
[Train] epoch 4 Batch 33 Loss 0.2945846915245056
[Train] epoch 4 Batch 34 Loss 0.48958325386047363
[Train] epoch 4 Batch 35 Loss 0.3101902902126312
[Train] epoch 4 Batch 36 Loss 0.3226584494113922
[Train] epoch 4 Batch 37 Loss 0.3715435862541199
[Train] epoch 4 Batch 38 Loss 0.3507990539073944
[Train] epoch 4 Batch 39 Loss 0.24255898594856262
[Train] epoch 4 Batch 40 Loss 0.2506779432296753
[Train] epoch 4 Batch 41 Loss 0.4278198778629303
[Train] epoch 4 Batch 42 Loss 0.46058616042137146
[Train] epoch 4 Batch 43 Loss 0.1977420151233673
[Train] epoch 4 Batch 44 Loss 0.3086012601852417
[Train] epoch 4 Batch 45 Loss 0.3042558431625366
[Train] epoch 4 Batch 46 Loss 0.2134033441543579
[Train] epoch 4 Batch 47 Loss 0.386289119720459
[Train] epoch 5 Batch 0 Loss 0.2121654748916626
[Train] epoch 5 Batch 1 Loss 0.19795584678649902
[Train] epoch 5 Batch 2 Loss 0.08974919468164444
[Train] epoch 5 Batch 3 Loss 0.2832106649875641
[Train] epoch 5 Batch 4 Loss 0.4504965543746948
[Train] epoch 5 Batch 5 Loss 0.26973968744277954
[Train] epoch 5 Batch 6 Loss 0.29147571325302124
[Train] epoch 5 Batch 7 Loss 0.18452708423137665
[Train] epoch 5 Batch 8 Loss 0.39918386936187744
[Train] epoch 5 Batch 9 Loss 0.1115393415093422
[Train] epoch 5 Batch 10 Loss 0.2369341105222702
[Train] epoch 5 Batch 11 Loss 0.27764037251472473
[Train] epoch 5 Batch 12 Loss 0.28386443853378296
[Train] epoch 5 Batch 13 Loss 0.2612566351890564
[Train] epoch 5 Batch 14 Loss 0.2628284990787506
[Train] epoch 5 Batch 15 Loss 0.382610559463501
[Train] epoch 5 Batch 16 Loss 0.23163144290447235
[Train] epoch 5 Batch 17 Loss 0.2053615152835846
[Train] epoch 5 Batch 18 Loss 0.4164773225784302
[Train] epoch 5 Batch 19 Loss 0.31211090087890625
[Train] epoch 5 Batch 20 Loss 0.4256877899169922
[Train] epoch 5 Batch 21 Loss 0.36428946256637573
[Train] epoch 5 Batch 22 Loss 0.4111771583557129
[Train] epoch 5 Batch 23 Loss 0.25960612297058105
[Train] epoch 5 Batch 24 Loss 0.36936214566230774
[Train] epoch 5 Batch 25 Loss 0.14786158502101898
[Train] epoch 5 Batch 26 Loss 0.3230642080307007
[Train] epoch 5 Batch 27 Loss 0.3470152020454407
[Train] epoch 5 Batch 28 Loss 0.2525653541088104
[Train] epoch 5 Batch 29 Loss 0.545939564704895
[Train] epoch 5 Batch 30 Loss 0.28607237339019775
[Train] epoch 5 Batch 31 Loss 0.27135416865348816
[Train] epoch 5 Batch 32 Loss 0.4568464159965515
[Train] epoch 5 Batch 33 Loss 0.1877303570508957
[Train] epoch 5 Batch 34 Loss 0.24336278438568115
[Train] epoch 5 Batch 35 Loss 0.36575478315353394
[Train] epoch 5 Batch 36 Loss 0.1577676683664322
[Train] epoch 5 Batch 37 Loss 0.27039241790771484
[Train] epoch 5 Batch 38 Loss 0.5282611846923828
[Train] epoch 5 Batch 39 Loss 0.3653308153152466
[Train] epoch 5 Batch 40 Loss 0.2005443274974823
[Train] epoch 5 Batch 41 Loss 0.40058034658432007
[Train] epoch 5 Batch 42 Loss 0.04973154515028
[Train] epoch 5 Batch 43 Loss 0.33515042066574097
[Train] epoch 5 Batch 44 Loss 0.23883336782455444
[Train] epoch 5 Batch 45 Loss 0.25971606373786926
[Train] epoch 5 Batch 46 Loss 0.3689318001270294
[Train] epoch 5 Batch 47 Loss 0.3283078670501709
[Train] epoch 6 Batch 0 Loss 0.38786062598228455
[Train] epoch 6 Batch 1 Loss 0.23504295945167542
[Train] epoch 6 Batch 2 Loss 0.3727617561817169
[Train] epoch 6 Batch 3 Loss 0.29073449969291687
[Train] epoch 6 Batch 4 Loss 0.3268747627735138
[Train] epoch 6 Batch 5 Loss 0.20824174582958221
[Train] epoch 6 Batch 6 Loss 0.38406720757484436
[Train] epoch 6 Batch 7 Loss 0.12055046856403351
[Train] epoch 6 Batch 8 Loss 0.10210353136062622
[Train] epoch 6 Batch 9 Loss 0.3787413239479065
[Train] epoch 6 Batch 10 Loss 0.2264816164970398
[Train] epoch 6 Batch 11 Loss 0.27674600481987
[Train] epoch 6 Batch 12 Loss 0.21763107180595398
[Train] epoch 6 Batch 13 Loss 0.4836403727531433
[Train] epoch 6 Batch 14 Loss 0.3059456944465637
[Train] epoch 6 Batch 15 Loss 0.18210279941558838
[Train] epoch 6 Batch 16 Loss 0.2561839818954468
[Train] epoch 6 Batch 17 Loss 0.3005613684654236
[Train] epoch 6 Batch 18 Loss 0.2985130548477173
[Train] epoch 6 Batch 19 Loss 0.14157676696777344
[Train] epoch 6 Batch 20 Loss 0.496182382106781
[Train] epoch 6 Batch 21 Loss 0.13823120296001434
[Train] epoch 6 Batch 22 Loss 0.18604491651058197
[Train] epoch 6 Batch 23 Loss 0.5049546957015991
[Train] epoch 6 Batch 24 Loss 0.28175118565559387
[Train] epoch 6 Batch 25 Loss 0.17570430040359497
[Train] epoch 6 Batch 26 Loss 0.24852785468101501
[Train] epoch 6 Batch 27 Loss 0.27649548649787903
[Train] epoch 6 Batch 28 Loss 0.30377376079559326
[Train] epoch 6 Batch 29 Loss 0.28614258766174316
[Train] epoch 6 Batch 30 Loss 0.2525668740272522
[Train] epoch 6 Batch 31 Loss 0.3872406482696533
[Train] epoch 6 Batch 32 Loss 0.3003832697868347
[Train] epoch 6 Batch 33 Loss 0.31260931491851807
[Train] epoch 6 Batch 34 Loss 0.16706742346286774
[Train] epoch 6 Batch 35 Loss 0.2296440750360489
[Train] epoch 6 Batch 36 Loss 0.36151230335235596
[Train] epoch 6 Batch 37 Loss 0.293337345123291
[Train] epoch 6 Batch 38 Loss 0.34140413999557495
[Train] epoch 6 Batch 39 Loss 0.3476793169975281
[Train] epoch 6 Batch 40 Loss 0.291864275932312
[Train] epoch 6 Batch 41 Loss 0.29202884435653687
[Train] epoch 6 Batch 42 Loss 0.31817924976348877
[Train] epoch 6 Batch 43 Loss 0.3320344090461731
[Train] epoch 6 Batch 44 Loss 0.5192521214485168
[Train] epoch 6 Batch 45 Loss 0.17468087375164032
[Train] epoch 6 Batch 46 Loss 0.4409738779067993
[Train] epoch 6 Batch 47 Loss 0.33773818612098694
[Train] epoch 7 Batch 0 Loss 0.5072234869003296
[Train] epoch 7 Batch 1 Loss 0.21055394411087036
[Train] epoch 7 Batch 2 Loss 0.24111367762088776
[Train] epoch 7 Batch 3 Loss 0.4552941918373108
[Train] epoch 7 Batch 4 Loss 0.555540144443512
[Train] epoch 7 Batch 5 Loss 0.5954633951187134
[Train] epoch 7 Batch 6 Loss 0.36254870891571045
[Train] epoch 7 Batch 7 Loss 0.46270227432250977
[Train] epoch 7 Batch 8 Loss 0.2992628514766693
[Train] epoch 7 Batch 9 Loss 0.35656067728996277
[Train] epoch 7 Batch 10 Loss 0.3091789484024048
[Train] epoch 7 Batch 11 Loss 0.29785996675491333
[Train] epoch 7 Batch 12 Loss 0.2752263844013214
[Train] epoch 7 Batch 13 Loss 0.3750828802585602
[Train] epoch 7 Batch 14 Loss 0.3741862177848816
[Train] epoch 7 Batch 15 Loss 0.3075229227542877
[Train] epoch 7 Batch 16 Loss 0.45767539739608765
[Train] epoch 7 Batch 17 Loss 0.3899579644203186
[Train] epoch 7 Batch 18 Loss 0.17142799496650696
[Train] epoch 7 Batch 19 Loss 0.40444567799568176
[Train] epoch 7 Batch 20 Loss 0.4317874312400818
[Train] epoch 7 Batch 21 Loss 0.29532840847969055
[Train] epoch 7 Batch 22 Loss 0.43141794204711914
[Train] epoch 7 Batch 23 Loss 0.5455788969993591
[Train] epoch 7 Batch 24 Loss 0.23959797620773315
[Train] epoch 7 Batch 25 Loss 0.14411410689353943
[Train] epoch 7 Batch 26 Loss 0.1844286322593689
[Train] epoch 7 Batch 27 Loss 0.25108015537261963
[Train] epoch 7 Batch 28 Loss 0.26885390281677246
[Train] epoch 7 Batch 29 Loss 0.1113465428352356
[Train] epoch 7 Batch 30 Loss 0.1498386561870575
[Train] epoch 7 Batch 31 Loss 0.1592191755771637
[Train] epoch 7 Batch 32 Loss 0.17193302512168884
[Train] epoch 7 Batch 33 Loss 0.29218313097953796
[Train] epoch 7 Batch 34 Loss 0.1852128952741623
[Train] epoch 7 Batch 35 Loss 0.24476948380470276
[Train] epoch 7 Batch 36 Loss 0.2993439733982086
[Train] epoch 7 Batch 37 Loss 0.25540706515312195
[Train] epoch 7 Batch 38 Loss 0.32419639825820923
[Train] epoch 7 Batch 39 Loss 0.3254427909851074
[Train] epoch 7 Batch 40 Loss 0.14888176321983337
[Train] epoch 7 Batch 41 Loss 0.2718440890312195
[Train] epoch 7 Batch 42 Loss 0.37451714277267456
[Train] epoch 7 Batch 43 Loss 0.18612666428089142
[Train] epoch 7 Batch 44 Loss 0.16934245824813843
[Train] epoch 7 Batch 45 Loss 0.2816624045372009
[Train] epoch 7 Batch 46 Loss 0.2465973198413849
[Train] epoch 7 Batch 47 Loss 0.30917537212371826
[Train] epoch 8 Batch 0 Loss 0.19104859232902527
[Train] epoch 8 Batch 1 Loss 0.30932313203811646
[Train] epoch 8 Batch 2 Loss 0.4427229166030884
[Train] epoch 8 Batch 3 Loss 0.32127469778060913
[Train] epoch 8 Batch 4 Loss 0.31766608357429504
[Train] epoch 8 Batch 5 Loss 0.18461361527442932
[Train] epoch 8 Batch 6 Loss 0.3549281656742096
[Train] epoch 8 Batch 7 Loss 0.4254807233810425
[Train] epoch 8 Batch 8 Loss 0.32204538583755493
[Train] epoch 8 Batch 9 Loss 0.36575233936309814
[Train] epoch 8 Batch 10 Loss 0.5231965780258179
[Train] epoch 8 Batch 11 Loss 0.25518593192100525
[Train] epoch 8 Batch 12 Loss 0.20026828348636627
[Train] epoch 8 Batch 13 Loss 0.10254573822021484
[Train] epoch 8 Batch 14 Loss 0.3749229907989502
[Train] epoch 8 Batch 15 Loss 0.3080245554447174
[Train] epoch 8 Batch 16 Loss 0.3913527727127075
[Train] epoch 8 Batch 17 Loss 0.1683400571346283
[Train] epoch 8 Batch 18 Loss 0.28935298323631287
[Train] epoch 8 Batch 19 Loss 0.18517616391181946
[Train] epoch 8 Batch 20 Loss 0.1703881323337555
[Train] epoch 8 Batch 21 Loss 0.16644233465194702
[Train] epoch 8 Batch 22 Loss 0.3064861595630646
[Train] epoch 8 Batch 23 Loss 0.22497090697288513
[Train] epoch 8 Batch 24 Loss 0.4014376997947693
[Train] epoch 8 Batch 25 Loss 0.3570433259010315
[Train] epoch 8 Batch 26 Loss 0.27979153394699097
[Train] epoch 8 Batch 27 Loss 0.35396844148635864
[Train] epoch 8 Batch 28 Loss 0.17879274487495422
[Train] epoch 8 Batch 29 Loss 0.4042122960090637
[Train] epoch 8 Batch 30 Loss 0.26225292682647705
[Train] epoch 8 Batch 31 Loss 0.301862508058548
[Train] epoch 8 Batch 32 Loss 0.35763365030288696
[Train] epoch 8 Batch 33 Loss 0.4500197768211365
[Train] epoch 8 Batch 34 Loss 0.33663445711135864
[Train] epoch 8 Batch 35 Loss 0.16036537289619446
[Train] epoch 8 Batch 36 Loss 0.3150958716869354
[Train] epoch 8 Batch 37 Loss 0.3457680940628052
[Train] epoch 8 Batch 38 Loss 0.25683513283729553
[Train] epoch 8 Batch 39 Loss 0.17285016179084778
[Train] epoch 8 Batch 40 Loss 0.2958815395832062
[Train] epoch 8 Batch 41 Loss 0.2125486135482788
[Train] epoch 8 Batch 42 Loss 0.2666487991809845
[Train] epoch 8 Batch 43 Loss 0.14116166532039642
[Train] epoch 8 Batch 44 Loss 0.26211437582969666
[Train] epoch 8 Batch 45 Loss 0.23109298944473267
[Train] epoch 8 Batch 46 Loss 0.42250362038612366
[Train] epoch 8 Batch 47 Loss 0.3786846399307251
[Train] epoch 9 Batch 0 Loss 0.26197031140327454
[Train] epoch 9 Batch 1 Loss 0.22201627492904663
[Train] epoch 9 Batch 2 Loss 0.3299908936023712
[Train] epoch 9 Batch 3 Loss 0.3415387272834778
[Train] epoch 9 Batch 4 Loss 0.23507128655910492
[Train] epoch 9 Batch 5 Loss 0.31022483110427856
[Train] epoch 9 Batch 6 Loss 0.08089114725589752
[Train] epoch 9 Batch 7 Loss 0.4177037477493286
[Train] epoch 9 Batch 8 Loss 0.13252811133861542
[Train] epoch 9 Batch 9 Loss 0.32337686419487
[Train] epoch 9 Batch 10 Loss 0.2744714319705963
[Train] epoch 9 Batch 11 Loss 0.10447908937931061
[Train] epoch 9 Batch 12 Loss 0.22421768307685852
[Train] epoch 9 Batch 13 Loss 0.3316395878791809
[Train] epoch 9 Batch 14 Loss 0.37269043922424316
[Train] epoch 9 Batch 15 Loss 0.06982067227363586
[Train] epoch 9 Batch 16 Loss 0.2646053433418274
[Train] epoch 9 Batch 17 Loss 0.34436094760894775
[Train] epoch 9 Batch 18 Loss 0.36305391788482666
[Train] epoch 9 Batch 19 Loss 0.16077706217765808
[Train] epoch 9 Batch 20 Loss 0.35050541162490845
[Train] epoch 9 Batch 21 Loss 0.4527723789215088
[Train] epoch 9 Batch 22 Loss 0.19957619905471802
[Train] epoch 9 Batch 23 Loss 0.15894490480422974
[Train] epoch 9 Batch 24 Loss 0.3596774935722351
[Train] epoch 9 Batch 25 Loss 0.15959253907203674
[Train] epoch 9 Batch 26 Loss 0.2876892685890198
[Train] epoch 9 Batch 27 Loss 0.294240266084671
[Train] epoch 9 Batch 28 Loss 0.19857871532440186
[Train] epoch 9 Batch 29 Loss 0.5016310214996338
[Train] epoch 9 Batch 30 Loss 0.3966325521469116
[Train] epoch 9 Batch 31 Loss 0.26395002007484436
[Train] epoch 9 Batch 32 Loss 0.3472169041633606
[Train] epoch 9 Batch 33 Loss 0.32406526803970337
[Train] epoch 9 Batch 34 Loss 0.4148576259613037
[Train] epoch 9 Batch 35 Loss 0.3442026376724243
[Train] epoch 9 Batch 36 Loss 0.3008520007133484
[Train] epoch 9 Batch 37 Loss 0.4168645143508911
[Train] epoch 9 Batch 38 Loss 0.35048723220825195
[Train] epoch 9 Batch 39 Loss 0.28658416867256165
[Train] epoch 9 Batch 40 Loss 0.384524941444397
[Train] epoch 9 Batch 41 Loss 0.06363534927368164
[Train] epoch 9 Batch 42 Loss 0.17276422679424286
[Train] epoch 9 Batch 43 Loss 0.1884852945804596
[Train] epoch 9 Batch 44 Loss 0.1631176918745041
[Train] epoch 9 Batch 45 Loss 0.280078262090683
[Train] epoch 9 Batch 46 Loss 0.4512857496738434
[Train] epoch 9 Batch 47 Loss 0.2915099263191223
[Train] epoch 10 Batch 0 Loss 0.056327566504478455
[Train] epoch 10 Batch 1 Loss 0.1684710681438446
[Train] epoch 10 Batch 2 Loss 0.5535032749176025
[Train] epoch 10 Batch 3 Loss 0.22421127557754517
[Train] epoch 10 Batch 4 Loss 0.37463802099227905
[Train] epoch 10 Batch 5 Loss 0.37375015020370483
[Train] epoch 10 Batch 6 Loss 0.48518747091293335
[Train] epoch 10 Batch 7 Loss 0.24043422937393188
[Train] epoch 10 Batch 8 Loss 0.2065088450908661
[Train] epoch 10 Batch 9 Loss 0.2404744029045105
[Train] epoch 10 Batch 10 Loss 0.3679325580596924
[Train] epoch 10 Batch 11 Loss 0.1980704814195633
[Train] epoch 10 Batch 12 Loss 0.22371600568294525
[Train] epoch 10 Batch 13 Loss 0.09730391204357147
[Train] epoch 10 Batch 14 Loss 0.21630853414535522
[Train] epoch 10 Batch 15 Loss 0.30386584997177124
[Train] epoch 10 Batch 16 Loss 0.32743901014328003
[Train] epoch 10 Batch 17 Loss 0.25823014974594116
[Train] epoch 10 Batch 18 Loss 0.22121943533420563
[Train] epoch 10 Batch 19 Loss 0.5188763737678528
[Train] epoch 10 Batch 20 Loss 0.3385535478591919
[Train] epoch 10 Batch 21 Loss 0.2910427153110504
[Train] epoch 10 Batch 22 Loss 0.2050859034061432
[Train] epoch 10 Batch 23 Loss 0.2595388889312744
[Train] epoch 10 Batch 24 Loss 0.253959596157074
[Train] epoch 10 Batch 25 Loss 0.16613608598709106
[Train] epoch 10 Batch 26 Loss 0.19352053105831146
[Train] epoch 10 Batch 27 Loss 0.49336522817611694
[Train] epoch 10 Batch 28 Loss 0.2222423255443573
[Train] epoch 10 Batch 29 Loss 0.2520769536495209
[Train] epoch 10 Batch 30 Loss 0.07259489595890045
[Train] epoch 10 Batch 31 Loss 0.3949189782142639
[Train] epoch 10 Batch 32 Loss 0.19687336683273315
[Train] epoch 10 Batch 33 Loss 0.32101282477378845
[Train] epoch 10 Batch 34 Loss 0.2545749545097351
[Train] epoch 10 Batch 35 Loss 0.33219438791275024
[Train] epoch 10 Batch 36 Loss 0.3076373338699341
[Train] epoch 10 Batch 37 Loss 0.3031654357910156
[Train] epoch 10 Batch 38 Loss 0.25015684962272644
[Train] epoch 10 Batch 39 Loss 0.1812569499015808
[Train] epoch 10 Batch 40 Loss 0.292726069688797
[Train] epoch 10 Batch 41 Loss 0.46952927112579346
[Train] epoch 10 Batch 42 Loss 0.25543004274368286
[Train] epoch 10 Batch 43 Loss 0.15571163594722748
[Train] epoch 10 Batch 44 Loss 0.49793827533721924
[Train] epoch 10 Batch 45 Loss 0.331159770488739
[Train] epoch 10 Batch 46 Loss 0.3229821026325226
[Train] epoch 10 Batch 47 Loss 0.4541547894477844
[Train] epoch 11 Batch 0 Loss 0.23733951151371002
[Train] epoch 11 Batch 1 Loss 0.3249819576740265
[Train] epoch 11 Batch 2 Loss 0.3082979917526245
[Train] epoch 11 Batch 3 Loss 0.30067873001098633
[Train] epoch 11 Batch 4 Loss 0.40805283188819885
[Train] epoch 11 Batch 5 Loss 0.5153579115867615
[Train] epoch 11 Batch 6 Loss 0.1913631558418274
[Train] epoch 11 Batch 7 Loss 0.21288004517555237
[Train] epoch 11 Batch 8 Loss 0.16407418251037598
[Train] epoch 11 Batch 9 Loss 0.4217076599597931
[Train] epoch 11 Batch 10 Loss 0.33159154653549194
[Train] epoch 11 Batch 11 Loss 0.287922203540802
[Train] epoch 11 Batch 12 Loss 0.4081012010574341
[Train] epoch 11 Batch 13 Loss 0.23915308713912964
[Train] epoch 11 Batch 14 Loss 0.39612361788749695
[Train] epoch 11 Batch 15 Loss 0.16225513815879822
[Train] epoch 11 Batch 16 Loss 0.3070489466190338
[Train] epoch 11 Batch 17 Loss 0.2279740571975708
[Train] epoch 11 Batch 18 Loss 0.23159527778625488
[Train] epoch 11 Batch 19 Loss 0.36877328157424927
[Train] epoch 11 Batch 20 Loss 0.048526763916015625
[Train] epoch 11 Batch 21 Loss 0.1339355856180191
[Train] epoch 11 Batch 22 Loss 0.1127406507730484
[Train] epoch 11 Batch 23 Loss 0.2471206933259964
[Train] epoch 11 Batch 24 Loss 0.4389860928058624
[Train] epoch 11 Batch 25 Loss 0.19539150595664978
[Train] epoch 11 Batch 26 Loss 0.23443877696990967
[Train] epoch 11 Batch 27 Loss 0.2165294736623764
[Train] epoch 11 Batch 28 Loss 0.2077254354953766
[Train] epoch 11 Batch 29 Loss 0.13036373257637024
[Train] epoch 11 Batch 30 Loss 0.2650267779827118
[Train] epoch 11 Batch 31 Loss 0.3139033913612366
[Train] epoch 11 Batch 32 Loss 0.25738149881362915
[Train] epoch 11 Batch 33 Loss 0.3067009150981903
[Train] epoch 11 Batch 34 Loss 0.33701103925704956
[Train] epoch 11 Batch 35 Loss 0.18045368790626526
[Train] epoch 11 Batch 36 Loss 0.43837106227874756
[Train] epoch 11 Batch 37 Loss 0.3977609872817993
[Train] epoch 11 Batch 38 Loss 0.26151129603385925
[Train] epoch 11 Batch 39 Loss 0.2569054365158081
[Train] epoch 11 Batch 40 Loss 0.25466805696487427
[Train] epoch 11 Batch 41 Loss 0.33229315280914307
[Train] epoch 11 Batch 42 Loss 0.478305459022522
[Train] epoch 11 Batch 43 Loss 0.3373330235481262
[Train] epoch 11 Batch 44 Loss 0.4898633658885956
[Train] epoch 11 Batch 45 Loss 0.345473051071167
[Train] epoch 11 Batch 46 Loss 0.16705285012722015
[Train] epoch 11 Batch 47 Loss 0.2992337942123413
[Train] epoch 12 Batch 0 Loss 0.39271169900894165
[Train] epoch 12 Batch 1 Loss 0.2701385021209717
[Train] epoch 12 Batch 2 Loss 0.24094414710998535
[Train] epoch 12 Batch 3 Loss 0.2916916012763977
[Train] epoch 12 Batch 4 Loss 0.2920938730239868
[Train] epoch 12 Batch 5 Loss 0.08806520700454712
[Train] epoch 12 Batch 6 Loss 0.2108118236064911
[Train] epoch 12 Batch 7 Loss 0.4282940626144409
[Train] epoch 12 Batch 8 Loss 0.35470524430274963
[Train] epoch 12 Batch 9 Loss 0.22022321820259094
[Train] epoch 12 Batch 10 Loss 0.3618624806404114
[Train] epoch 12 Batch 11 Loss 0.20891691744327545
[Train] epoch 12 Batch 12 Loss 0.16440150141716003
[Train] epoch 12 Batch 13 Loss 0.4721100628376007
[Train] epoch 12 Batch 14 Loss 0.27197349071502686
[Train] epoch 12 Batch 15 Loss 0.3538215756416321
[Train] epoch 12 Batch 16 Loss 0.42519181966781616
[Train] epoch 12 Batch 17 Loss 0.21781712770462036
[Train] epoch 12 Batch 18 Loss 0.44303834438323975
[Train] epoch 12 Batch 19 Loss 0.2193300724029541
[Train] epoch 12 Batch 20 Loss 0.24256792664527893
[Train] epoch 12 Batch 21 Loss 0.16243183612823486
[Train] epoch 12 Batch 22 Loss 0.24328100681304932
[Train] epoch 12 Batch 23 Loss 0.218345046043396
[Train] epoch 12 Batch 24 Loss 0.35792678594589233
[Train] epoch 12 Batch 25 Loss 0.2441556453704834
[Train] epoch 12 Batch 26 Loss 0.17121675610542297
[Train] epoch 12 Batch 27 Loss 0.33512452244758606
[Train] epoch 12 Batch 28 Loss 0.16799001395702362
[Train] epoch 12 Batch 29 Loss 0.31286972761154175
[Train] epoch 12 Batch 30 Loss 0.26339808106422424
[Train] epoch 12 Batch 31 Loss 0.13938090205192566
[Train] epoch 12 Batch 32 Loss 0.5001224279403687
[Train] epoch 12 Batch 33 Loss 0.23099930584430695
[Train] epoch 12 Batch 34 Loss 0.24834144115447998
[Train] epoch 12 Batch 35 Loss 0.3198230564594269
[Train] epoch 12 Batch 36 Loss 0.34194010496139526
[Train] epoch 12 Batch 37 Loss 0.3142991364002228
[Train] epoch 12 Batch 38 Loss 0.24947451055049896
[Train] epoch 12 Batch 39 Loss 0.3243557810783386
[Train] epoch 12 Batch 40 Loss 0.0998733714222908
[Train] epoch 12 Batch 41 Loss 0.1976439356803894
[Train] epoch 12 Batch 42 Loss 0.3648478388786316
[Train] epoch 12 Batch 43 Loss 0.05015166848897934
[Train] epoch 12 Batch 44 Loss 0.23774585127830505
[Train] epoch 12 Batch 45 Loss 0.27210646867752075
[Train] epoch 12 Batch 46 Loss 0.3439178466796875
[Train] epoch 12 Batch 47 Loss 0.3362519443035126
[Train] epoch 13 Batch 0 Loss 0.44290101528167725
[Train] epoch 13 Batch 1 Loss 0.2507637143135071
[Train] epoch 13 Batch 2 Loss 0.3400980234146118
[Train] epoch 13 Batch 3 Loss 0.3673844337463379
[Train] epoch 13 Batch 4 Loss 0.3552336096763611
[Train] epoch 13 Batch 5 Loss 0.2811114490032196
[Train] epoch 13 Batch 6 Loss 0.14285479485988617
[Train] epoch 13 Batch 7 Loss 0.29700398445129395
[Train] epoch 13 Batch 8 Loss 0.3295491635799408
[Train] epoch 13 Batch 9 Loss 0.1464303731918335
[Train] epoch 13 Batch 10 Loss 0.5197956562042236
[Train] epoch 13 Batch 11 Loss 0.39931178092956543
[Train] epoch 13 Batch 12 Loss 0.3699009418487549
[Train] epoch 13 Batch 13 Loss 0.46201425790786743
[Train] epoch 13 Batch 14 Loss 0.2324678599834442
[Train] epoch 13 Batch 15 Loss 0.2813567519187927
[Train] epoch 13 Batch 16 Loss 0.10612645745277405
[Train] epoch 13 Batch 17 Loss 0.1857169270515442
[Train] epoch 13 Batch 18 Loss 0.39009350538253784
[Train] epoch 13 Batch 19 Loss 0.19871529936790466
[Train] epoch 13 Batch 20 Loss 0.15126191079616547
[Train] epoch 13 Batch 21 Loss 0.3285258412361145
[Train] epoch 13 Batch 22 Loss 0.28836145997047424
[Train] epoch 13 Batch 23 Loss 0.2421596348285675
[Train] epoch 13 Batch 24 Loss 0.26786208152770996
[Train] epoch 13 Batch 25 Loss 0.28213194012641907
[Train] epoch 13 Batch 26 Loss 0.1778470277786255
[Train] epoch 13 Batch 27 Loss 0.27032801508903503
[Train] epoch 13 Batch 28 Loss 0.28286057710647583
[Train] epoch 13 Batch 29 Loss 0.35731565952301025
[Train] epoch 13 Batch 30 Loss 0.5242692232131958
[Train] epoch 13 Batch 31 Loss 0.36862409114837646
[Train] epoch 13 Batch 32 Loss 0.43163561820983887
[Train] epoch 13 Batch 33 Loss 0.15882453322410583
[Train] epoch 13 Batch 34 Loss 0.29171353578567505
[Train] epoch 13 Batch 35 Loss 0.3266914486885071
[Train] epoch 13 Batch 36 Loss 0.1622900366783142
[Train] epoch 13 Batch 37 Loss 0.3157161474227905
[Train] epoch 13 Batch 38 Loss 0.2713075280189514
[Train] epoch 13 Batch 39 Loss 0.11010535806417465
[Train] epoch 13 Batch 40 Loss 0.10884841531515121
[Train] epoch 13 Batch 41 Loss 0.18263819813728333
[Train] epoch 13 Batch 42 Loss 0.20676417648792267
[Train] epoch 13 Batch 43 Loss 0.1885368824005127
[Train] epoch 13 Batch 44 Loss 0.23166531324386597
[Train] epoch 13 Batch 45 Loss 0.23439516127109528
[Train] epoch 13 Batch 46 Loss 0.12653419375419617
[Train] epoch 13 Batch 47 Loss 0.06966660171747208
[Train] epoch 14 Batch 0 Loss 0.32220327854156494
[Train] epoch 14 Batch 1 Loss 0.29232215881347656
[Train] epoch 14 Batch 2 Loss 0.23472796380519867
[Train] epoch 14 Batch 3 Loss 0.408023864030838
[Train] epoch 14 Batch 4 Loss 0.3124893307685852
[Train] epoch 14 Batch 5 Loss 0.1884554624557495
[Train] epoch 14 Batch 6 Loss 0.3017538785934448
[Train] epoch 14 Batch 7 Loss 0.28824955224990845
[Train] epoch 14 Batch 8 Loss 0.3240894675254822
[Train] epoch 14 Batch 9 Loss 0.18680930137634277
[Train] epoch 14 Batch 10 Loss 0.1906844973564148
[Train] epoch 14 Batch 11 Loss 0.4395064115524292
[Train] epoch 14 Batch 12 Loss 0.4231650233268738
[Train] epoch 14 Batch 13 Loss 0.23542384803295135
[Train] epoch 14 Batch 14 Loss 0.20728957653045654
[Train] epoch 14 Batch 15 Loss 0.32295191287994385
[Train] epoch 14 Batch 16 Loss 0.20689278841018677
[Train] epoch 14 Batch 17 Loss 0.27059465646743774
[Train] epoch 14 Batch 18 Loss 0.22112902998924255
[Train] epoch 14 Batch 19 Loss 0.2471478283405304
[Train] epoch 14 Batch 20 Loss 0.24429652094841003
[Train] epoch 14 Batch 21 Loss 0.586198091506958
[Train] epoch 14 Batch 22 Loss 0.20178720355033875
[Train] epoch 14 Batch 23 Loss 0.211066335439682
[Train] epoch 14 Batch 24 Loss 0.3780561685562134
[Train] epoch 14 Batch 25 Loss 0.13967233896255493
[Train] epoch 14 Batch 26 Loss 0.256759911775589
[Train] epoch 14 Batch 27 Loss 0.3133890628814697
[Train] epoch 14 Batch 28 Loss 0.27048903703689575
[Train] epoch 14 Batch 29 Loss 0.21980217099189758
[Train] epoch 14 Batch 30 Loss 0.08039744198322296
[Train] epoch 14 Batch 31 Loss 0.1871722787618637
[Train] epoch 14 Batch 32 Loss 0.3452354669570923
[Train] epoch 14 Batch 33 Loss 0.2383824586868286
[Train] epoch 14 Batch 34 Loss 0.3849853277206421
[Train] epoch 14 Batch 35 Loss 0.26996880769729614
[Train] epoch 14 Batch 36 Loss 0.15945006906986237
[Train] epoch 14 Batch 37 Loss 0.16597023606300354
[Train] epoch 14 Batch 38 Loss 0.1975364089012146
[Train] epoch 14 Batch 39 Loss 0.20770135521888733
[Train] epoch 14 Batch 40 Loss 0.3499985933303833
[Train] epoch 14 Batch 41 Loss 0.06899674236774445
[Train] epoch 14 Batch 42 Loss 0.35372182726860046
[Train] epoch 14 Batch 43 Loss 0.27061188220977783
[Train] epoch 14 Batch 44 Loss 0.2742699384689331
[Train] epoch 14 Batch 45 Loss 0.23278707265853882
[Train] epoch 14 Batch 46 Loss 0.25523191690444946
[Train] epoch 14 Batch 47 Loss 0.29393845796585083
[Train] epoch 15 Batch 0 Loss 0.31426090002059937
[Train] epoch 15 Batch 1 Loss 0.23889370262622833
[Train] epoch 15 Batch 2 Loss 0.14651140570640564
[Train] epoch 15 Batch 3 Loss 0.05917984992265701
[Train] epoch 15 Batch 4 Loss 0.4845629930496216
[Train] epoch 15 Batch 5 Loss 0.20460106432437897
[Train] epoch 15 Batch 6 Loss 0.3451085686683655
[Train] epoch 15 Batch 7 Loss 0.32437169551849365
[Train] epoch 15 Batch 8 Loss 0.1523258537054062
[Train] epoch 15 Batch 9 Loss 0.33958664536476135
[Train] epoch 15 Batch 10 Loss 0.3080289363861084
[Train] epoch 15 Batch 11 Loss 0.3061918616294861
[Train] epoch 15 Batch 12 Loss 0.29500752687454224
[Train] epoch 15 Batch 13 Loss 0.2231813371181488
[Train] epoch 15 Batch 14 Loss 0.26358217000961304
[Train] epoch 15 Batch 15 Loss 0.14012223482131958
[Train] epoch 15 Batch 16 Loss 0.3204237222671509
[Train] epoch 15 Batch 17 Loss 0.11121337115764618
[Train] epoch 15 Batch 18 Loss 0.36511746048927307
[Train] epoch 15 Batch 19 Loss 0.22017134726047516
[Train] epoch 15 Batch 20 Loss 0.20984050631523132
[Train] epoch 15 Batch 21 Loss 0.2936437427997589
[Train] epoch 15 Batch 22 Loss 0.16031363606452942
[Train] epoch 15 Batch 23 Loss 0.24523544311523438
[Train] epoch 15 Batch 24 Loss 0.2629812955856323
[Train] epoch 15 Batch 25 Loss 0.2525060474872589
[Train] epoch 15 Batch 26 Loss 0.27693063020706177
[Train] epoch 15 Batch 27 Loss 0.24379616975784302
[Train] epoch 15 Batch 28 Loss 0.26854705810546875
[Train] epoch 15 Batch 29 Loss 0.24131979048252106
[Train] epoch 15 Batch 30 Loss 0.2665422558784485
[Train] epoch 15 Batch 31 Loss 0.3302299976348877
[Train] epoch 15 Batch 32 Loss 0.3392931818962097
[Train] epoch 15 Batch 33 Loss 0.2693181037902832
[Train] epoch 15 Batch 34 Loss 0.27314645051956177
[Train] epoch 15 Batch 35 Loss 0.23394939303398132
[Train] epoch 15 Batch 36 Loss 0.2747790515422821
[Train] epoch 15 Batch 37 Loss 0.25531142950057983
[Train] epoch 15 Batch 38 Loss 0.2523508667945862
[Train] epoch 15 Batch 39 Loss 0.09868650138378143
[Train] epoch 15 Batch 40 Loss 0.16083285212516785
[Train] epoch 15 Batch 41 Loss 0.12948812544345856
[Train] epoch 15 Batch 42 Loss 0.1483931541442871
[Train] epoch 15 Batch 43 Loss 0.22313722968101501
[Train] epoch 15 Batch 44 Loss 0.11072128266096115
[Train] epoch 15 Batch 45 Loss 0.20482918620109558
[Train] epoch 15 Batch 46 Loss 0.2663975954055786
[Train] epoch 15 Batch 47 Loss 0.2784298062324524
[Train] epoch 16 Batch 0 Loss 0.3516594171524048
[Train] epoch 16 Batch 1 Loss 0.29941391944885254
[Train] epoch 16 Batch 2 Loss 0.419874370098114
[Train] epoch 16 Batch 3 Loss 0.3302881121635437
[Train] epoch 16 Batch 4 Loss 0.23208087682724
[Train] epoch 16 Batch 5 Loss 0.17084404826164246
[Train] epoch 16 Batch 6 Loss 0.20155301690101624
[Train] epoch 16 Batch 7 Loss 0.3208145499229431
[Train] epoch 16 Batch 8 Loss 0.1457900106906891
[Train] epoch 16 Batch 9 Loss 0.09431170672178268
[Train] epoch 16 Batch 10 Loss 0.2982264757156372
[Train] epoch 16 Batch 11 Loss 0.21593204140663147
[Train] epoch 16 Batch 12 Loss 0.17437292635440826
[Train] epoch 16 Batch 13 Loss 0.27440589666366577
[Train] epoch 16 Batch 14 Loss 0.09624896198511124
[Train] epoch 16 Batch 15 Loss 0.1629796177148819
[Train] epoch 16 Batch 16 Loss 0.2921130061149597
[Train] epoch 16 Batch 17 Loss 0.3310983180999756
[Train] epoch 16 Batch 18 Loss 0.17858406901359558
[Train] epoch 16 Batch 19 Loss 0.4420287609100342
[Train] epoch 16 Batch 20 Loss 0.10929447412490845
[Train] epoch 16 Batch 21 Loss 0.2873848080635071
[Train] epoch 16 Batch 22 Loss 0.11231425404548645
[Train] epoch 16 Batch 23 Loss 0.3872109353542328
[Train] epoch 16 Batch 24 Loss 0.28956738114356995
[Train] epoch 16 Batch 25 Loss 0.13343127071857452
[Train] epoch 16 Batch 26 Loss 0.16351322829723358
[Train] epoch 16 Batch 27 Loss 0.2250785529613495
[Train] epoch 16 Batch 28 Loss 0.22495251893997192
[Train] epoch 16 Batch 29 Loss 0.2010318785905838
[Train] epoch 16 Batch 30 Loss 0.2710716128349304
[Train] epoch 16 Batch 31 Loss 0.3358074724674225
[Train] epoch 16 Batch 32 Loss 0.21538005769252777
[Train] epoch 16 Batch 33 Loss 0.355678528547287
[Train] epoch 16 Batch 34 Loss 0.2754937410354614
[Train] epoch 16 Batch 35 Loss 0.10778713971376419
[Train] epoch 16 Batch 36 Loss 0.23489776253700256
[Train] epoch 16 Batch 37 Loss 0.2844036817550659
[Train] epoch 16 Batch 38 Loss 0.2581581175327301
[Train] epoch 16 Batch 39 Loss 0.24089279770851135
[Train] epoch 16 Batch 40 Loss 0.2722584307193756
[Train] epoch 16 Batch 41 Loss 0.246842622756958
[Train] epoch 16 Batch 42 Loss 0.3349190652370453
[Train] epoch 16 Batch 43 Loss 0.18912896513938904
[Train] epoch 16 Batch 44 Loss 0.04366769269108772
[Train] epoch 16 Batch 45 Loss 0.19237475097179413
[Train] epoch 16 Batch 46 Loss 0.21661163866519928
[Train] epoch 16 Batch 47 Loss 0.11565113812685013
[Train] epoch 17 Batch 0 Loss 0.24538114666938782
[Train] epoch 17 Batch 1 Loss 0.1954708844423294
[Train] epoch 17 Batch 2 Loss 0.25280308723449707
[Train] epoch 17 Batch 3 Loss 0.24440142512321472
[Train] epoch 17 Batch 4 Loss 0.196233868598938
[Train] epoch 17 Batch 5 Loss 0.2925967872142792
[Train] epoch 17 Batch 6 Loss 0.33245882391929626
[Train] epoch 17 Batch 7 Loss 0.20823007822036743
[Train] epoch 17 Batch 8 Loss 0.1934577077627182
[Train] epoch 17 Batch 9 Loss 0.1263481080532074
[Train] epoch 17 Batch 10 Loss 0.17826667428016663
[Train] epoch 17 Batch 11 Loss 0.3009592592716217
[Train] epoch 17 Batch 12 Loss 0.32236066460609436
[Train] epoch 17 Batch 13 Loss 0.28770774602890015
[Train] epoch 17 Batch 14 Loss 0.1364646553993225
[Train] epoch 17 Batch 15 Loss 0.12178509682416916
[Train] epoch 17 Batch 16 Loss 0.33643871545791626
[Train] epoch 17 Batch 17 Loss 0.2500428259372711
[Train] epoch 17 Batch 18 Loss 0.3849466145038605
[Train] epoch 17 Batch 19 Loss 0.17143383622169495
[Train] epoch 17 Batch 20 Loss 0.2957378625869751
[Train] epoch 17 Batch 21 Loss 0.25816774368286133
[Train] epoch 17 Batch 22 Loss 0.2992634177207947
[Train] epoch 17 Batch 23 Loss 0.3069770634174347
[Train] epoch 17 Batch 24 Loss 0.23988032341003418
[Train] epoch 17 Batch 25 Loss 0.13999879360198975
[Train] epoch 17 Batch 26 Loss 0.18959160149097443
[Train] epoch 17 Batch 27 Loss 0.23122388124465942
[Train] epoch 17 Batch 28 Loss 0.20185986161231995
[Train] epoch 17 Batch 29 Loss 0.303652822971344
[Train] epoch 17 Batch 30 Loss 0.10865991562604904
[Train] epoch 17 Batch 31 Loss 0.26513442397117615
[Train] epoch 17 Batch 32 Loss 0.27775099873542786
[Train] epoch 17 Batch 33 Loss 0.2644674777984619
[Train] epoch 17 Batch 34 Loss 0.26767218112945557
[Train] epoch 17 Batch 35 Loss 0.29610100388526917
[Train] epoch 17 Batch 36 Loss 0.22465313971042633
[Train] epoch 17 Batch 37 Loss 0.3667188882827759
[Train] epoch 17 Batch 38 Loss 0.1228245422244072
[Train] epoch 17 Batch 39 Loss 0.2291448712348938
[Train] epoch 17 Batch 40 Loss 0.14012426137924194
[Train] epoch 17 Batch 41 Loss 0.10494973510503769
[Train] epoch 17 Batch 42 Loss 0.34654924273490906
[Train] epoch 17 Batch 43 Loss 0.17661651968955994
[Train] epoch 17 Batch 44 Loss 0.21953615546226501
[Train] epoch 17 Batch 45 Loss 0.3106377422809601
[Train] epoch 17 Batch 46 Loss 0.1384553611278534
[Train] epoch 17 Batch 47 Loss 0.2753331661224365
[Train] epoch 18 Batch 0 Loss 0.38893741369247437
[Train] epoch 18 Batch 1 Loss 0.3139793276786804
[Train] epoch 18 Batch 2 Loss 0.22028616070747375
[Train] epoch 18 Batch 3 Loss 0.24759572744369507
[Train] epoch 18 Batch 4 Loss 0.30714136362075806
[Train] epoch 18 Batch 5 Loss 0.21961528062820435
[Train] epoch 18 Batch 6 Loss 0.2239232361316681
[Train] epoch 18 Batch 7 Loss 0.3501196503639221
[Train] epoch 18 Batch 8 Loss 0.33210110664367676
[Train] epoch 18 Batch 9 Loss 0.09127680957317352
[Train] epoch 18 Batch 10 Loss 0.13293784856796265
[Train] epoch 18 Batch 11 Loss 0.13780012726783752
[Train] epoch 18 Batch 12 Loss 0.2735268771648407
[Train] epoch 18 Batch 13 Loss 0.19154071807861328
[Train] epoch 18 Batch 14 Loss 0.1383366882801056
[Train] epoch 18 Batch 15 Loss 0.1924694925546646
[Train] epoch 18 Batch 16 Loss 0.16536270081996918
[Train] epoch 18 Batch 17 Loss 0.3801548182964325
[Train] epoch 18 Batch 18 Loss 0.3202296197414398
[Train] epoch 18 Batch 19 Loss 0.14574140310287476
[Train] epoch 18 Batch 20 Loss 0.3100116550922394
[Train] epoch 18 Batch 21 Loss 0.16858109831809998
[Train] epoch 18 Batch 22 Loss 0.3791627287864685
[Train] epoch 18 Batch 23 Loss 0.3390370011329651
[Train] epoch 18 Batch 24 Loss 0.23995643854141235
[Train] epoch 18 Batch 25 Loss 0.16916146874427795
[Train] epoch 18 Batch 26 Loss 0.2392481565475464
[Train] epoch 18 Batch 27 Loss 0.1358613222837448
[Train] epoch 18 Batch 28 Loss 0.23884207010269165
[Train] epoch 18 Batch 29 Loss 0.15716660022735596
[Train] epoch 18 Batch 30 Loss 0.28145870566368103
[Train] epoch 18 Batch 31 Loss 0.20496177673339844
[Train] epoch 18 Batch 32 Loss 0.20794573426246643
[Train] epoch 18 Batch 33 Loss 0.2693328559398651
[Train] epoch 18 Batch 34 Loss 0.27556994557380676
[Train] epoch 18 Batch 35 Loss 0.26177459955215454
[Train] epoch 18 Batch 36 Loss 0.26259952783584595
[Train] epoch 18 Batch 37 Loss 0.136256605386734
[Train] epoch 18 Batch 38 Loss 0.3440955877304077
[Train] epoch 18 Batch 39 Loss 0.30126798152923584
[Train] epoch 18 Batch 40 Loss 0.4698377251625061
[Train] epoch 18 Batch 41 Loss 0.21822193264961243
[Train] epoch 18 Batch 42 Loss 0.20308563113212585
[Train] epoch 18 Batch 43 Loss 0.32240062952041626
[Train] epoch 18 Batch 44 Loss 0.12363997101783752
[Train] epoch 18 Batch 45 Loss 0.15352016687393188
[Train] epoch 18 Batch 46 Loss 0.20133641362190247
[Train] epoch 18 Batch 47 Loss 0.10589298605918884
[Train] epoch 19 Batch 0 Loss 0.2318163961172104
[Train] epoch 19 Batch 1 Loss 0.28613704442977905
[Train] epoch 19 Batch 2 Loss 0.13262298703193665
[Train] epoch 19 Batch 3 Loss 0.22168582677841187
[Train] epoch 19 Batch 4 Loss 0.4475294351577759
[Train] epoch 19 Batch 5 Loss 0.2894110679626465
[Train] epoch 19 Batch 6 Loss 0.14244918525218964
[Train] epoch 19 Batch 7 Loss 0.20688921213150024
[Train] epoch 19 Batch 8 Loss 0.12332667410373688
[Train] epoch 19 Batch 9 Loss 0.37581366300582886
[Train] epoch 19 Batch 10 Loss 0.25083407759666443
[Train] epoch 19 Batch 11 Loss 0.24544033408164978
[Train] epoch 19 Batch 12 Loss 0.2042832374572754
[Train] epoch 19 Batch 13 Loss 0.2296690046787262
[Train] epoch 19 Batch 14 Loss 0.1528211385011673
[Train] epoch 19 Batch 15 Loss 0.13576781749725342
[Train] epoch 19 Batch 16 Loss 0.16827534139156342
[Train] epoch 19 Batch 17 Loss 0.22773465514183044
[Train] epoch 19 Batch 18 Loss 0.11046767979860306
[Train] epoch 19 Batch 19 Loss 0.16536402702331543
[Train] epoch 19 Batch 20 Loss 0.09571699053049088
[Train] epoch 19 Batch 21 Loss 0.2717088460922241
[Train] epoch 19 Batch 22 Loss 0.18148565292358398
[Train] epoch 19 Batch 23 Loss 0.27842170000076294
[Train] epoch 19 Batch 24 Loss 0.1567957103252411
[Train] epoch 19 Batch 25 Loss 0.18564185500144958
[Train] epoch 19 Batch 26 Loss 0.2902047634124756
[Train] epoch 19 Batch 27 Loss 0.15080322325229645
[Train] epoch 19 Batch 28 Loss 0.197572261095047
[Train] epoch 19 Batch 29 Loss 0.3554905652999878
[Train] epoch 19 Batch 30 Loss 0.5490840673446655
[Train] epoch 19 Batch 31 Loss 0.424237459897995
[Train] epoch 19 Batch 32 Loss 0.20590360462665558
[Train] epoch 19 Batch 33 Loss 0.2598399519920349
[Train] epoch 19 Batch 34 Loss 0.22930178046226501
[Train] epoch 19 Batch 35 Loss 0.23136168718338013
[Train] epoch 19 Batch 36 Loss 0.21905654668807983
[Train] epoch 19 Batch 37 Loss 0.14604312181472778
[Train] epoch 19 Batch 38 Loss 0.15507152676582336
[Train] epoch 19 Batch 39 Loss 0.32440096139907837
[Train] epoch 19 Batch 40 Loss 0.31592243909835815
[Train] epoch 19 Batch 41 Loss 0.33974725008010864
[Train] epoch 19 Batch 42 Loss 0.18029488623142242
[Train] epoch 19 Batch 43 Loss 0.14944307506084442
[Train] epoch 19 Batch 44 Loss 0.1665015071630478
[Train] epoch 19 Batch 45 Loss 0.2525193393230438
[Train] epoch 19 Batch 46 Loss 0.34942948818206787
[Train] epoch 19 Batch 47 Loss 0.2640050947666168
[Train] epoch 20 Batch 0 Loss 0.26186323165893555
[Train] epoch 20 Batch 1 Loss 0.18528839945793152
[Train] epoch 20 Batch 2 Loss 0.20774737000465393
[Train] epoch 20 Batch 3 Loss 0.28499895334243774
[Train] epoch 20 Batch 4 Loss 0.21545153856277466
[Train] epoch 20 Batch 5 Loss 0.17309072613716125
[Train] epoch 20 Batch 6 Loss 0.2098684012889862
[Train] epoch 20 Batch 7 Loss 0.2067464292049408
[Train] epoch 20 Batch 8 Loss 0.17502348124980927
[Train] epoch 20 Batch 9 Loss 0.24203065037727356
[Train] epoch 20 Batch 10 Loss 0.26920485496520996
[Train] epoch 20 Batch 11 Loss 0.32752561569213867
[Train] epoch 20 Batch 12 Loss 0.24175554513931274
[Train] epoch 20 Batch 13 Loss 0.34543681144714355
[Train] epoch 20 Batch 14 Loss 0.22426247596740723
[Train] epoch 20 Batch 15 Loss 0.21726779639720917
[Train] epoch 20 Batch 16 Loss 0.4192473888397217
[Train] epoch 20 Batch 17 Loss 0.17935317754745483
[Train] epoch 20 Batch 18 Loss 0.2210005223751068
[Train] epoch 20 Batch 19 Loss 0.25287339091300964
[Train] epoch 20 Batch 20 Loss 0.24458134174346924
[Train] epoch 20 Batch 21 Loss 0.23093241453170776
[Train] epoch 20 Batch 22 Loss 0.24555885791778564
[Train] epoch 20 Batch 23 Loss 0.30702272057533264
[Train] epoch 20 Batch 24 Loss 0.19879969954490662
[Train] epoch 20 Batch 25 Loss 0.12426057457923889
[Train] epoch 20 Batch 26 Loss 0.23149099946022034
[Train] epoch 20 Batch 27 Loss 0.2573080062866211
[Train] epoch 20 Batch 28 Loss 0.17559677362442017
[Train] epoch 20 Batch 29 Loss 0.15065008401870728
[Train] epoch 20 Batch 30 Loss 0.26065778732299805
[Train] epoch 20 Batch 31 Loss 0.27467110753059387
[Train] epoch 20 Batch 32 Loss 0.21800971031188965
[Train] epoch 20 Batch 33 Loss 0.21087238192558289
[Train] epoch 20 Batch 34 Loss 0.2546728849411011
[Train] epoch 20 Batch 35 Loss 0.2387973964214325
[Train] epoch 20 Batch 36 Loss 0.20970885455608368
[Train] epoch 20 Batch 37 Loss 0.2184303104877472
[Train] epoch 20 Batch 38 Loss 0.2750656008720398
[Train] epoch 20 Batch 39 Loss 0.19998836517333984
[Train] epoch 20 Batch 40 Loss 0.25075167417526245
[Train] epoch 20 Batch 41 Loss 0.2710829973220825
[Train] epoch 20 Batch 42 Loss 0.19736452400684357
[Train] epoch 20 Batch 43 Loss 0.32604292035102844
[Train] epoch 20 Batch 44 Loss 0.24216008186340332
[Train] epoch 20 Batch 45 Loss 0.16552585363388062
[Train] epoch 20 Batch 46 Loss 0.357875794172287
[Train] epoch 20 Batch 47 Loss 0.2947670817375183
[Train] epoch 21 Batch 0 Loss 0.13547593355178833
[Train] epoch 21 Batch 1 Loss 0.2036275714635849
[Train] epoch 21 Batch 2 Loss 0.17766842246055603
[Train] epoch 21 Batch 3 Loss 0.3083479404449463
[Train] epoch 21 Batch 4 Loss 0.2409064769744873
[Train] epoch 21 Batch 5 Loss 0.2295534610748291
[Train] epoch 21 Batch 6 Loss 0.15486501157283783
[Train] epoch 21 Batch 7 Loss 0.22453802824020386
[Train] epoch 21 Batch 8 Loss 0.13306722044944763
[Train] epoch 21 Batch 9 Loss 0.19466981291770935
[Train] epoch 21 Batch 10 Loss 0.11478405445814133
[Train] epoch 21 Batch 11 Loss 0.12701088190078735
[Train] epoch 21 Batch 12 Loss 0.20191290974617004
[Train] epoch 21 Batch 13 Loss 0.37619173526763916
[Train] epoch 21 Batch 14 Loss 0.2882469594478607
[Train] epoch 21 Batch 15 Loss 0.3247109651565552
[Train] epoch 21 Batch 16 Loss 0.26636022329330444
[Train] epoch 21 Batch 17 Loss 0.30367475748062134
[Train] epoch 21 Batch 18 Loss 0.26277992129325867
[Train] epoch 21 Batch 19 Loss 0.3045254051685333
[Train] epoch 21 Batch 20 Loss 0.17683088779449463
[Train] epoch 21 Batch 21 Loss 0.1932680755853653
[Train] epoch 21 Batch 22 Loss 0.20614799857139587
[Train] epoch 21 Batch 23 Loss 0.24634867906570435
[Train] epoch 21 Batch 24 Loss 0.21636641025543213
[Train] epoch 21 Batch 25 Loss 0.10737553238868713
[Train] epoch 21 Batch 26 Loss 0.13310255110263824
[Train] epoch 21 Batch 27 Loss 0.3226008117198944
[Train] epoch 21 Batch 28 Loss 0.10084918886423111
[Train] epoch 21 Batch 29 Loss 0.46644675731658936
[Train] epoch 21 Batch 30 Loss 0.4463726282119751
[Train] epoch 21 Batch 31 Loss 0.2013745903968811
[Train] epoch 21 Batch 32 Loss 0.2143290489912033
[Train] epoch 21 Batch 33 Loss 0.13164152204990387
[Train] epoch 21 Batch 34 Loss 0.17217767238616943
[Train] epoch 21 Batch 35 Loss 0.287978857755661
[Train] epoch 21 Batch 36 Loss 0.22633931040763855
[Train] epoch 21 Batch 37 Loss 0.1926402896642685
[Train] epoch 21 Batch 38 Loss 0.2603846788406372
[Train] epoch 21 Batch 39 Loss 0.19306910037994385
[Train] epoch 21 Batch 40 Loss 0.1833024024963379
[Train] epoch 21 Batch 41 Loss 0.39383918046951294
[Train] epoch 21 Batch 42 Loss 0.19528993964195251
[Train] epoch 21 Batch 43 Loss 0.23223437368869781
[Train] epoch 21 Batch 44 Loss 0.2669169306755066
[Train] epoch 21 Batch 45 Loss 0.2735366225242615
[Train] epoch 21 Batch 46 Loss 0.17082467675209045
[Train] epoch 21 Batch 47 Loss 0.2774629592895508
[Train] epoch 22 Batch 0 Loss 0.44825243949890137
[Train] epoch 22 Batch 1 Loss 0.26317352056503296
[Train] epoch 22 Batch 2 Loss 0.31965696811676025
[Train] epoch 22 Batch 3 Loss 0.3127182722091675
[Train] epoch 22 Batch 4 Loss 0.30596601963043213
[Train] epoch 22 Batch 5 Loss 0.3244064450263977
[Train] epoch 22 Batch 6 Loss 0.19193404912948608
[Train] epoch 22 Batch 7 Loss 0.24135875701904297
[Train] epoch 22 Batch 8 Loss 0.1351163238286972
[Train] epoch 22 Batch 9 Loss 0.097697913646698
[Train] epoch 22 Batch 10 Loss 0.21768693625926971
[Train] epoch 22 Batch 11 Loss 0.24843715131282806
[Train] epoch 22 Batch 12 Loss 0.4293366074562073
[Train] epoch 22 Batch 13 Loss 0.26475074887275696
[Train] epoch 22 Batch 14 Loss 0.1771710216999054
[Train] epoch 22 Batch 15 Loss 0.402102530002594
[Train] epoch 22 Batch 16 Loss 0.28242194652557373
[Train] epoch 22 Batch 17 Loss 0.3222406506538391
[Train] epoch 22 Batch 18 Loss 0.022299468517303467
[Train] epoch 22 Batch 19 Loss 0.2300179898738861
[Train] epoch 22 Batch 20 Loss 0.21741032600402832
[Train] epoch 22 Batch 21 Loss 0.37829238176345825
[Train] epoch 22 Batch 22 Loss 0.22221314907073975
[Train] epoch 22 Batch 23 Loss 0.1868801862001419
[Train] epoch 22 Batch 24 Loss 0.1123722717165947
[Train] epoch 22 Batch 25 Loss 0.15443336963653564
[Train] epoch 22 Batch 26 Loss 0.2286013513803482
[Train] epoch 22 Batch 27 Loss 0.329799622297287
[Train] epoch 22 Batch 28 Loss 0.24669408798217773
[Train] epoch 22 Batch 29 Loss 0.24364960193634033
[Train] epoch 22 Batch 30 Loss 0.2499934732913971
[Train] epoch 22 Batch 31 Loss 0.15337540209293365
[Train] epoch 22 Batch 32 Loss 0.2897435128688812
[Train] epoch 22 Batch 33 Loss 0.24864982068538666
[Train] epoch 22 Batch 34 Loss 0.2399347573518753
[Train] epoch 22 Batch 35 Loss 0.4498218894004822
[Train] epoch 22 Batch 36 Loss 0.3633643388748169
[Train] epoch 22 Batch 37 Loss 0.268687903881073
[Train] epoch 22 Batch 38 Loss 0.38340693712234497
[Train] epoch 22 Batch 39 Loss 0.053390227258205414
[Train] epoch 22 Batch 40 Loss 0.12479184567928314
[Train] epoch 22 Batch 41 Loss 0.21003372967243195
[Train] epoch 22 Batch 42 Loss 0.2641771137714386
[Train] epoch 22 Batch 43 Loss 0.23034755885601044
[Train] epoch 22 Batch 44 Loss 0.12130823731422424
[Train] epoch 22 Batch 45 Loss 0.10013804584741592
[Train] epoch 22 Batch 46 Loss 0.282674640417099
[Train] epoch 22 Batch 47 Loss 0.3360215425491333
[Train] epoch 23 Batch 0 Loss 0.2709357440471649
[Train] epoch 23 Batch 1 Loss 0.3172072172164917
[Train] epoch 23 Batch 2 Loss 0.2780139148235321
[Train] epoch 23 Batch 3 Loss 0.20271119475364685
[Train] epoch 23 Batch 4 Loss 0.09261968731880188
[Train] epoch 23 Batch 5 Loss 0.22843489050865173
[Train] epoch 23 Batch 6 Loss 0.15546810626983643
[Train] epoch 23 Batch 7 Loss 0.15312767028808594
[Train] epoch 23 Batch 8 Loss 0.25248968601226807
[Train] epoch 23 Batch 9 Loss 0.29280921816825867
[Train] epoch 23 Batch 10 Loss 0.26840972900390625
[Train] epoch 23 Batch 11 Loss 0.2759130895137787
[Train] epoch 23 Batch 12 Loss 0.1439630687236786
[Train] epoch 23 Batch 13 Loss 0.2919124662876129
[Train] epoch 23 Batch 14 Loss 0.2010643184185028
[Train] epoch 23 Batch 15 Loss 0.2681618332862854
[Train] epoch 23 Batch 16 Loss 0.24509215354919434
[Train] epoch 23 Batch 17 Loss 0.2854909300804138
[Train] epoch 23 Batch 18 Loss 0.14909692108631134
[Train] epoch 23 Batch 19 Loss 0.24722477793693542
[Train] epoch 23 Batch 20 Loss 0.30046018958091736
[Train] epoch 23 Batch 21 Loss 0.2509452700614929
[Train] epoch 23 Batch 22 Loss 0.19058117270469666
[Train] epoch 23 Batch 23 Loss 0.31250470876693726
[Train] epoch 23 Batch 24 Loss 0.2866196930408478
[Train] epoch 23 Batch 25 Loss 0.17090678215026855
[Train] epoch 23 Batch 26 Loss 0.17771486937999725
[Train] epoch 23 Batch 27 Loss 0.30925899744033813
[Train] epoch 23 Batch 28 Loss 0.1164015457034111
[Train] epoch 23 Batch 29 Loss 0.34605783224105835
[Train] epoch 23 Batch 30 Loss 0.3352150321006775
[Train] epoch 23 Batch 31 Loss 0.38583284616470337
[Train] epoch 23 Batch 32 Loss 0.07506965100765228
[Train] epoch 23 Batch 33 Loss 0.4630270004272461
[Train] epoch 23 Batch 34 Loss 0.15623512864112854
[Train] epoch 23 Batch 35 Loss 0.19631054997444153
[Train] epoch 23 Batch 36 Loss 0.26011762022972107
[Train] epoch 23 Batch 37 Loss 0.30362728238105774
[Train] epoch 23 Batch 38 Loss 0.19642123579978943
[Train] epoch 23 Batch 39 Loss 0.22397080063819885
[Train] epoch 23 Batch 40 Loss 0.23185308277606964
[Train] epoch 23 Batch 41 Loss 0.1286659687757492
[Train] epoch 23 Batch 42 Loss 0.15392768383026123
[Train] epoch 23 Batch 43 Loss 0.24478131532669067
[Train] epoch 23 Batch 44 Loss 0.12913444638252258
[Train] epoch 23 Batch 45 Loss 0.17519904673099518
[Train] epoch 23 Batch 46 Loss 0.11153250187635422
[Train] epoch 23 Batch 47 Loss 0.1782311350107193
[Train] epoch 24 Batch 0 Loss 0.15305081009864807
[Train] epoch 24 Batch 1 Loss 0.30767834186553955
[Train] epoch 24 Batch 2 Loss 0.13017131388187408
[Train] epoch 24 Batch 3 Loss 0.22842201590538025
[Train] epoch 24 Batch 4 Loss 0.13261784613132477
[Train] epoch 24 Batch 5 Loss 0.22580569982528687
[Train] epoch 24 Batch 6 Loss 0.3298102021217346
[Train] epoch 24 Batch 7 Loss 0.14095862209796906
[Train] epoch 24 Batch 8 Loss 0.14423443377017975
[Train] epoch 24 Batch 9 Loss 0.3727097511291504
[Train] epoch 24 Batch 10 Loss 0.23905818164348602
[Train] epoch 24 Batch 11 Loss 0.21578827500343323
[Train] epoch 24 Batch 12 Loss 0.3096286654472351
[Train] epoch 24 Batch 13 Loss 0.1505042314529419
[Train] epoch 24 Batch 14 Loss 0.39156702160835266
[Train] epoch 24 Batch 15 Loss 0.11006709933280945
[Train] epoch 24 Batch 16 Loss 0.23729756474494934
[Train] epoch 24 Batch 17 Loss 0.19169920682907104
[Train] epoch 24 Batch 18 Loss 0.13328908383846283
[Train] epoch 24 Batch 19 Loss 0.27485084533691406
[Train] epoch 24 Batch 20 Loss 0.2606687843799591
[Train] epoch 24 Batch 21 Loss 0.2201291024684906
[Train] epoch 24 Batch 22 Loss 0.21435284614562988
[Train] epoch 24 Batch 23 Loss 0.16495001316070557
[Train] epoch 24 Batch 24 Loss 0.16830460727214813
[Train] epoch 24 Batch 25 Loss 0.1186591237783432
[Train] epoch 24 Batch 26 Loss 0.17484021186828613
[Train] epoch 24 Batch 27 Loss 0.44014132022857666
[Train] epoch 24 Batch 28 Loss 0.15293602645397186
[Train] epoch 24 Batch 29 Loss 0.18359166383743286
[Train] epoch 24 Batch 30 Loss 0.20818068087100983
[Train] epoch 24 Batch 31 Loss 0.2633262872695923
[Train] epoch 24 Batch 32 Loss 0.2884337902069092
[Train] epoch 24 Batch 33 Loss 0.2414938360452652
[Train] epoch 24 Batch 34 Loss 0.15331199765205383
[Train] epoch 24 Batch 35 Loss 0.1987423449754715
[Train] epoch 24 Batch 36 Loss 0.32804417610168457
[Train] epoch 24 Batch 37 Loss 0.19126373529434204
[Train] epoch 24 Batch 38 Loss 0.2277868092060089
[Train] epoch 24 Batch 39 Loss 0.2516736388206482
[Train] epoch 24 Batch 40 Loss 0.1318937987089157
[Train] epoch 24 Batch 41 Loss 0.32630470395088196
[Train] epoch 24 Batch 42 Loss 0.3450794219970703
[Train] epoch 24 Batch 43 Loss 0.17070338129997253
[Train] epoch 24 Batch 44 Loss 0.164057195186615
[Train] epoch 24 Batch 45 Loss 0.31314748525619507
[Train] epoch 24 Batch 46 Loss 0.1845257580280304
[Train] epoch 24 Batch 47 Loss 0.22380799055099487
[Train] epoch 25 Batch 0 Loss 0.12773534655570984
[Train] epoch 25 Batch 1 Loss 0.34604817628860474
[Train] epoch 25 Batch 2 Loss 0.28323718905448914
[Train] epoch 25 Batch 3 Loss 0.1488828957080841
[Train] epoch 25 Batch 4 Loss 0.26022592186927795
[Train] epoch 25 Batch 5 Loss 0.25234082341194153
[Train] epoch 25 Batch 6 Loss 0.0890335813164711
[Train] epoch 25 Batch 7 Loss 0.17266061902046204
[Train] epoch 25 Batch 8 Loss 0.12547039985656738
[Train] epoch 25 Batch 9 Loss 0.12216175347566605
[Train] epoch 25 Batch 10 Loss 0.09551502019166946
[Train] epoch 25 Batch 11 Loss 0.2636205554008484
[Train] epoch 25 Batch 12 Loss 0.2104349434375763
[Train] epoch 25 Batch 13 Loss 0.3073827922344208
[Train] epoch 25 Batch 14 Loss 0.28328052163124084
[Train] epoch 25 Batch 15 Loss 0.24353645741939545
[Train] epoch 25 Batch 16 Loss 0.2071557193994522
[Train] epoch 25 Batch 17 Loss 0.24381685256958008
[Train] epoch 25 Batch 18 Loss 0.21078498661518097
[Train] epoch 25 Batch 19 Loss 0.3679121136665344
[Train] epoch 25 Batch 20 Loss 0.277588814496994
[Train] epoch 25 Batch 21 Loss 0.15379664301872253
[Train] epoch 25 Batch 22 Loss 0.3495389223098755
[Train] epoch 25 Batch 23 Loss 0.22270047664642334
[Train] epoch 25 Batch 24 Loss 0.2117922306060791
[Train] epoch 25 Batch 25 Loss 0.14303642511367798
[Train] epoch 25 Batch 26 Loss 0.23400898277759552
[Train] epoch 25 Batch 27 Loss 0.23729869723320007
[Train] epoch 25 Batch 28 Loss 0.21630418300628662
[Train] epoch 25 Batch 29 Loss 0.14362959563732147
[Train] epoch 25 Batch 30 Loss 0.23808008432388306
[Train] epoch 25 Batch 31 Loss 0.15455618500709534
[Train] epoch 25 Batch 32 Loss 0.17422060668468475
[Train] epoch 25 Batch 33 Loss 0.30587440729141235
[Train] epoch 25 Batch 34 Loss 0.2368381768465042
[Train] epoch 25 Batch 35 Loss 0.05985252559185028
[Train] epoch 25 Batch 36 Loss 0.26867955923080444
[Train] epoch 25 Batch 37 Loss 0.21375130116939545
[Train] epoch 25 Batch 38 Loss 0.3144628405570984
[Train] epoch 25 Batch 39 Loss 0.1274539977312088
[Train] epoch 25 Batch 40 Loss 0.1823272407054901
[Train] epoch 25 Batch 41 Loss 0.12755028903484344
[Train] epoch 25 Batch 42 Loss 0.2695368528366089
[Train] epoch 25 Batch 43 Loss 0.1687179058790207
[Train] epoch 25 Batch 44 Loss 0.23044681549072266
[Train] epoch 25 Batch 45 Loss 0.339546263217926
[Train] epoch 25 Batch 46 Loss 0.4753291606903076
[Train] epoch 25 Batch 47 Loss 0.25612083077430725
[Train] epoch 26 Batch 0 Loss 0.23453110456466675
[Train] epoch 26 Batch 1 Loss 0.2123795598745346
[Train] epoch 26 Batch 2 Loss 0.3063085377216339
[Train] epoch 26 Batch 3 Loss 0.12492156773805618
[Train] epoch 26 Batch 4 Loss 0.12860018014907837
[Train] epoch 26 Batch 5 Loss 0.2665805220603943
[Train] epoch 26 Batch 6 Loss 0.18240946531295776
[Train] epoch 26 Batch 7 Loss 0.29798632860183716
[Train] epoch 26 Batch 8 Loss 0.2077150046825409
[Train] epoch 26 Batch 9 Loss 0.3204561769962311
[Train] epoch 26 Batch 10 Loss 0.13497492671012878
[Train] epoch 26 Batch 11 Loss 0.21410918235778809
[Train] epoch 26 Batch 12 Loss 0.1424483358860016
[Train] epoch 26 Batch 13 Loss 0.13708198070526123
[Train] epoch 26 Batch 14 Loss 0.12900444865226746
[Train] epoch 26 Batch 15 Loss 0.17225930094718933
[Train] epoch 26 Batch 16 Loss 0.2091248780488968
[Train] epoch 26 Batch 17 Loss 0.08894999325275421
[Train] epoch 26 Batch 18 Loss 0.2081652134656906
[Train] epoch 26 Batch 19 Loss 0.29958218336105347
[Train] epoch 26 Batch 20 Loss 0.14913100004196167
[Train] epoch 26 Batch 21 Loss 0.1932186484336853
[Train] epoch 26 Batch 22 Loss 0.1604578197002411
[Train] epoch 26 Batch 23 Loss 0.2851264774799347
[Train] epoch 26 Batch 24 Loss 0.25549301505088806
[Train] epoch 26 Batch 25 Loss 0.1971774399280548
[Train] epoch 26 Batch 26 Loss 0.23702740669250488
[Train] epoch 26 Batch 27 Loss 0.3243040442466736
[Train] epoch 26 Batch 28 Loss 0.11344403028488159
[Train] epoch 26 Batch 29 Loss 0.28548869490623474
[Train] epoch 26 Batch 30 Loss 0.18822571635246277
[Train] epoch 26 Batch 31 Loss 0.18769672513008118
[Train] epoch 26 Batch 32 Loss 0.2165660411119461
[Train] epoch 26 Batch 33 Loss 0.15752822160720825
[Train] epoch 26 Batch 34 Loss 0.3003680408000946
[Train] epoch 26 Batch 35 Loss 0.16637584567070007
[Train] epoch 26 Batch 36 Loss 0.3876155614852905
[Train] epoch 26 Batch 37 Loss 0.29548364877700806
[Train] epoch 26 Batch 38 Loss 0.3390875458717346
[Train] epoch 26 Batch 39 Loss 0.33285820484161377
[Train] epoch 26 Batch 40 Loss 0.18346558511257172
[Train] epoch 26 Batch 41 Loss 0.24751229584217072
[Train] epoch 26 Batch 42 Loss 0.27274832129478455
[Train] epoch 26 Batch 43 Loss 0.3609845042228699
[Train] epoch 26 Batch 44 Loss 0.32797175645828247
[Train] epoch 26 Batch 45 Loss 0.19460724294185638
[Train] epoch 26 Batch 46 Loss 0.19260677695274353
[Train] epoch 26 Batch 47 Loss 0.13812845945358276
[Train] epoch 27 Batch 0 Loss 0.26045161485671997
[Train] epoch 27 Batch 1 Loss 0.16677436232566833
[Train] epoch 27 Batch 2 Loss 0.17551462352275848
[Train] epoch 27 Batch 3 Loss 0.35034650564193726
[Train] epoch 27 Batch 4 Loss 0.1664876788854599
[Train] epoch 27 Batch 5 Loss 0.22205835580825806
[Train] epoch 27 Batch 6 Loss 0.17434874176979065
[Train] epoch 27 Batch 7 Loss 0.14514663815498352
[Train] epoch 27 Batch 8 Loss 0.30462369322776794
[Train] epoch 27 Batch 9 Loss 0.20939436554908752
[Train] epoch 27 Batch 10 Loss 0.3008989095687866
[Train] epoch 27 Batch 11 Loss 0.191778302192688
[Train] epoch 27 Batch 12 Loss 0.14847689867019653
[Train] epoch 27 Batch 13 Loss 0.2057095617055893
[Train] epoch 27 Batch 14 Loss 0.2113204002380371
[Train] epoch 27 Batch 15 Loss 0.40148115158081055
[Train] epoch 27 Batch 16 Loss 0.27900874614715576
[Train] epoch 27 Batch 17 Loss 0.16606396436691284
[Train] epoch 27 Batch 18 Loss 0.1943313181400299
[Train] epoch 27 Batch 19 Loss 0.19245514273643494
[Train] epoch 27 Batch 20 Loss 0.3423350155353546
[Train] epoch 27 Batch 21 Loss 0.2990961968898773
[Train] epoch 27 Batch 22 Loss 0.34448277950286865
[Train] epoch 27 Batch 23 Loss 0.1530042588710785
[Train] epoch 27 Batch 24 Loss 0.3006437420845032
[Train] epoch 27 Batch 25 Loss 0.19865384697914124
[Train] epoch 27 Batch 26 Loss 0.1952526569366455
[Train] epoch 27 Batch 27 Loss 0.19311964511871338
[Train] epoch 27 Batch 28 Loss 0.2273760735988617
[Train] epoch 27 Batch 29 Loss 0.16308587789535522
[Train] epoch 27 Batch 30 Loss 0.12418968975543976
[Train] epoch 27 Batch 31 Loss 0.3195340633392334
[Train] epoch 27 Batch 32 Loss 0.21130333840847015
[Train] epoch 27 Batch 33 Loss 0.20793797075748444
[Train] epoch 27 Batch 34 Loss 0.3093269467353821
[Train] epoch 27 Batch 35 Loss 0.27452552318573
[Train] epoch 27 Batch 36 Loss 0.27881520986557007
[Train] epoch 27 Batch 37 Loss 0.1544390469789505
[Train] epoch 27 Batch 38 Loss 0.16435132920742035
[Train] epoch 27 Batch 39 Loss 0.1557503342628479
[Train] epoch 27 Batch 40 Loss 0.29039138555526733
[Train] epoch 27 Batch 41 Loss 0.15437527000904083
[Train] epoch 27 Batch 42 Loss 0.15079718828201294
[Train] epoch 27 Batch 43 Loss 0.1013079285621643
[Train] epoch 27 Batch 44 Loss 0.14529262483119965
[Train] epoch 27 Batch 45 Loss 0.2418634295463562
[Train] epoch 27 Batch 46 Loss 0.28636544942855835
[Train] epoch 27 Batch 47 Loss 0.18119627237319946
[Train] epoch 28 Batch 0 Loss 0.12895722687244415
[Train] epoch 28 Batch 1 Loss 0.234533429145813
[Train] epoch 28 Batch 2 Loss 0.15990132093429565
[Train] epoch 28 Batch 3 Loss 0.15976323187351227
[Train] epoch 28 Batch 4 Loss 0.32325100898742676
[Train] epoch 28 Batch 5 Loss 0.10782822966575623
[Train] epoch 28 Batch 6 Loss 0.2434835135936737
[Train] epoch 28 Batch 7 Loss 0.1725984513759613
[Train] epoch 28 Batch 8 Loss 0.1938624083995819
[Train] epoch 28 Batch 9 Loss 0.17458143830299377
[Train] epoch 28 Batch 10 Loss 0.16938869655132294
[Train] epoch 28 Batch 11 Loss 0.21197599172592163
[Train] epoch 28 Batch 12 Loss 0.14530819654464722
[Train] epoch 28 Batch 13 Loss 0.060514092445373535
[Train] epoch 28 Batch 14 Loss 0.10968494415283203
[Train] epoch 28 Batch 15 Loss 0.21486885845661163
[Train] epoch 28 Batch 16 Loss 0.22867369651794434
[Train] epoch 28 Batch 17 Loss 0.3245832622051239
[Train] epoch 28 Batch 18 Loss 0.32032305002212524
[Train] epoch 28 Batch 19 Loss 0.277447909116745
[Train] epoch 28 Batch 20 Loss 0.16882705688476562
[Train] epoch 28 Batch 21 Loss 0.3388022184371948
[Train] epoch 28 Batch 22 Loss 0.16698384284973145
[Train] epoch 28 Batch 23 Loss 0.33749669790267944
[Train] epoch 28 Batch 24 Loss 0.27379634976387024
[Train] epoch 28 Batch 25 Loss 0.27209529280662537
[Train] epoch 28 Batch 26 Loss 0.25046423077583313
[Train] epoch 28 Batch 27 Loss 0.08468302339315414
[Train] epoch 28 Batch 28 Loss 0.16392795741558075
[Train] epoch 28 Batch 29 Loss 0.0987747460603714
[Train] epoch 28 Batch 30 Loss 0.22015738487243652
[Train] epoch 28 Batch 31 Loss 0.14361342787742615
[Train] epoch 28 Batch 32 Loss 0.16851094365119934
[Train] epoch 28 Batch 33 Loss 0.1778331696987152
[Train] epoch 28 Batch 34 Loss 0.30010727047920227
[Train] epoch 28 Batch 35 Loss 0.2358747124671936
[Train] epoch 28 Batch 36 Loss 0.10808172821998596
[Train] epoch 28 Batch 37 Loss 0.271167129278183
[Train] epoch 28 Batch 38 Loss 0.4031420946121216
[Train] epoch 28 Batch 39 Loss 0.2600865662097931
[Train] epoch 28 Batch 40 Loss 0.3819468021392822
[Train] epoch 28 Batch 41 Loss 0.29688194394111633
[Train] epoch 28 Batch 42 Loss 0.13590571284294128
[Train] epoch 28 Batch 43 Loss 0.212211012840271
[Train] epoch 28 Batch 44 Loss 0.2888377904891968
[Train] epoch 28 Batch 45 Loss 0.32600927352905273
[Train] epoch 28 Batch 46 Loss 0.20271779596805573
[Train] epoch 28 Batch 47 Loss 0.1502615213394165
[Train] epoch 29 Batch 0 Loss 0.24437576532363892
[Train] epoch 29 Batch 1 Loss 0.21760018169879913
[Train] epoch 29 Batch 2 Loss 0.03976694121956825
[Train] epoch 29 Batch 3 Loss 0.12238472700119019
[Train] epoch 29 Batch 4 Loss 0.1674065738916397
[Train] epoch 29 Batch 5 Loss 0.1710204780101776
[Train] epoch 29 Batch 6 Loss 0.2092631757259369
[Train] epoch 29 Batch 7 Loss 0.19301331043243408
[Train] epoch 29 Batch 8 Loss 0.1744363009929657
[Train] epoch 29 Batch 9 Loss 0.23416167497634888
[Train] epoch 29 Batch 10 Loss 0.23451294004917145
[Train] epoch 29 Batch 11 Loss 0.10577840358018875
[Train] epoch 29 Batch 12 Loss 0.3588222861289978
[Train] epoch 29 Batch 13 Loss 0.1337207406759262
[Train] epoch 29 Batch 14 Loss 0.11990238726139069
[Train] epoch 29 Batch 15 Loss 0.10235392302274704
[Train] epoch 29 Batch 16 Loss 0.3134857416152954
[Train] epoch 29 Batch 17 Loss 0.18123161792755127
[Train] epoch 29 Batch 18 Loss 0.19158703088760376
[Train] epoch 29 Batch 19 Loss 0.28818821907043457
[Train] epoch 29 Batch 20 Loss 0.3077975809574127
[Train] epoch 29 Batch 21 Loss 0.1303742378950119
[Train] epoch 29 Batch 22 Loss 0.20285749435424805
[Train] epoch 29 Batch 23 Loss 0.20373356342315674
[Train] epoch 29 Batch 24 Loss 0.30180346965789795
[Train] epoch 29 Batch 25 Loss 0.283352792263031
[Train] epoch 29 Batch 26 Loss 0.12150769680738449
[Train] epoch 29 Batch 27 Loss 0.10966728627681732
[Train] epoch 29 Batch 28 Loss 0.274988055229187
[Train] epoch 29 Batch 29 Loss 0.2379666268825531
[Train] epoch 29 Batch 30 Loss 0.16162565350532532
[Train] epoch 29 Batch 31 Loss 0.07984718680381775
[Train] epoch 29 Batch 32 Loss 0.3583136200904846
[Train] epoch 29 Batch 33 Loss 0.2369215041399002
[Train] epoch 29 Batch 34 Loss 0.219289630651474
[Train] epoch 29 Batch 35 Loss 0.2424437701702118
[Train] epoch 29 Batch 36 Loss 0.40075749158859253
[Train] epoch 29 Batch 37 Loss 0.14655131101608276
[Train] epoch 29 Batch 38 Loss 0.2703391909599304
[Train] epoch 29 Batch 39 Loss 0.09428971260786057
[Train] epoch 29 Batch 40 Loss 0.27293676137924194
[Train] epoch 29 Batch 41 Loss 0.35785114765167236
[Train] epoch 29 Batch 42 Loss 0.21386271715164185
[Train] epoch 29 Batch 43 Loss 0.3606445789337158
[Train] epoch 29 Batch 44 Loss 0.22079116106033325
[Train] epoch 29 Batch 45 Loss 0.09207011759281158
[Train] epoch 29 Batch 46 Loss 0.37112605571746826
[Train] epoch 29 Batch 47 Loss 0.21586434543132782
[Train] epoch 30 Batch 0 Loss 0.26698434352874756
[Train] epoch 30 Batch 1 Loss 0.3676135838031769
[Train] epoch 30 Batch 2 Loss 0.044306039810180664
[Train] epoch 30 Batch 3 Loss 0.23480883240699768
[Train] epoch 30 Batch 4 Loss 0.25546950101852417
[Train] epoch 30 Batch 5 Loss 0.2050362378358841
[Train] epoch 30 Batch 6 Loss 0.2573990225791931
[Train] epoch 30 Batch 7 Loss 0.2863334119319916
[Train] epoch 30 Batch 8 Loss 0.22570142149925232
[Train] epoch 30 Batch 9 Loss 0.1200154647231102
[Train] epoch 30 Batch 10 Loss 0.24752581119537354
[Train] epoch 30 Batch 11 Loss 0.20919790863990784
[Train] epoch 30 Batch 12 Loss 0.3787101209163666
[Train] epoch 30 Batch 13 Loss 0.2764696776866913
[Train] epoch 30 Batch 14 Loss 0.3277909457683563
[Train] epoch 30 Batch 15 Loss 0.37808865308761597
[Train] epoch 30 Batch 16 Loss 0.18130072951316833
[Train] epoch 30 Batch 17 Loss 0.08394834399223328
[Train] epoch 30 Batch 18 Loss 0.07547088712453842
[Train] epoch 30 Batch 19 Loss 0.34287285804748535
[Train] epoch 30 Batch 20 Loss 0.043643925338983536
[Train] epoch 30 Batch 21 Loss 0.16202785074710846
[Train] epoch 30 Batch 22 Loss 0.1757373809814453
[Train] epoch 30 Batch 23 Loss 0.35096490383148193
[Train] epoch 30 Batch 24 Loss 0.2638682723045349
[Train] epoch 30 Batch 25 Loss 0.2755036950111389
[Train] epoch 30 Batch 26 Loss 0.19406577944755554
[Train] epoch 30 Batch 27 Loss 0.2810569405555725
[Train] epoch 30 Batch 28 Loss 0.19944822788238525
[Train] epoch 30 Batch 29 Loss 0.12653225660324097
[Train] epoch 30 Batch 30 Loss 0.2558634281158447
[Train] epoch 30 Batch 31 Loss 0.24334105849266052
[Train] epoch 30 Batch 32 Loss 0.350808709859848
[Train] epoch 30 Batch 33 Loss 0.21158486604690552
[Train] epoch 30 Batch 34 Loss 0.2193639576435089
[Train] epoch 30 Batch 35 Loss 0.3176863193511963
[Train] epoch 30 Batch 36 Loss 0.19820380210876465
[Train] epoch 30 Batch 37 Loss 0.26546406745910645
[Train] epoch 30 Batch 38 Loss 0.1821262240409851
[Train] epoch 30 Batch 39 Loss 0.1965712010860443
[Train] epoch 30 Batch 40 Loss 0.16814777255058289
[Train] epoch 30 Batch 41 Loss 0.12423177063465118
[Train] epoch 30 Batch 42 Loss 0.17041555047035217
[Train] epoch 30 Batch 43 Loss 0.10007399320602417
[Train] epoch 30 Batch 44 Loss 0.23182865977287292
[Train] epoch 30 Batch 45 Loss 0.21959906816482544
[Train] epoch 30 Batch 46 Loss 0.31453174352645874
[Train] epoch 30 Batch 47 Loss 0.3052034378051758
[Train] epoch 31 Batch 0 Loss 0.10334290564060211
[Train] epoch 31 Batch 1 Loss 0.17213325202465057
[Train] epoch 31 Batch 2 Loss 0.28696203231811523
[Train] epoch 31 Batch 3 Loss 0.2327292561531067
[Train] epoch 31 Batch 4 Loss 0.20954549312591553
[Train] epoch 31 Batch 5 Loss 0.2116386592388153
[Train] epoch 31 Batch 6 Loss 0.20891277492046356
[Train] epoch 31 Batch 7 Loss 0.22017183899879456
[Train] epoch 31 Batch 8 Loss 0.16527922451496124
[Train] epoch 31 Batch 9 Loss 0.26920366287231445
[Train] epoch 31 Batch 10 Loss 0.36756426095962524
[Train] epoch 31 Batch 11 Loss 0.1662682592868805
[Train] epoch 31 Batch 12 Loss 0.23164960741996765
[Train] epoch 31 Batch 13 Loss 0.18978959321975708
[Train] epoch 31 Batch 14 Loss 0.30995965003967285
[Train] epoch 31 Batch 15 Loss 0.20726415514945984
[Train] epoch 31 Batch 16 Loss 0.17837543785572052
[Train] epoch 31 Batch 17 Loss 0.14899593591690063
[Train] epoch 31 Batch 18 Loss 0.19974012672901154
[Train] epoch 31 Batch 19 Loss 0.26795732975006104
[Train] epoch 31 Batch 20 Loss 0.14067573845386505
[Train] epoch 31 Batch 21 Loss 0.1419931799173355
[Train] epoch 31 Batch 22 Loss 0.19787994027137756
[Train] epoch 31 Batch 23 Loss 0.2918926477432251
[Train] epoch 31 Batch 24 Loss 0.08163785934448242
[Train] epoch 31 Batch 25 Loss 0.18095606565475464
[Train] epoch 31 Batch 26 Loss 0.26060548424720764
[Train] epoch 31 Batch 27 Loss 0.24781328439712524
[Train] epoch 31 Batch 28 Loss 0.23188719153404236
[Train] epoch 31 Batch 29 Loss 0.25463223457336426
[Train] epoch 31 Batch 30 Loss 0.15775498747825623
[Train] epoch 31 Batch 31 Loss 0.20836758613586426
[Train] epoch 31 Batch 32 Loss 0.23690125346183777
[Train] epoch 31 Batch 33 Loss 0.29501304030418396
[Train] epoch 31 Batch 34 Loss 0.38340678811073303
[Train] epoch 31 Batch 35 Loss 0.3373510241508484
[Train] epoch 31 Batch 36 Loss 0.20222286880016327
[Train] epoch 31 Batch 37 Loss 0.13670365512371063
[Train] epoch 31 Batch 38 Loss 0.2691180408000946
[Train] epoch 31 Batch 39 Loss 0.34563374519348145
[Train] epoch 31 Batch 40 Loss 0.2106972336769104
[Train] epoch 31 Batch 41 Loss 0.23017734289169312
[Train] epoch 31 Batch 42 Loss 0.244380384683609
[Train] epoch 31 Batch 43 Loss 0.32774507999420166
[Train] epoch 31 Batch 44 Loss 0.10054877400398254
[Train] epoch 31 Batch 45 Loss 0.09926694631576538
[Train] epoch 31 Batch 46 Loss 0.20885132253170013
[Train] epoch 31 Batch 47 Loss 0.08907204121351242
[Train] epoch 32 Batch 0 Loss 0.30370163917541504
[Train] epoch 32 Batch 1 Loss 0.17953316867351532
[Train] epoch 32 Batch 2 Loss 0.17536385357379913
[Train] epoch 32 Batch 3 Loss 0.31625276803970337
[Train] epoch 32 Batch 4 Loss 0.28029540181159973
[Train] epoch 32 Batch 5 Loss 0.211696058511734
[Train] epoch 32 Batch 6 Loss 0.052844129502773285
[Train] epoch 32 Batch 7 Loss 0.2697354555130005
[Train] epoch 32 Batch 8 Loss 0.39885467290878296
[Train] epoch 32 Batch 9 Loss 0.2258528470993042
[Train] epoch 32 Batch 10 Loss 0.14074771106243134
[Train] epoch 32 Batch 11 Loss 0.2434779703617096
[Train] epoch 32 Batch 12 Loss 0.22540488839149475
[Train] epoch 32 Batch 13 Loss 0.16518530249595642
[Train] epoch 32 Batch 14 Loss 0.31021928787231445
[Train] epoch 32 Batch 15 Loss 0.31098392605781555
[Train] epoch 32 Batch 16 Loss 0.1002751886844635
[Train] epoch 32 Batch 17 Loss 0.19778522849082947
[Train] epoch 32 Batch 18 Loss 0.12561529874801636
[Train] epoch 32 Batch 19 Loss 0.20545119047164917
[Train] epoch 32 Batch 20 Loss 0.3075524568557739
[Train] epoch 32 Batch 21 Loss 0.07905110716819763
[Train] epoch 32 Batch 22 Loss 0.18099749088287354
[Train] epoch 32 Batch 23 Loss 0.17096714675426483
[Train] epoch 32 Batch 24 Loss 0.12531684339046478
[Train] epoch 32 Batch 25 Loss 0.11017786711454391
[Train] epoch 32 Batch 26 Loss 0.35227975249290466
[Train] epoch 32 Batch 27 Loss 0.10306216031312943
[Train] epoch 32 Batch 28 Loss 0.39061984419822693
[Train] epoch 32 Batch 29 Loss 0.3520544767379761
[Train] epoch 32 Batch 30 Loss 0.23372872173786163
[Train] epoch 32 Batch 31 Loss 0.1426917165517807
[Train] epoch 32 Batch 32 Loss 0.26414424180984497
[Train] epoch 32 Batch 33 Loss 0.11557354032993317
[Train] epoch 32 Batch 34 Loss 0.2671492099761963
[Train] epoch 32 Batch 35 Loss 0.22880777716636658
[Train] epoch 32 Batch 36 Loss 0.263823002576828
[Train] epoch 32 Batch 37 Loss 0.2497757077217102
[Train] epoch 32 Batch 38 Loss 0.2323201596736908
[Train] epoch 32 Batch 39 Loss 0.09923210740089417
[Train] epoch 32 Batch 40 Loss 0.3827306926250458
[Train] epoch 32 Batch 41 Loss 0.04231296852231026
[Train] epoch 32 Batch 42 Loss 0.30164647102355957
[Train] epoch 32 Batch 43 Loss 0.17546617984771729
[Train] epoch 32 Batch 44 Loss 0.12295249104499817
[Train] epoch 32 Batch 45 Loss 0.14954093098640442
[Train] epoch 32 Batch 46 Loss 0.24610450863838196
[Train] epoch 32 Batch 47 Loss 0.22966548800468445
[Train] epoch 33 Batch 0 Loss 0.26994675397872925
[Train] epoch 33 Batch 1 Loss 0.20301967859268188
[Train] epoch 33 Batch 2 Loss 0.06666764616966248
[Train] epoch 33 Batch 3 Loss 0.3083611726760864
[Train] epoch 33 Batch 4 Loss 0.14859378337860107
[Train] epoch 33 Batch 5 Loss 0.1712324321269989
[Train] epoch 33 Batch 6 Loss 0.17504557967185974
[Train] epoch 33 Batch 7 Loss 0.17955836653709412
[Train] epoch 33 Batch 8 Loss 0.26797905564308167
[Train] epoch 33 Batch 9 Loss 0.16433459520339966
[Train] epoch 33 Batch 10 Loss 0.21504512429237366
[Train] epoch 33 Batch 11 Loss 0.16172030568122864
[Train] epoch 33 Batch 12 Loss 0.21772779524326324
[Train] epoch 33 Batch 13 Loss 0.2385270595550537
[Train] epoch 33 Batch 14 Loss 0.14737851917743683
[Train] epoch 33 Batch 15 Loss 0.3511393964290619
[Train] epoch 33 Batch 16 Loss 0.2656456232070923
[Train] epoch 33 Batch 17 Loss 0.24348649382591248
[Train] epoch 33 Batch 18 Loss 0.20069004595279694
[Train] epoch 33 Batch 19 Loss 0.177705317735672
[Train] epoch 33 Batch 20 Loss 0.1677643060684204
[Train] epoch 33 Batch 21 Loss 0.20432907342910767
[Train] epoch 33 Batch 22 Loss 0.1229974702000618
[Train] epoch 33 Batch 23 Loss 0.20216047763824463
[Train] epoch 33 Batch 24 Loss 0.1171707808971405
[Train] epoch 33 Batch 25 Loss 0.2699538469314575
[Train] epoch 33 Batch 26 Loss 0.26319196820259094
[Train] epoch 33 Batch 27 Loss 0.14703640341758728
[Train] epoch 33 Batch 28 Loss 0.3084477186203003
[Train] epoch 33 Batch 29 Loss 0.16099826991558075
[Train] epoch 33 Batch 30 Loss 0.39246219396591187
[Train] epoch 33 Batch 31 Loss 0.15834593772888184
[Train] epoch 33 Batch 32 Loss 0.3425832986831665
[Train] epoch 33 Batch 33 Loss 0.24910765886306763
[Train] epoch 33 Batch 34 Loss 0.27741897106170654
[Train] epoch 33 Batch 35 Loss 0.1824522465467453
[Train] epoch 33 Batch 36 Loss 0.29428887367248535
[Train] epoch 33 Batch 37 Loss 0.10896490514278412
[Train] epoch 33 Batch 38 Loss 0.1745808720588684
[Train] epoch 33 Batch 39 Loss 0.27045756578445435
[Train] epoch 33 Batch 40 Loss 0.23989591002464294
[Train] epoch 33 Batch 41 Loss 0.24512344598770142
[Train] epoch 33 Batch 42 Loss 0.13170747458934784
[Train] epoch 33 Batch 43 Loss 0.13392925262451172
[Train] epoch 33 Batch 44 Loss 0.19114050269126892
[Train] epoch 33 Batch 45 Loss 0.264712393283844
[Train] epoch 33 Batch 46 Loss 0.21817301213741302
[Train] epoch 33 Batch 47 Loss 0.21838781237602234
[Train] epoch 34 Batch 0 Loss 0.21210184693336487
[Train] epoch 34 Batch 1 Loss 0.26254239678382874
[Train] epoch 34 Batch 2 Loss 0.25777560472488403
[Train] epoch 34 Batch 3 Loss 0.09637769311666489
[Train] epoch 34 Batch 4 Loss 0.1375800222158432
[Train] epoch 34 Batch 5 Loss 0.16333003342151642
[Train] epoch 34 Batch 6 Loss 0.13490794599056244
[Train] epoch 34 Batch 7 Loss 0.3247746527194977
[Train] epoch 34 Batch 8 Loss 0.2124219685792923
[Train] epoch 34 Batch 9 Loss 0.27816933393478394
[Train] epoch 34 Batch 10 Loss 0.39864805340766907
[Train] epoch 34 Batch 11 Loss 0.1963348090648651
[Train] epoch 34 Batch 12 Loss 0.23060159385204315
[Train] epoch 34 Batch 13 Loss 0.18456998467445374
[Train] epoch 34 Batch 14 Loss 0.17629189789295197
[Train] epoch 34 Batch 15 Loss 0.3140062093734741
[Train] epoch 34 Batch 16 Loss 0.24054822325706482
[Train] epoch 34 Batch 17 Loss 0.16197563707828522
[Train] epoch 34 Batch 18 Loss 0.13691020011901855
[Train] epoch 34 Batch 19 Loss 0.1472385972738266
[Train] epoch 34 Batch 20 Loss 0.392919659614563
[Train] epoch 34 Batch 21 Loss 0.2359859049320221
[Train] epoch 34 Batch 22 Loss 0.41294240951538086
[Train] epoch 34 Batch 23 Loss 0.19414205849170685
[Train] epoch 34 Batch 24 Loss 0.3518333435058594
[Train] epoch 34 Batch 25 Loss 0.30595284700393677
[Train] epoch 34 Batch 26 Loss 0.12269535660743713
[Train] epoch 34 Batch 27 Loss 0.2536694407463074
[Train] epoch 34 Batch 28 Loss 0.2079516351222992
[Train] epoch 34 Batch 29 Loss 0.18758663535118103
[Train] epoch 34 Batch 30 Loss 0.19628548622131348
[Train] epoch 34 Batch 31 Loss 0.17857027053833008
[Train] epoch 34 Batch 32 Loss 0.2669711709022522
[Train] epoch 34 Batch 33 Loss 0.026661837473511696
[Train] epoch 34 Batch 34 Loss 0.18359443545341492
[Train] epoch 34 Batch 35 Loss 0.28721439838409424
[Train] epoch 34 Batch 36 Loss 0.21513450145721436
[Train] epoch 34 Batch 37 Loss 0.26407721638679504
[Train] epoch 34 Batch 38 Loss 0.2762344479560852
[Train] epoch 34 Batch 39 Loss 0.1677701622247696
[Train] epoch 34 Batch 40 Loss 0.22653332352638245
[Train] epoch 34 Batch 41 Loss 0.2982460856437683
[Train] epoch 34 Batch 42 Loss 0.34776824712753296
[Train] epoch 34 Batch 43 Loss 0.24727463722229004
[Train] epoch 34 Batch 44 Loss 0.23520812392234802
[Train] epoch 34 Batch 45 Loss 0.08414801210165024
[Train] epoch 34 Batch 46 Loss 0.23459109663963318
[Train] epoch 34 Batch 47 Loss 0.20613831281661987
[Train] epoch 35 Batch 0 Loss 0.28357115387916565
[Train] epoch 35 Batch 1 Loss 0.13906897604465485
[Train] epoch 35 Batch 2 Loss 0.23648187518119812
[Train] epoch 35 Batch 3 Loss 0.17299923300743103
[Train] epoch 35 Batch 4 Loss 0.1980363130569458
[Train] epoch 35 Batch 5 Loss 0.26314985752105713
[Train] epoch 35 Batch 6 Loss 0.3523368239402771
[Train] epoch 35 Batch 7 Loss 0.1990496814250946
[Train] epoch 35 Batch 8 Loss 0.09165117144584656
[Train] epoch 35 Batch 9 Loss 0.352455735206604
[Train] epoch 35 Batch 10 Loss 0.08948633074760437
[Train] epoch 35 Batch 11 Loss 0.26176556944847107
[Train] epoch 35 Batch 12 Loss 0.22105038166046143
[Train] epoch 35 Batch 13 Loss 0.47464555501937866
[Train] epoch 35 Batch 14 Loss 0.2638331651687622
[Train] epoch 35 Batch 15 Loss 0.21176792681217194
[Train] epoch 35 Batch 16 Loss 0.1661669909954071
[Train] epoch 35 Batch 17 Loss 0.26655128598213196
[Train] epoch 35 Batch 18 Loss 0.26446300745010376
[Train] epoch 35 Batch 19 Loss 0.2206539809703827
[Train] epoch 35 Batch 20 Loss 0.12313413619995117
[Train] epoch 35 Batch 21 Loss 0.3624112904071808
[Train] epoch 35 Batch 22 Loss 0.2034081220626831
[Train] epoch 35 Batch 23 Loss 0.16656631231307983
[Train] epoch 35 Batch 24 Loss 0.08992813527584076
[Train] epoch 35 Batch 25 Loss 0.30924296379089355
[Train] epoch 35 Batch 26 Loss 0.13751162588596344
[Train] epoch 35 Batch 27 Loss 0.1351546198129654
[Train] epoch 35 Batch 28 Loss 0.2668216824531555
[Train] epoch 35 Batch 29 Loss 0.16591331362724304
[Train] epoch 35 Batch 30 Loss 0.1926276534795761
[Train] epoch 35 Batch 31 Loss 0.1486208736896515
[Train] epoch 35 Batch 32 Loss 0.13864442706108093
[Train] epoch 35 Batch 33 Loss 0.29087910056114197
[Train] epoch 35 Batch 34 Loss 0.19125811755657196
[Train] epoch 35 Batch 35 Loss 0.23479381203651428
[Train] epoch 35 Batch 36 Loss 0.13963520526885986
[Train] epoch 35 Batch 37 Loss 0.26559028029441833
[Train] epoch 35 Batch 38 Loss 0.2552935481071472
[Train] epoch 35 Batch 39 Loss 0.265435129404068
[Train] epoch 35 Batch 40 Loss 0.2542741894721985
[Train] epoch 35 Batch 41 Loss 0.12692797183990479
[Train] epoch 35 Batch 42 Loss 0.17771735787391663
[Train] epoch 35 Batch 43 Loss 0.270542174577713
[Train] epoch 35 Batch 44 Loss 0.19975128769874573
[Train] epoch 35 Batch 45 Loss 0.19874924421310425
[Train] epoch 35 Batch 46 Loss 0.27192261815071106
[Train] epoch 35 Batch 47 Loss 0.20542359352111816
[Train] epoch 36 Batch 0 Loss 0.3116466999053955
[Train] epoch 36 Batch 1 Loss 0.1901264488697052
[Train] epoch 36 Batch 2 Loss 0.202989399433136
[Train] epoch 36 Batch 3 Loss 0.35642606019973755
[Train] epoch 36 Batch 4 Loss 0.18348902463912964
[Train] epoch 36 Batch 5 Loss 0.1307377815246582
[Train] epoch 36 Batch 6 Loss 0.108338363468647
[Train] epoch 36 Batch 7 Loss 0.17146135866641998
[Train] epoch 36 Batch 8 Loss 0.17414608597755432
[Train] epoch 36 Batch 9 Loss 0.28797686100006104
[Train] epoch 36 Batch 10 Loss 0.1208021342754364
[Train] epoch 36 Batch 11 Loss 0.1345827281475067
[Train] epoch 36 Batch 12 Loss 0.2808002233505249
[Train] epoch 36 Batch 13 Loss 0.2428765594959259
[Train] epoch 36 Batch 14 Loss 0.09618260711431503
[Train] epoch 36 Batch 15 Loss 0.21159881353378296
[Train] epoch 36 Batch 16 Loss 0.30232203006744385
[Train] epoch 36 Batch 17 Loss 0.2693473696708679
[Train] epoch 36 Batch 18 Loss 0.09087400883436203
[Train] epoch 36 Batch 19 Loss 0.19840896129608154
[Train] epoch 36 Batch 20 Loss 0.2314578890800476
[Train] epoch 36 Batch 21 Loss 0.13227245211601257
[Train] epoch 36 Batch 22 Loss 0.04667874798178673
[Train] epoch 36 Batch 23 Loss 0.2005131095647812
[Train] epoch 36 Batch 24 Loss 0.33205845952033997
[Train] epoch 36 Batch 25 Loss 0.14005924761295319
[Train] epoch 36 Batch 26 Loss 0.19678351283073425
[Train] epoch 36 Batch 27 Loss 0.20242127776145935
[Train] epoch 36 Batch 28 Loss 0.1751367300748825
[Train] epoch 36 Batch 29 Loss 0.2155793309211731
[Train] epoch 36 Batch 30 Loss 0.2552792727947235
[Train] epoch 36 Batch 31 Loss 0.23406806588172913
[Train] epoch 36 Batch 32 Loss 0.13454020023345947
[Train] epoch 36 Batch 33 Loss 0.14320039749145508
[Train] epoch 36 Batch 34 Loss 0.24657681584358215
[Train] epoch 36 Batch 35 Loss 0.36208030581474304
[Train] epoch 36 Batch 36 Loss 0.07245899736881256
[Train] epoch 36 Batch 37 Loss 0.2325114607810974
[Train] epoch 36 Batch 38 Loss 0.2411201000213623
[Train] epoch 36 Batch 39 Loss 0.2068876475095749
[Train] epoch 36 Batch 40 Loss 0.22755166888237
[Train] epoch 36 Batch 41 Loss 0.44902801513671875
[Train] epoch 36 Batch 42 Loss 0.09847202897071838
[Train] epoch 36 Batch 43 Loss 0.43736404180526733
[Train] epoch 36 Batch 44 Loss 0.22952359914779663
[Train] epoch 36 Batch 45 Loss 0.30505722761154175
[Train] epoch 36 Batch 46 Loss 0.26627209782600403
[Train] epoch 36 Batch 47 Loss 0.13431227207183838
[Train] epoch 37 Batch 0 Loss 0.32628995180130005
[Train] epoch 37 Batch 1 Loss 0.18789108097553253
[Train] epoch 37 Batch 2 Loss 0.19000041484832764
[Train] epoch 37 Batch 3 Loss 0.1912897676229477
[Train] epoch 37 Batch 4 Loss 0.1819857954978943
[Train] epoch 37 Batch 5 Loss 0.12492738664150238
[Train] epoch 37 Batch 6 Loss 0.29555314779281616
[Train] epoch 37 Batch 7 Loss 0.24299296736717224
[Train] epoch 37 Batch 8 Loss 0.2164665162563324
[Train] epoch 37 Batch 9 Loss 0.2114304006099701
[Train] epoch 37 Batch 10 Loss 0.11687888950109482
[Train] epoch 37 Batch 11 Loss 0.3486683666706085
[Train] epoch 37 Batch 12 Loss 0.15196900069713593
[Train] epoch 37 Batch 13 Loss 0.1276814341545105
[Train] epoch 37 Batch 14 Loss 0.08216366916894913
[Train] epoch 37 Batch 15 Loss 0.26656317710876465
[Train] epoch 37 Batch 16 Loss 0.09726583957672119
[Train] epoch 37 Batch 17 Loss 0.34768742322921753
[Train] epoch 37 Batch 18 Loss 0.18912965059280396
[Train] epoch 37 Batch 19 Loss 0.19473223388195038
[Train] epoch 37 Batch 20 Loss 0.15959441661834717
[Train] epoch 37 Batch 21 Loss 0.2744752764701843
[Train] epoch 37 Batch 22 Loss 0.05221368372440338
[Train] epoch 37 Batch 23 Loss 0.14687928557395935
[Train] epoch 37 Batch 24 Loss 0.18853086233139038
[Train] epoch 37 Batch 25 Loss 0.21578556299209595
[Train] epoch 37 Batch 26 Loss 0.34095460176467896
[Train] epoch 37 Batch 27 Loss 0.333171546459198
[Train] epoch 37 Batch 28 Loss 0.43711745738983154
[Train] epoch 37 Batch 29 Loss 0.20602720975875854
[Train] epoch 37 Batch 30 Loss 0.19432568550109863
[Train] epoch 37 Batch 31 Loss 0.21022436022758484
[Train] epoch 37 Batch 32 Loss 0.1638275682926178
[Train] epoch 37 Batch 33 Loss 0.2658948302268982
[Train] epoch 37 Batch 34 Loss 0.17979055643081665
[Train] epoch 37 Batch 35 Loss 0.12239142507314682
[Train] epoch 37 Batch 36 Loss 0.3931680917739868
[Train] epoch 37 Batch 37 Loss 0.12028255313634872
[Train] epoch 37 Batch 38 Loss 0.1266879439353943
[Train] epoch 37 Batch 39 Loss 0.3514775037765503
[Train] epoch 37 Batch 40 Loss 0.18469971418380737
[Train] epoch 37 Batch 41 Loss 0.2532605826854706
[Train] epoch 37 Batch 42 Loss 0.3628448247909546
[Train] epoch 37 Batch 43 Loss 0.1815289556980133
[Train] epoch 37 Batch 44 Loss 0.20532144606113434
[Train] epoch 37 Batch 45 Loss 0.30591946840286255
[Train] epoch 37 Batch 46 Loss 0.24351224303245544
[Train] epoch 37 Batch 47 Loss 0.15514035522937775
[Train] epoch 38 Batch 0 Loss 0.28008151054382324
[Train] epoch 38 Batch 1 Loss 0.25680655241012573
[Train] epoch 38 Batch 2 Loss 0.12260647118091583
[Train] epoch 38 Batch 3 Loss 0.2272542417049408
[Train] epoch 38 Batch 4 Loss 0.27074193954467773
[Train] epoch 38 Batch 5 Loss 0.2909530997276306
[Train] epoch 38 Batch 6 Loss 0.21833190321922302
[Train] epoch 38 Batch 7 Loss 0.23107807338237762
[Train] epoch 38 Batch 8 Loss 0.23907238245010376
[Train] epoch 38 Batch 9 Loss 0.14836084842681885
[Train] epoch 38 Batch 10 Loss 0.12897023558616638
[Train] epoch 38 Batch 11 Loss 0.2494167685508728
[Train] epoch 38 Batch 12 Loss 0.13155391812324524
[Train] epoch 38 Batch 13 Loss 0.15480944514274597
[Train] epoch 38 Batch 14 Loss 0.20893657207489014
[Train] epoch 38 Batch 15 Loss 0.18894296884536743
[Train] epoch 38 Batch 16 Loss 0.2453060895204544
[Train] epoch 38 Batch 17 Loss 0.3152652382850647
[Train] epoch 38 Batch 18 Loss 0.32068532705307007
[Train] epoch 38 Batch 19 Loss 0.29369276762008667
[Train] epoch 38 Batch 20 Loss 0.30214518308639526
[Train] epoch 38 Batch 21 Loss 0.33564329147338867
[Train] epoch 38 Batch 22 Loss 0.08369466662406921
[Train] epoch 38 Batch 23 Loss 0.31296637654304504
[Train] epoch 38 Batch 24 Loss 0.3693487346172333
[Train] epoch 38 Batch 25 Loss 0.2658877670764923
[Train] epoch 38 Batch 26 Loss 0.11810160428285599
[Train] epoch 38 Batch 27 Loss 0.18426957726478577
[Train] epoch 38 Batch 28 Loss 0.18619008362293243
[Train] epoch 38 Batch 29 Loss 0.13668185472488403
[Train] epoch 38 Batch 30 Loss 0.25600093603134155
[Train] epoch 38 Batch 31 Loss 0.13584090769290924
[Train] epoch 38 Batch 32 Loss 0.12176471948623657
[Train] epoch 38 Batch 33 Loss 0.22683584690093994
[Train] epoch 38 Batch 34 Loss 0.1479359120130539
[Train] epoch 38 Batch 35 Loss 0.2153773158788681
[Train] epoch 38 Batch 36 Loss 0.1874505877494812
[Train] epoch 38 Batch 37 Loss 0.24758291244506836
[Train] epoch 38 Batch 38 Loss 0.17464283108711243
[Train] epoch 38 Batch 39 Loss 0.17820045351982117
[Train] epoch 38 Batch 40 Loss 0.09759354591369629
[Train] epoch 38 Batch 41 Loss 0.3295515477657318
[Train] epoch 38 Batch 42 Loss 0.20270025730133057
[Train] epoch 38 Batch 43 Loss 0.21469613909721375
[Train] epoch 38 Batch 44 Loss 0.09147024154663086
[Train] epoch 38 Batch 45 Loss 0.22865623235702515
[Train] epoch 38 Batch 46 Loss 0.21119648218154907
[Train] epoch 38 Batch 47 Loss 0.20222246646881104
[Train] epoch 39 Batch 0 Loss 0.0942860096693039
[Train] epoch 39 Batch 1 Loss 0.1618642359972
[Train] epoch 39 Batch 2 Loss 0.13661545515060425
[Train] epoch 39 Batch 3 Loss 0.2450985312461853
[Train] epoch 39 Batch 4 Loss 0.119235098361969
[Train] epoch 39 Batch 5 Loss 0.0686095580458641
[Train] epoch 39 Batch 6 Loss 0.08045326173305511
[Train] epoch 39 Batch 7 Loss 0.34181568026542664
[Train] epoch 39 Batch 8 Loss 0.1350334733724594
[Train] epoch 39 Batch 9 Loss 0.22536474466323853
[Train] epoch 39 Batch 10 Loss 0.19686096906661987
[Train] epoch 39 Batch 11 Loss 0.3098723888397217
[Train] epoch 39 Batch 12 Loss 0.2912251949310303
[Train] epoch 39 Batch 13 Loss 0.2721962034702301
[Train] epoch 39 Batch 14 Loss 0.11808386445045471
[Train] epoch 39 Batch 15 Loss 0.36962422728538513
[Train] epoch 39 Batch 16 Loss 0.26986923813819885
[Train] epoch 39 Batch 17 Loss 0.19935086369514465
[Train] epoch 39 Batch 18 Loss 0.2542003393173218
[Train] epoch 39 Batch 19 Loss 0.3139292895793915
[Train] epoch 39 Batch 20 Loss 0.2002459466457367
[Train] epoch 39 Batch 21 Loss 0.11826328933238983
[Train] epoch 39 Batch 22 Loss 0.1538003534078598
[Train] epoch 39 Batch 23 Loss 0.15706011652946472
[Train] epoch 39 Batch 24 Loss 0.19170083105564117
[Train] epoch 39 Batch 25 Loss 0.3115551173686981
[Train] epoch 39 Batch 26 Loss 0.32257747650146484
[Train] epoch 39 Batch 27 Loss 0.2992147207260132
[Train] epoch 39 Batch 28 Loss 0.21713608503341675
[Train] epoch 39 Batch 29 Loss 0.19415982067584991
[Train] epoch 39 Batch 30 Loss 0.04443114623427391
[Train] epoch 39 Batch 31 Loss 0.07545961439609528
[Train] epoch 39 Batch 32 Loss 0.1357567012310028
[Train] epoch 39 Batch 33 Loss 0.22261476516723633
[Train] epoch 39 Batch 34 Loss 0.26428794860839844
[Train] epoch 39 Batch 35 Loss 0.13948550820350647
[Train] epoch 39 Batch 36 Loss 0.23290324211120605
[Train] epoch 39 Batch 37 Loss 0.3432166278362274
[Train] epoch 39 Batch 38 Loss 0.2439512312412262
[Train] epoch 39 Batch 39 Loss 0.20971018075942993
[Train] epoch 39 Batch 40 Loss 0.23468434810638428
[Train] epoch 39 Batch 41 Loss 0.10719652473926544
[Train] epoch 39 Batch 42 Loss 0.22216814756393433
[Train] epoch 39 Batch 43 Loss 0.20379750430583954
[Train] epoch 39 Batch 44 Loss 0.23487593233585358
[Train] epoch 39 Batch 45 Loss 0.22582264244556427
[Train] epoch 39 Batch 46 Loss 0.1791580319404602
[Train] epoch 39 Batch 47 Loss 0.28135114908218384
[Train] epoch 40 Batch 0 Loss 0.22837963700294495
[Train] epoch 40 Batch 1 Loss 0.22581732273101807
[Train] epoch 40 Batch 2 Loss 0.1537024825811386
[Train] epoch 40 Batch 3 Loss 0.18391767144203186
[Train] epoch 40 Batch 4 Loss 0.2043813019990921
[Train] epoch 40 Batch 5 Loss 0.21367496252059937
[Train] epoch 40 Batch 6 Loss 0.07845579832792282
[Train] epoch 40 Batch 7 Loss 0.4128493070602417
[Train] epoch 40 Batch 8 Loss 0.17609328031539917
[Train] epoch 40 Batch 9 Loss 0.3583311438560486
[Train] epoch 40 Batch 10 Loss 0.14279776811599731
[Train] epoch 40 Batch 11 Loss 0.3047792613506317
[Train] epoch 40 Batch 12 Loss 0.09660173207521439
[Train] epoch 40 Batch 13 Loss 0.33705222606658936
[Train] epoch 40 Batch 14 Loss 0.28079110383987427
[Train] epoch 40 Batch 15 Loss 0.3380437195301056
[Train] epoch 40 Batch 16 Loss 0.2542850375175476
[Train] epoch 40 Batch 17 Loss 0.16100206971168518
[Train] epoch 40 Batch 18 Loss 0.16963225603103638
[Train] epoch 40 Batch 19 Loss 0.4632100462913513
[Train] epoch 40 Batch 20 Loss 0.15111446380615234
[Train] epoch 40 Batch 21 Loss 0.1491430401802063
[Train] epoch 40 Batch 22 Loss 0.19099712371826172
[Train] epoch 40 Batch 23 Loss 0.26972606778144836
[Train] epoch 40 Batch 24 Loss 0.2762749493122101
[Train] epoch 40 Batch 25 Loss 0.02189495787024498
[Train] epoch 40 Batch 26 Loss 0.08729197084903717
[Train] epoch 40 Batch 27 Loss 0.2280893325805664
[Train] epoch 40 Batch 28 Loss 0.24805444478988647
[Train] epoch 40 Batch 29 Loss 0.17706792056560516
[Train] epoch 40 Batch 30 Loss 0.12747952342033386
[Train] epoch 40 Batch 31 Loss 0.13511180877685547
[Train] epoch 40 Batch 32 Loss 0.3258008062839508
[Train] epoch 40 Batch 33 Loss 0.1884814351797104
[Train] epoch 40 Batch 34 Loss 0.32974502444267273
[Train] epoch 40 Batch 35 Loss 0.2654441297054291
[Train] epoch 40 Batch 36 Loss 0.2534972131252289
[Train] epoch 40 Batch 37 Loss 0.20461517572402954
[Train] epoch 40 Batch 38 Loss 0.04823596030473709
[Train] epoch 40 Batch 39 Loss 0.27637961506843567
[Train] epoch 40 Batch 40 Loss 0.243885800242424
[Train] epoch 40 Batch 41 Loss 0.2321402132511139
[Train] epoch 40 Batch 42 Loss 0.3356720209121704
[Train] epoch 40 Batch 43 Loss 0.2982019782066345
[Train] epoch 40 Batch 44 Loss 0.20680049061775208
[Train] epoch 40 Batch 45 Loss 0.14000706374645233
[Train] epoch 40 Batch 46 Loss 0.22474569082260132
[Train] epoch 40 Batch 47 Loss 0.10727085173130035
[Train] epoch 41 Batch 0 Loss 0.22657591104507446
[Train] epoch 41 Batch 1 Loss 0.2087479531764984
[Train] epoch 41 Batch 2 Loss 0.206329345703125
[Train] epoch 41 Batch 3 Loss 0.15426231920719147
[Train] epoch 41 Batch 4 Loss 0.15012022852897644
[Train] epoch 41 Batch 5 Loss 0.25772133469581604
[Train] epoch 41 Batch 6 Loss 0.10567215085029602
[Train] epoch 41 Batch 7 Loss 0.17598983645439148
[Train] epoch 41 Batch 8 Loss 0.2860462963581085
[Train] epoch 41 Batch 9 Loss 0.17374742031097412
[Train] epoch 41 Batch 10 Loss 0.08104674518108368
[Train] epoch 41 Batch 11 Loss 0.10674063116312027
[Train] epoch 41 Batch 12 Loss 0.26735493540763855
[Train] epoch 41 Batch 13 Loss 0.17809057235717773
[Train] epoch 41 Batch 14 Loss 0.2577219605445862
[Train] epoch 41 Batch 15 Loss 0.2320064902305603
[Train] epoch 41 Batch 16 Loss 0.11318165063858032
[Train] epoch 41 Batch 17 Loss 0.2976519763469696
[Train] epoch 41 Batch 18 Loss 0.258609801530838
[Train] epoch 41 Batch 19 Loss 0.18551456928253174
[Train] epoch 41 Batch 20 Loss 0.3311619758605957
[Train] epoch 41 Batch 21 Loss 0.1698116958141327
[Train] epoch 41 Batch 22 Loss 0.12341177463531494
[Train] epoch 41 Batch 23 Loss 0.14725641906261444
[Train] epoch 41 Batch 24 Loss 0.2746227979660034
[Train] epoch 41 Batch 25 Loss 0.3967337906360626
[Train] epoch 41 Batch 26 Loss 0.28973519802093506
[Train] epoch 41 Batch 27 Loss 0.1410713493824005
[Train] epoch 41 Batch 28 Loss 0.20105630159378052
[Train] epoch 41 Batch 29 Loss 0.346709668636322
[Train] epoch 41 Batch 30 Loss 0.188612699508667
[Train] epoch 41 Batch 31 Loss 0.2531983256340027
[Train] epoch 41 Batch 32 Loss 0.3120501935482025
[Train] epoch 41 Batch 33 Loss 0.04996728152036667
[Train] epoch 41 Batch 34 Loss 0.12513239681720734
[Train] epoch 41 Batch 35 Loss 0.22130948305130005
[Train] epoch 41 Batch 36 Loss 0.15535792708396912
[Train] epoch 41 Batch 37 Loss 0.2431136965751648
[Train] epoch 41 Batch 38 Loss 0.22112956643104553
[Train] epoch 41 Batch 39 Loss 0.26923492550849915
[Train] epoch 41 Batch 40 Loss 0.1892716884613037
[Train] epoch 41 Batch 41 Loss 0.24368460476398468
[Train] epoch 41 Batch 42 Loss 0.1578313410282135
[Train] epoch 41 Batch 43 Loss 0.2110997587442398
[Train] epoch 41 Batch 44 Loss 0.2622784376144409
[Train] epoch 41 Batch 45 Loss 0.2893304228782654
[Train] epoch 41 Batch 46 Loss 0.23791053891181946
[Train] epoch 41 Batch 47 Loss 0.16623324155807495
[Train] epoch 42 Batch 0 Loss 0.15533338487148285
[Train] epoch 42 Batch 1 Loss 0.2481951117515564
[Train] epoch 42 Batch 2 Loss 0.21035435795783997
[Train] epoch 42 Batch 3 Loss 0.2927008867263794
[Train] epoch 42 Batch 4 Loss 0.23609934747219086
[Train] epoch 42 Batch 5 Loss 0.22102317214012146
[Train] epoch 42 Batch 6 Loss 0.25289449095726013
[Train] epoch 42 Batch 7 Loss 0.2911449074745178
[Train] epoch 42 Batch 8 Loss 0.37709933519363403
[Train] epoch 42 Batch 9 Loss 0.04070822149515152
[Train] epoch 42 Batch 10 Loss 0.21141287684440613
[Train] epoch 42 Batch 11 Loss 0.17203795909881592
[Train] epoch 42 Batch 12 Loss 0.10075996816158295
[Train] epoch 42 Batch 13 Loss 0.3036889433860779
[Train] epoch 42 Batch 14 Loss 0.1559770405292511
[Train] epoch 42 Batch 15 Loss 0.2768280804157257
[Train] epoch 42 Batch 16 Loss 0.07677359879016876
[Train] epoch 42 Batch 17 Loss 0.1519237458705902
[Train] epoch 42 Batch 18 Loss 0.1892070472240448
[Train] epoch 42 Batch 19 Loss 0.16428576409816742
[Train] epoch 42 Batch 20 Loss 0.12779191136360168
[Train] epoch 42 Batch 21 Loss 0.2255503237247467
[Train] epoch 42 Batch 22 Loss 0.32574471831321716
[Train] epoch 42 Batch 23 Loss 0.19802695512771606
[Train] epoch 42 Batch 24 Loss 0.1150716245174408
[Train] epoch 42 Batch 25 Loss 0.25751733779907227
[Train] epoch 42 Batch 26 Loss 0.22117552161216736
[Train] epoch 42 Batch 27 Loss 0.21059361100196838
[Train] epoch 42 Batch 28 Loss 0.29809969663619995
[Train] epoch 42 Batch 29 Loss 0.226139634847641
[Train] epoch 42 Batch 30 Loss 0.11424915492534637
[Train] epoch 42 Batch 31 Loss 0.14556005597114563
[Train] epoch 42 Batch 32 Loss 0.1844993531703949
[Train] epoch 42 Batch 33 Loss 0.18607953190803528
[Train] epoch 42 Batch 34 Loss 0.2153301239013672
[Train] epoch 42 Batch 35 Loss 0.1533232182264328
[Train] epoch 42 Batch 36 Loss 0.1829761564731598
[Train] epoch 42 Batch 37 Loss 0.09554439783096313
[Train] epoch 42 Batch 38 Loss 0.16266977787017822
[Train] epoch 42 Batch 39 Loss 0.05386662483215332
[Train] epoch 42 Batch 40 Loss 0.33198195695877075
[Train] epoch 42 Batch 41 Loss 0.055206816643476486
[Train] epoch 42 Batch 42 Loss 0.14742474257946014
[Train] epoch 42 Batch 43 Loss 0.34866875410079956
[Train] epoch 42 Batch 44 Loss 0.3575762212276459
[Train] epoch 42 Batch 45 Loss 0.28526461124420166
[Train] epoch 42 Batch 46 Loss 0.24821342527866364
[Train] epoch 42 Batch 47 Loss 0.19927343726158142
[Train] epoch 43 Batch 0 Loss 0.14528365433216095
[Train] epoch 43 Batch 1 Loss 0.1889571249485016
[Train] epoch 43 Batch 2 Loss 0.18603301048278809
[Train] epoch 43 Batch 3 Loss 0.2279929369688034
[Train] epoch 43 Batch 4 Loss 0.22546088695526123
[Train] epoch 43 Batch 5 Loss 0.2742885947227478
[Train] epoch 43 Batch 6 Loss 0.22648873925209045
[Train] epoch 43 Batch 7 Loss 0.2190999984741211
[Train] epoch 43 Batch 8 Loss 0.0907704159617424
[Train] epoch 43 Batch 9 Loss 0.29993581771850586
[Train] epoch 43 Batch 10 Loss 0.3076777756214142
[Train] epoch 43 Batch 11 Loss 0.2442348599433899
[Train] epoch 43 Batch 12 Loss 0.4001716077327728
[Train] epoch 43 Batch 13 Loss 0.12351573258638382
[Train] epoch 43 Batch 14 Loss 0.29742151498794556
[Train] epoch 43 Batch 15 Loss 0.1850389540195465
[Train] epoch 43 Batch 16 Loss 0.14878803491592407
[Train] epoch 43 Batch 17 Loss 0.15063273906707764
[Train] epoch 43 Batch 18 Loss 0.3196360468864441
[Train] epoch 43 Batch 19 Loss 0.22324302792549133
[Train] epoch 43 Batch 20 Loss 0.12328245490789413
[Train] epoch 43 Batch 21 Loss 0.2563413381576538
[Train] epoch 43 Batch 22 Loss 0.1854318380355835
[Train] epoch 43 Batch 23 Loss 0.3617303967475891
[Train] epoch 43 Batch 24 Loss 0.21833191812038422
[Train] epoch 43 Batch 25 Loss 0.2006232738494873
[Train] epoch 43 Batch 26 Loss 0.12402112782001495
[Train] epoch 43 Batch 27 Loss 0.32837027311325073
[Train] epoch 43 Batch 28 Loss 0.2575524151325226
[Train] epoch 43 Batch 29 Loss 0.12046506255865097
[Train] epoch 43 Batch 30 Loss 0.17499735951423645
[Train] epoch 43 Batch 31 Loss 0.2722264528274536
[Train] epoch 43 Batch 32 Loss 0.24373292922973633
[Train] epoch 43 Batch 33 Loss 0.040012650191783905
[Train] epoch 43 Batch 34 Loss 0.2795785367488861
[Train] epoch 43 Batch 35 Loss 0.11656087636947632
[Train] epoch 43 Batch 36 Loss 0.10199297964572906
[Train] epoch 43 Batch 37 Loss 0.1920190155506134
[Train] epoch 43 Batch 38 Loss 0.026178592815995216
[Train] epoch 43 Batch 39 Loss 0.15290690958499908
[Train] epoch 43 Batch 40 Loss 0.13695642352104187
[Train] epoch 43 Batch 41 Loss 0.11899463832378387
[Train] epoch 43 Batch 42 Loss 0.21937240660190582
[Train] epoch 43 Batch 43 Loss 0.23510722815990448
[Train] epoch 43 Batch 44 Loss 0.24865321815013885
[Train] epoch 43 Batch 45 Loss 0.256187379360199
[Train] epoch 43 Batch 46 Loss 0.15902753174304962
[Train] epoch 43 Batch 47 Loss 0.23460711538791656
[Train] epoch 44 Batch 0 Loss 0.3295271396636963
[Train] epoch 44 Batch 1 Loss 0.12610861659049988
[Train] epoch 44 Batch 2 Loss 0.206688791513443
[Train] epoch 44 Batch 3 Loss 0.20863643288612366
[Train] epoch 44 Batch 4 Loss 0.2340729832649231
[Train] epoch 44 Batch 5 Loss 0.07192368805408478
[Train] epoch 44 Batch 6 Loss 0.10442652553319931
[Train] epoch 44 Batch 7 Loss 0.11603830754756927
[Train] epoch 44 Batch 8 Loss 0.08814994245767593
[Train] epoch 44 Batch 9 Loss 0.2960846424102783
[Train] epoch 44 Batch 10 Loss 0.12343871593475342
[Train] epoch 44 Batch 11 Loss 0.22208599746227264
[Train] epoch 44 Batch 12 Loss 0.11660302430391312
[Train] epoch 44 Batch 13 Loss 0.06956832855939865
[Train] epoch 44 Batch 14 Loss 0.2620943784713745
[Train] epoch 44 Batch 15 Loss 0.2198207676410675
[Train] epoch 44 Batch 16 Loss 0.21947374939918518
[Train] epoch 44 Batch 17 Loss 0.12554864585399628
[Train] epoch 44 Batch 18 Loss 0.15096689760684967
[Train] epoch 44 Batch 19 Loss 0.33929312229156494
[Train] epoch 44 Batch 20 Loss 0.19442293047904968
[Train] epoch 44 Batch 21 Loss 0.09471706300973892
[Train] epoch 44 Batch 22 Loss 0.18989582359790802
[Train] epoch 44 Batch 23 Loss 0.19813667237758636
[Train] epoch 44 Batch 24 Loss 0.22122545540332794
[Train] epoch 44 Batch 25 Loss 0.2511971592903137
[Train] epoch 44 Batch 26 Loss 0.11626547574996948
[Train] epoch 44 Batch 27 Loss 0.1559339314699173
[Train] epoch 44 Batch 28 Loss 0.2512187659740448
[Train] epoch 44 Batch 29 Loss 0.12343985587358475
[Train] epoch 44 Batch 30 Loss 0.1459563672542572
[Train] epoch 44 Batch 31 Loss 0.259784460067749
[Train] epoch 44 Batch 32 Loss 0.35091733932495117
[Train] epoch 44 Batch 33 Loss 0.2080659717321396
[Train] epoch 44 Batch 34 Loss 0.3275115191936493
[Train] epoch 44 Batch 35 Loss 0.32600879669189453
[Train] epoch 44 Batch 36 Loss 0.18376073241233826
[Train] epoch 44 Batch 37 Loss 0.2265736162662506
[Train] epoch 44 Batch 38 Loss 0.17015114426612854
[Train] epoch 44 Batch 39 Loss 0.2131684422492981
[Train] epoch 44 Batch 40 Loss 0.26277095079421997
[Train] epoch 44 Batch 41 Loss 0.18284685909748077
[Train] epoch 44 Batch 42 Loss 0.1268102526664734
[Train] epoch 44 Batch 43 Loss 0.33297300338745117
[Train] epoch 44 Batch 44 Loss 0.17168475687503815
[Train] epoch 44 Batch 45 Loss 0.24631914496421814
[Train] epoch 44 Batch 46 Loss 0.0928124338388443
[Train] epoch 44 Batch 47 Loss 0.2554358243942261
[Train] epoch 45 Batch 0 Loss 0.17658492922782898
[Train] epoch 45 Batch 1 Loss 0.17233000695705414
[Train] epoch 45 Batch 2 Loss 0.36118990182876587
[Train] epoch 45 Batch 3 Loss 0.14121101796627045
[Train] epoch 45 Batch 4 Loss 0.21036458015441895
[Train] epoch 45 Batch 5 Loss 0.2142362892627716
[Train] epoch 45 Batch 6 Loss 0.16995960474014282
[Train] epoch 45 Batch 7 Loss 0.23032331466674805
[Train] epoch 45 Batch 8 Loss 0.2478114664554596
[Train] epoch 45 Batch 9 Loss 0.19263581931591034
[Train] epoch 45 Batch 10 Loss 0.18368002772331238
[Train] epoch 45 Batch 11 Loss 0.265297532081604
[Train] epoch 45 Batch 12 Loss 0.1750049591064453
[Train] epoch 45 Batch 13 Loss 0.21887323260307312
[Train] epoch 45 Batch 14 Loss 0.2841423749923706
[Train] epoch 45 Batch 15 Loss 0.13095009326934814
[Train] epoch 45 Batch 16 Loss 0.14461901783943176
[Train] epoch 45 Batch 17 Loss 0.0878763347864151
[Train] epoch 45 Batch 18 Loss 0.27954402565956116
[Train] epoch 45 Batch 19 Loss 0.2153291255235672
[Train] epoch 45 Batch 20 Loss 0.13656534254550934
[Train] epoch 45 Batch 21 Loss 0.26567739248275757
[Train] epoch 45 Batch 22 Loss 0.21889519691467285
[Train] epoch 45 Batch 23 Loss 0.32959991693496704
[Train] epoch 45 Batch 24 Loss 0.2656722366809845
[Train] epoch 45 Batch 25 Loss 0.23520860075950623
[Train] epoch 45 Batch 26 Loss 0.14438167214393616
[Train] epoch 45 Batch 27 Loss 0.12071549892425537
[Train] epoch 45 Batch 28 Loss 0.19409091770648956
[Train] epoch 45 Batch 29 Loss 0.20799264311790466
[Train] epoch 45 Batch 30 Loss 0.1893298476934433
[Train] epoch 45 Batch 31 Loss 0.23512783646583557
[Train] epoch 45 Batch 32 Loss 0.10183174163103104
[Train] epoch 45 Batch 33 Loss 0.14423789083957672
[Train] epoch 45 Batch 34 Loss 0.16148582100868225
[Train] epoch 45 Batch 35 Loss 0.13111445307731628
[Train] epoch 45 Batch 36 Loss 0.23598727583885193
[Train] epoch 45 Batch 37 Loss 0.34154805541038513
[Train] epoch 45 Batch 38 Loss 0.1741899847984314
[Train] epoch 45 Batch 39 Loss 0.17420952022075653
[Train] epoch 45 Batch 40 Loss 0.2797308564186096
[Train] epoch 45 Batch 41 Loss 0.15858231484889984
[Train] epoch 45 Batch 42 Loss 0.2544553279876709
[Train] epoch 45 Batch 43 Loss 0.1331523060798645
[Train] epoch 45 Batch 44 Loss 0.19281989336013794
[Train] epoch 45 Batch 45 Loss 0.17114415764808655
[Train] epoch 45 Batch 46 Loss 0.22495733201503754
[Train] epoch 45 Batch 47 Loss 0.26346132159233093
[Train] epoch 46 Batch 0 Loss 0.25027981400489807
[Train] epoch 46 Batch 1 Loss 0.1628352701663971
[Train] epoch 46 Batch 2 Loss 0.2281651347875595
[Train] epoch 46 Batch 3 Loss 0.1863878220319748
[Train] epoch 46 Batch 4 Loss 0.07516101002693176
[Train] epoch 46 Batch 5 Loss 0.12228173017501831
[Train] epoch 46 Batch 6 Loss 0.37284624576568604
[Train] epoch 46 Batch 7 Loss 0.19712838530540466
[Train] epoch 46 Batch 8 Loss 0.27848660945892334
[Train] epoch 46 Batch 9 Loss 0.2080167829990387
[Train] epoch 46 Batch 10 Loss 0.21717333793640137
[Train] epoch 46 Batch 11 Loss 0.2441527098417282
[Train] epoch 46 Batch 12 Loss 0.2206968069076538
[Train] epoch 46 Batch 13 Loss 0.32257914543151855
[Train] epoch 46 Batch 14 Loss 0.21511544287204742
[Train] epoch 46 Batch 15 Loss 0.3575480282306671
[Train] epoch 46 Batch 16 Loss 0.29788121581077576
[Train] epoch 46 Batch 17 Loss 0.22347790002822876
[Train] epoch 46 Batch 18 Loss 0.25181183218955994
[Train] epoch 46 Batch 19 Loss 0.2854171693325043
[Train] epoch 46 Batch 20 Loss 0.25743138790130615
[Train] epoch 46 Batch 21 Loss 0.2640606760978699
[Train] epoch 46 Batch 22 Loss 0.1781073808670044
[Train] epoch 46 Batch 23 Loss 0.08653667569160461
[Train] epoch 46 Batch 24 Loss 0.3018210530281067
[Train] epoch 46 Batch 25 Loss 0.1171654686331749
[Train] epoch 46 Batch 26 Loss 0.1434646099805832
[Train] epoch 46 Batch 27 Loss 0.08516260981559753
[Train] epoch 46 Batch 28 Loss 0.14131498336791992
[Train] epoch 46 Batch 29 Loss 0.11700667440891266
[Train] epoch 46 Batch 30 Loss 0.21415574848651886
[Train] epoch 46 Batch 31 Loss 0.2291354238986969
[Train] epoch 46 Batch 32 Loss 0.12453410029411316
[Train] epoch 46 Batch 33 Loss 0.1102936640381813
[Train] epoch 46 Batch 34 Loss 0.2883869409561157
[Train] epoch 46 Batch 35 Loss 0.22749724984169006
[Train] epoch 46 Batch 36 Loss 0.21554991602897644
[Train] epoch 46 Batch 37 Loss 0.2640877664089203
[Train] epoch 46 Batch 38 Loss 0.31316256523132324
[Train] epoch 46 Batch 39 Loss 0.13259291648864746
[Train] epoch 46 Batch 40 Loss 0.2851889133453369
[Train] epoch 46 Batch 41 Loss 0.18901634216308594
[Train] epoch 46 Batch 42 Loss 0.24917155504226685
[Train] epoch 46 Batch 43 Loss 0.1662164032459259
[Train] epoch 46 Batch 44 Loss 0.188760444521904
[Train] epoch 46 Batch 45 Loss 0.2651117742061615
[Train] epoch 46 Batch 46 Loss 0.16239872574806213
[Train] epoch 46 Batch 47 Loss 0.08279646933078766
[Train] epoch 47 Batch 0 Loss 0.28042638301849365
[Train] epoch 47 Batch 1 Loss 0.16516877710819244
[Train] epoch 47 Batch 2 Loss 0.2337164282798767
[Train] epoch 47 Batch 3 Loss 0.09740724414587021
[Train] epoch 47 Batch 4 Loss 0.2548198401927948
[Train] epoch 47 Batch 5 Loss 0.18206557631492615
[Train] epoch 47 Batch 6 Loss 0.21678189933300018
[Train] epoch 47 Batch 7 Loss 0.2312571406364441
[Train] epoch 47 Batch 8 Loss 0.35454875230789185
[Train] epoch 47 Batch 9 Loss 0.21461808681488037
[Train] epoch 47 Batch 10 Loss 0.2769029140472412
[Train] epoch 47 Batch 11 Loss 0.21366551518440247
[Train] epoch 47 Batch 12 Loss 0.22962000966072083
[Train] epoch 47 Batch 13 Loss 0.21084943413734436
[Train] epoch 47 Batch 14 Loss 0.24011628329753876
[Train] epoch 47 Batch 15 Loss 0.1434473693370819
[Train] epoch 47 Batch 16 Loss 0.3180535137653351
[Train] epoch 47 Batch 17 Loss 0.22918161749839783
[Train] epoch 47 Batch 18 Loss 0.21899977326393127
[Train] epoch 47 Batch 19 Loss 0.1837102472782135
[Train] epoch 47 Batch 20 Loss 0.3234659731388092
[Train] epoch 47 Batch 21 Loss 0.1705961972475052
[Train] epoch 47 Batch 22 Loss 0.2414822280406952
[Train] epoch 47 Batch 23 Loss 0.20283523201942444
[Train] epoch 47 Batch 24 Loss 0.18352431058883667
[Train] epoch 47 Batch 25 Loss 0.1433718502521515
[Train] epoch 47 Batch 26 Loss 0.28856155276298523
[Train] epoch 47 Batch 27 Loss 0.24576035141944885
[Train] epoch 47 Batch 28 Loss 0.20613892376422882
[Train] epoch 47 Batch 29 Loss 0.15144459903240204
[Train] epoch 47 Batch 30 Loss 0.22857852280139923
[Train] epoch 47 Batch 31 Loss 0.17654389142990112
[Train] epoch 47 Batch 32 Loss 0.08429063856601715
[Train] epoch 47 Batch 33 Loss 0.12960587441921234
[Train] epoch 47 Batch 34 Loss 0.19719798862934113
[Train] epoch 47 Batch 35 Loss 0.29639822244644165
[Train] epoch 47 Batch 36 Loss 0.18368521332740784
[Train] epoch 47 Batch 37 Loss 0.21276941895484924
[Train] epoch 47 Batch 38 Loss 0.1125599592924118
[Train] epoch 47 Batch 39 Loss 0.1639721840620041
[Train] epoch 47 Batch 40 Loss 0.2589835524559021
[Train] epoch 47 Batch 41 Loss 0.1378197818994522
[Train] epoch 47 Batch 42 Loss 0.16920004785060883
[Train] epoch 47 Batch 43 Loss 0.1681899130344391
[Train] epoch 47 Batch 44 Loss 0.15903571248054504
[Train] epoch 47 Batch 45 Loss 0.18451499938964844
[Train] epoch 47 Batch 46 Loss 0.1517336666584015
[Train] epoch 47 Batch 47 Loss 0.20574243366718292
[Train] epoch 48 Batch 0 Loss 0.21119244396686554
[Train] epoch 48 Batch 1 Loss 0.17114463448524475
[Train] epoch 48 Batch 2 Loss 0.4208143949508667
[Train] epoch 48 Batch 3 Loss 0.27384495735168457
[Train] epoch 48 Batch 4 Loss 0.20112355053424835
[Train] epoch 48 Batch 5 Loss 0.17719322443008423
[Train] epoch 48 Batch 6 Loss 0.42620885372161865
[Train] epoch 48 Batch 7 Loss 0.13432562351226807
[Train] epoch 48 Batch 8 Loss 0.1909555196762085
[Train] epoch 48 Batch 9 Loss 0.19899779558181763
[Train] epoch 48 Batch 10 Loss 0.24122656881809235
[Train] epoch 48 Batch 11 Loss 0.22160378098487854
[Train] epoch 48 Batch 12 Loss 0.18420585989952087
[Train] epoch 48 Batch 13 Loss 0.2317623496055603
[Train] epoch 48 Batch 14 Loss 0.18258601427078247
[Train] epoch 48 Batch 15 Loss 0.14632731676101685
[Train] epoch 48 Batch 16 Loss 0.18404440581798553
[Train] epoch 48 Batch 17 Loss 0.21209834516048431
[Train] epoch 48 Batch 18 Loss 0.2500959634780884
[Train] epoch 48 Batch 19 Loss 0.21151652932167053
[Train] epoch 48 Batch 20 Loss 0.13419610261917114
[Train] epoch 48 Batch 21 Loss 0.0762556716799736
[Train] epoch 48 Batch 22 Loss 0.2460431456565857
[Train] epoch 48 Batch 23 Loss 0.2312094271183014
[Train] epoch 48 Batch 24 Loss 0.10947392135858536
[Train] epoch 48 Batch 25 Loss 0.39820075035095215
[Train] epoch 48 Batch 26 Loss 0.164542093873024
[Train] epoch 48 Batch 27 Loss 0.12972575426101685
[Train] epoch 48 Batch 28 Loss 0.07613703608512878
[Train] epoch 48 Batch 29 Loss 0.22264708578586578
[Train] epoch 48 Batch 30 Loss 0.19421933591365814
[Train] epoch 48 Batch 31 Loss 0.27715495228767395
[Train] epoch 48 Batch 32 Loss 0.11777722835540771
[Train] epoch 48 Batch 33 Loss 0.22093510627746582
[Train] epoch 48 Batch 34 Loss 0.13402114808559418
[Train] epoch 48 Batch 35 Loss 0.06987695395946503
[Train] epoch 48 Batch 36 Loss 0.257280170917511
[Train] epoch 48 Batch 37 Loss 0.1326598972082138
[Train] epoch 48 Batch 38 Loss 0.20859727263450623
[Train] epoch 48 Batch 39 Loss 0.31826359033584595
[Train] epoch 48 Batch 40 Loss 0.18006035685539246
[Train] epoch 48 Batch 41 Loss 0.14281171560287476
[Train] epoch 48 Batch 42 Loss 0.09270358830690384
[Train] epoch 48 Batch 43 Loss 0.28013181686401367
[Train] epoch 48 Batch 44 Loss 0.1339748501777649
[Train] epoch 48 Batch 45 Loss 0.07584240287542343
[Train] epoch 48 Batch 46 Loss 0.33162498474121094
[Train] epoch 48 Batch 47 Loss 0.07429017126560211
[Train] epoch 49 Batch 0 Loss 0.2042325884103775
[Train] epoch 49 Batch 1 Loss 0.20100784301757812
[Train] epoch 49 Batch 2 Loss 0.14888542890548706
[Train] epoch 49 Batch 3 Loss 0.06344780325889587
[Train] epoch 49 Batch 4 Loss 0.1992829144001007
[Train] epoch 49 Batch 5 Loss 0.2901066541671753
[Train] epoch 49 Batch 6 Loss 0.10919584333896637
[Train] epoch 49 Batch 7 Loss 0.09774206578731537
[Train] epoch 49 Batch 8 Loss 0.12593361735343933
[Train] epoch 49 Batch 9 Loss 0.339693546295166
[Train] epoch 49 Batch 10 Loss 0.1595119833946228
[Train] epoch 49 Batch 11 Loss 0.1978881061077118
[Train] epoch 49 Batch 12 Loss 0.10156787186861038
[Train] epoch 49 Batch 13 Loss 0.21418128907680511
[Train] epoch 49 Batch 14 Loss 0.13026130199432373
[Train] epoch 49 Batch 15 Loss 0.3063010573387146
[Train] epoch 49 Batch 16 Loss 0.1746581345796585
[Train] epoch 49 Batch 17 Loss 0.21017897129058838
[Train] epoch 49 Batch 18 Loss 0.1790604591369629
[Train] epoch 49 Batch 19 Loss 0.20079374313354492
[Train] epoch 49 Batch 20 Loss 0.18261907994747162
[Train] epoch 49 Batch 21 Loss 0.15633971989154816
[Train] epoch 49 Batch 22 Loss 0.2324305772781372
[Train] epoch 49 Batch 23 Loss 0.22341573238372803
[Train] epoch 49 Batch 24 Loss 0.132010817527771
[Train] epoch 49 Batch 25 Loss 0.25315290689468384
[Train] epoch 49 Batch 26 Loss 0.1613156944513321
[Train] epoch 49 Batch 27 Loss 0.13305965065956116
[Train] epoch 49 Batch 28 Loss 0.12164611369371414
[Train] epoch 49 Batch 29 Loss 0.304019033908844
[Train] epoch 49 Batch 30 Loss 0.20420348644256592
[Train] epoch 49 Batch 31 Loss 0.20443391799926758
[Train] epoch 49 Batch 32 Loss 0.2724704444408417
[Train] epoch 49 Batch 33 Loss 0.16535209119319916
[Train] epoch 49 Batch 34 Loss 0.30923783779144287
[Train] epoch 49 Batch 35 Loss 0.10493282973766327
[Train] epoch 49 Batch 36 Loss 0.15402622520923615
[Train] epoch 49 Batch 37 Loss 0.2476046085357666
[Train] epoch 49 Batch 38 Loss 0.16478830575942993
[Train] epoch 49 Batch 39 Loss 0.18039879202842712
[Train] epoch 49 Batch 40 Loss 0.12567536532878876
[Train] epoch 49 Batch 41 Loss 0.19430847465991974
[Train] epoch 49 Batch 42 Loss 0.2202337384223938
[Train] epoch 49 Batch 43 Loss 0.08840684592723846
[Train] epoch 49 Batch 44 Loss 0.1885516196489334
[Train] epoch 49 Batch 45 Loss 0.27084091305732727
[Train] epoch 49 Batch 46 Loss 0.2707153260707855
[Train] epoch 49 Batch 47 Loss 0.1551828533411026
[Train] epoch 50 Batch 0 Loss 0.20470982789993286
[Train] epoch 50 Batch 1 Loss 0.1559905856847763
[Train] epoch 50 Batch 2 Loss 0.17345449328422546
[Train] epoch 50 Batch 3 Loss 0.20277810096740723
[Train] epoch 50 Batch 4 Loss 0.10031278431415558
[Train] epoch 50 Batch 5 Loss 0.10912109166383743
[Train] epoch 50 Batch 6 Loss 0.1539057493209839
[Train] epoch 50 Batch 7 Loss 0.11430573463439941
[Train] epoch 50 Batch 8 Loss 0.13623833656311035
[Train] epoch 50 Batch 9 Loss 0.14576171338558197
[Train] epoch 50 Batch 10 Loss 0.13727129995822906
[Train] epoch 50 Batch 11 Loss 0.09970603138208389
[Train] epoch 50 Batch 12 Loss 0.2321963608264923
[Train] epoch 50 Batch 13 Loss 0.27872520685195923
[Train] epoch 50 Batch 14 Loss 0.11437374353408813
[Train] epoch 50 Batch 15 Loss 0.19374659657478333
[Train] epoch 50 Batch 16 Loss 0.10116799175739288
[Train] epoch 50 Batch 17 Loss 0.21908649802207947
[Train] epoch 50 Batch 18 Loss 0.1979152411222458
[Train] epoch 50 Batch 19 Loss 0.1280219405889511
[Train] epoch 50 Batch 20 Loss 0.046207450330257416
[Train] epoch 50 Batch 21 Loss 0.23779523372650146
[Train] epoch 50 Batch 22 Loss 0.32180291414260864
[Train] epoch 50 Batch 23 Loss 0.29579469561576843
[Train] epoch 50 Batch 24 Loss 0.2666415274143219
[Train] epoch 50 Batch 25 Loss 0.2637082040309906
[Train] epoch 50 Batch 26 Loss 0.17763949930667877
[Train] epoch 50 Batch 27 Loss 0.2570596933364868
[Train] epoch 50 Batch 28 Loss 0.20538949966430664
[Train] epoch 50 Batch 29 Loss 0.1406363546848297
[Train] epoch 50 Batch 30 Loss 0.18173041939735413
[Train] epoch 50 Batch 31 Loss 0.23472124338150024
[Train] epoch 50 Batch 32 Loss 0.19388149678707123
[Train] epoch 50 Batch 33 Loss 0.20277690887451172
[Train] epoch 50 Batch 34 Loss 0.23659321665763855
[Train] epoch 50 Batch 35 Loss 0.14044903218746185
[Train] epoch 50 Batch 36 Loss 0.24670809507369995
[Train] epoch 50 Batch 37 Loss 0.0472983792424202
[Train] epoch 50 Batch 38 Loss 0.31108957529067993
[Train] epoch 50 Batch 39 Loss 0.2847195267677307
[Train] epoch 50 Batch 40 Loss 0.2100757658481598
[Train] epoch 50 Batch 41 Loss 0.19033214449882507
[Train] epoch 50 Batch 42 Loss 0.07904645800590515
[Train] epoch 50 Batch 43 Loss 0.28274837136268616
[Train] epoch 50 Batch 44 Loss 0.14684799313545227
[Train] epoch 50 Batch 45 Loss 0.30938053131103516
[Train] epoch 50 Batch 46 Loss 0.14894768595695496
[Train] epoch 50 Batch 47 Loss 0.2571376860141754
[Train] epoch 51 Batch 0 Loss 0.09766912460327148
[Train] epoch 51 Batch 1 Loss 0.20364615321159363
[Train] epoch 51 Batch 2 Loss 0.1234845221042633
[Train] epoch 51 Batch 3 Loss 0.2744881510734558
[Train] epoch 51 Batch 4 Loss 0.10152941942214966
[Train] epoch 51 Batch 5 Loss 0.20495200157165527
[Train] epoch 51 Batch 6 Loss 0.24205176532268524
[Train] epoch 51 Batch 7 Loss 0.2738005518913269
[Train] epoch 51 Batch 8 Loss 0.12640410661697388
[Train] epoch 51 Batch 9 Loss 0.08937203884124756
[Train] epoch 51 Batch 10 Loss 0.17755457758903503
[Train] epoch 51 Batch 11 Loss 0.42967963218688965
[Train] epoch 51 Batch 12 Loss 0.2535082697868347
[Train] epoch 51 Batch 13 Loss 0.26818346977233887
[Train] epoch 51 Batch 14 Loss 0.14117242395877838
[Train] epoch 51 Batch 15 Loss 0.36000242829322815
[Train] epoch 51 Batch 16 Loss 0.3850693106651306
[Train] epoch 51 Batch 17 Loss 0.24297988414764404
[Train] epoch 51 Batch 18 Loss 0.09505730867385864
[Train] epoch 51 Batch 19 Loss 0.284931480884552
[Train] epoch 51 Batch 20 Loss 0.10924040526151657
[Train] epoch 51 Batch 21 Loss 0.2932721674442291
[Train] epoch 51 Batch 22 Loss 0.19996419548988342
[Train] epoch 51 Batch 23 Loss 0.3443604111671448
[Train] epoch 51 Batch 24 Loss 0.045995961874723434
[Train] epoch 51 Batch 25 Loss 0.19689014554023743
[Train] epoch 51 Batch 26 Loss 0.1313139945268631
[Train] epoch 51 Batch 27 Loss 0.15635333955287933
[Train] epoch 51 Batch 28 Loss 0.3176972270011902
[Train] epoch 51 Batch 29 Loss 0.16189506649971008
[Train] epoch 51 Batch 30 Loss 0.23258250951766968
[Train] epoch 51 Batch 31 Loss 0.07564224302768707
[Train] epoch 51 Batch 32 Loss 0.18919315934181213
[Train] epoch 51 Batch 33 Loss 0.07993592321872711
[Train] epoch 51 Batch 34 Loss 0.22303858399391174
[Train] epoch 51 Batch 35 Loss 0.1133882999420166
[Train] epoch 51 Batch 36 Loss 0.14805567264556885
[Train] epoch 51 Batch 37 Loss 0.3086813688278198
[Train] epoch 51 Batch 38 Loss 0.24685850739479065
[Train] epoch 51 Batch 39 Loss 0.35741478204727173
[Train] epoch 51 Batch 40 Loss 0.04974077641963959
[Train] epoch 51 Batch 41 Loss 0.35244545340538025
[Train] epoch 51 Batch 42 Loss 0.14691807329654694
[Train] epoch 51 Batch 43 Loss 0.08613325655460358
[Train] epoch 51 Batch 44 Loss 0.06982390582561493
[Train] epoch 51 Batch 45 Loss 0.09263920783996582
[Train] epoch 51 Batch 46 Loss 0.2914363145828247
[Train] epoch 51 Batch 47 Loss 0.22522464394569397
[Train] epoch 52 Batch 0 Loss 0.11793410778045654
[Train] epoch 52 Batch 1 Loss 0.2429509162902832
[Train] epoch 52 Batch 2 Loss 0.26154351234436035
[Train] epoch 52 Batch 3 Loss 0.14874599874019623
[Train] epoch 52 Batch 4 Loss 0.05333956331014633
[Train] epoch 52 Batch 5 Loss 0.04727461561560631
[Train] epoch 52 Batch 6 Loss 0.20418781042099
[Train] epoch 52 Batch 7 Loss 0.08947773277759552
[Train] epoch 52 Batch 8 Loss 0.20761755108833313
[Train] epoch 52 Batch 9 Loss 0.18879470229148865
[Train] epoch 52 Batch 10 Loss 0.1497357189655304
[Train] epoch 52 Batch 11 Loss 0.16508041322231293
[Train] epoch 52 Batch 12 Loss 0.20122888684272766
[Train] epoch 52 Batch 13 Loss 0.1944398581981659
[Train] epoch 52 Batch 14 Loss 0.13891522586345673
[Train] epoch 52 Batch 15 Loss 0.17725183069705963
[Train] epoch 52 Batch 16 Loss 0.199898362159729
[Train] epoch 52 Batch 17 Loss 0.11671092361211777
[Train] epoch 52 Batch 18 Loss 0.14653831720352173
[Train] epoch 52 Batch 19 Loss 0.1605684757232666
[Train] epoch 52 Batch 20 Loss 0.09633789956569672
[Train] epoch 52 Batch 21 Loss 0.15077751874923706
[Train] epoch 52 Batch 22 Loss 0.26648056507110596
[Train] epoch 52 Batch 23 Loss 0.12815557420253754
[Train] epoch 52 Batch 24 Loss 0.22011101245880127
[Train] epoch 52 Batch 25 Loss 0.25630801916122437
[Train] epoch 52 Batch 26 Loss 0.2238544225692749
[Train] epoch 52 Batch 27 Loss 0.15514589846134186
[Train] epoch 52 Batch 28 Loss 0.15349836647510529
[Train] epoch 52 Batch 29 Loss 0.22982841730117798
[Train] epoch 52 Batch 30 Loss 0.23078002035617828
[Train] epoch 52 Batch 31 Loss 0.33198124170303345
[Train] epoch 52 Batch 32 Loss 0.06423865258693695
[Train] epoch 52 Batch 33 Loss 0.12227970361709595
[Train] epoch 52 Batch 34 Loss 0.14358778297901154
[Train] epoch 52 Batch 35 Loss 0.20104214549064636
[Train] epoch 52 Batch 36 Loss 0.26521432399749756
[Train] epoch 52 Batch 37 Loss 0.17011265456676483
[Train] epoch 52 Batch 38 Loss 0.2125040739774704
[Train] epoch 52 Batch 39 Loss 0.10591316223144531
[Train] epoch 52 Batch 40 Loss 0.19649702310562134
[Train] epoch 52 Batch 41 Loss 0.20583638548851013
[Train] epoch 52 Batch 42 Loss 0.21318255364894867
[Train] epoch 52 Batch 43 Loss 0.2940463125705719
[Train] epoch 52 Batch 44 Loss 0.18105420470237732
[Train] epoch 52 Batch 45 Loss 0.22096505761146545
[Train] epoch 52 Batch 46 Loss 0.1620863676071167
[Train] epoch 52 Batch 47 Loss 0.14769871532917023
[Train] epoch 53 Batch 0 Loss 0.2564048767089844
[Train] epoch 53 Batch 1 Loss 0.03063626028597355
[Train] epoch 53 Batch 2 Loss 0.24575719237327576
[Train] epoch 53 Batch 3 Loss 0.220289945602417
[Train] epoch 53 Batch 4 Loss 0.2863365411758423
[Train] epoch 53 Batch 5 Loss 0.11188259720802307
[Train] epoch 53 Batch 6 Loss 0.1747695505619049
[Train] epoch 53 Batch 7 Loss 0.2111724615097046
[Train] epoch 53 Batch 8 Loss 0.1394619643688202
[Train] epoch 53 Batch 9 Loss 0.27043473720550537
[Train] epoch 53 Batch 10 Loss 0.14363081753253937
[Train] epoch 53 Batch 11 Loss 0.13873997330665588
[Train] epoch 53 Batch 12 Loss 0.276689350605011
[Train] epoch 53 Batch 13 Loss 0.21051722764968872
[Train] epoch 53 Batch 14 Loss 0.16502955555915833
[Train] epoch 53 Batch 15 Loss 0.058384016156196594
[Train] epoch 53 Batch 16 Loss 0.29969483613967896
[Train] epoch 53 Batch 17 Loss 0.09827709943056107
[Train] epoch 53 Batch 18 Loss 0.19348931312561035
[Train] epoch 53 Batch 19 Loss 0.1958465427160263
[Train] epoch 53 Batch 20 Loss 0.17998576164245605
[Train] epoch 53 Batch 21 Loss 0.04836799204349518
[Train] epoch 53 Batch 22 Loss 0.16838644444942474
[Train] epoch 53 Batch 23 Loss 0.2372940182685852
[Train] epoch 53 Batch 24 Loss 0.11854322254657745
[Train] epoch 53 Batch 25 Loss 0.14176198840141296
[Train] epoch 53 Batch 26 Loss 0.20746135711669922
[Train] epoch 53 Batch 27 Loss 0.2258721888065338
[Train] epoch 53 Batch 28 Loss 0.18160966038703918
[Train] epoch 53 Batch 29 Loss 0.16359326243400574
[Train] epoch 53 Batch 30 Loss 0.16371379792690277
[Train] epoch 53 Batch 31 Loss 0.128986656665802
[Train] epoch 53 Batch 32 Loss 0.19436192512512207
[Train] epoch 53 Batch 33 Loss 0.1652785837650299
[Train] epoch 53 Batch 34 Loss 0.04769553616642952
[Train] epoch 53 Batch 35 Loss 0.2804471552371979
[Train] epoch 53 Batch 36 Loss 0.1322077512741089
[Train] epoch 53 Batch 37 Loss 0.2204892933368683
[Train] epoch 53 Batch 38 Loss 0.22508910298347473
[Train] epoch 53 Batch 39 Loss 0.17542707920074463
[Train] epoch 53 Batch 40 Loss 0.07966950535774231
[Train] epoch 53 Batch 41 Loss 0.08378872275352478
[Train] epoch 53 Batch 42 Loss 0.06539009511470795
[Train] epoch 53 Batch 43 Loss 0.20494654774665833
[Train] epoch 53 Batch 44 Loss 0.10170883685350418
[Train] epoch 53 Batch 45 Loss 0.28647467494010925
[Train] epoch 53 Batch 46 Loss 0.14006198942661285
[Train] epoch 53 Batch 47 Loss 0.28857991099357605
[Train] epoch 54 Batch 0 Loss 0.20759044587612152
[Train] epoch 54 Batch 1 Loss 0.2942221164703369
[Train] epoch 54 Batch 2 Loss 0.22517427802085876
[Train] epoch 54 Batch 3 Loss 0.2450585961341858
[Train] epoch 54 Batch 4 Loss 0.19975502789020538
[Train] epoch 54 Batch 5 Loss 0.1340593844652176
[Train] epoch 54 Batch 6 Loss 0.14720377326011658
[Train] epoch 54 Batch 7 Loss 0.2316964864730835
[Train] epoch 54 Batch 8 Loss 0.18644902110099792
[Train] epoch 54 Batch 9 Loss 0.12738393247127533
[Train] epoch 54 Batch 10 Loss 0.3231877088546753
[Train] epoch 54 Batch 11 Loss 0.23191693425178528
[Train] epoch 54 Batch 12 Loss 0.26141759753227234
[Train] epoch 54 Batch 13 Loss 0.19102942943572998
[Train] epoch 54 Batch 14 Loss 0.05272272229194641
[Train] epoch 54 Batch 15 Loss 0.21962539851665497
[Train] epoch 54 Batch 16 Loss 0.23770016431808472
[Train] epoch 54 Batch 17 Loss 0.2589437663555145
[Train] epoch 54 Batch 18 Loss 0.07092815637588501
[Train] epoch 54 Batch 19 Loss 0.12465760856866837
[Train] epoch 54 Batch 20 Loss 0.12360209971666336
[Train] epoch 54 Batch 21 Loss 1.0728851975727594e-06
[Train] epoch 54 Batch 22 Loss 0.03705854341387749
[Train] epoch 54 Batch 23 Loss 0.1184622198343277
[Train] epoch 54 Batch 24 Loss 0.12551310658454895
[Train] epoch 54 Batch 25 Loss 0.1544928103685379
[Train] epoch 54 Batch 26 Loss 0.19579780101776123
[Train] epoch 54 Batch 27 Loss 0.16213460266590118
[Train] epoch 54 Batch 28 Loss 0.15070976316928864
[Train] epoch 54 Batch 29 Loss 0.19249875843524933
[Train] epoch 54 Batch 30 Loss 0.1801619529724121
[Train] epoch 54 Batch 31 Loss 0.11810297518968582
[Train] epoch 54 Batch 32 Loss 0.13615356385707855
[Train] epoch 54 Batch 33 Loss 0.24284949898719788
[Train] epoch 54 Batch 34 Loss 0.26444754004478455
[Train] epoch 54 Batch 35 Loss 0.1206858679652214
[Train] epoch 54 Batch 36 Loss 0.23353508114814758
[Train] epoch 54 Batch 37 Loss 0.17838291823863983
[Train] epoch 54 Batch 38 Loss 0.041599880903959274
[Train] epoch 54 Batch 39 Loss 0.27865171432495117
[Train] epoch 54 Batch 40 Loss 0.2822423577308655
[Train] epoch 54 Batch 41 Loss 0.23856288194656372
[Train] epoch 54 Batch 42 Loss 0.1623542755842209
[Train] epoch 54 Batch 43 Loss 0.19623704254627228
[Train] epoch 54 Batch 44 Loss 0.13520269095897675
[Train] epoch 54 Batch 45 Loss 0.18393389880657196
[Train] epoch 54 Batch 46 Loss 0.1585012674331665
[Train] epoch 54 Batch 47 Loss 0.29265302419662476
[Train] epoch 55 Batch 0 Loss 0.15955546498298645
[Train] epoch 55 Batch 1 Loss 0.14127589762210846
[Train] epoch 55 Batch 2 Loss 0.14419794082641602
[Train] epoch 55 Batch 3 Loss 0.2232360690832138
[Train] epoch 55 Batch 4 Loss 0.22973892092704773
[Train] epoch 55 Batch 5 Loss 0.19245268404483795
[Train] epoch 55 Batch 6 Loss 0.09948371350765228
[Train] epoch 55 Batch 7 Loss 0.1860596239566803
[Train] epoch 55 Batch 8 Loss 0.09155575931072235
[Train] epoch 55 Batch 9 Loss 0.13047043979167938
[Train] epoch 55 Batch 10 Loss 0.19580380618572235
[Train] epoch 55 Batch 11 Loss 0.27551189064979553
[Train] epoch 55 Batch 12 Loss 0.09387463331222534
[Train] epoch 55 Batch 13 Loss 0.15414759516716003
[Train] epoch 55 Batch 14 Loss 0.2644059658050537
[Train] epoch 55 Batch 15 Loss 0.231456458568573
[Train] epoch 55 Batch 16 Loss 0.14838096499443054
[Train] epoch 55 Batch 17 Loss 0.20561224222183228
[Train] epoch 55 Batch 18 Loss 0.1996212601661682
[Train] epoch 55 Batch 19 Loss 0.14684253931045532
[Train] epoch 55 Batch 20 Loss 0.19466447830200195
[Train] epoch 55 Batch 21 Loss 0.1404128521680832
[Train] epoch 55 Batch 22 Loss 0.10753579437732697
[Train] epoch 55 Batch 23 Loss 0.2928835153579712
[Train] epoch 55 Batch 24 Loss 0.09460148215293884
[Train] epoch 55 Batch 25 Loss 0.3541339635848999
[Train] epoch 55 Batch 26 Loss 0.09206335991621017
[Train] epoch 55 Batch 27 Loss 0.10567182302474976
[Train] epoch 55 Batch 28 Loss 0.15928667783737183
[Train] epoch 55 Batch 29 Loss 0.20437858998775482
[Train] epoch 55 Batch 30 Loss 0.1040436327457428
[Train] epoch 55 Batch 31 Loss 0.044394735246896744
[Train] epoch 55 Batch 32 Loss 0.3070663809776306
[Train] epoch 55 Batch 33 Loss 0.2402157336473465
[Train] epoch 55 Batch 34 Loss 0.2619490325450897
[Train] epoch 55 Batch 35 Loss 0.08804063498973846
[Train] epoch 55 Batch 36 Loss 0.1365545243024826
[Train] epoch 55 Batch 37 Loss 0.18642950057983398
[Train] epoch 55 Batch 38 Loss 0.1306731253862381
[Train] epoch 55 Batch 39 Loss 0.028639020398259163
[Train] epoch 55 Batch 40 Loss 0.09277322143316269
[Train] epoch 55 Batch 41 Loss 0.262497216463089
[Train] epoch 55 Batch 42 Loss 0.17864219844341278
[Train] epoch 55 Batch 43 Loss 0.18859218060970306
[Train] epoch 55 Batch 44 Loss 0.20839549601078033
[Train] epoch 55 Batch 45 Loss 0.17733515799045563
[Train] epoch 55 Batch 46 Loss 0.1692381650209427
[Train] epoch 55 Batch 47 Loss 0.19076377153396606
[Train] epoch 56 Batch 0 Loss 0.1305285543203354
[Train] epoch 56 Batch 1 Loss 0.24172234535217285
[Train] epoch 56 Batch 2 Loss 0.19158011674880981
[Train] epoch 56 Batch 3 Loss 0.05357002094388008
[Train] epoch 56 Batch 4 Loss 0.19286060333251953
[Train] epoch 56 Batch 5 Loss 0.19237923622131348
[Train] epoch 56 Batch 6 Loss 0.1992996335029602
[Train] epoch 56 Batch 7 Loss 0.22616824507713318
[Train] epoch 56 Batch 8 Loss 0.09465561807155609
[Train] epoch 56 Batch 9 Loss 0.12376487255096436
[Train] epoch 56 Batch 10 Loss 0.18075518310070038
[Train] epoch 56 Batch 11 Loss 0.2392222136259079
[Train] epoch 56 Batch 12 Loss 0.16152110695838928
[Train] epoch 56 Batch 13 Loss 0.09417705237865448
[Train] epoch 56 Batch 14 Loss 0.17919720709323883
[Train] epoch 56 Batch 15 Loss 0.09795567393302917
[Train] epoch 56 Batch 16 Loss 0.20199835300445557
[Train] epoch 56 Batch 17 Loss 0.09950320422649384
[Train] epoch 56 Batch 18 Loss 0.13953623175621033
[Train] epoch 56 Batch 19 Loss 0.19772180914878845
[Train] epoch 56 Batch 20 Loss 0.2320660799741745
[Train] epoch 56 Batch 21 Loss 0.12082889676094055
[Train] epoch 56 Batch 22 Loss 0.2554709315299988
[Train] epoch 56 Batch 23 Loss 0.14546602964401245
[Train] epoch 56 Batch 24 Loss 0.157564178109169
[Train] epoch 56 Batch 25 Loss 0.2741466164588928
[Train] epoch 56 Batch 26 Loss 0.21751661598682404
[Train] epoch 56 Batch 27 Loss 0.12822620570659637
[Train] epoch 56 Batch 28 Loss 0.3317420482635498
[Train] epoch 56 Batch 29 Loss 0.13369309902191162
[Train] epoch 56 Batch 30 Loss 0.18310663104057312
[Train] epoch 56 Batch 31 Loss 0.17930945754051208
[Train] epoch 56 Batch 32 Loss 0.14706654846668243
[Train] epoch 56 Batch 33 Loss 0.10601407289505005
[Train] epoch 56 Batch 34 Loss 0.14073427021503448
[Train] epoch 56 Batch 35 Loss 0.2310798168182373
[Train] epoch 56 Batch 36 Loss 0.20472988486289978
[Train] epoch 56 Batch 37 Loss 0.1807205080986023
[Train] epoch 56 Batch 38 Loss 0.18381597101688385
[Train] epoch 56 Batch 39 Loss 0.08719004690647125
[Train] epoch 56 Batch 40 Loss 0.16607090830802917
[Train] epoch 56 Batch 41 Loss 0.16284626722335815
[Train] epoch 56 Batch 42 Loss 0.24732092022895813
[Train] epoch 56 Batch 43 Loss 0.07372219115495682
[Train] epoch 56 Batch 44 Loss 0.131515234708786
[Train] epoch 56 Batch 45 Loss 0.2174302339553833
[Train] epoch 56 Batch 46 Loss 0.15919145941734314
[Train] epoch 56 Batch 47 Loss 0.28816357254981995
[Train] epoch 57 Batch 0 Loss 0.18827152252197266
[Train] epoch 57 Batch 1 Loss 0.25954586267471313
[Train] epoch 57 Batch 2 Loss 0.08653666079044342
[Train] epoch 57 Batch 3 Loss 0.2415473908185959
[Train] epoch 57 Batch 4 Loss 0.3032899498939514
[Train] epoch 57 Batch 5 Loss 0.16867318749427795
[Train] epoch 57 Batch 6 Loss 0.15309526026248932
[Train] epoch 57 Batch 7 Loss 0.20789386332035065
[Train] epoch 57 Batch 8 Loss 0.051564231514930725
[Train] epoch 57 Batch 9 Loss 0.09720447659492493
[Train] epoch 57 Batch 10 Loss 0.1328929364681244
[Train] epoch 57 Batch 11 Loss 0.09904830157756805
[Train] epoch 57 Batch 12 Loss 0.08958301693201065
[Train] epoch 57 Batch 13 Loss 0.08284919708967209
[Train] epoch 57 Batch 14 Loss 0.18604707717895508
[Train] epoch 57 Batch 15 Loss 0.1796923726797104
[Train] epoch 57 Batch 16 Loss 0.20302917063236237
[Train] epoch 57 Batch 17 Loss 0.11065816879272461
[Train] epoch 57 Batch 18 Loss 0.08291451632976532
[Train] epoch 57 Batch 19 Loss 0.26298820972442627
[Train] epoch 57 Batch 20 Loss 0.16410402953624725
[Train] epoch 57 Batch 21 Loss 0.16262640058994293
[Train] epoch 57 Batch 22 Loss 0.06924183666706085
[Train] epoch 57 Batch 23 Loss 0.3129771947860718
[Train] epoch 57 Batch 24 Loss 0.13445383310317993
[Train] epoch 57 Batch 25 Loss 0.19140243530273438
[Train] epoch 57 Batch 26 Loss 0.20705953240394592
[Train] epoch 57 Batch 27 Loss 0.22924651205539703
[Train] epoch 57 Batch 28 Loss 0.3230098485946655
[Train] epoch 57 Batch 29 Loss 0.14937283098697662
[Train] epoch 57 Batch 30 Loss 0.051690880209207535
[Train] epoch 57 Batch 31 Loss 0.10259459912776947
[Train] epoch 57 Batch 32 Loss 0.22023522853851318
[Train] epoch 57 Batch 33 Loss 0.07751965522766113
[Train] epoch 57 Batch 34 Loss 0.20668472349643707
[Train] epoch 57 Batch 35 Loss 0.1380637139081955
[Train] epoch 57 Batch 36 Loss 0.08446384966373444
[Train] epoch 57 Batch 37 Loss 0.20538952946662903
[Train] epoch 57 Batch 38 Loss 0.259404718875885
[Train] epoch 57 Batch 39 Loss 0.1920349895954132
[Train] epoch 57 Batch 40 Loss 0.21949608623981476
[Train] epoch 57 Batch 41 Loss 0.1577766239643097
[Train] epoch 57 Batch 42 Loss 0.09623762220144272
[Train] epoch 57 Batch 43 Loss 0.04272662475705147
[Train] epoch 57 Batch 44 Loss 0.1765260100364685
[Train] epoch 57 Batch 45 Loss 0.2021244466304779
[Train] epoch 57 Batch 46 Loss 0.25665518641471863
[Train] epoch 57 Batch 47 Loss 0.3197231590747833
[Train] epoch 58 Batch 0 Loss 0.16687332093715668
[Train] epoch 58 Batch 1 Loss 0.11853969097137451
[Train] epoch 58 Batch 2 Loss 0.21276602149009705
[Train] epoch 58 Batch 3 Loss 0.0548144169151783
[Train] epoch 58 Batch 4 Loss 0.14489415287971497
[Train] epoch 58 Batch 5 Loss 0.13230019807815552
[Train] epoch 58 Batch 6 Loss 0.1472499668598175
[Train] epoch 58 Batch 7 Loss 0.13313648104667664
[Train] epoch 58 Batch 8 Loss 0.13780903816223145
[Train] epoch 58 Batch 9 Loss 0.20712152123451233
[Train] epoch 58 Batch 10 Loss 0.14128991961479187
[Train] epoch 58 Batch 11 Loss 0.09607788175344467
[Train] epoch 58 Batch 12 Loss 0.1604727804660797
[Train] epoch 58 Batch 13 Loss 0.12191388010978699
[Train] epoch 58 Batch 14 Loss 0.1649300456047058
[Train] epoch 58 Batch 15 Loss 0.15098337829113007
[Train] epoch 58 Batch 16 Loss 0.11334884911775589
[Train] epoch 58 Batch 17 Loss 0.24951061606407166
[Train] epoch 58 Batch 18 Loss 0.16475379467010498
[Train] epoch 58 Batch 19 Loss 0.25590622425079346
[Train] epoch 58 Batch 20 Loss 0.20231300592422485
[Train] epoch 58 Batch 21 Loss 0.24349504709243774
[Train] epoch 58 Batch 22 Loss 0.1470998376607895
[Train] epoch 58 Batch 23 Loss 0.2543090283870697
[Train] epoch 58 Batch 24 Loss 0.15338033437728882
[Train] epoch 58 Batch 25 Loss 0.0858289897441864
[Train] epoch 58 Batch 26 Loss 0.09486109018325806
[Train] epoch 58 Batch 27 Loss 0.18044839799404144
[Train] epoch 58 Batch 28 Loss 0.35891133546829224
[Train] epoch 58 Batch 29 Loss 0.09349808841943741
[Train] epoch 58 Batch 30 Loss 0.07891805469989777
[Train] epoch 58 Batch 31 Loss 0.22486776113510132
[Train] epoch 58 Batch 32 Loss 0.12544170022010803
[Train] epoch 58 Batch 33 Loss 0.2870372235774994
[Train] epoch 58 Batch 34 Loss 0.06543473154306412
[Train] epoch 58 Batch 35 Loss 0.15113769471645355
[Train] epoch 58 Batch 36 Loss 0.24841241538524628
[Train] epoch 58 Batch 37 Loss 0.16661575436592102
[Train] epoch 58 Batch 38 Loss 0.12833285331726074
[Train] epoch 58 Batch 39 Loss 0.15621495246887207
[Train] epoch 58 Batch 40 Loss 0.23118546605110168
[Train] epoch 58 Batch 41 Loss 0.2057379186153412
[Train] epoch 58 Batch 42 Loss 0.27608343958854675
[Train] epoch 58 Batch 43 Loss 0.28901004791259766
[Train] epoch 58 Batch 44 Loss 0.1962449550628662
[Train] epoch 58 Batch 45 Loss 0.19721385836601257
[Train] epoch 58 Batch 46 Loss 0.21385067701339722
[Train] epoch 58 Batch 47 Loss 0.1478886604309082
[Train] epoch 59 Batch 0 Loss 0.16934429109096527
[Train] epoch 59 Batch 1 Loss 0.18368418514728546
[Train] epoch 59 Batch 2 Loss 0.2040848731994629
[Train] epoch 59 Batch 3 Loss 0.1396046280860901
[Train] epoch 59 Batch 4 Loss 0.1475071758031845
[Train] epoch 59 Batch 5 Loss 0.16918325424194336
[Train] epoch 59 Batch 6 Loss 0.20116737484931946
[Train] epoch 59 Batch 7 Loss 0.2622741460800171
[Train] epoch 59 Batch 8 Loss 0.29221558570861816
[Train] epoch 59 Batch 9 Loss 0.24564319849014282
[Train] epoch 59 Batch 10 Loss 0.08087466657161713
[Train] epoch 59 Batch 11 Loss 0.1126115620136261
[Train] epoch 59 Batch 12 Loss 0.17325975000858307
[Train] epoch 59 Batch 13 Loss 0.08503653109073639
[Train] epoch 59 Batch 14 Loss 0.19405856728553772
[Train] epoch 59 Batch 15 Loss 0.10326249897480011
[Train] epoch 59 Batch 16 Loss 0.22987473011016846
[Train] epoch 59 Batch 17 Loss 0.22636663913726807
[Train] epoch 59 Batch 18 Loss 0.09156106412410736
[Train] epoch 59 Batch 19 Loss 0.21866202354431152
[Train] epoch 59 Batch 20 Loss 0.09921780228614807
[Train] epoch 59 Batch 21 Loss 0.16645213961601257
[Train] epoch 59 Batch 22 Loss 0.09375698119401932
[Train] epoch 59 Batch 23 Loss 0.08063910901546478
[Train] epoch 59 Batch 24 Loss 0.20821580290794373
[Train] epoch 59 Batch 25 Loss 0.10009869933128357
[Train] epoch 59 Batch 26 Loss 0.17793530225753784
[Train] epoch 59 Batch 27 Loss 0.11822839081287384
[Train] epoch 59 Batch 28 Loss 0.13139209151268005
[Train] epoch 59 Batch 29 Loss 0.15733139216899872
[Train] epoch 59 Batch 30 Loss 0.2623841464519501
[Train] epoch 59 Batch 31 Loss 0.23032039403915405
[Train] epoch 59 Batch 32 Loss 0.12485973536968231
[Train] epoch 59 Batch 33 Loss 0.12720388174057007
[Train] epoch 59 Batch 34 Loss 0.24980728328227997
[Train] epoch 59 Batch 35 Loss 0.1529441773891449
[Train] epoch 59 Batch 36 Loss 0.12878073751926422
[Train] epoch 59 Batch 37 Loss 0.20958775281906128
[Train] epoch 59 Batch 38 Loss 0.22688785195350647
[Train] epoch 59 Batch 39 Loss 0.12457886338233948
[Train] epoch 59 Batch 40 Loss 0.20579345524311066
[Train] epoch 59 Batch 41 Loss 0.24122080206871033
[Train] epoch 59 Batch 42 Loss 0.11851257085800171
[Train] epoch 59 Batch 43 Loss 0.16061916947364807
[Train] epoch 59 Batch 44 Loss 0.1631810963153839
[Train] epoch 59 Batch 45 Loss 0.22400976717472076
[Train] epoch 59 Batch 46 Loss 0.18543493747711182
[Train] epoch 59 Batch 47 Loss 0.08804784715175629
[Train] epoch 60 Batch 0 Loss 0.13694849610328674
[Train] epoch 60 Batch 1 Loss 0.2293282151222229
[Train] epoch 60 Batch 2 Loss 0.13455802202224731
[Train] epoch 60 Batch 3 Loss 0.050210580229759216
[Train] epoch 60 Batch 4 Loss 0.19502688944339752
[Train] epoch 60 Batch 5 Loss 0.10042591392993927
[Train] epoch 60 Batch 6 Loss 0.20094797015190125
[Train] epoch 60 Batch 7 Loss 0.17030273377895355
[Train] epoch 60 Batch 8 Loss 0.17740744352340698
[Train] epoch 60 Batch 9 Loss 0.1153135746717453
[Train] epoch 60 Batch 10 Loss 0.12877613306045532
[Train] epoch 60 Batch 11 Loss 0.18167392909526825
[Train] epoch 60 Batch 12 Loss 0.26961788535118103
[Train] epoch 60 Batch 13 Loss 0.15108607709407806
[Train] epoch 60 Batch 14 Loss 0.16835249960422516
[Train] epoch 60 Batch 15 Loss 0.16001535952091217
[Train] epoch 60 Batch 16 Loss 0.14996680617332458
[Train] epoch 60 Batch 17 Loss 0.17076106369495392
[Train] epoch 60 Batch 18 Loss 0.15838313102722168
[Train] epoch 60 Batch 19 Loss 0.28042787313461304
[Train] epoch 60 Batch 20 Loss 0.17858389019966125
[Train] epoch 60 Batch 21 Loss 0.24612310528755188
[Train] epoch 60 Batch 22 Loss 0.2163388729095459
[Train] epoch 60 Batch 23 Loss 0.2719610333442688
[Train] epoch 60 Batch 24 Loss 0.03125929832458496
[Train] epoch 60 Batch 25 Loss 0.11118916422128677
[Train] epoch 60 Batch 26 Loss 0.22306205332279205
[Train] epoch 60 Batch 27 Loss 0.15630550682544708
[Train] epoch 60 Batch 28 Loss 0.1549215018749237
[Train] epoch 60 Batch 29 Loss 0.270031213760376
[Train] epoch 60 Batch 30 Loss 0.23454539477825165
[Train] epoch 60 Batch 31 Loss 0.14552807807922363
[Train] epoch 60 Batch 32 Loss 0.19121041893959045
[Train] epoch 60 Batch 33 Loss 0.16938504576683044
[Train] epoch 60 Batch 34 Loss 0.09487129747867584
[Train] epoch 60 Batch 35 Loss 0.20531746745109558
[Train] epoch 60 Batch 36 Loss 0.3033449053764343
[Train] epoch 60 Batch 37 Loss 0.16489775478839874
[Train] epoch 60 Batch 38 Loss 0.054213836789131165
[Train] epoch 60 Batch 39 Loss 0.24978917837142944
[Train] epoch 60 Batch 40 Loss 0.24318653345108032
[Train] epoch 60 Batch 41 Loss 0.13411381840705872
[Train] epoch 60 Batch 42 Loss 0.15746450424194336
[Train] epoch 60 Batch 43 Loss 0.17657984793186188
[Train] epoch 60 Batch 44 Loss 0.05113112926483154
[Train] epoch 60 Batch 45 Loss 0.20965033769607544
[Train] epoch 60 Batch 46 Loss 0.22115696966648102
[Train] epoch 60 Batch 47 Loss 0.14550906419754028
[Train] epoch 61 Batch 0 Loss 0.17426307499408722
[Train] epoch 61 Batch 1 Loss 0.11798763275146484
[Train] epoch 61 Batch 2 Loss 0.19441016018390656
[Train] epoch 61 Batch 3 Loss 0.20919212698936462
[Train] epoch 61 Batch 4 Loss 0.26065874099731445
[Train] epoch 61 Batch 5 Loss 0.12620611488819122
[Train] epoch 61 Batch 6 Loss 0.20786428451538086
[Train] epoch 61 Batch 7 Loss 0.15433484315872192
[Train] epoch 61 Batch 8 Loss 0.19838333129882812
[Train] epoch 61 Batch 9 Loss 0.11667294800281525
[Train] epoch 61 Batch 10 Loss 0.23898670077323914
[Train] epoch 61 Batch 11 Loss 0.15856975317001343
[Train] epoch 61 Batch 12 Loss 0.23210150003433228
[Train] epoch 61 Batch 13 Loss 0.2507852017879486
[Train] epoch 61 Batch 14 Loss 0.19657808542251587
[Train] epoch 61 Batch 15 Loss 0.17109306156635284
[Train] epoch 61 Batch 16 Loss 0.10332660377025604
[Train] epoch 61 Batch 17 Loss 0.18997807800769806
[Train] epoch 61 Batch 18 Loss 0.07555921375751495
[Train] epoch 61 Batch 19 Loss 0.19311076402664185
[Train] epoch 61 Batch 20 Loss 0.25090599060058594
[Train] epoch 61 Batch 21 Loss 0.21081238985061646
[Train] epoch 61 Batch 22 Loss 0.11728337407112122
[Train] epoch 61 Batch 23 Loss 0.1260286271572113
[Train] epoch 61 Batch 24 Loss 0.15865381062030792
[Train] epoch 61 Batch 25 Loss 0.18565860390663147
[Train] epoch 61 Batch 26 Loss 0.07291485369205475
[Train] epoch 61 Batch 27 Loss 0.12373629212379456
[Train] epoch 61 Batch 28 Loss 0.1662764549255371
[Train] epoch 61 Batch 29 Loss 0.11132356524467468
[Train] epoch 61 Batch 30 Loss 0.17000174522399902
[Train] epoch 61 Batch 31 Loss 0.17245683073997498
[Train] epoch 61 Batch 32 Loss 0.14202731847763062
[Train] epoch 61 Batch 33 Loss 0.17538481950759888
[Train] epoch 61 Batch 34 Loss 0.12419393658638
[Train] epoch 61 Batch 35 Loss 0.20089179277420044
[Train] epoch 61 Batch 36 Loss 0.1265578716993332
[Train] epoch 61 Batch 37 Loss 0.2552117109298706
[Train] epoch 61 Batch 38 Loss 0.2849489450454712
[Train] epoch 61 Batch 39 Loss 0.1328863501548767
[Train] epoch 61 Batch 40 Loss 0.22350363433361053
[Train] epoch 61 Batch 41 Loss 0.14726068079471588
[Train] epoch 61 Batch 42 Loss 0.12425856292247772
[Train] epoch 61 Batch 43 Loss 0.13692697882652283
[Train] epoch 61 Batch 44 Loss 0.062206946313381195
[Train] epoch 61 Batch 45 Loss 0.0676543191075325
[Train] epoch 61 Batch 46 Loss 0.23479199409484863
[Train] epoch 61 Batch 47 Loss 0.20438377559185028
[Train] epoch 62 Batch 0 Loss 0.21537837386131287
[Train] epoch 62 Batch 1 Loss 0.18498146533966064
[Train] epoch 62 Batch 2 Loss 0.20551452040672302
[Train] epoch 62 Batch 3 Loss 0.06953117996454239
[Train] epoch 62 Batch 4 Loss 0.24041283130645752
[Train] epoch 62 Batch 5 Loss 0.12707246840000153
[Train] epoch 62 Batch 6 Loss 0.09176720678806305
[Train] epoch 62 Batch 7 Loss 0.15740415453910828
[Train] epoch 62 Batch 8 Loss 0.09963235259056091
[Train] epoch 62 Batch 9 Loss 0.2240903377532959
[Train] epoch 62 Batch 10 Loss 0.02307455986738205
[Train] epoch 62 Batch 11 Loss 0.08871878683567047
[Train] epoch 62 Batch 12 Loss 0.10191357880830765
[Train] epoch 62 Batch 13 Loss 0.0404641218483448
[Train] epoch 62 Batch 14 Loss 0.2039417028427124
[Train] epoch 62 Batch 15 Loss 0.15692280232906342
[Train] epoch 62 Batch 16 Loss 0.24121984839439392
[Train] epoch 62 Batch 17 Loss 0.19801057875156403
[Train] epoch 62 Batch 18 Loss 0.20339623093605042
[Train] epoch 62 Batch 19 Loss 0.23738223314285278
[Train] epoch 62 Batch 20 Loss 0.01504467148333788
[Train] epoch 62 Batch 21 Loss 0.20434808731079102
[Train] epoch 62 Batch 22 Loss 0.2962099313735962
[Train] epoch 62 Batch 23 Loss 0.196511372923851
[Train] epoch 62 Batch 24 Loss 0.0953298956155777
[Train] epoch 62 Batch 25 Loss 0.13801206648349762
[Train] epoch 62 Batch 26 Loss 0.3052901029586792
[Train] epoch 62 Batch 27 Loss 0.16752496361732483
[Train] epoch 62 Batch 28 Loss 0.23032201826572418
[Train] epoch 62 Batch 29 Loss 0.09519074857234955
[Train] epoch 62 Batch 30 Loss 0.2094797044992447
[Train] epoch 62 Batch 31 Loss 0.07145282626152039
[Train] epoch 62 Batch 32 Loss 0.24522943794727325
[Train] epoch 62 Batch 33 Loss 0.03944004699587822
[Train] epoch 62 Batch 34 Loss 0.24210225045681
[Train] epoch 62 Batch 35 Loss 0.11851250380277634
[Train] epoch 62 Batch 36 Loss 0.16201217472553253
[Train] epoch 62 Batch 37 Loss 0.28612515330314636
[Train] epoch 62 Batch 38 Loss 0.14912404119968414
[Train] epoch 62 Batch 39 Loss 0.15992581844329834
[Train] epoch 62 Batch 40 Loss 0.09558554738759995
[Train] epoch 62 Batch 41 Loss 0.13571412861347198
[Train] epoch 62 Batch 42 Loss 0.2215711772441864
[Train] epoch 62 Batch 43 Loss 0.05231032148003578
[Train] epoch 62 Batch 44 Loss 0.2159079909324646
[Train] epoch 62 Batch 45 Loss 0.19621406495571136
[Train] epoch 62 Batch 46 Loss 0.17095372080802917
[Train] epoch 62 Batch 47 Loss 0.2497541606426239
[Train] epoch 63 Batch 0 Loss 0.2627963423728943
[Train] epoch 63 Batch 1 Loss 0.1318422555923462
[Train] epoch 63 Batch 2 Loss 0.1526116132736206
[Train] epoch 63 Batch 3 Loss 0.14588437974452972
[Train] epoch 63 Batch 4 Loss 0.14409895241260529
[Train] epoch 63 Batch 5 Loss 0.22606852650642395
[Train] epoch 63 Batch 6 Loss 0.16516441106796265
[Train] epoch 63 Batch 7 Loss 0.13006645441055298
[Train] epoch 63 Batch 8 Loss 0.2362872064113617
[Train] epoch 63 Batch 9 Loss 0.20680202543735504
[Train] epoch 63 Batch 10 Loss 0.2667309641838074
[Train] epoch 63 Batch 11 Loss 0.1515427529811859
[Train] epoch 63 Batch 12 Loss 0.16622768342494965
[Train] epoch 63 Batch 13 Loss 0.18362784385681152
[Train] epoch 63 Batch 14 Loss 0.16658684611320496
[Train] epoch 63 Batch 15 Loss 0.1698874831199646
[Train] epoch 63 Batch 16 Loss 0.2674744129180908
[Train] epoch 63 Batch 17 Loss 0.1733425259590149
[Train] epoch 63 Batch 18 Loss 0.21886682510375977
[Train] epoch 63 Batch 19 Loss 0.223202183842659
[Train] epoch 63 Batch 20 Loss 0.08525566756725311
[Train] epoch 63 Batch 21 Loss 0.1861569881439209
[Train] epoch 63 Batch 22 Loss 0.1410687267780304
[Train] epoch 63 Batch 23 Loss 0.21394267678260803
[Train] epoch 63 Batch 24 Loss 0.12250816822052002
[Train] epoch 63 Batch 25 Loss 0.22875924408435822
[Train] epoch 63 Batch 26 Loss 0.15437054634094238
[Train] epoch 63 Batch 27 Loss 0.09295612573623657
[Train] epoch 63 Batch 28 Loss 0.14995048940181732
[Train] epoch 63 Batch 29 Loss 0.14125248789787292
[Train] epoch 63 Batch 30 Loss 0.09300580620765686
[Train] epoch 63 Batch 31 Loss 0.19219635426998138
[Train] epoch 63 Batch 32 Loss 0.1524531990289688
[Train] epoch 63 Batch 33 Loss 0.20284169912338257
[Train] epoch 63 Batch 34 Loss 0.13269756734371185
[Train] epoch 63 Batch 35 Loss 0.11599340289831161
[Train] epoch 63 Batch 36 Loss 0.13207590579986572
[Train] epoch 63 Batch 37 Loss 0.07972043752670288
[Train] epoch 63 Batch 38 Loss 0.20698460936546326
[Train] epoch 63 Batch 39 Loss 0.33813419938087463
[Train] epoch 63 Batch 40 Loss 0.07774722576141357
[Train] epoch 63 Batch 41 Loss 0.1407911777496338
[Train] epoch 63 Batch 42 Loss 0.18604983389377594
[Train] epoch 63 Batch 43 Loss 0.25025230646133423
[Train] epoch 63 Batch 44 Loss 0.1664634644985199
[Train] epoch 63 Batch 45 Loss 0.016891900449991226
[Train] epoch 63 Batch 46 Loss 0.13360802829265594
[Train] epoch 63 Batch 47 Loss 0.12095361948013306
[Train] epoch 64 Batch 0 Loss 0.19449114799499512
[Train] epoch 64 Batch 1 Loss 0.16590960323810577
[Train] epoch 64 Batch 2 Loss 0.16256621479988098
[Train] epoch 64 Batch 3 Loss 0.11765865981578827
[Train] epoch 64 Batch 4 Loss 0.1365332454442978
[Train] epoch 64 Batch 5 Loss 0.1337694227695465
[Train] epoch 64 Batch 6 Loss 0.28323566913604736
[Train] epoch 64 Batch 7 Loss 0.28718385100364685
[Train] epoch 64 Batch 8 Loss 0.21353760361671448
[Train] epoch 64 Batch 9 Loss 0.2653813362121582
[Train] epoch 64 Batch 10 Loss 0.134238138794899
[Train] epoch 64 Batch 11 Loss 0.1296996772289276
[Train] epoch 64 Batch 12 Loss 0.24059012532234192
[Train] epoch 64 Batch 13 Loss 0.1285610795021057
[Train] epoch 64 Batch 14 Loss 0.12314151227474213
[Train] epoch 64 Batch 15 Loss 0.1992988884449005
[Train] epoch 64 Batch 16 Loss 0.31800025701522827
[Train] epoch 64 Batch 17 Loss 0.12880119681358337
[Train] epoch 64 Batch 18 Loss 0.1669946014881134
[Train] epoch 64 Batch 19 Loss 0.049223098903894424
[Train] epoch 64 Batch 20 Loss 0.15426111221313477
[Train] epoch 64 Batch 21 Loss 0.1550096720457077
[Train] epoch 64 Batch 22 Loss 0.15744337439537048
[Train] epoch 64 Batch 23 Loss 0.09098771214485168
[Train] epoch 64 Batch 24 Loss 0.039299409836530685
[Train] epoch 64 Batch 25 Loss 0.2807048261165619
[Train] epoch 64 Batch 26 Loss 0.18688444793224335
[Train] epoch 64 Batch 27 Loss 0.18589454889297485
[Train] epoch 64 Batch 28 Loss 0.22736556828022003
[Train] epoch 64 Batch 29 Loss 0.16121762990951538
[Train] epoch 64 Batch 30 Loss 0.159245103597641
[Train] epoch 64 Batch 31 Loss 0.03974217176437378
[Train] epoch 64 Batch 32 Loss 0.16433817148208618
[Train] epoch 64 Batch 33 Loss 0.16217108070850372
[Train] epoch 64 Batch 34 Loss 0.20293179154396057
[Train] epoch 64 Batch 35 Loss 0.16551879048347473
[Train] epoch 64 Batch 36 Loss 0.1793440878391266
[Train] epoch 64 Batch 37 Loss 0.13322441279888153
[Train] epoch 64 Batch 38 Loss 0.2623426616191864
[Train] epoch 64 Batch 39 Loss 0.2213435173034668
[Train] epoch 64 Batch 40 Loss 0.19951710104942322
[Train] epoch 64 Batch 41 Loss 0.23964844644069672
[Train] epoch 64 Batch 42 Loss 0.19107407331466675
[Train] epoch 64 Batch 43 Loss 0.0890507847070694
[Train] epoch 64 Batch 44 Loss 0.17694267630577087
[Train] epoch 64 Batch 45 Loss 0.05815949663519859
[Train] epoch 64 Batch 46 Loss 0.06981063634157181
[Train] epoch 64 Batch 47 Loss 0.3483460247516632
[Train] epoch 65 Batch 0 Loss 0.12781718373298645
[Train] epoch 65 Batch 1 Loss 0.12250792980194092
[Train] epoch 65 Batch 2 Loss 0.0892348438501358
[Train] epoch 65 Batch 3 Loss 0.26102587580680847
[Train] epoch 65 Batch 4 Loss 0.19670183956623077
[Train] epoch 65 Batch 5 Loss 0.12771110236644745
[Train] epoch 65 Batch 6 Loss 0.15153850615024567
[Train] epoch 65 Batch 7 Loss 0.08859357237815857
[Train] epoch 65 Batch 8 Loss 0.08986467868089676
[Train] epoch 65 Batch 9 Loss 0.18823425471782684
[Train] epoch 65 Batch 10 Loss 0.24679093062877655
[Train] epoch 65 Batch 11 Loss 0.1608678102493286
[Train] epoch 65 Batch 12 Loss 0.12260156869888306
[Train] epoch 65 Batch 13 Loss 0.07783207297325134
[Train] epoch 65 Batch 14 Loss 0.1928238421678543
[Train] epoch 65 Batch 15 Loss 0.24783679842948914
[Train] epoch 65 Batch 16 Loss 0.22964730858802795
[Train] epoch 65 Batch 17 Loss 0.26970598101615906
[Train] epoch 65 Batch 18 Loss 0.16317252814769745
[Train] epoch 65 Batch 19 Loss 0.04863113537430763
[Train] epoch 65 Batch 20 Loss 0.09019748866558075
[Train] epoch 65 Batch 21 Loss 0.24384905397891998
[Train] epoch 65 Batch 22 Loss 0.18314507603645325
[Train] epoch 65 Batch 23 Loss 0.13912054896354675
[Train] epoch 65 Batch 24 Loss 0.15613582730293274
[Train] epoch 65 Batch 25 Loss 0.1783645749092102
[Train] epoch 65 Batch 26 Loss 0.24706318974494934
[Train] epoch 65 Batch 27 Loss 0.2135714739561081
[Train] epoch 65 Batch 28 Loss 0.12318973988294601
[Train] epoch 65 Batch 29 Loss 0.24087080359458923
[Train] epoch 65 Batch 30 Loss 0.1914205253124237
[Train] epoch 65 Batch 31 Loss 0.048393260687589645
[Train] epoch 65 Batch 32 Loss 0.1540955901145935
[Train] epoch 65 Batch 33 Loss 0.27883481979370117
[Train] epoch 65 Batch 34 Loss 0.2426106333732605
[Train] epoch 65 Batch 35 Loss 0.09521626681089401
[Train] epoch 65 Batch 36 Loss 0.1349732130765915
[Train] epoch 65 Batch 37 Loss 0.22843217849731445
[Train] epoch 65 Batch 38 Loss 0.1560782790184021
[Train] epoch 65 Batch 39 Loss 0.0523698516190052
[Train] epoch 65 Batch 40 Loss 0.20938953757286072
[Train] epoch 65 Batch 41 Loss 0.15496382117271423
[Train] epoch 65 Batch 42 Loss 0.2152286320924759
[Train] epoch 65 Batch 43 Loss 0.17478874325752258
[Train] epoch 65 Batch 44 Loss 0.11209610104560852
[Train] epoch 65 Batch 45 Loss 0.22013399004936218
[Train] epoch 65 Batch 46 Loss 0.10647918283939362
[Train] epoch 65 Batch 47 Loss 0.1275121122598648
[Train] epoch 66 Batch 0 Loss 0.15528006851673126
[Train] epoch 66 Batch 1 Loss 0.049949537962675095
[Train] epoch 66 Batch 2 Loss 0.17670047283172607
[Train] epoch 66 Batch 3 Loss 0.1912783980369568
[Train] epoch 66 Batch 4 Loss 0.11255631595849991
[Train] epoch 66 Batch 5 Loss 0.11509962379932404
[Train] epoch 66 Batch 6 Loss 0.12652942538261414
[Train] epoch 66 Batch 7 Loss 0.1787433922290802
[Train] epoch 66 Batch 8 Loss 0.16177889704704285
[Train] epoch 66 Batch 9 Loss 0.11588986963033676
[Train] epoch 66 Batch 10 Loss 0.06957545131444931
[Train] epoch 66 Batch 11 Loss 0.2639169692993164
[Train] epoch 66 Batch 12 Loss 0.1551370620727539
[Train] epoch 66 Batch 13 Loss 0.1573013961315155
[Train] epoch 66 Batch 14 Loss 0.11009727418422699
[Train] epoch 66 Batch 15 Loss 0.36953818798065186
[Train] epoch 66 Batch 16 Loss 0.13293910026550293
[Train] epoch 66 Batch 17 Loss 0.2556271255016327
[Train] epoch 66 Batch 18 Loss 0.12492737919092178
[Train] epoch 66 Batch 19 Loss 0.14195185899734497
[Train] epoch 66 Batch 20 Loss 0.21707487106323242
[Train] epoch 66 Batch 21 Loss 0.14411865174770355
[Train] epoch 66 Batch 22 Loss 0.16898584365844727
[Train] epoch 66 Batch 23 Loss 0.19640126824378967
[Train] epoch 66 Batch 24 Loss 0.2937662601470947
[Train] epoch 66 Batch 25 Loss 0.1334075629711151
[Train] epoch 66 Batch 26 Loss 0.14342185854911804
[Train] epoch 66 Batch 27 Loss 0.23597076535224915
[Train] epoch 66 Batch 28 Loss 0.17571017146110535
[Train] epoch 66 Batch 29 Loss 0.1594931185245514
[Train] epoch 66 Batch 30 Loss 0.1806412637233734
[Train] epoch 66 Batch 31 Loss 0.22626230120658875
[Train] epoch 66 Batch 32 Loss 0.13573218882083893
[Train] epoch 66 Batch 33 Loss 0.16963204741477966
[Train] epoch 66 Batch 34 Loss 0.2349701225757599
[Train] epoch 66 Batch 35 Loss 0.12389516830444336
[Train] epoch 66 Batch 36 Loss 0.03286179155111313
[Train] epoch 66 Batch 37 Loss 0.1949009895324707
[Train] epoch 66 Batch 38 Loss 2.7723113817046396e-05
[Train] epoch 66 Batch 39 Loss 0.16932445764541626
[Train] epoch 66 Batch 40 Loss 0.07608888298273087
[Train] epoch 66 Batch 41 Loss 0.09676453471183777
[Train] epoch 66 Batch 42 Loss 0.19857338070869446
[Train] epoch 66 Batch 43 Loss 0.04977790266275406
[Train] epoch 66 Batch 44 Loss 0.2071743607521057
[Train] epoch 66 Batch 45 Loss 0.13045157492160797
[Train] epoch 66 Batch 46 Loss 0.1822432577610016
[Train] epoch 66 Batch 47 Loss 0.32052525877952576
[Train] epoch 67 Batch 0 Loss 0.24669483304023743
[Train] epoch 67 Batch 1 Loss 0.20372426509857178
[Train] epoch 67 Batch 2 Loss 0.07232291251420975
[Train] epoch 67 Batch 3 Loss 0.0697641670703888
[Train] epoch 67 Batch 4 Loss 0.20641981065273285
[Train] epoch 67 Batch 5 Loss 0.053412944078445435
[Train] epoch 67 Batch 6 Loss 0.1163749098777771
[Train] epoch 67 Batch 7 Loss 0.23444251716136932
[Train] epoch 67 Batch 8 Loss 0.1766415238380432
[Train] epoch 67 Batch 9 Loss 0.1938011646270752
[Train] epoch 67 Batch 10 Loss 0.31555041670799255
[Train] epoch 67 Batch 11 Loss 0.3102385997772217
[Train] epoch 67 Batch 12 Loss 0.23205892741680145
[Train] epoch 67 Batch 13 Loss 0.1511438488960266
[Train] epoch 67 Batch 14 Loss 0.1597268283367157
[Train] epoch 67 Batch 15 Loss 0.19387555122375488
[Train] epoch 67 Batch 16 Loss 0.13739940524101257
[Train] epoch 67 Batch 17 Loss 0.17545247077941895
[Train] epoch 67 Batch 18 Loss 0.1920308917760849
[Train] epoch 67 Batch 19 Loss 0.11171189695596695
[Train] epoch 67 Batch 20 Loss 0.26641845703125
[Train] epoch 67 Batch 21 Loss 0.1628796011209488
[Train] epoch 67 Batch 22 Loss 0.21490508317947388
[Train] epoch 67 Batch 23 Loss 0.19157686829566956
[Train] epoch 67 Batch 24 Loss 0.15731360018253326
[Train] epoch 67 Batch 25 Loss 0.11276164650917053
[Train] epoch 67 Batch 26 Loss 0.23105329275131226
[Train] epoch 67 Batch 27 Loss 0.11949774622917175
[Train] epoch 67 Batch 28 Loss 0.174386665225029
[Train] epoch 67 Batch 29 Loss 0.1510515958070755
[Train] epoch 67 Batch 30 Loss 0.07849261909723282
[Train] epoch 67 Batch 31 Loss 0.2618553638458252
[Train] epoch 67 Batch 32 Loss 0.1628645360469818
[Train] epoch 67 Batch 33 Loss 0.09924989938735962
[Train] epoch 67 Batch 34 Loss 0.12951037287712097
[Train] epoch 67 Batch 35 Loss 0.1534825712442398
[Train] epoch 67 Batch 36 Loss 0.14279931783676147
[Train] epoch 67 Batch 37 Loss 0.12690702080726624
[Train] epoch 67 Batch 38 Loss 0.16459929943084717
[Train] epoch 67 Batch 39 Loss 0.049207981675863266
[Train] epoch 67 Batch 40 Loss 0.11106540262699127
[Train] epoch 67 Batch 41 Loss 0.18879066407680511
[Train] epoch 67 Batch 42 Loss 0.16543787717819214
[Train] epoch 67 Batch 43 Loss 0.23559580743312836
[Train] epoch 67 Batch 44 Loss 0.04998131841421127
[Train] epoch 67 Batch 45 Loss 0.06053122505545616
[Train] epoch 67 Batch 46 Loss 0.06077483296394348
[Train] epoch 67 Batch 47 Loss 0.15052258968353271
[Train] epoch 68 Batch 0 Loss 0.1351235806941986
[Train] epoch 68 Batch 1 Loss 0.08834823220968246
[Train] epoch 68 Batch 2 Loss 0.12695200741291046
[Train] epoch 68 Batch 3 Loss 0.10701880604028702
[Train] epoch 68 Batch 4 Loss 0.2062123417854309
[Train] epoch 68 Batch 5 Loss 0.22005291283130646
[Train] epoch 68 Batch 6 Loss 0.1158517375588417
[Train] epoch 68 Batch 7 Loss 0.2022285759449005
[Train] epoch 68 Batch 8 Loss 0.11338183283805847
[Train] epoch 68 Batch 9 Loss 0.12190647423267365
[Train] epoch 68 Batch 10 Loss 0.13514238595962524
[Train] epoch 68 Batch 11 Loss 0.13397172093391418
[Train] epoch 68 Batch 12 Loss 0.2237846404314041
[Train] epoch 68 Batch 13 Loss 0.24328982830047607
[Train] epoch 68 Batch 14 Loss 0.21262000501155853
[Train] epoch 68 Batch 15 Loss 0.20170307159423828
[Train] epoch 68 Batch 16 Loss 0.14926253259181976
[Train] epoch 68 Batch 17 Loss 0.1281864196062088
[Train] epoch 68 Batch 18 Loss 0.19713959097862244
[Train] epoch 68 Batch 19 Loss 0.08318664878606796
[Train] epoch 68 Batch 20 Loss 0.08201862126588821
[Train] epoch 68 Batch 21 Loss 0.1037377417087555
[Train] epoch 68 Batch 22 Loss 0.17019228637218475
[Train] epoch 68 Batch 23 Loss 0.11254073679447174
[Train] epoch 68 Batch 24 Loss 0.20255261659622192
[Train] epoch 68 Batch 25 Loss 0.2599731683731079
[Train] epoch 68 Batch 26 Loss 0.23423224687576294
[Train] epoch 68 Batch 27 Loss 0.1454906016588211
[Train] epoch 68 Batch 28 Loss 0.19071942567825317
[Train] epoch 68 Batch 29 Loss 0.18206802010536194
[Train] epoch 68 Batch 30 Loss 0.16117292642593384
[Train] epoch 68 Batch 31 Loss 0.1880207657814026
[Train] epoch 68 Batch 32 Loss 0.11037394404411316
[Train] epoch 68 Batch 33 Loss 0.20934849977493286
[Train] epoch 68 Batch 34 Loss 0.18975010514259338
[Train] epoch 68 Batch 35 Loss 0.21424683928489685
[Train] epoch 68 Batch 36 Loss 0.17286594212055206
[Train] epoch 68 Batch 37 Loss 0.019225697964429855
[Train] epoch 68 Batch 38 Loss 0.19185873866081238
[Train] epoch 68 Batch 39 Loss 0.17877790331840515
[Train] epoch 68 Batch 40 Loss 0.04448491334915161
[Train] epoch 68 Batch 41 Loss 0.2198190987110138
[Train] epoch 68 Batch 42 Loss 0.20348119735717773
[Train] epoch 68 Batch 43 Loss 0.1530778855085373
[Train] epoch 68 Batch 44 Loss 0.1743713915348053
[Train] epoch 68 Batch 45 Loss 0.15009617805480957
[Train] epoch 68 Batch 46 Loss 0.07419843226671219
[Train] epoch 68 Batch 47 Loss 0.18731635808944702
[Train] epoch 69 Batch 0 Loss 0.16366325318813324
[Train] epoch 69 Batch 1 Loss 0.265773206949234
[Train] epoch 69 Batch 2 Loss 0.10969168692827225
[Train] epoch 69 Batch 3 Loss 0.13319028913974762
[Train] epoch 69 Batch 4 Loss 0.2162441611289978
[Train] epoch 69 Batch 5 Loss 0.26156100630760193
[Train] epoch 69 Batch 6 Loss 0.2729470431804657
[Train] epoch 69 Batch 7 Loss 0.24248656630516052
[Train] epoch 69 Batch 8 Loss 0.12592509388923645
[Train] epoch 69 Batch 9 Loss 0.16393867135047913
[Train] epoch 69 Batch 10 Loss 0.20620568096637726
[Train] epoch 69 Batch 11 Loss 0.13635458052158356
[Train] epoch 69 Batch 12 Loss 0.09897002577781677
[Train] epoch 69 Batch 13 Loss 0.07398693263530731
[Train] epoch 69 Batch 14 Loss 0.12484055757522583
[Train] epoch 69 Batch 15 Loss 0.09072580933570862
[Train] epoch 69 Batch 16 Loss 0.26561182737350464
[Train] epoch 69 Batch 17 Loss 0.1253119558095932
[Train] epoch 69 Batch 18 Loss 0.17621652781963348
[Train] epoch 69 Batch 19 Loss 0.241367369890213
[Train] epoch 69 Batch 20 Loss 0.036061689257621765
[Train] epoch 69 Batch 21 Loss 0.1758597493171692
[Train] epoch 69 Batch 22 Loss 0.1951373666524887
[Train] epoch 69 Batch 23 Loss 0.11456955969333649
[Train] epoch 69 Batch 24 Loss 0.11320571601390839
[Train] epoch 69 Batch 25 Loss 0.22588102519512177
[Train] epoch 69 Batch 26 Loss 0.14793117344379425
[Train] epoch 69 Batch 27 Loss 0.0457494780421257
[Train] epoch 69 Batch 28 Loss 0.1464010626077652
[Train] epoch 69 Batch 29 Loss 0.15466871857643127
[Train] epoch 69 Batch 30 Loss 0.24528074264526367
[Train] epoch 69 Batch 31 Loss 0.14100445806980133
[Train] epoch 69 Batch 32 Loss 0.22342213988304138
[Train] epoch 69 Batch 33 Loss 0.14779020845890045
[Train] epoch 69 Batch 34 Loss 0.1431800127029419
[Train] epoch 69 Batch 35 Loss 0.19064415991306305
[Train] epoch 69 Batch 36 Loss 0.16522487998008728
[Train] epoch 69 Batch 37 Loss 0.12347964197397232
[Train] epoch 69 Batch 38 Loss 0.07709202170372009
[Train] epoch 69 Batch 39 Loss 0.02810913510620594
[Train] epoch 69 Batch 40 Loss 0.17088599503040314
[Train] epoch 69 Batch 41 Loss 0.18118789792060852
[Train] epoch 69 Batch 42 Loss 0.1919356882572174
[Train] epoch 69 Batch 43 Loss 0.24560150504112244
[Train] epoch 69 Batch 44 Loss 0.08082795143127441
[Train] epoch 69 Batch 45 Loss 0.15219005942344666
[Train] epoch 69 Batch 46 Loss 0.253415584564209
[Train] epoch 69 Batch 47 Loss 0.11148469150066376
[Train] epoch 70 Batch 0 Loss 0.25648000836372375
[Train] epoch 70 Batch 1 Loss 0.14725780487060547
[Train] epoch 70 Batch 2 Loss 0.09074847400188446
[Train] epoch 70 Batch 3 Loss 0.15946033596992493
[Train] epoch 70 Batch 4 Loss 0.06911738216876984
[Train] epoch 70 Batch 5 Loss 0.1520785689353943
[Train] epoch 70 Batch 6 Loss 0.1983502209186554
[Train] epoch 70 Batch 7 Loss 0.06573086231946945
[Train] epoch 70 Batch 8 Loss 0.1098698079586029
[Train] epoch 70 Batch 9 Loss 0.13645169138908386
[Train] epoch 70 Batch 10 Loss 0.06523311883211136
[Train] epoch 70 Batch 11 Loss 0.1986696422100067
[Train] epoch 70 Batch 12 Loss 0.11789451539516449
[Train] epoch 70 Batch 13 Loss 0.1574997454881668
[Train] epoch 70 Batch 14 Loss 0.1698388159275055
[Train] epoch 70 Batch 15 Loss 0.14342224597930908
[Train] epoch 70 Batch 16 Loss 0.16479213535785675
[Train] epoch 70 Batch 17 Loss 0.0909278392791748
[Train] epoch 70 Batch 18 Loss 0.1406199038028717
[Train] epoch 70 Batch 19 Loss 0.22288548946380615
[Train] epoch 70 Batch 20 Loss 0.19413641095161438
[Train] epoch 70 Batch 21 Loss 0.16424842178821564
[Train] epoch 70 Batch 22 Loss 0.059497907757759094
[Train] epoch 70 Batch 23 Loss 0.10793693363666534
[Train] epoch 70 Batch 24 Loss 0.2548057436943054
[Train] epoch 70 Batch 25 Loss 0.18933060765266418
[Train] epoch 70 Batch 26 Loss 0.26358962059020996
[Train] epoch 70 Batch 27 Loss 0.18696646392345428
[Train] epoch 70 Batch 28 Loss 0.21604818105697632
[Train] epoch 70 Batch 29 Loss 0.24413155019283295
[Train] epoch 70 Batch 30 Loss 0.19590125977993011
[Train] epoch 70 Batch 31 Loss 0.2026844322681427
[Train] epoch 70 Batch 32 Loss 0.1587347388267517
[Train] epoch 70 Batch 33 Loss 0.24459293484687805
[Train] epoch 70 Batch 34 Loss 0.3090313673019409
[Train] epoch 70 Batch 35 Loss 0.12136872112751007
[Train] epoch 70 Batch 36 Loss 0.14719349145889282
[Train] epoch 70 Batch 37 Loss 0.11912952363491058
[Train] epoch 70 Batch 38 Loss 0.10657120496034622
[Train] epoch 70 Batch 39 Loss 0.14858309924602509
[Train] epoch 70 Batch 40 Loss 0.22176989912986755
[Train] epoch 70 Batch 41 Loss 0.08742474019527435
[Train] epoch 70 Batch 42 Loss 0.08760453760623932
[Train] epoch 70 Batch 43 Loss 0.2763698995113373
[Train] epoch 70 Batch 44 Loss 0.20343706011772156
[Train] epoch 70 Batch 45 Loss 0.1404624581336975
[Train] epoch 70 Batch 46 Loss 0.1258000284433365
[Train] epoch 70 Batch 47 Loss 0.15140371024608612
[Train] epoch 71 Batch 0 Loss 0.08712974190711975
[Train] epoch 71 Batch 1 Loss 0.207780659198761
[Train] epoch 71 Batch 2 Loss 0.1523970514535904
[Train] epoch 71 Batch 3 Loss 0.12552034854888916
[Train] epoch 71 Batch 4 Loss 0.21832194924354553
[Train] epoch 71 Batch 5 Loss 0.16487181186676025
[Train] epoch 71 Batch 6 Loss 0.12367455661296844
[Train] epoch 71 Batch 7 Loss 0.26299217343330383
[Train] epoch 71 Batch 8 Loss 0.13218456506729126
[Train] epoch 71 Batch 9 Loss 0.1289995312690735
[Train] epoch 71 Batch 10 Loss 0.09136351197957993
[Train] epoch 71 Batch 11 Loss 0.1889212280511856
[Train] epoch 71 Batch 12 Loss 0.23034897446632385
[Train] epoch 71 Batch 13 Loss 0.2587060332298279
[Train] epoch 71 Batch 14 Loss 0.17033815383911133
[Train] epoch 71 Batch 15 Loss 0.10843753069639206
[Train] epoch 71 Batch 16 Loss 0.21732313930988312
[Train] epoch 71 Batch 17 Loss 0.07559792697429657
[Train] epoch 71 Batch 18 Loss 0.07851444184780121
[Train] epoch 71 Batch 19 Loss 0.15225183963775635
[Train] epoch 71 Batch 20 Loss 0.20055997371673584
[Train] epoch 71 Batch 21 Loss 0.2042291760444641
[Train] epoch 71 Batch 22 Loss 0.13877256214618683
[Train] epoch 71 Batch 23 Loss 0.11873520910739899
[Train] epoch 71 Batch 24 Loss 0.05011124908924103
[Train] epoch 71 Batch 25 Loss 0.20526477694511414
[Train] epoch 71 Batch 26 Loss 0.18662424385547638
[Train] epoch 71 Batch 27 Loss 0.22465896606445312
[Train] epoch 71 Batch 28 Loss 0.1955380141735077
[Train] epoch 71 Batch 29 Loss 0.11906039714813232
[Train] epoch 71 Batch 30 Loss 0.244611456990242
[Train] epoch 71 Batch 31 Loss 0.15256227552890778
[Train] epoch 71 Batch 32 Loss 0.2589077353477478
[Train] epoch 71 Batch 33 Loss 0.06930144876241684
[Train] epoch 71 Batch 34 Loss 0.1502847820520401
[Train] epoch 71 Batch 35 Loss 0.08927835524082184
[Train] epoch 71 Batch 36 Loss 0.08767011761665344
[Train] epoch 71 Batch 37 Loss 0.21073681116104126
[Train] epoch 71 Batch 38 Loss 0.16389234364032745
[Train] epoch 71 Batch 39 Loss 0.16130280494689941
[Train] epoch 71 Batch 40 Loss 0.12143483012914658
[Train] epoch 71 Batch 41 Loss 0.14758656919002533
[Train] epoch 71 Batch 42 Loss 0.16922342777252197
[Train] epoch 71 Batch 43 Loss 0.09003275632858276
[Train] epoch 71 Batch 44 Loss 0.18736326694488525
[Train] epoch 71 Batch 45 Loss 0.24212056398391724
[Train] epoch 71 Batch 46 Loss 0.13800011575222015
[Train] epoch 71 Batch 47 Loss 0.225798100233078
[Train] epoch 72 Batch 0 Loss 0.08601684868335724
[Train] epoch 72 Batch 1 Loss 0.16707636415958405
[Train] epoch 72 Batch 2 Loss 0.12002259492874146
[Train] epoch 72 Batch 3 Loss 0.2385454922914505
[Train] epoch 72 Batch 4 Loss 0.26714205741882324
[Train] epoch 72 Batch 5 Loss 0.15226425230503082
[Train] epoch 72 Batch 6 Loss 0.10173626244068146
[Train] epoch 72 Batch 7 Loss 0.18254730105400085
[Train] epoch 72 Batch 8 Loss 0.18714752793312073
[Train] epoch 72 Batch 9 Loss 0.21375983953475952
[Train] epoch 72 Batch 10 Loss 0.07649390399456024
[Train] epoch 72 Batch 11 Loss 0.3275810778141022
[Train] epoch 72 Batch 12 Loss 0.16954053938388824
[Train] epoch 72 Batch 13 Loss 0.19253206253051758
[Train] epoch 72 Batch 14 Loss 0.24544242024421692
[Train] epoch 72 Batch 15 Loss 0.1122269481420517
[Train] epoch 72 Batch 16 Loss 0.19565537571907043
[Train] epoch 72 Batch 17 Loss 0.0780508890748024
[Train] epoch 72 Batch 18 Loss 0.030573684722185135
[Train] epoch 72 Batch 19 Loss 0.22968989610671997
[Train] epoch 72 Batch 20 Loss 0.09511411190032959
[Train] epoch 72 Batch 21 Loss 0.0953327938914299
[Train] epoch 72 Batch 22 Loss 0.18881815671920776
[Train] epoch 72 Batch 23 Loss 0.15570631623268127
[Train] epoch 72 Batch 24 Loss 0.25790923833847046
[Train] epoch 72 Batch 25 Loss 0.168214350938797
[Train] epoch 72 Batch 26 Loss 0.11745279282331467
[Train] epoch 72 Batch 27 Loss 0.13135500252246857
[Train] epoch 72 Batch 28 Loss 0.12394478917121887
[Train] epoch 72 Batch 29 Loss 0.06327839195728302
[Train] epoch 72 Batch 30 Loss 0.12506288290023804
[Train] epoch 72 Batch 31 Loss 0.1754283607006073
[Train] epoch 72 Batch 32 Loss 0.19011232256889343
[Train] epoch 72 Batch 33 Loss 0.14798325300216675
[Train] epoch 72 Batch 34 Loss 0.08001674711704254
[Train] epoch 72 Batch 35 Loss 0.30412977933883667
[Train] epoch 72 Batch 36 Loss 0.13456419110298157
[Train] epoch 72 Batch 37 Loss 0.11096160858869553
[Train] epoch 72 Batch 38 Loss 0.15025188028812408
[Train] epoch 72 Batch 39 Loss 0.08540003001689911
[Train] epoch 72 Batch 40 Loss 0.12345278263092041
[Train] epoch 72 Batch 41 Loss 0.26464390754699707
[Train] epoch 72 Batch 42 Loss 0.1607993096113205
[Train] epoch 72 Batch 43 Loss 0.13570217788219452
[Train] epoch 72 Batch 44 Loss 0.1995345950126648
[Train] epoch 72 Batch 45 Loss 0.1998996138572693
[Train] epoch 72 Batch 46 Loss 0.2459891140460968
[Train] epoch 72 Batch 47 Loss 0.12434618175029755
[Train] epoch 73 Batch 0 Loss 0.19789910316467285
[Train] epoch 73 Batch 1 Loss 0.1879872828722
[Train] epoch 73 Batch 2 Loss 0.18854114413261414
[Train] epoch 73 Batch 3 Loss 0.042189013212919235
[Train] epoch 73 Batch 4 Loss 0.18101345002651215
[Train] epoch 73 Batch 5 Loss 0.15433546900749207
[Train] epoch 73 Batch 6 Loss 0.15374302864074707
[Train] epoch 73 Batch 7 Loss 0.2751822769641876
[Train] epoch 73 Batch 8 Loss 0.10911047458648682
[Train] epoch 73 Batch 9 Loss 0.12227073311805725
[Train] epoch 73 Batch 10 Loss 0.16851481795310974
[Train] epoch 73 Batch 11 Loss 0.1250913292169571
[Train] epoch 73 Batch 12 Loss 0.12253566831350327
[Train] epoch 73 Batch 13 Loss 0.08319319039583206
[Train] epoch 73 Batch 14 Loss 0.22500282526016235
[Train] epoch 73 Batch 15 Loss 0.11220136284828186
[Train] epoch 73 Batch 16 Loss 0.15387596189975739
[Train] epoch 73 Batch 17 Loss 0.11576385796070099
[Train] epoch 73 Batch 18 Loss 0.18448562920093536
[Train] epoch 73 Batch 19 Loss 0.13833650946617126
[Train] epoch 73 Batch 20 Loss 0.15059061348438263
[Train] epoch 73 Batch 21 Loss 0.23186293244361877
[Train] epoch 73 Batch 22 Loss 0.20280911028385162
[Train] epoch 73 Batch 23 Loss 0.1854420304298401
[Train] epoch 73 Batch 24 Loss 0.13956351578235626
[Train] epoch 73 Batch 25 Loss 0.21020053327083588
[Train] epoch 73 Batch 26 Loss 0.13403132557868958
[Train] epoch 73 Batch 27 Loss 0.0899401307106018
[Train] epoch 73 Batch 28 Loss 0.18858033418655396
[Train] epoch 73 Batch 29 Loss 0.1155415028333664
[Train] epoch 73 Batch 30 Loss 0.07446102052927017
[Train] epoch 73 Batch 31 Loss 0.12184341996908188
[Train] epoch 73 Batch 32 Loss 0.20643801987171173
[Train] epoch 73 Batch 33 Loss 0.19539740681648254
[Train] epoch 73 Batch 34 Loss 0.20225299894809723
[Train] epoch 73 Batch 35 Loss 0.12550324201583862
[Train] epoch 73 Batch 36 Loss 0.19928210973739624
[Train] epoch 73 Batch 37 Loss 0.18875159323215485
[Train] epoch 73 Batch 38 Loss 0.2505565881729126
[Train] epoch 73 Batch 39 Loss 0.12067275494337082
[Train] epoch 73 Batch 40 Loss 0.05903617665171623
[Train] epoch 73 Batch 41 Loss 0.0844903290271759
[Train] epoch 73 Batch 42 Loss 0.27778348326683044
[Train] epoch 73 Batch 43 Loss 0.13467258214950562
[Train] epoch 73 Batch 44 Loss 0.1802145391702652
[Train] epoch 73 Batch 45 Loss 0.2634754180908203
[Train] epoch 73 Batch 46 Loss 0.20237472653388977
[Train] epoch 73 Batch 47 Loss 0.1264929473400116
[Train] epoch 74 Batch 0 Loss 0.24743306636810303
[Train] epoch 74 Batch 1 Loss 0.13399526476860046
[Train] epoch 74 Batch 2 Loss 0.2698887586593628
[Train] epoch 74 Batch 3 Loss 0.08348676562309265
[Train] epoch 74 Batch 4 Loss 0.14382515847682953
[Train] epoch 74 Batch 5 Loss 0.13333922624588013
[Train] epoch 74 Batch 6 Loss 0.1840265989303589
[Train] epoch 74 Batch 7 Loss 0.12785856425762177
[Train] epoch 74 Batch 8 Loss 0.1171296238899231
[Train] epoch 74 Batch 9 Loss 0.10547144711017609
[Train] epoch 74 Batch 10 Loss 0.1420900970697403
[Train] epoch 74 Batch 11 Loss 0.19910848140716553
[Train] epoch 74 Batch 12 Loss 0.08788608014583588
[Train] epoch 74 Batch 13 Loss 0.12804611027240753
[Train] epoch 74 Batch 14 Loss 0.261918842792511
[Train] epoch 74 Batch 15 Loss 0.1618671417236328
[Train] epoch 74 Batch 16 Loss 0.23784318566322327
[Train] epoch 74 Batch 17 Loss 0.11228303611278534
[Train] epoch 74 Batch 18 Loss 0.15809370577335358
[Train] epoch 74 Batch 19 Loss 0.12475136667490005
[Train] epoch 74 Batch 20 Loss 0.11679726839065552
[Train] epoch 74 Batch 21 Loss 0.07663211226463318
[Train] epoch 74 Batch 22 Loss 0.23766353726387024
[Train] epoch 74 Batch 23 Loss 0.03560464084148407
[Train] epoch 74 Batch 24 Loss 0.1659371554851532
[Train] epoch 74 Batch 25 Loss 0.11522426456212997
[Train] epoch 74 Batch 26 Loss 0.20464007556438446
[Train] epoch 74 Batch 27 Loss 0.1067698746919632
[Train] epoch 74 Batch 28 Loss 0.2301778942346573
[Train] epoch 74 Batch 29 Loss 0.19178016483783722
[Train] epoch 74 Batch 30 Loss 0.25929123163223267
[Train] epoch 74 Batch 31 Loss 0.2408093810081482
[Train] epoch 74 Batch 32 Loss 0.037795647978782654
[Train] epoch 74 Batch 33 Loss 0.23752504587173462
[Train] epoch 74 Batch 34 Loss 0.09561795741319656
[Train] epoch 74 Batch 35 Loss 0.08396191895008087
[Train] epoch 74 Batch 36 Loss 0.11822683364152908
[Train] epoch 74 Batch 37 Loss 0.20071999728679657
[Train] epoch 74 Batch 38 Loss 0.2050495594739914
[Train] epoch 74 Batch 39 Loss 0.11825862526893616
[Train] epoch 74 Batch 40 Loss 0.11706700921058655
[Train] epoch 74 Batch 41 Loss 0.17519186437129974
[Train] epoch 74 Batch 42 Loss 0.08026294410228729
[Train] epoch 74 Batch 43 Loss 0.2730821669101715
[Train] epoch 74 Batch 44 Loss 0.18184733390808105
[Train] epoch 74 Batch 45 Loss 0.2633526623249054
[Train] epoch 74 Batch 46 Loss 0.15436384081840515
[Train] epoch 74 Batch 47 Loss 0.020090069621801376
[Train] epoch 75 Batch 0 Loss 0.21847964823246002
[Train] epoch 75 Batch 1 Loss 0.08194273710250854
[Train] epoch 75 Batch 2 Loss 0.11890429258346558
[Train] epoch 75 Batch 3 Loss 0.11766162514686584
[Train] epoch 75 Batch 4 Loss 0.1309724599123001
[Train] epoch 75 Batch 5 Loss 0.1227455884218216
[Train] epoch 75 Batch 6 Loss 0.2060765027999878
[Train] epoch 75 Batch 7 Loss 0.17787733674049377
[Train] epoch 75 Batch 8 Loss 0.15767470002174377
[Train] epoch 75 Batch 9 Loss 0.14974893629550934
[Train] epoch 75 Batch 10 Loss 0.13451506197452545
[Train] epoch 75 Batch 11 Loss 0.120995432138443
[Train] epoch 75 Batch 12 Loss 0.17403674125671387
[Train] epoch 75 Batch 13 Loss 0.0901595950126648
[Train] epoch 75 Batch 14 Loss 0.16097262501716614
[Train] epoch 75 Batch 15 Loss 0.20611301064491272
[Train] epoch 75 Batch 16 Loss 0.23374775052070618
[Train] epoch 75 Batch 17 Loss 0.1176242083311081
[Train] epoch 75 Batch 18 Loss 0.07912317663431168
[Train] epoch 75 Batch 19 Loss 0.07783404737710953
[Train] epoch 75 Batch 20 Loss 0.25967487692832947
[Train] epoch 75 Batch 21 Loss 0.1972297728061676
[Train] epoch 75 Batch 22 Loss 0.048129454255104065
[Train] epoch 75 Batch 23 Loss 0.14382049441337585
[Train] epoch 75 Batch 24 Loss 0.1875961571931839
[Train] epoch 75 Batch 25 Loss 0.19085679948329926
[Train] epoch 75 Batch 26 Loss 0.2283872663974762
[Train] epoch 75 Batch 27 Loss 0.1882978081703186
[Train] epoch 75 Batch 28 Loss 0.24597999453544617
[Train] epoch 75 Batch 29 Loss 0.11949849128723145
[Train] epoch 75 Batch 30 Loss 0.1164713054895401
[Train] epoch 75 Batch 31 Loss 0.15621982514858246
[Train] epoch 75 Batch 32 Loss 0.14603465795516968
[Train] epoch 75 Batch 33 Loss 0.2226766049861908
[Train] epoch 75 Batch 34 Loss 0.16380609571933746
[Train] epoch 75 Batch 35 Loss 0.05881751701235771
[Train] epoch 75 Batch 36 Loss 0.04847393557429314
[Train] epoch 75 Batch 37 Loss 0.2701341509819031
[Train] epoch 75 Batch 38 Loss 0.23860874772071838
[Train] epoch 75 Batch 39 Loss 0.07366742938756943
[Train] epoch 75 Batch 40 Loss 0.21589019894599915
[Train] epoch 75 Batch 41 Loss 0.24742941558361053
[Train] epoch 75 Batch 42 Loss 0.08504492044448853
[Train] epoch 75 Batch 43 Loss 0.08322511613368988
[Train] epoch 75 Batch 44 Loss 0.07417641580104828
[Train] epoch 75 Batch 45 Loss 0.16749662160873413
[Train] epoch 75 Batch 46 Loss 0.2008930742740631
[Train] epoch 75 Batch 47 Loss 0.2140786349773407
[Train] epoch 76 Batch 0 Loss 0.11387915164232254
[Train] epoch 76 Batch 1 Loss 0.19081349670886993
[Train] epoch 76 Batch 2 Loss 0.15678343176841736
[Train] epoch 76 Batch 3 Loss 0.22946800291538239
[Train] epoch 76 Batch 4 Loss 0.14778997004032135
[Train] epoch 76 Batch 5 Loss 0.15715152025222778
[Train] epoch 76 Batch 6 Loss 0.10117286443710327
[Train] epoch 76 Batch 7 Loss 0.22189903259277344
[Train] epoch 76 Batch 8 Loss 0.19223713874816895
[Train] epoch 76 Batch 9 Loss 0.12635678052902222
[Train] epoch 76 Batch 10 Loss 0.1767117977142334
[Train] epoch 76 Batch 11 Loss 0.18684332072734833
[Train] epoch 76 Batch 12 Loss 0.2148893177509308
[Train] epoch 76 Batch 13 Loss 0.11116012930870056
[Train] epoch 76 Batch 14 Loss 0.16051103174686432
[Train] epoch 76 Batch 15 Loss 0.14029261469841003
[Train] epoch 76 Batch 16 Loss 0.042610350996255875
[Train] epoch 76 Batch 17 Loss 0.07593832910060883
[Train] epoch 76 Batch 18 Loss 0.12626048922538757
[Train] epoch 76 Batch 19 Loss 0.10631920397281647
[Train] epoch 76 Batch 20 Loss 0.2831054627895355
[Train] epoch 76 Batch 21 Loss 0.19306007027626038
[Train] epoch 76 Batch 22 Loss 0.05765175819396973
[Train] epoch 76 Batch 23 Loss 0.10365938395261765
[Train] epoch 76 Batch 24 Loss 0.25979065895080566
[Train] epoch 76 Batch 25 Loss 0.10774095356464386
[Train] epoch 76 Batch 26 Loss 0.1156458854675293
[Train] epoch 76 Batch 27 Loss 0.20391815900802612
[Train] epoch 76 Batch 28 Loss 0.12109541147947311
[Train] epoch 76 Batch 29 Loss 0.16349810361862183
[Train] epoch 76 Batch 30 Loss 0.11983410269021988
[Train] epoch 76 Batch 31 Loss 0.20482894778251648
[Train] epoch 76 Batch 32 Loss 0.037780217826366425
[Train] epoch 76 Batch 33 Loss 0.1794780194759369
[Train] epoch 76 Batch 34 Loss 0.11148925125598907
[Train] epoch 76 Batch 35 Loss 0.23025718331336975
[Train] epoch 76 Batch 36 Loss 0.14591342210769653
[Train] epoch 76 Batch 37 Loss 0.26144275069236755
[Train] epoch 76 Batch 38 Loss 0.11956005543470383
[Train] epoch 76 Batch 39 Loss 0.08404998481273651
[Train] epoch 76 Batch 40 Loss 0.18678945302963257
[Train] epoch 76 Batch 41 Loss 0.1645098626613617
[Train] epoch 76 Batch 42 Loss 0.20619404315948486
[Train] epoch 76 Batch 43 Loss 0.18879877030849457
[Train] epoch 76 Batch 44 Loss 0.21914039552211761
[Train] epoch 76 Batch 45 Loss 0.04313884675502777
[Train] epoch 76 Batch 46 Loss 0.16226571798324585
[Train] epoch 76 Batch 47 Loss 0.2428704798221588
[Train] epoch 77 Batch 0 Loss 0.1505824774503708
[Train] epoch 77 Batch 1 Loss 0.13111694157123566
[Train] epoch 77 Batch 2 Loss 0.11194673180580139
[Train] epoch 77 Batch 3 Loss 0.19162367284297943
[Train] epoch 77 Batch 4 Loss 0.031300708651542664
[Train] epoch 77 Batch 5 Loss 0.26319620013237
[Train] epoch 77 Batch 6 Loss 0.25229328870773315
[Train] epoch 77 Batch 7 Loss 0.2260356992483139
[Train] epoch 77 Batch 8 Loss 0.09588460624217987
[Train] epoch 77 Batch 9 Loss 0.10379035770893097
[Train] epoch 77 Batch 10 Loss 0.1971934735774994
[Train] epoch 77 Batch 11 Loss 0.13104285299777985
[Train] epoch 77 Batch 12 Loss 0.08076878637075424
[Train] epoch 77 Batch 13 Loss 0.11379221081733704
[Train] epoch 77 Batch 14 Loss 0.11353524029254913
[Train] epoch 77 Batch 15 Loss 0.15940731763839722
[Train] epoch 77 Batch 16 Loss 0.08810334652662277
[Train] epoch 77 Batch 17 Loss 0.2023324966430664
[Train] epoch 77 Batch 18 Loss 0.06880804896354675
[Train] epoch 77 Batch 19 Loss 0.25858834385871887
[Train] epoch 77 Batch 20 Loss 0.14984960854053497
[Train] epoch 77 Batch 21 Loss 0.14182326197624207
[Train] epoch 77 Batch 22 Loss 0.14694035053253174
[Train] epoch 77 Batch 23 Loss 0.15806686878204346
[Train] epoch 77 Batch 24 Loss 0.2723275423049927
[Train] epoch 77 Batch 25 Loss 0.10880672186613083
[Train] epoch 77 Batch 26 Loss 0.2024824023246765
[Train] epoch 77 Batch 27 Loss 0.13206113874912262
[Train] epoch 77 Batch 28 Loss 0.218057781457901
[Train] epoch 77 Batch 29 Loss 0.10628346353769302
[Train] epoch 77 Batch 30 Loss 0.13388162851333618
[Train] epoch 77 Batch 31 Loss 0.22655551135540009
[Train] epoch 77 Batch 32 Loss 0.12443872541189194
[Train] epoch 77 Batch 33 Loss 0.1544436514377594
[Train] epoch 77 Batch 34 Loss 0.24777449667453766
[Train] epoch 77 Batch 35 Loss 0.15329839289188385
[Train] epoch 77 Batch 36 Loss 0.19493071734905243
[Train] epoch 77 Batch 37 Loss 0.15060769021511078
[Train] epoch 77 Batch 38 Loss 0.0938999131321907
[Train] epoch 77 Batch 39 Loss 0.0739542618393898
[Train] epoch 77 Batch 40 Loss 0.22726953029632568
[Train] epoch 77 Batch 41 Loss 0.2094619870185852
[Train] epoch 77 Batch 42 Loss 0.15754461288452148
[Train] epoch 77 Batch 43 Loss 0.12813442945480347
[Train] epoch 77 Batch 44 Loss 0.22732847929000854
[Train] epoch 77 Batch 45 Loss 0.18295490741729736
[Train] epoch 77 Batch 46 Loss 0.1655009388923645
[Train] epoch 77 Batch 47 Loss 0.08691210299730301
[Train] epoch 78 Batch 0 Loss 0.27813732624053955
[Train] epoch 78 Batch 1 Loss 0.30365198850631714
[Train] epoch 78 Batch 2 Loss 0.13891172409057617
[Train] epoch 78 Batch 3 Loss 0.17891263961791992
[Train] epoch 78 Batch 4 Loss 0.14908075332641602
[Train] epoch 78 Batch 5 Loss 0.1836223602294922
[Train] epoch 78 Batch 6 Loss 0.030410056933760643
[Train] epoch 78 Batch 7 Loss 0.15978728234767914
[Train] epoch 78 Batch 8 Loss 0.1888381391763687
[Train] epoch 78 Batch 9 Loss 0.2190093696117401
[Train] epoch 78 Batch 10 Loss 0.3380984663963318
[Train] epoch 78 Batch 11 Loss 0.14361581206321716
[Train] epoch 78 Batch 12 Loss 0.19491033256053925
[Train] epoch 78 Batch 13 Loss 0.18813323974609375
[Train] epoch 78 Batch 14 Loss 0.1982181966304779
[Train] epoch 78 Batch 15 Loss 0.21011880040168762
[Train] epoch 78 Batch 16 Loss 0.11692691594362259
[Train] epoch 78 Batch 17 Loss 0.1457502692937851
[Train] epoch 78 Batch 18 Loss 0.076565220952034
[Train] epoch 78 Batch 19 Loss 0.02902902103960514
[Train] epoch 78 Batch 20 Loss 0.0840420201420784
[Train] epoch 78 Batch 21 Loss 0.23083937168121338
[Train] epoch 78 Batch 22 Loss 0.09031946957111359
[Train] epoch 78 Batch 23 Loss 0.1945270597934723
[Train] epoch 78 Batch 24 Loss 0.1888560950756073
[Train] epoch 78 Batch 25 Loss 0.09350945055484772
[Train] epoch 78 Batch 26 Loss 0.2586557865142822
[Train] epoch 78 Batch 27 Loss 0.09425969421863556
[Train] epoch 78 Batch 28 Loss 0.18836666643619537
[Train] epoch 78 Batch 29 Loss 0.15479958057403564
[Train] epoch 78 Batch 30 Loss 0.0390247106552124
[Train] epoch 78 Batch 31 Loss 0.13266974687576294
[Train] epoch 78 Batch 32 Loss 0.19465702772140503
[Train] epoch 78 Batch 33 Loss 0.13374972343444824
[Train] epoch 78 Batch 34 Loss 0.15957577526569366
[Train] epoch 78 Batch 35 Loss 0.3056262135505676
[Train] epoch 78 Batch 36 Loss 0.12418857961893082
[Train] epoch 78 Batch 37 Loss 0.2305774688720703
[Train] epoch 78 Batch 38 Loss 0.06919398903846741
[Train] epoch 78 Batch 39 Loss 0.14810022711753845
[Train] epoch 78 Batch 40 Loss 0.05117272958159447
[Train] epoch 78 Batch 41 Loss 0.12042418122291565
[Train] epoch 78 Batch 42 Loss 0.15412913262844086
[Train] epoch 78 Batch 43 Loss 0.06047162413597107
[Train] epoch 78 Batch 44 Loss 0.03738609701395035
[Train] epoch 78 Batch 45 Loss 0.18845820426940918
[Train] epoch 78 Batch 46 Loss 0.2512674331665039
[Train] epoch 78 Batch 47 Loss 0.11510990560054779
[Train] epoch 79 Batch 0 Loss 0.1536412388086319
[Train] epoch 79 Batch 1 Loss 0.22606369853019714
[Train] epoch 79 Batch 2 Loss 0.2545650601387024
[Train] epoch 79 Batch 3 Loss 0.18617403507232666
[Train] epoch 79 Batch 4 Loss 0.1264965683221817
[Train] epoch 79 Batch 5 Loss 0.18664471805095673
[Train] epoch 79 Batch 6 Loss 0.0837642177939415
[Train] epoch 79 Batch 7 Loss 0.08301025629043579
[Train] epoch 79 Batch 8 Loss 0.14861154556274414
[Train] epoch 79 Batch 9 Loss 0.1921703964471817
[Train] epoch 79 Batch 10 Loss 0.1405736804008484
[Train] epoch 79 Batch 11 Loss 0.1820460855960846
[Train] epoch 79 Batch 12 Loss 0.26575249433517456
[Train] epoch 79 Batch 13 Loss 0.08591876178979874
[Train] epoch 79 Batch 14 Loss 0.15238727629184723
[Train] epoch 79 Batch 15 Loss 0.3019682466983795
[Train] epoch 79 Batch 16 Loss 0.2626323699951172
[Train] epoch 79 Batch 17 Loss 0.2298692762851715
[Train] epoch 79 Batch 18 Loss 0.19122731685638428
[Train] epoch 79 Batch 19 Loss 0.12201569974422455
[Train] epoch 79 Batch 20 Loss 0.07202812284231186
[Train] epoch 79 Batch 21 Loss 0.13680559396743774
[Train] epoch 79 Batch 22 Loss 0.16499102115631104
[Train] epoch 79 Batch 23 Loss 0.21990570425987244
[Train] epoch 79 Batch 24 Loss 0.15386036038398743
[Train] epoch 79 Batch 25 Loss 0.09682240337133408
[Train] epoch 79 Batch 26 Loss 0.24402007460594177
[Train] epoch 79 Batch 27 Loss 0.14362935721874237
[Train] epoch 79 Batch 28 Loss 0.07305555790662766
[Train] epoch 79 Batch 29 Loss 0.08292129635810852
[Train] epoch 79 Batch 30 Loss 0.31664565205574036
[Train] epoch 79 Batch 31 Loss 0.06511175632476807
[Train] epoch 79 Batch 32 Loss 0.111050546169281
[Train] epoch 79 Batch 33 Loss 0.245658278465271
[Train] epoch 79 Batch 34 Loss 0.1196182370185852
[Train] epoch 79 Batch 35 Loss 0.12737010419368744
[Train] epoch 79 Batch 36 Loss 0.11177822202444077
[Train] epoch 79 Batch 37 Loss 0.150966614484787
[Train] epoch 79 Batch 38 Loss 0.1648486703634262
[Train] epoch 79 Batch 39 Loss 0.12221837043762207
[Train] epoch 79 Batch 40 Loss 0.11797302961349487
[Train] epoch 79 Batch 41 Loss 0.16934658586978912
[Train] epoch 79 Batch 42 Loss 0.1496022641658783
[Train] epoch 79 Batch 43 Loss 0.08370526134967804
[Train] epoch 79 Batch 44 Loss 0.1201765388250351
[Train] epoch 79 Batch 45 Loss 0.13174940645694733
[Train] epoch 79 Batch 46 Loss 0.21083393692970276
[Train] epoch 79 Batch 47 Loss 0.1312522441148758
[Train] epoch 80 Batch 0 Loss 0.17640681564807892
[Train] epoch 80 Batch 1 Loss 0.194755420088768
[Train] epoch 80 Batch 2 Loss 0.09047271311283112
[Train] epoch 80 Batch 3 Loss 0.0775250643491745
[Train] epoch 80 Batch 4 Loss 0.18126380443572998
[Train] epoch 80 Batch 5 Loss 0.1696721911430359
[Train] epoch 80 Batch 6 Loss 0.203609436750412
[Train] epoch 80 Batch 7 Loss 0.21046188473701477
[Train] epoch 80 Batch 8 Loss 0.1484682559967041
[Train] epoch 80 Batch 9 Loss 0.08451526612043381
[Train] epoch 80 Batch 10 Loss 0.15051265060901642
[Train] epoch 80 Batch 11 Loss 0.17049866914749146
[Train] epoch 80 Batch 12 Loss 0.19609452784061432
[Train] epoch 80 Batch 13 Loss 0.16340558230876923
[Train] epoch 80 Batch 14 Loss 0.15202471613883972
[Train] epoch 80 Batch 15 Loss 0.11733368784189224
[Train] epoch 80 Batch 16 Loss 0.23082831501960754
[Train] epoch 80 Batch 17 Loss 0.12526683509349823
[Train] epoch 80 Batch 18 Loss 0.18925262987613678
[Train] epoch 80 Batch 19 Loss 0.1939127892255783
[Train] epoch 80 Batch 20 Loss 0.273971825838089
[Train] epoch 80 Batch 21 Loss 0.2265019714832306
[Train] epoch 80 Batch 22 Loss 0.18919968605041504
[Train] epoch 80 Batch 23 Loss 0.07731235027313232
[Train] epoch 80 Batch 24 Loss 0.22114768624305725
[Train] epoch 80 Batch 25 Loss 0.18590079247951508
[Train] epoch 80 Batch 26 Loss 0.1598053276538849
[Train] epoch 80 Batch 27 Loss 0.1540071815252304
[Train] epoch 80 Batch 28 Loss 0.18781334161758423
[Train] epoch 80 Batch 29 Loss 0.1578618437051773
[Train] epoch 80 Batch 30 Loss 0.248667374253273
[Train] epoch 80 Batch 31 Loss 0.16896727681159973
[Train] epoch 80 Batch 32 Loss 0.07123340666294098
[Train] epoch 80 Batch 33 Loss 0.10515868663787842
[Train] epoch 80 Batch 34 Loss 0.11329103261232376
[Train] epoch 80 Batch 35 Loss 0.07614383101463318
[Train] epoch 80 Batch 36 Loss 0.21837745606899261
[Train] epoch 80 Batch 37 Loss 0.17712196707725525
[Train] epoch 80 Batch 38 Loss 0.13026978075504303
[Train] epoch 80 Batch 39 Loss 0.07929708808660507
[Train] epoch 80 Batch 40 Loss 0.07312946021556854
[Train] epoch 80 Batch 41 Loss 0.20358595252037048
[Train] epoch 80 Batch 42 Loss 0.17711806297302246
[Train] epoch 80 Batch 43 Loss 0.08198128640651703
[Train] epoch 80 Batch 44 Loss 0.11375542730093002
[Train] epoch 80 Batch 45 Loss 0.1294727921485901
[Train] epoch 80 Batch 46 Loss 0.19119495153427124
[Train] epoch 80 Batch 47 Loss 0.18255682289600372
[Train] epoch 81 Batch 0 Loss 0.03753659874200821
[Train] epoch 81 Batch 1 Loss 0.16362130641937256
[Train] epoch 81 Batch 2 Loss 0.2953275144100189
[Train] epoch 81 Batch 3 Loss 0.07123713940382004
[Train] epoch 81 Batch 4 Loss 0.06278534978628159
[Train] epoch 81 Batch 5 Loss 0.1651674211025238
[Train] epoch 81 Batch 6 Loss 0.20275552570819855
[Train] epoch 81 Batch 7 Loss 0.2661632001399994
[Train] epoch 81 Batch 8 Loss 0.08449859172105789
[Train] epoch 81 Batch 9 Loss 0.23159512877464294
[Train] epoch 81 Batch 10 Loss 0.19993525743484497
[Train] epoch 81 Batch 11 Loss 0.10058747231960297
[Train] epoch 81 Batch 12 Loss 0.15961039066314697
[Train] epoch 81 Batch 13 Loss 0.1424795389175415
[Train] epoch 81 Batch 14 Loss 0.2471071481704712
[Train] epoch 81 Batch 15 Loss 0.22645831108093262
[Train] epoch 81 Batch 16 Loss 0.18306390941143036
[Train] epoch 81 Batch 17 Loss 0.15516047179698944
[Train] epoch 81 Batch 18 Loss 0.18710294365882874
[Train] epoch 81 Batch 19 Loss 0.12807492911815643
[Train] epoch 81 Batch 20 Loss 0.08386300504207611
[Train] epoch 81 Batch 21 Loss 0.2105804681777954
[Train] epoch 81 Batch 22 Loss 0.052110977470874786
[Train] epoch 81 Batch 23 Loss 0.16324998438358307
[Train] epoch 81 Batch 24 Loss 0.11445952951908112
[Train] epoch 81 Batch 25 Loss 0.04237394407391548
[Train] epoch 81 Batch 26 Loss 0.19293442368507385
[Train] epoch 81 Batch 27 Loss 0.11066582798957825
[Train] epoch 81 Batch 28 Loss 0.19852128624916077
[Train] epoch 81 Batch 29 Loss 0.14736241102218628
[Train] epoch 81 Batch 30 Loss 0.12018736451864243
[Train] epoch 81 Batch 31 Loss 0.30660098791122437
[Train] epoch 81 Batch 32 Loss 0.11173979938030243
[Train] epoch 81 Batch 33 Loss 0.12068676203489304
[Train] epoch 81 Batch 34 Loss 0.16971419751644135
[Train] epoch 81 Batch 35 Loss 0.11598701030015945
[Train] epoch 81 Batch 36 Loss 0.19099682569503784
[Train] epoch 81 Batch 37 Loss 0.18527942895889282
[Train] epoch 81 Batch 38 Loss 0.14707891643047333
[Train] epoch 81 Batch 39 Loss 0.1551520824432373
[Train] epoch 81 Batch 40 Loss 0.18606531620025635
[Train] epoch 81 Batch 41 Loss 0.15132386982440948
[Train] epoch 81 Batch 42 Loss 0.12470439076423645
[Train] epoch 81 Batch 43 Loss 0.08491670340299606
[Train] epoch 81 Batch 44 Loss 0.16587302088737488
[Train] epoch 81 Batch 45 Loss 0.07974149286746979
[Train] epoch 81 Batch 46 Loss 0.11299799382686615
[Train] epoch 81 Batch 47 Loss 0.1828019618988037
[Train] epoch 82 Batch 0 Loss 0.0805310308933258
[Train] epoch 82 Batch 1 Loss 0.05535273998975754
[Train] epoch 82 Batch 2 Loss 0.20835044980049133
[Train] epoch 82 Batch 3 Loss 0.22426891326904297
[Train] epoch 82 Batch 4 Loss 0.19694027304649353
[Train] epoch 82 Batch 5 Loss 0.12903419137001038
[Train] epoch 82 Batch 6 Loss 0.1556745320558548
[Train] epoch 82 Batch 7 Loss 0.1677093803882599
[Train] epoch 82 Batch 8 Loss 0.2275085598230362
[Train] epoch 82 Batch 9 Loss 0.09644194692373276
[Train] epoch 82 Batch 10 Loss 0.18346351385116577
[Train] epoch 82 Batch 11 Loss 0.08593447506427765
[Train] epoch 82 Batch 12 Loss 0.08916407823562622
[Train] epoch 82 Batch 13 Loss 0.10984565317630768
[Train] epoch 82 Batch 14 Loss 0.11816512048244476
[Train] epoch 82 Batch 15 Loss 0.022364351898431778
[Train] epoch 82 Batch 16 Loss 0.18296445906162262
[Train] epoch 82 Batch 17 Loss 0.25674909353256226
[Train] epoch 82 Batch 18 Loss 0.06758163124322891
[Train] epoch 82 Batch 19 Loss 0.24650192260742188
[Train] epoch 82 Batch 20 Loss 0.09862621873617172
[Train] epoch 82 Batch 21 Loss 0.23171280324459076
[Train] epoch 82 Batch 22 Loss 0.25936901569366455
[Train] epoch 82 Batch 23 Loss 0.11218664050102234
[Train] epoch 82 Batch 24 Loss 0.21301491558551788
[Train] epoch 82 Batch 25 Loss 0.14111825823783875
[Train] epoch 82 Batch 26 Loss 0.21886859834194183
[Train] epoch 82 Batch 27 Loss 0.14512576162815094
[Train] epoch 82 Batch 28 Loss 0.19261129200458527
[Train] epoch 82 Batch 29 Loss 0.11621028184890747
[Train] epoch 82 Batch 30 Loss 0.1933676153421402
[Train] epoch 82 Batch 31 Loss 0.11242521554231644
[Train] epoch 82 Batch 32 Loss 0.17402809858322144
[Train] epoch 82 Batch 33 Loss 0.10820869356393814
[Train] epoch 82 Batch 34 Loss 0.1518571674823761
[Train] epoch 82 Batch 35 Loss 0.18268483877182007
[Train] epoch 82 Batch 36 Loss 0.2058267593383789
[Train] epoch 82 Batch 37 Loss 0.12732569873332977
[Train] epoch 82 Batch 38 Loss 0.16458101570606232
[Train] epoch 82 Batch 39 Loss 0.17920182645320892
[Train] epoch 82 Batch 40 Loss 0.1582661122083664
[Train] epoch 82 Batch 41 Loss 0.28296345472335815
[Train] epoch 82 Batch 42 Loss 0.14781594276428223
[Train] epoch 82 Batch 43 Loss 0.14876389503479004
[Train] epoch 82 Batch 44 Loss 0.11054238677024841
[Train] epoch 82 Batch 45 Loss 0.20247168838977814
[Train] epoch 82 Batch 46 Loss 0.07783040404319763
[Train] epoch 82 Batch 47 Loss 0.1491430252790451
[Train] epoch 83 Batch 0 Loss 0.1869998574256897
[Train] epoch 83 Batch 1 Loss 0.14761969447135925
[Train] epoch 83 Batch 2 Loss 0.16392174363136292
[Train] epoch 83 Batch 3 Loss 0.14661262929439545
[Train] epoch 83 Batch 4 Loss 0.00968971848487854
[Train] epoch 83 Batch 5 Loss 0.10134826600551605
[Train] epoch 83 Batch 6 Loss 0.19359377026557922
[Train] epoch 83 Batch 7 Loss 0.07121427357196808
[Train] epoch 83 Batch 8 Loss 0.2383318543434143
[Train] epoch 83 Batch 9 Loss 0.11828816682100296
[Train] epoch 83 Batch 10 Loss 0.27282941341400146
[Train] epoch 83 Batch 11 Loss 0.13443420827388763
[Train] epoch 83 Batch 12 Loss 0.1652635782957077
[Train] epoch 83 Batch 13 Loss 0.1697547733783722
[Train] epoch 83 Batch 14 Loss 0.1175365075469017
[Train] epoch 83 Batch 15 Loss 0.1583598554134369
[Train] epoch 83 Batch 16 Loss 0.1299179643392563
[Train] epoch 83 Batch 17 Loss 0.20428724586963654
[Train] epoch 83 Batch 18 Loss 0.18687687814235687
[Train] epoch 83 Batch 19 Loss 0.056354597210884094
[Train] epoch 83 Batch 20 Loss 0.13425497710704803
[Train] epoch 83 Batch 21 Loss 0.21668896079063416
[Train] epoch 83 Batch 22 Loss 0.046802207827568054
[Train] epoch 83 Batch 23 Loss 0.18269287049770355
[Train] epoch 83 Batch 24 Loss 0.13051646947860718
[Train] epoch 83 Batch 25 Loss 0.03720764070749283
[Train] epoch 83 Batch 26 Loss 0.17039674520492554
[Train] epoch 83 Batch 27 Loss 0.15813857316970825
[Train] epoch 83 Batch 28 Loss 0.15828320384025574
[Train] epoch 83 Batch 29 Loss 0.2516741454601288
[Train] epoch 83 Batch 30 Loss 0.1602054238319397
[Train] epoch 83 Batch 31 Loss 0.18453635275363922
[Train] epoch 83 Batch 32 Loss 0.1824224293231964
[Train] epoch 83 Batch 33 Loss 0.204008087515831
[Train] epoch 83 Batch 34 Loss 0.15828421711921692
[Train] epoch 83 Batch 35 Loss 0.18222980201244354
[Train] epoch 83 Batch 36 Loss 0.14080674946308136
[Train] epoch 83 Batch 37 Loss 0.2064693570137024
[Train] epoch 83 Batch 38 Loss 0.2056819349527359
[Train] epoch 83 Batch 39 Loss 0.22197218239307404
[Train] epoch 83 Batch 40 Loss 0.14166884124279022
[Train] epoch 83 Batch 41 Loss 0.05895504727959633
[Train] epoch 83 Batch 42 Loss 0.15341903269290924
[Train] epoch 83 Batch 43 Loss 0.10816415399312973
[Train] epoch 83 Batch 44 Loss 0.1548512727022171
[Train] epoch 83 Batch 45 Loss 0.08687879890203476
[Train] epoch 83 Batch 46 Loss 0.14695192873477936
[Train] epoch 83 Batch 47 Loss 0.3275713324546814
[Train] epoch 84 Batch 0 Loss 0.11286407709121704
[Train] epoch 84 Batch 1 Loss 0.20840531587600708
[Train] epoch 84 Batch 2 Loss 0.26253384351730347
[Train] epoch 84 Batch 3 Loss 1.0728851975727594e-06
[Train] epoch 84 Batch 4 Loss 0.16440847516059875
[Train] epoch 84 Batch 5 Loss 0.19779092073440552
[Train] epoch 84 Batch 6 Loss 0.14984232187271118
[Train] epoch 84 Batch 7 Loss 0.14503715932369232
[Train] epoch 84 Batch 8 Loss 0.16957204043865204
[Train] epoch 84 Batch 9 Loss 0.11874160915613174
[Train] epoch 84 Batch 10 Loss 0.07422563433647156
[Train] epoch 84 Batch 11 Loss 0.10973469913005829
[Train] epoch 84 Batch 12 Loss 0.28846606612205505
[Train] epoch 84 Batch 13 Loss 0.22188904881477356
[Train] epoch 84 Batch 14 Loss 0.15493717789649963
[Train] epoch 84 Batch 15 Loss 0.05379275232553482
[Train] epoch 84 Batch 16 Loss 0.09392198175191879
[Train] epoch 84 Batch 17 Loss 0.23779623210430145
[Train] epoch 84 Batch 18 Loss 0.008795971982181072
[Train] epoch 84 Batch 19 Loss 0.16317038238048553
[Train] epoch 84 Batch 20 Loss 0.11136427521705627
[Train] epoch 84 Batch 21 Loss 0.11287166178226471
[Train] epoch 84 Batch 22 Loss 0.19111967086791992
[Train] epoch 84 Batch 23 Loss 0.03534480556845665
[Train] epoch 84 Batch 24 Loss 0.18488840758800507
[Train] epoch 84 Batch 25 Loss 0.19239193201065063
[Train] epoch 84 Batch 26 Loss 0.03533328324556351
[Train] epoch 84 Batch 27 Loss 0.09184695780277252
[Train] epoch 84 Batch 28 Loss 0.12324207276105881
[Train] epoch 84 Batch 29 Loss 0.22187183797359467
[Train] epoch 84 Batch 30 Loss 0.1626731902360916
[Train] epoch 84 Batch 31 Loss 0.19097861647605896
[Train] epoch 84 Batch 32 Loss 0.2455308437347412
[Train] epoch 84 Batch 33 Loss 0.22719308733940125
[Train] epoch 84 Batch 34 Loss 0.1749339997768402
[Train] epoch 84 Batch 35 Loss 0.10376931726932526
[Train] epoch 84 Batch 36 Loss 0.26659536361694336
[Train] epoch 84 Batch 37 Loss 0.19463972747325897
[Train] epoch 84 Batch 38 Loss 0.26083943247795105
[Train] epoch 84 Batch 39 Loss 0.054912589490413666
[Train] epoch 84 Batch 40 Loss 0.03862154856324196
[Train] epoch 84 Batch 41 Loss 0.30073082447052
[Train] epoch 84 Batch 42 Loss 0.04477414861321449
[Train] epoch 84 Batch 43 Loss 0.050404611974954605
[Train] epoch 84 Batch 44 Loss 0.08131054043769836
[Train] epoch 84 Batch 45 Loss 0.20174282789230347
[Train] epoch 84 Batch 46 Loss 0.2646656036376953
[Train] epoch 84 Batch 47 Loss 0.24129167199134827
[Train] epoch 85 Batch 0 Loss 0.18011300265789032
[Train] epoch 85 Batch 1 Loss 0.14774616062641144
[Train] epoch 85 Batch 2 Loss 0.1386752426624298
[Train] epoch 85 Batch 3 Loss 0.1492433249950409
[Train] epoch 85 Batch 4 Loss 0.28851157426834106
[Train] epoch 85 Batch 5 Loss 0.08083239197731018
[Train] epoch 85 Batch 6 Loss 0.12351960688829422
[Train] epoch 85 Batch 7 Loss 0.19356706738471985
[Train] epoch 85 Batch 8 Loss 0.2016558051109314
[Train] epoch 85 Batch 9 Loss 0.08172042667865753
[Train] epoch 85 Batch 10 Loss 0.0829285979270935
[Train] epoch 85 Batch 11 Loss 0.1976713240146637
[Train] epoch 85 Batch 12 Loss 0.1538095921278
[Train] epoch 85 Batch 13 Loss 0.11441116780042648
[Train] epoch 85 Batch 14 Loss 0.22446957230567932
[Train] epoch 85 Batch 15 Loss 0.21669521927833557
[Train] epoch 85 Batch 16 Loss 0.2525056004524231
[Train] epoch 85 Batch 17 Loss 0.23850758373737335
[Train] epoch 85 Batch 18 Loss 0.1477499008178711
[Train] epoch 85 Batch 19 Loss 0.16625402867794037
[Train] epoch 85 Batch 20 Loss 0.18658915162086487
[Train] epoch 85 Batch 21 Loss 0.09891779720783234
[Train] epoch 85 Batch 22 Loss 0.2228739857673645
[Train] epoch 85 Batch 23 Loss 0.05341199040412903
[Train] epoch 85 Batch 24 Loss 0.16366323828697205
[Train] epoch 85 Batch 25 Loss 1.0728851975727594e-06
[Train] epoch 85 Batch 26 Loss 0.2196163535118103
[Train] epoch 85 Batch 27 Loss 0.18297524750232697
[Train] epoch 85 Batch 28 Loss 0.1466946005821228
[Train] epoch 85 Batch 29 Loss 0.08736060559749603
[Train] epoch 85 Batch 30 Loss 0.2586425244808197
[Train] epoch 85 Batch 31 Loss 0.17206424474716187
[Train] epoch 85 Batch 32 Loss 0.013757521286606789
[Train] epoch 85 Batch 33 Loss 0.15178726613521576
[Train] epoch 85 Batch 34 Loss 0.14869362115859985
[Train] epoch 85 Batch 35 Loss 0.09229692071676254
[Train] epoch 85 Batch 36 Loss 0.15896913409233093
[Train] epoch 85 Batch 37 Loss 0.15705472230911255
[Train] epoch 85 Batch 38 Loss 0.08333155512809753
[Train] epoch 85 Batch 39 Loss 0.07640108466148376
[Train] epoch 85 Batch 40 Loss 0.18435649573802948
[Train] epoch 85 Batch 41 Loss 0.19391734898090363
[Train] epoch 85 Batch 42 Loss 0.021246034651994705
[Train] epoch 85 Batch 43 Loss 0.16492581367492676
[Train] epoch 85 Batch 44 Loss 0.15416619181632996
[Train] epoch 85 Batch 45 Loss 0.2608802616596222
[Train] epoch 85 Batch 46 Loss 0.12286946177482605
[Train] epoch 85 Batch 47 Loss 0.1617342084646225
[Train] epoch 86 Batch 0 Loss 0.15559683740139008
[Train] epoch 86 Batch 1 Loss 0.2737133800983429
[Train] epoch 86 Batch 2 Loss 0.2405739426612854
[Train] epoch 86 Batch 3 Loss 0.10895489156246185
[Train] epoch 86 Batch 4 Loss 0.14860254526138306
[Train] epoch 86 Batch 5 Loss 0.23996885120868683
[Train] epoch 86 Batch 6 Loss 0.1455126702785492
[Train] epoch 86 Batch 7 Loss 0.12885639071464539
[Train] epoch 86 Batch 8 Loss 0.24625656008720398
[Train] epoch 86 Batch 9 Loss 0.22915492951869965
[Train] epoch 86 Batch 10 Loss 0.15954774618148804
[Train] epoch 86 Batch 11 Loss 0.19842524826526642
[Train] epoch 86 Batch 12 Loss 0.15620078146457672
[Train] epoch 86 Batch 13 Loss 0.12780411541461945
[Train] epoch 86 Batch 14 Loss 0.24098539352416992
[Train] epoch 86 Batch 15 Loss 0.07745899260044098
[Train] epoch 86 Batch 16 Loss 0.03739798814058304
[Train] epoch 86 Batch 17 Loss 0.14192721247673035
[Train] epoch 86 Batch 18 Loss 0.30158519744873047
[Train] epoch 86 Batch 19 Loss 0.105448879301548
[Train] epoch 86 Batch 20 Loss 0.0827992707490921
[Train] epoch 86 Batch 21 Loss 0.20108231902122498
[Train] epoch 86 Batch 22 Loss 0.16198930144309998
[Train] epoch 86 Batch 23 Loss 0.16989707946777344
[Train] epoch 86 Batch 24 Loss 0.13015244901180267
[Train] epoch 86 Batch 25 Loss 0.1122959703207016
[Train] epoch 86 Batch 26 Loss 0.11790873110294342
[Train] epoch 86 Batch 27 Loss 0.16487576067447662
[Train] epoch 86 Batch 28 Loss 0.1428115963935852
[Train] epoch 86 Batch 29 Loss 0.12177441269159317
[Train] epoch 86 Batch 30 Loss 0.26117146015167236
[Train] epoch 86 Batch 31 Loss 0.13056962192058563
[Train] epoch 86 Batch 32 Loss 0.19615349173545837
[Train] epoch 86 Batch 33 Loss 0.08355371654033661
[Train] epoch 86 Batch 34 Loss 0.12170493602752686
[Train] epoch 86 Batch 35 Loss 0.19490408897399902
[Train] epoch 86 Batch 36 Loss 0.18488836288452148
[Train] epoch 86 Batch 37 Loss 0.07197723537683487
[Train] epoch 86 Batch 38 Loss 0.04872134327888489
[Train] epoch 86 Batch 39 Loss 0.24792182445526123
[Train] epoch 86 Batch 40 Loss 0.1443489044904709
[Train] epoch 86 Batch 41 Loss 1.0728851975727594e-06
[Train] epoch 86 Batch 42 Loss 0.11490941047668457
[Train] epoch 86 Batch 43 Loss 0.18291042745113373
[Train] epoch 86 Batch 44 Loss 0.14170169830322266
[Train] epoch 86 Batch 45 Loss 0.19897010922431946
[Train] epoch 86 Batch 46 Loss 0.07041921466588974
[Train] epoch 86 Batch 47 Loss 0.22006836533546448
[Train] epoch 87 Batch 0 Loss 0.13735201954841614
[Train] epoch 87 Batch 1 Loss 0.22425979375839233
[Train] epoch 87 Batch 2 Loss 0.14701296389102936
[Train] epoch 87 Batch 3 Loss 0.11545895785093307
[Train] epoch 87 Batch 4 Loss 0.07340016216039658
[Train] epoch 87 Batch 5 Loss 0.18269899487495422
[Train] epoch 87 Batch 6 Loss 0.05689788609743118
[Train] epoch 87 Batch 7 Loss 0.20332935452461243
[Train] epoch 87 Batch 8 Loss 0.0988260805606842
[Train] epoch 87 Batch 9 Loss 0.08897970616817474
[Train] epoch 87 Batch 10 Loss 0.18136638402938843
[Train] epoch 87 Batch 11 Loss 0.11178544163703918
[Train] epoch 87 Batch 12 Loss 0.20017887651920319
[Train] epoch 87 Batch 13 Loss 0.12453510612249374
[Train] epoch 87 Batch 14 Loss 0.08355436474084854
[Train] epoch 87 Batch 15 Loss 0.12245896458625793
[Train] epoch 87 Batch 16 Loss 0.22361481189727783
[Train] epoch 87 Batch 17 Loss 0.20573464035987854
[Train] epoch 87 Batch 18 Loss 0.17392587661743164
[Train] epoch 87 Batch 19 Loss 0.07290279865264893
[Train] epoch 87 Batch 20 Loss 0.11502346396446228
[Train] epoch 87 Batch 21 Loss 0.07611171156167984
[Train] epoch 87 Batch 22 Loss 0.12360627204179764
[Train] epoch 87 Batch 23 Loss 0.17937341332435608
[Train] epoch 87 Batch 24 Loss 0.2712092399597168
[Train] epoch 87 Batch 25 Loss 0.3236628770828247
[Train] epoch 87 Batch 26 Loss 0.2353295087814331
[Train] epoch 87 Batch 27 Loss 0.21898308396339417
[Train] epoch 87 Batch 28 Loss 0.13842037320137024
[Train] epoch 87 Batch 29 Loss 0.25669580698013306
[Train] epoch 87 Batch 30 Loss 0.17757311463356018
[Train] epoch 87 Batch 31 Loss 0.1225622296333313
[Train] epoch 87 Batch 32 Loss 0.14838512241840363
[Train] epoch 87 Batch 33 Loss 0.15585805475711823
[Train] epoch 87 Batch 34 Loss 0.2839990556240082
[Train] epoch 87 Batch 35 Loss 0.07472190260887146
[Train] epoch 87 Batch 36 Loss 0.1757189929485321
[Train] epoch 87 Batch 37 Loss 0.2787915766239166
[Train] epoch 87 Batch 38 Loss 0.3397068381309509
[Train] epoch 87 Batch 39 Loss 0.27737075090408325
[Train] epoch 87 Batch 40 Loss 0.11849827319383621
[Train] epoch 87 Batch 41 Loss 0.9448984861373901
[Train] epoch 87 Batch 42 Loss 0.1847236454486847
[Train] epoch 87 Batch 43 Loss 1.2085013389587402
[Train] epoch 87 Batch 44 Loss 0.9434043765068054
[Train] epoch 87 Batch 45 Loss 1.8905774354934692
[Train] epoch 87 Batch 46 Loss 1.4647587537765503
[Train] epoch 87 Batch 47 Loss 1.7215898036956787
[Train] epoch 88 Batch 0 Loss 0.6196863055229187
[Train] epoch 88 Batch 1 Loss 0.6982216835021973
[Train] epoch 88 Batch 2 Loss 0.734962522983551
[Train] epoch 88 Batch 3 Loss 0.3141472637653351
[Train] epoch 88 Batch 4 Loss 0.3286662697792053
[Train] epoch 88 Batch 5 Loss 0.22933918237686157
[Train] epoch 88 Batch 6 Loss 0.2471526563167572
[Train] epoch 88 Batch 7 Loss 0.34438347816467285
[Train] epoch 88 Batch 8 Loss 0.24864913523197174
[Train] epoch 88 Batch 9 Loss 0.2270095944404602
[Train] epoch 88 Batch 10 Loss 0.13343219459056854
[Train] epoch 88 Batch 11 Loss 0.4221428334712982
[Train] epoch 88 Batch 12 Loss 0.6544588208198547
[Train] epoch 88 Batch 13 Loss 0.24133026599884033
[Train] epoch 88 Batch 14 Loss 0.16144247353076935
[Train] epoch 88 Batch 15 Loss 0.1296813040971756
[Train] epoch 88 Batch 16 Loss 0.2514053285121918
[Train] epoch 88 Batch 17 Loss 0.16887132823467255
[Train] epoch 88 Batch 18 Loss 0.2769431173801422
[Train] epoch 88 Batch 19 Loss 0.37611591815948486
[Train] epoch 88 Batch 20 Loss 0.05698670074343681
[Train] epoch 88 Batch 21 Loss 0.6696651577949524
[Train] epoch 88 Batch 22 Loss 1.2262065410614014
[Train] epoch 88 Batch 23 Loss 1.196825385093689
[Train] epoch 88 Batch 24 Loss 1.4092177152633667
[Train] epoch 88 Batch 25 Loss 1.8614319562911987
[Train] epoch 88 Batch 26 Loss 0.8791093230247498
[Train] epoch 88 Batch 27 Loss 0.5747677087783813
[Train] epoch 88 Batch 28 Loss 0.6658010482788086
[Train] epoch 88 Batch 29 Loss 0.9114083051681519
[Train] epoch 88 Batch 30 Loss 1.2701148986816406
[Train] epoch 88 Batch 31 Loss 1.2353938817977905
[Train] epoch 88 Batch 32 Loss 1.3078486919403076
[Train] epoch 88 Batch 33 Loss 0.8033077120780945
[Train] epoch 88 Batch 34 Loss 0.6504254937171936
[Train] epoch 88 Batch 35 Loss 0.8678420782089233
[Train] epoch 88 Batch 36 Loss 0.7622861266136169
[Train] epoch 88 Batch 37 Loss 0.3963935375213623
[Train] epoch 88 Batch 38 Loss 0.3288693428039551
[Train] epoch 88 Batch 39 Loss 0.3306439220905304
[Train] epoch 88 Batch 40 Loss 0.7369047403335571
[Train] epoch 88 Batch 41 Loss 0.38265225291252136
[Train] epoch 88 Batch 42 Loss 0.292097806930542
[Train] epoch 88 Batch 43 Loss 0.13079354166984558
[Train] epoch 88 Batch 44 Loss 0.16689622402191162
[Train] epoch 88 Batch 45 Loss 0.22980624437332153
[Train] epoch 88 Batch 46 Loss 0.2094385325908661
[Train] epoch 88 Batch 47 Loss 0.3165428638458252
[Train] epoch 89 Batch 0 Loss 0.12723565101623535
[Train] epoch 89 Batch 1 Loss 0.2616626024246216
[Train] epoch 89 Batch 2 Loss 0.35986262559890747
[Train] epoch 89 Batch 3 Loss 0.2153526246547699
[Train] epoch 89 Batch 4 Loss 0.3248729407787323
[Train] epoch 89 Batch 5 Loss 0.2934139370918274
[Train] epoch 89 Batch 6 Loss 0.21271510422229767
[Train] epoch 89 Batch 7 Loss 0.1073220893740654
[Train] epoch 89 Batch 8 Loss 0.2827710807323456
[Train] epoch 89 Batch 9 Loss 0.17338722944259644
[Train] epoch 89 Batch 10 Loss 0.13413086533546448
[Train] epoch 89 Batch 11 Loss 0.12011325359344482
[Train] epoch 89 Batch 12 Loss 0.302749365568161
[Train] epoch 89 Batch 13 Loss 0.1571013331413269
[Train] epoch 89 Batch 14 Loss 0.25864899158477783
[Train] epoch 89 Batch 15 Loss 0.15946729481220245
[Train] epoch 89 Batch 16 Loss 0.07708941400051117
[Train] epoch 89 Batch 17 Loss 0.09202432632446289
[Train] epoch 89 Batch 18 Loss 0.28360164165496826
[Train] epoch 89 Batch 19 Loss 0.24808287620544434
[Train] epoch 89 Batch 20 Loss 0.30419665575027466
[Train] epoch 89 Batch 21 Loss 0.2563892900943756
[Train] epoch 89 Batch 22 Loss 0.18137717247009277
[Train] epoch 89 Batch 23 Loss 0.08149877935647964
[Train] epoch 89 Batch 24 Loss 0.08469720929861069
[Train] epoch 89 Batch 25 Loss 0.08806286752223969
[Train] epoch 89 Batch 26 Loss 0.15301793813705444
[Train] epoch 89 Batch 27 Loss 0.2465352714061737
[Train] epoch 89 Batch 28 Loss 0.21924161911010742
[Train] epoch 89 Batch 29 Loss 0.12176874279975891
[Train] epoch 89 Batch 30 Loss 0.3392074704170227
[Train] epoch 89 Batch 31 Loss 0.07556380331516266
[Train] epoch 89 Batch 32 Loss 0.15138335525989532
[Train] epoch 89 Batch 33 Loss 0.1981346607208252
[Train] epoch 89 Batch 34 Loss 0.2165183573961258
[Train] epoch 89 Batch 35 Loss 0.17124292254447937
[Train] epoch 89 Batch 36 Loss 0.10459579527378082
[Train] epoch 89 Batch 37 Loss 0.22976914048194885
[Train] epoch 89 Batch 38 Loss 0.21566611528396606
[Train] epoch 89 Batch 39 Loss 0.22091162204742432
[Train] epoch 89 Batch 40 Loss 0.38705089688301086
[Train] epoch 89 Batch 41 Loss 0.2918417751789093
[Train] epoch 89 Batch 42 Loss 0.3515172600746155
[Train] epoch 89 Batch 43 Loss 0.33092260360717773
[Train] epoch 89 Batch 44 Loss 0.33472055196762085
[Train] epoch 89 Batch 45 Loss 0.2492670714855194
[Train] epoch 89 Batch 46 Loss 0.17841146886348724
[Train] epoch 89 Batch 47 Loss 0.2185726910829544
[Train] epoch 90 Batch 0 Loss 0.25230878591537476
[Train] epoch 90 Batch 1 Loss 0.22880113124847412
[Train] epoch 90 Batch 2 Loss 0.20483709871768951
[Train] epoch 90 Batch 3 Loss 0.3456195890903473
[Train] epoch 90 Batch 4 Loss 0.15011239051818848
[Train] epoch 90 Batch 5 Loss 0.14153331518173218
[Train] epoch 90 Batch 6 Loss 0.29817306995391846
[Train] epoch 90 Batch 7 Loss 0.08261936902999878
[Train] epoch 90 Batch 8 Loss 0.07369958609342575
[Train] epoch 90 Batch 9 Loss 0.3321196138858795
[Train] epoch 90 Batch 10 Loss 0.15359914302825928
[Train] epoch 90 Batch 11 Loss 0.1521463245153427
[Train] epoch 90 Batch 12 Loss 0.2857910990715027
[Train] epoch 90 Batch 13 Loss 0.21341508626937866
[Train] epoch 90 Batch 14 Loss 0.1836499720811844
[Train] epoch 90 Batch 15 Loss 0.11088647693395615
[Train] epoch 90 Batch 16 Loss 0.14718613028526306
[Train] epoch 90 Batch 17 Loss 0.05157670006155968
[Train] epoch 90 Batch 18 Loss 0.07348810136318207
[Train] epoch 90 Batch 19 Loss 0.1496228128671646
[Train] epoch 90 Batch 20 Loss 0.2366122305393219
[Train] epoch 90 Batch 21 Loss 0.08219946920871735
[Train] epoch 90 Batch 22 Loss 0.0905129611492157
[Train] epoch 90 Batch 23 Loss 0.11793223768472672
[Train] epoch 90 Batch 24 Loss 0.14879003167152405
[Train] epoch 90 Batch 25 Loss 0.1483888328075409
[Train] epoch 90 Batch 26 Loss 0.22110214829444885
[Train] epoch 90 Batch 27 Loss 0.3096526265144348
[Train] epoch 90 Batch 28 Loss 0.2567526698112488
[Train] epoch 90 Batch 29 Loss 0.34671449661254883
[Train] epoch 90 Batch 30 Loss 0.14619076251983643
[Train] epoch 90 Batch 31 Loss 0.15369340777397156
[Train] epoch 90 Batch 32 Loss 0.17643369734287262
[Train] epoch 90 Batch 33 Loss 0.21999114751815796
[Train] epoch 90 Batch 34 Loss 0.17581221461296082
[Train] epoch 90 Batch 35 Loss 0.18257012963294983
[Train] epoch 90 Batch 36 Loss 0.036190591752529144
[Train] epoch 90 Batch 37 Loss 0.28516849875450134
[Train] epoch 90 Batch 38 Loss 0.11482012271881104
[Train] epoch 90 Batch 39 Loss 0.21972951292991638
[Train] epoch 90 Batch 40 Loss 0.285103976726532
[Train] epoch 90 Batch 41 Loss 0.37582725286483765
[Train] epoch 90 Batch 42 Loss 0.14572954177856445
[Train] epoch 90 Batch 43 Loss 0.15867818892002106
[Train] epoch 90 Batch 44 Loss 0.2488611489534378
[Train] epoch 90 Batch 45 Loss 0.2560049891471863
[Train] epoch 90 Batch 46 Loss 0.22625187039375305
[Train] epoch 90 Batch 47 Loss 0.13950207829475403
[Train] epoch 91 Batch 0 Loss 0.15969151258468628
[Train] epoch 91 Batch 1 Loss 0.1396811306476593
[Train] epoch 91 Batch 2 Loss 0.1761092245578766
[Train] epoch 91 Batch 3 Loss 0.2848517894744873
[Train] epoch 91 Batch 4 Loss 0.24935446679592133
[Train] epoch 91 Batch 5 Loss 0.18179050087928772
[Train] epoch 91 Batch 6 Loss 0.26666736602783203
[Train] epoch 91 Batch 7 Loss 0.21188554167747498
[Train] epoch 91 Batch 8 Loss 0.14521130919456482
[Train] epoch 91 Batch 9 Loss 0.27882760763168335
[Train] epoch 91 Batch 10 Loss 0.20608831942081451
[Train] epoch 91 Batch 11 Loss 0.011371945030987263
[Train] epoch 91 Batch 12 Loss 0.14468668401241302
[Train] epoch 91 Batch 13 Loss 0.29032444953918457
[Train] epoch 91 Batch 14 Loss 0.21200327575206757
[Train] epoch 91 Batch 15 Loss 0.25317347049713135
[Train] epoch 91 Batch 16 Loss 0.18124791979789734
[Train] epoch 91 Batch 17 Loss 0.24763223528862
[Train] epoch 91 Batch 18 Loss 0.16964194178581238
[Train] epoch 91 Batch 19 Loss 0.3201737701892853
[Train] epoch 91 Batch 20 Loss 0.18118169903755188
[Train] epoch 91 Batch 21 Loss 0.18746384978294373
[Train] epoch 91 Batch 22 Loss 0.2721998691558838
[Train] epoch 91 Batch 23 Loss 0.11998947709798813
[Train] epoch 91 Batch 24 Loss 0.10295639932155609
[Train] epoch 91 Batch 25 Loss 0.2223779857158661
[Train] epoch 91 Batch 26 Loss 0.07892075181007385
[Train] epoch 91 Batch 27 Loss 0.15099020302295685
[Train] epoch 91 Batch 28 Loss 0.14469145238399506
[Train] epoch 91 Batch 29 Loss 0.041984520852565765
[Train] epoch 91 Batch 30 Loss 0.21755272150039673
[Train] epoch 91 Batch 31 Loss 0.34559115767478943
[Train] epoch 91 Batch 32 Loss 0.054945673793554306
[Train] epoch 91 Batch 33 Loss 0.17527970671653748
[Train] epoch 91 Batch 34 Loss 0.18253101408481598
[Train] epoch 91 Batch 35 Loss 0.24250081181526184
[Train] epoch 91 Batch 36 Loss 0.18800053000450134
[Train] epoch 91 Batch 37 Loss 0.18877282738685608
[Train] epoch 91 Batch 38 Loss 0.07888808101415634
[Train] epoch 91 Batch 39 Loss 0.11467977613210678
[Train] epoch 91 Batch 40 Loss 0.29691293835639954
[Train] epoch 91 Batch 41 Loss 0.21741928160190582
[Train] epoch 91 Batch 42 Loss 0.27786022424697876
[Train] epoch 91 Batch 43 Loss 0.11527692526578903
[Train] epoch 91 Batch 44 Loss 0.1750185191631317
[Train] epoch 91 Batch 45 Loss 0.22319865226745605
[Train] epoch 91 Batch 46 Loss 0.03613130375742912
[Train] epoch 91 Batch 47 Loss 0.22229593992233276
[Train] epoch 92 Batch 0 Loss 0.14424827694892883
[Train] epoch 92 Batch 1 Loss 0.10774305462837219
[Train] epoch 92 Batch 2 Loss 0.17488832771778107
[Train] epoch 92 Batch 3 Loss 0.1366448700428009
[Train] epoch 92 Batch 4 Loss 0.3193058371543884
[Train] epoch 92 Batch 5 Loss 0.2054843008518219
[Train] epoch 92 Batch 6 Loss 0.27838802337646484
[Train] epoch 92 Batch 7 Loss 0.24142777919769287
[Train] epoch 92 Batch 8 Loss 0.21923595666885376
[Train] epoch 92 Batch 9 Loss 0.1173117458820343
[Train] epoch 92 Batch 10 Loss 0.2472410947084427
[Train] epoch 92 Batch 11 Loss 0.11683736741542816
[Train] epoch 92 Batch 12 Loss 0.1085970550775528
[Train] epoch 92 Batch 13 Loss 0.24760529398918152
[Train] epoch 92 Batch 14 Loss 0.24740955233573914
[Train] epoch 92 Batch 15 Loss 0.24143481254577637
[Train] epoch 92 Batch 16 Loss 0.24704532325267792
[Train] epoch 92 Batch 17 Loss 0.11039264500141144
[Train] epoch 92 Batch 18 Loss 0.30285680294036865
[Train] epoch 92 Batch 19 Loss 0.22244636714458466
[Train] epoch 92 Batch 20 Loss 0.07798472046852112
[Train] epoch 92 Batch 21 Loss 0.13174790143966675
[Train] epoch 92 Batch 22 Loss 0.10901486873626709
[Train] epoch 92 Batch 23 Loss 0.2477436065673828
[Train] epoch 92 Batch 24 Loss 0.23079007863998413
[Train] epoch 92 Batch 25 Loss 0.20560169219970703
[Train] epoch 92 Batch 26 Loss 0.21244633197784424
[Train] epoch 92 Batch 27 Loss 0.006301902700215578
[Train] epoch 92 Batch 28 Loss 0.06349849700927734
[Train] epoch 92 Batch 29 Loss 0.18200773000717163
[Train] epoch 92 Batch 30 Loss 0.10899975895881653
[Train] epoch 92 Batch 31 Loss 0.17547866702079773
[Train] epoch 92 Batch 32 Loss 0.1270870864391327
[Train] epoch 92 Batch 33 Loss 0.2488745152950287
[Train] epoch 92 Batch 34 Loss 0.32082632184028625
[Train] epoch 92 Batch 35 Loss 0.18649587035179138
[Train] epoch 92 Batch 36 Loss 0.211602121591568
[Train] epoch 92 Batch 37 Loss 0.174674391746521
[Train] epoch 92 Batch 38 Loss 0.1499824821949005
[Train] epoch 92 Batch 39 Loss 0.18061703443527222
[Train] epoch 92 Batch 40 Loss 0.2828749418258667
[Train] epoch 92 Batch 41 Loss 0.08211761713027954
[Train] epoch 92 Batch 42 Loss 0.28226935863494873
[Train] epoch 92 Batch 43 Loss 0.22099637985229492
[Train] epoch 92 Batch 44 Loss 0.08434192091226578
[Train] epoch 92 Batch 45 Loss 0.252127468585968
[Train] epoch 92 Batch 46 Loss 0.2774606943130493
[Train] epoch 92 Batch 47 Loss 0.10789941996335983
[Train] epoch 93 Batch 0 Loss 0.23624186217784882
[Train] epoch 93 Batch 1 Loss 0.18655070662498474
[Train] epoch 93 Batch 2 Loss 0.2721480131149292
[Train] epoch 93 Batch 3 Loss 0.21188010275363922
[Train] epoch 93 Batch 4 Loss 0.21192480623722076
[Train] epoch 93 Batch 5 Loss 0.18169520795345306
[Train] epoch 93 Batch 6 Loss 0.14516504108905792
[Train] epoch 93 Batch 7 Loss 0.21796709299087524
[Train] epoch 93 Batch 8 Loss 0.042302049696445465
[Train] epoch 93 Batch 9 Loss 0.1880323737859726
[Train] epoch 93 Batch 10 Loss 0.18195968866348267
[Train] epoch 93 Batch 11 Loss 0.1809004843235016
[Train] epoch 93 Batch 12 Loss 0.3198299705982208
[Train] epoch 93 Batch 13 Loss 0.30856287479400635
[Train] epoch 93 Batch 14 Loss 0.3087834119796753
[Train] epoch 93 Batch 15 Loss 0.04777129739522934
[Train] epoch 93 Batch 16 Loss 0.13866449892520905
[Train] epoch 93 Batch 17 Loss 0.14447146654129028
[Train] epoch 93 Batch 18 Loss 0.0777164101600647
[Train] epoch 93 Batch 19 Loss 0.1798376888036728
[Train] epoch 93 Batch 20 Loss 0.24668681621551514
[Train] epoch 93 Batch 21 Loss 0.25766509771347046
[Train] epoch 93 Batch 22 Loss 0.14394816756248474
[Train] epoch 93 Batch 23 Loss 0.205361008644104
[Train] epoch 93 Batch 24 Loss 0.21011774241924286
[Train] epoch 93 Batch 25 Loss 0.18483781814575195
[Train] epoch 93 Batch 26 Loss 0.11821950227022171
[Train] epoch 93 Batch 27 Loss 0.10729177296161652
[Train] epoch 93 Batch 28 Loss 0.12214665114879608
[Train] epoch 93 Batch 29 Loss 0.18363314867019653
[Train] epoch 93 Batch 30 Loss 0.3535776138305664
[Train] epoch 93 Batch 31 Loss 0.1793346256017685
[Train] epoch 93 Batch 32 Loss 0.1382366418838501
[Train] epoch 93 Batch 33 Loss 0.10265392065048218
[Train] epoch 93 Batch 34 Loss 0.18469206988811493
[Train] epoch 93 Batch 35 Loss 0.17422521114349365
[Train] epoch 93 Batch 36 Loss 0.13845384120941162
[Train] epoch 93 Batch 37 Loss 0.21504420042037964
[Train] epoch 93 Batch 38 Loss 0.040756046772003174
[Train] epoch 93 Batch 39 Loss 0.11753979325294495
[Train] epoch 93 Batch 40 Loss 0.2513202726840973
[Train] epoch 93 Batch 41 Loss 0.21486619114875793
[Train] epoch 93 Batch 42 Loss 0.21488234400749207
[Train] epoch 93 Batch 43 Loss 0.08164568990468979
[Train] epoch 93 Batch 44 Loss 0.15275517106056213
[Train] epoch 93 Batch 45 Loss 0.1693284958600998
[Train] epoch 93 Batch 46 Loss 0.27652695775032043
[Train] epoch 93 Batch 47 Loss 0.3474297523498535
[Train] epoch 94 Batch 0 Loss 0.046412110328674316
[Train] epoch 94 Batch 1 Loss 0.17424196004867554
[Train] epoch 94 Batch 2 Loss 0.15608903765678406
[Train] epoch 94 Batch 3 Loss 0.41311514377593994
[Train] epoch 94 Batch 4 Loss 0.14429602026939392
[Train] epoch 94 Batch 5 Loss 0.10285588353872299
[Train] epoch 94 Batch 6 Loss 0.23735862970352173
[Train] epoch 94 Batch 7 Loss 0.20489779114723206
[Train] epoch 94 Batch 8 Loss 0.1167127788066864
[Train] epoch 94 Batch 9 Loss 0.5525210499763489
[Train] epoch 94 Batch 10 Loss 0.21167732775211334
[Train] epoch 94 Batch 11 Loss 0.10251979529857635
[Train] epoch 94 Batch 12 Loss 0.18814527988433838
[Train] epoch 94 Batch 13 Loss 0.2166280299425125
[Train] epoch 94 Batch 14 Loss 0.2523020803928375
[Train] epoch 94 Batch 15 Loss 0.27195194363594055
[Train] epoch 94 Batch 16 Loss 0.1612168848514557
[Train] epoch 94 Batch 17 Loss 0.3500171899795532
[Train] epoch 94 Batch 18 Loss 0.11345414817333221
[Train] epoch 94 Batch 19 Loss 0.1491602510213852
[Train] epoch 94 Batch 20 Loss 0.3491213321685791
[Train] epoch 94 Batch 21 Loss 0.3174981474876404
[Train] epoch 94 Batch 22 Loss 0.13858290016651154
[Train] epoch 94 Batch 23 Loss 0.2871643900871277
[Train] epoch 94 Batch 24 Loss 0.17434699833393097
[Train] epoch 94 Batch 25 Loss 0.08106055110692978
[Train] epoch 94 Batch 26 Loss 0.15302658081054688
[Train] epoch 94 Batch 27 Loss 0.10882601141929626
[Train] epoch 94 Batch 28 Loss 0.016415145248174667
[Train] epoch 94 Batch 29 Loss 0.20535534620285034
[Train] epoch 94 Batch 30 Loss 0.17413529753684998
[Train] epoch 94 Batch 31 Loss 0.04332546144723892
[Train] epoch 94 Batch 32 Loss 0.19057203829288483
[Train] epoch 94 Batch 33 Loss 0.18485978245735168
[Train] epoch 94 Batch 34 Loss 0.17611122131347656
[Train] epoch 94 Batch 35 Loss 0.24707117676734924
[Train] epoch 94 Batch 36 Loss 0.18090052902698517
[Train] epoch 94 Batch 37 Loss 0.2569501996040344
[Train] epoch 94 Batch 38 Loss 0.1831875741481781
[Train] epoch 94 Batch 39 Loss 0.11166349798440933
[Train] epoch 94 Batch 40 Loss 0.16845306754112244
[Train] epoch 94 Batch 41 Loss 0.0776422992348671
[Train] epoch 94 Batch 42 Loss 0.1460469365119934
[Train] epoch 94 Batch 43 Loss 0.16494397819042206
[Train] epoch 94 Batch 44 Loss 0.24955405294895172
[Train] epoch 94 Batch 45 Loss 0.2639368772506714
[Train] epoch 94 Batch 46 Loss 0.11544746160507202
[Train] epoch 94 Batch 47 Loss 0.17121003568172455
[Train] epoch 95 Batch 0 Loss 0.14878027141094208
[Train] epoch 95 Batch 1 Loss 0.2830079197883606
[Train] epoch 95 Batch 2 Loss 0.22829961776733398
[Train] epoch 95 Batch 3 Loss 0.1448509395122528
[Train] epoch 95 Batch 4 Loss 0.3816312551498413
[Train] epoch 95 Batch 5 Loss 0.21826662123203278
[Train] epoch 95 Batch 6 Loss 0.21168695390224457
[Train] epoch 95 Batch 7 Loss 0.13212540745735168
[Train] epoch 95 Batch 8 Loss 0.24902164936065674
[Train] epoch 95 Batch 9 Loss 0.07917517423629761
[Train] epoch 95 Batch 10 Loss 0.12658117711544037
[Train] epoch 95 Batch 11 Loss 0.18116098642349243
[Train] epoch 95 Batch 12 Loss 0.28341034054756165
[Train] epoch 95 Batch 13 Loss 0.24230560660362244
[Train] epoch 95 Batch 14 Loss 0.07719658315181732
[Train] epoch 95 Batch 15 Loss 0.2162458896636963
[Train] epoch 95 Batch 16 Loss 0.1808301955461502
[Train] epoch 95 Batch 17 Loss 0.2513543367385864
[Train] epoch 95 Batch 18 Loss 0.13874614238739014
[Train] epoch 95 Batch 19 Loss 0.18451017141342163
[Train] epoch 95 Batch 20 Loss 0.11322857439517975
[Train] epoch 95 Batch 21 Loss 0.2817786931991577
[Train] epoch 95 Batch 22 Loss 0.18598990142345428
[Train] epoch 95 Batch 23 Loss 0.26468247175216675
[Train] epoch 95 Batch 24 Loss 0.07214903831481934
[Train] epoch 95 Batch 25 Loss 0.144735187292099
[Train] epoch 95 Batch 26 Loss 0.11430583894252777
[Train] epoch 95 Batch 27 Loss 0.21171030402183533
[Train] epoch 95 Batch 28 Loss 0.28966522216796875
[Train] epoch 95 Batch 29 Loss 0.19346672296524048
[Train] epoch 95 Batch 30 Loss 0.2111290693283081
[Train] epoch 95 Batch 31 Loss 0.17529606819152832
[Train] epoch 95 Batch 32 Loss 0.2722245752811432
[Train] epoch 95 Batch 33 Loss 0.16948044300079346
[Train] epoch 95 Batch 34 Loss 0.17523843050003052
[Train] epoch 95 Batch 35 Loss 0.0778990387916565
[Train] epoch 95 Batch 36 Loss 0.1694536954164505
[Train] epoch 95 Batch 37 Loss 0.20570629835128784
[Train] epoch 95 Batch 38 Loss 0.10831858217716217
[Train] epoch 95 Batch 39 Loss 0.11434677243232727
[Train] epoch 95 Batch 40 Loss 0.2276674062013626
[Train] epoch 95 Batch 41 Loss 0.3081304728984833
[Train] epoch 95 Batch 42 Loss 0.06666764616966248
[Train] epoch 95 Batch 43 Loss 0.28338146209716797
[Train] epoch 95 Batch 44 Loss 0.2519671320915222
[Train] epoch 95 Batch 45 Loss 0.12406677007675171
[Train] epoch 95 Batch 46 Loss 0.17960315942764282
[Train] epoch 95 Batch 47 Loss 0.10283620655536652
[Train] epoch 96 Batch 0 Loss 0.27157875895500183
[Train] epoch 96 Batch 1 Loss 0.11278825998306274
[Train] epoch 96 Batch 2 Loss 0.133334219455719
[Train] epoch 96 Batch 3 Loss 0.10787585377693176
[Train] epoch 96 Batch 4 Loss 0.08657962083816528
[Train] epoch 96 Batch 5 Loss 0.15357862412929535
[Train] epoch 96 Batch 6 Loss 0.14847038686275482
[Train] epoch 96 Batch 7 Loss 0.1437319815158844
[Train] epoch 96 Batch 8 Loss 0.3529800772666931
[Train] epoch 96 Batch 9 Loss 0.1534377485513687
[Train] epoch 96 Batch 10 Loss 0.1070488914847374
[Train] epoch 96 Batch 11 Loss 0.18528084456920624
[Train] epoch 96 Batch 12 Loss 0.18299409747123718
[Train] epoch 96 Batch 13 Loss 0.21864010393619537
[Train] epoch 96 Batch 14 Loss 0.1751897931098938
[Train] epoch 96 Batch 15 Loss 0.1478690654039383
[Train] epoch 96 Batch 16 Loss 0.10764289647340775
[Train] epoch 96 Batch 17 Loss 0.3491135835647583
[Train] epoch 96 Batch 18 Loss 0.30812549591064453
[Train] epoch 96 Batch 19 Loss 0.26458051800727844
[Train] epoch 96 Batch 20 Loss 0.39234668016433716
[Train] epoch 96 Batch 21 Loss 0.3303757309913635
[Train] epoch 96 Batch 22 Loss 0.15057212114334106
[Train] epoch 96 Batch 23 Loss 0.18562312424182892
[Train] epoch 96 Batch 24 Loss 0.11231115460395813
[Train] epoch 96 Batch 25 Loss 0.11149850487709045
[Train] epoch 96 Batch 26 Loss 0.12971587479114532
[Train] epoch 96 Batch 27 Loss 0.2218538522720337
[Train] epoch 96 Batch 28 Loss 0.2135085165500641
[Train] epoch 96 Batch 29 Loss 0.17962968349456787
[Train] epoch 96 Batch 30 Loss 0.24219608306884766
[Train] epoch 96 Batch 31 Loss 0.17476573586463928
[Train] epoch 96 Batch 32 Loss 0.2114657163619995
[Train] epoch 96 Batch 33 Loss 0.38627690076828003
[Train] epoch 96 Batch 34 Loss 0.21711593866348267
[Train] epoch 96 Batch 35 Loss 0.10863373428583145
[Train] epoch 96 Batch 36 Loss 0.15171946585178375
[Train] epoch 96 Batch 37 Loss 0.23616015911102295
[Train] epoch 96 Batch 38 Loss 0.21289849281311035
[Train] epoch 96 Batch 39 Loss 0.14585383236408234
[Train] epoch 96 Batch 40 Loss 0.14020559191703796
[Train] epoch 96 Batch 41 Loss 0.18168459832668304
[Train] epoch 96 Batch 42 Loss 0.2575640380382538
[Train] epoch 96 Batch 43 Loss 0.0800187960267067
[Train] epoch 96 Batch 44 Loss 0.08664527535438538
[Train] epoch 96 Batch 45 Loss 0.13979572057724
[Train] epoch 96 Batch 46 Loss 0.33005011081695557
[Train] epoch 96 Batch 47 Loss 0.04263753443956375
[Train] epoch 97 Batch 0 Loss 0.24921868741512299
[Train] epoch 97 Batch 1 Loss 0.18266189098358154
[Train] epoch 97 Batch 2 Loss 0.07893013209104538
[Train] epoch 97 Batch 3 Loss 0.23036903142929077
[Train] epoch 97 Batch 4 Loss 0.21813222765922546
[Train] epoch 97 Batch 5 Loss 0.2420891970396042
[Train] epoch 97 Batch 6 Loss 0.1809411644935608
[Train] epoch 97 Batch 7 Loss 0.21148383617401123
[Train] epoch 97 Batch 8 Loss 0.1813649982213974
[Train] epoch 97 Batch 9 Loss 0.28368401527404785
[Train] epoch 97 Batch 10 Loss 0.1753045916557312
[Train] epoch 97 Batch 11 Loss 0.2220112383365631
[Train] epoch 97 Batch 12 Loss 0.21099504828453064
[Train] epoch 97 Batch 13 Loss 0.22217079997062683
[Train] epoch 97 Batch 14 Loss 0.1747165322303772
[Train] epoch 97 Batch 15 Loss 0.21571651101112366
[Train] epoch 97 Batch 16 Loss 0.18418891727924347
[Train] epoch 97 Batch 17 Loss 0.2831287682056427
[Train] epoch 97 Batch 18 Loss 0.34489554166793823
[Train] epoch 97 Batch 19 Loss 0.14414474368095398
[Train] epoch 97 Batch 20 Loss 0.0816154032945633
[Train] epoch 97 Batch 21 Loss 0.17446359992027283
[Train] epoch 97 Batch 22 Loss 0.10796979069709778
[Train] epoch 97 Batch 23 Loss 0.10676433145999908
[Train] epoch 97 Batch 24 Loss 0.10290361940860748
[Train] epoch 97 Batch 25 Loss 0.13802176713943481
[Train] epoch 97 Batch 26 Loss 0.14703930914402008
[Train] epoch 97 Batch 27 Loss 0.17843472957611084
[Train] epoch 97 Batch 28 Loss 0.11620444059371948
[Train] epoch 97 Batch 29 Loss 0.3061915338039398
[Train] epoch 97 Batch 30 Loss 0.08020136505365372
[Train] epoch 97 Batch 31 Loss 0.10734781622886658
[Train] epoch 97 Batch 32 Loss 0.1426575481891632
[Train] epoch 97 Batch 33 Loss 0.3450383245944977
[Train] epoch 97 Batch 34 Loss 0.13728637993335724
[Train] epoch 97 Batch 35 Loss 0.1475394368171692
[Train] epoch 97 Batch 36 Loss 0.25294822454452515
[Train] epoch 97 Batch 37 Loss 0.14838509261608124
[Train] epoch 97 Batch 38 Loss 0.07254018634557724
[Train] epoch 97 Batch 39 Loss 0.2864207923412323
[Train] epoch 97 Batch 40 Loss 0.20409192144870758
[Train] epoch 97 Batch 41 Loss 0.1430821418762207
[Train] epoch 97 Batch 42 Loss 0.06666764616966248
[Train] epoch 97 Batch 43 Loss 0.2179889976978302
[Train] epoch 97 Batch 44 Loss 0.14217934012413025
[Train] epoch 97 Batch 45 Loss 0.28557008504867554
[Train] epoch 97 Batch 46 Loss 0.1727447509765625
[Train] epoch 97 Batch 47 Loss 0.25170785188674927
[Train] epoch 98 Batch 0 Loss 0.24515560269355774
[Train] epoch 98 Batch 1 Loss 0.27713799476623535
[Train] epoch 98 Batch 2 Loss 0.17372164130210876
[Train] epoch 98 Batch 3 Loss 0.1423473358154297
[Train] epoch 98 Batch 4 Loss 0.3207475543022156
[Train] epoch 98 Batch 5 Loss 0.07537779211997986
[Train] epoch 98 Batch 6 Loss 0.20411992073059082
[Train] epoch 98 Batch 7 Loss 0.2812340557575226
[Train] epoch 98 Batch 8 Loss 0.24919286370277405
[Train] epoch 98 Batch 9 Loss 0.04812554270029068
[Train] epoch 98 Batch 10 Loss 0.008355746045708656
[Train] epoch 98 Batch 11 Loss 0.08045370876789093
[Train] epoch 98 Batch 12 Loss 0.1772320568561554
[Train] epoch 98 Batch 13 Loss 0.24070359766483307
[Train] epoch 98 Batch 14 Loss 0.14939850568771362
[Train] epoch 98 Batch 15 Loss 0.2089468389749527
[Train] epoch 98 Batch 16 Loss 0.2541811466217041
[Train] epoch 98 Batch 17 Loss 0.07619424164295197
[Train] epoch 98 Batch 18 Loss 0.10271373391151428
[Train] epoch 98 Batch 19 Loss 0.11210019886493683
[Train] epoch 98 Batch 20 Loss 0.18532177805900574
[Train] epoch 98 Batch 21 Loss 0.142767995595932
[Train] epoch 98 Batch 22 Loss 0.3387562036514282
[Train] epoch 98 Batch 23 Loss 0.203794926404953
[Train] epoch 98 Batch 24 Loss 0.17855055630207062
[Train] epoch 98 Batch 25 Loss 0.2435847967863083
[Train] epoch 98 Batch 26 Loss 0.07605060935020447
[Train] epoch 98 Batch 27 Loss 0.24553851783275604
[Train] epoch 98 Batch 28 Loss 0.14676281809806824
[Train] epoch 98 Batch 29 Loss 0.14171263575553894
[Train] epoch 98 Batch 30 Loss 0.20954298973083496
[Train] epoch 98 Batch 31 Loss 0.11115029454231262
[Train] epoch 98 Batch 32 Loss 0.17343765497207642
[Train] epoch 98 Batch 33 Loss 0.31147634983062744
[Train] epoch 98 Batch 34 Loss 0.28145015239715576
[Train] epoch 98 Batch 35 Loss 0.2499500960111618
[Train] epoch 98 Batch 36 Loss 0.24059456586837769
[Train] epoch 98 Batch 37 Loss 0.17830997705459595
[Train] epoch 98 Batch 38 Loss 0.27631276845932007
[Train] epoch 98 Batch 39 Loss 0.2096157968044281
[Train] epoch 98 Batch 40 Loss 0.107393778860569
[Train] epoch 98 Batch 41 Loss 0.18340042233467102
[Train] epoch 98 Batch 42 Loss 0.11222818493843079
[Train] epoch 98 Batch 43 Loss 0.16910386085510254
[Train] epoch 98 Batch 44 Loss 0.10750614106655121
[Train] epoch 98 Batch 45 Loss 0.1788361370563507
[Train] epoch 98 Batch 46 Loss 0.1786460429430008
[Train] epoch 98 Batch 47 Loss 0.22358345985412598
[Train] epoch 99 Batch 0 Loss 0.2192518711090088
[Train] epoch 99 Batch 1 Loss 0.2048962563276291
[Train] epoch 99 Batch 2 Loss 0.10693518817424774
[Train] epoch 99 Batch 3 Loss 0.2048567682504654
[Train] epoch 99 Batch 4 Loss 0.10719136148691177
[Train] epoch 99 Batch 5 Loss 0.276309609413147
[Train] epoch 99 Batch 6 Loss 0.14302633702754974
[Train] epoch 99 Batch 7 Loss 0.1070735901594162
[Train] epoch 99 Batch 8 Loss 0.11158251762390137
[Train] epoch 99 Batch 9 Loss 0.2136954665184021
[Train] epoch 99 Batch 10 Loss 0.14701932668685913
[Train] epoch 99 Batch 11 Loss 0.4046569764614105
[Train] epoch 99 Batch 12 Loss 0.37783294916152954
[Train] epoch 99 Batch 13 Loss 0.17753714323043823
[Train] epoch 99 Batch 14 Loss 0.27590280771255493
[Train] epoch 99 Batch 15 Loss 0.11552385985851288
[Train] epoch 99 Batch 16 Loss 0.133334219455719
[Train] epoch 99 Batch 17 Loss 0.146803081035614
[Train] epoch 99 Batch 18 Loss 0.21779507398605347
[Train] epoch 99 Batch 19 Loss 0.11076240241527557
[Train] epoch 99 Batch 20 Loss 0.11483439058065414
[Train] epoch 99 Batch 21 Loss 0.37761402130126953
[Train] epoch 99 Batch 22 Loss 0.03992302715778351
[Train] epoch 99 Batch 23 Loss 0.27942734956741333
[Train] epoch 99 Batch 24 Loss 0.07900214195251465
[Train] epoch 99 Batch 25 Loss 0.07079391181468964
[Train] epoch 99 Batch 26 Loss 0.1729535311460495
[Train] epoch 99 Batch 27 Loss 0.11508454382419586
[Train] epoch 99 Batch 28 Loss 0.1417202651500702
[Train] epoch 99 Batch 29 Loss 0.24745622277259827
[Train] epoch 99 Batch 30 Loss 0.23914948105812073
[Train] epoch 99 Batch 31 Loss 0.23996660113334656
[Train] epoch 99 Batch 32 Loss 0.21788416802883148
[Train] epoch 99 Batch 33 Loss 0.28419333696365356
[Train] epoch 99 Batch 34 Loss 0.1412317454814911
[Train] epoch 99 Batch 35 Loss 0.24378421902656555
[Train] epoch 99 Batch 36 Loss 0.2823639512062073
[Train] epoch 99 Batch 37 Loss 0.11098409444093704
[Train] epoch 99 Batch 38 Loss 0.20818187296390533
[Train] epoch 99 Batch 39 Loss 0.11047644913196564
[Train] epoch 99 Batch 40 Loss 0.14560556411743164
[Train] epoch 99 Batch 41 Loss 0.1451851725578308
[Train] epoch 99 Batch 42 Loss 0.1414385735988617
[Train] epoch 99 Batch 43 Loss 0.1143595278263092
[Train] epoch 99 Batch 44 Loss 0.31097638607025146
[Train] epoch 99 Batch 45 Loss 0.047666266560554504
[Train] epoch 99 Batch 46 Loss 0.20496010780334473
[Train] epoch 99 Batch 47 Loss 0.1725422590970993
[Train] epoch 100 Batch 0 Loss 0.14275532960891724
[Train] epoch 100 Batch 1 Loss 0.28355303406715393
[Train] epoch 100 Batch 2 Loss 0.14135536551475525
[Train] epoch 100 Batch 3 Loss 0.2169678658246994
[Train] epoch 100 Batch 4 Loss 0.11005189269781113
[Train] epoch 100 Batch 5 Loss 0.13751265406608582
[Train] epoch 100 Batch 6 Loss 0.18407338857650757
[Train] epoch 100 Batch 7 Loss 0.30560606718063354
[Train] epoch 100 Batch 8 Loss 0.27943655848503113
[Train] epoch 100 Batch 9 Loss 0.24381452798843384
[Train] epoch 100 Batch 10 Loss 0.1724649965763092
[Train] epoch 100 Batch 11 Loss 0.2751415967941284
[Train] epoch 100 Batch 12 Loss 0.14640067517757416
[Train] epoch 100 Batch 13 Loss 0.24356040358543396
[Train] epoch 100 Batch 14 Loss 0.1732928454875946
[Train] epoch 100 Batch 15 Loss 1.0728851975727594e-06
[Train] epoch 100 Batch 16 Loss 0.03975507616996765
[Train] epoch 100 Batch 17 Loss 0.08863865584135056
[Train] epoch 100 Batch 18 Loss 0.11078384518623352
[Train] epoch 100 Batch 19 Loss 0.17307960987091064
[Train] epoch 100 Batch 20 Loss 0.1869024783372879
[Train] epoch 100 Batch 21 Loss 0.3823668360710144
[Train] epoch 100 Batch 22 Loss 0.20883780717849731
[Train] epoch 100 Batch 23 Loss 0.17362433671951294
[Train] epoch 100 Batch 24 Loss 0.1830722987651825
[Train] epoch 100 Batch 25 Loss 0.07128588855266571
[Train] epoch 100 Batch 26 Loss 0.3424966037273407
[Train] epoch 100 Batch 27 Loss 0.18728730082511902
[Train] epoch 100 Batch 28 Loss 0.17805643379688263
[Train] epoch 100 Batch 29 Loss 0.24469663202762604
[Train] epoch 100 Batch 30 Loss 0.03563595190644264
[Train] epoch 100 Batch 31 Loss 0.11112843453884125
[Train] epoch 100 Batch 32 Loss 0.2399827539920807
[Train] epoch 100 Batch 33 Loss 0.178310826420784
[Train] epoch 100 Batch 34 Loss 0.10619565099477768
[Train] epoch 100 Batch 35 Loss 0.17299383878707886
[Train] epoch 100 Batch 36 Loss 0.2489197850227356
[Train] epoch 100 Batch 37 Loss 0.2484305053949356
[Train] epoch 100 Batch 38 Loss 0.0790487751364708
[Train] epoch 100 Batch 39 Loss 0.14527752995491028
[Train] epoch 100 Batch 40 Loss 0.14321084320545197
[Train] epoch 100 Batch 41 Loss 0.18258245289325714
[Train] epoch 100 Batch 42 Loss 0.13743248581886292
[Train] epoch 100 Batch 43 Loss 0.07073410600423813
[Train] epoch 100 Batch 44 Loss 0.217235267162323
[Train] epoch 100 Batch 45 Loss 0.33782273530960083
[Train] epoch 100 Batch 46 Loss 0.2127854824066162
[Train] epoch 100 Batch 47 Loss 0.3075113296508789
[Train] epoch 101 Batch 0 Loss 0.1499721258878708
[Train] epoch 101 Batch 1 Loss 0.03582548350095749
[Train] epoch 101 Batch 2 Loss 0.21250015497207642
[Train] epoch 101 Batch 3 Loss 0.27093952894210815
[Train] epoch 101 Batch 4 Loss 0.3185959458351135
[Train] epoch 101 Batch 5 Loss 0.24639958143234253
[Train] epoch 101 Batch 6 Loss 0.20878463983535767
[Train] epoch 101 Batch 7 Loss 0.17624413967132568
[Train] epoch 101 Batch 8 Loss 0.11090871691703796
[Train] epoch 101 Batch 9 Loss 0.2120557427406311
[Train] epoch 101 Batch 10 Loss 0.2133880853652954
[Train] epoch 101 Batch 11 Loss 0.2443082332611084
[Train] epoch 101 Batch 12 Loss 0.06666764616966248
[Train] epoch 101 Batch 13 Loss 0.23958301544189453
[Train] epoch 101 Batch 14 Loss 0.15137247741222382
[Train] epoch 101 Batch 15 Loss 0.35611075162887573
[Train] epoch 101 Batch 16 Loss 0.18260666728019714
[Train] epoch 101 Batch 17 Loss 0.21391752362251282
[Train] epoch 101 Batch 18 Loss 0.13785013556480408
[Train] epoch 101 Batch 19 Loss 0.08068684488534927
[Train] epoch 101 Batch 20 Loss 0.1165708601474762
[Train] epoch 101 Batch 21 Loss 0.27582281827926636
[Train] epoch 101 Batch 22 Loss 0.2808898687362671
[Train] epoch 101 Batch 23 Loss 0.21439523994922638
[Train] epoch 101 Batch 24 Loss 0.1426859050989151
[Train] epoch 101 Batch 25 Loss 0.1782306283712387
[Train] epoch 101 Batch 26 Loss 0.04060223326086998
[Train] epoch 101 Batch 27 Loss 0.14733856916427612
[Train] epoch 101 Batch 28 Loss 0.2043786197900772
[Train] epoch 101 Batch 29 Loss 0.102306067943573
[Train] epoch 101 Batch 30 Loss 0.07133083790540695
[Train] epoch 101 Batch 31 Loss 0.17837674915790558
[Train] epoch 101 Batch 32 Loss 0.1469380408525467
[Train] epoch 101 Batch 33 Loss 0.17813719809055328
[Train] epoch 101 Batch 34 Loss 0.24006614089012146
[Train] epoch 101 Batch 35 Loss 0.3069242835044861
[Train] epoch 101 Batch 36 Loss 0.20440657436847687
[Train] epoch 101 Batch 37 Loss 0.18674814701080322
[Train] epoch 101 Batch 38 Loss 0.2091035544872284
[Train] epoch 101 Batch 39 Loss 0.10229645669460297
[Train] epoch 101 Batch 40 Loss 0.3866092562675476
[Train] epoch 101 Batch 41 Loss 0.14223794639110565
[Train] epoch 101 Batch 42 Loss 0.10670550167560577
[Train] epoch 101 Batch 43 Loss 0.13770252466201782
[Train] epoch 101 Batch 44 Loss 0.18200841546058655
[Train] epoch 101 Batch 45 Loss 0.11074855178594589
[Train] epoch 101 Batch 46 Loss 0.24434524774551392
[Train] epoch 101 Batch 47 Loss 0.15098078548908234
[Train] epoch 102 Batch 0 Loss 0.11037151515483856
[Train] epoch 102 Batch 1 Loss 0.10668674856424332
[Train] epoch 102 Batch 2 Loss 0.1374712586402893
[Train] epoch 102 Batch 3 Loss 0.17333003878593445
[Train] epoch 102 Batch 4 Loss 0.14646673202514648
[Train] epoch 102 Batch 5 Loss 0.1143941804766655
[Train] epoch 102 Batch 6 Loss 0.3023015558719635
[Train] epoch 102 Batch 7 Loss 0.17756131291389465
[Train] epoch 102 Batch 8 Loss 0.2046026587486267
[Train] epoch 102 Batch 9 Loss 0.035154253244400024
[Train] epoch 102 Batch 10 Loss 0.24435663223266602
[Train] epoch 102 Batch 11 Loss 0.07518855482339859
[Train] epoch 102 Batch 12 Loss 0.1496523916721344
[Train] epoch 102 Batch 13 Loss 0.20371627807617188
[Train] epoch 102 Batch 14 Loss 0.2351100742816925
[Train] epoch 102 Batch 15 Loss 0.1735510677099228
[Train] epoch 102 Batch 16 Loss 0.20733648538589478
[Train] epoch 102 Batch 17 Loss 0.04292009398341179
[Train] epoch 102 Batch 18 Loss 0.10914777219295502
[Train] epoch 102 Batch 19 Loss 0.21218982338905334
[Train] epoch 102 Batch 20 Loss 0.15673328936100006
[Train] epoch 102 Batch 21 Loss 0.27864882349967957
[Train] epoch 102 Batch 22 Loss 0.21512597799301147
[Train] epoch 102 Batch 23 Loss 0.3100678026676178
[Train] epoch 102 Batch 24 Loss 0.14093580842018127
[Train] epoch 102 Batch 25 Loss 0.038474924862384796
[Train] epoch 102 Batch 26 Loss 0.1447441279888153
[Train] epoch 102 Batch 27 Loss 0.17201337218284607
[Train] epoch 102 Batch 28 Loss 0.23900628089904785
[Train] epoch 102 Batch 29 Loss 0.3185219466686249
[Train] epoch 102 Batch 30 Loss 0.2438635379076004
[Train] epoch 102 Batch 31 Loss 0.21661901473999023
[Train] epoch 102 Batch 32 Loss 0.14147990942001343
[Train] epoch 102 Batch 33 Loss 0.1448308527469635
[Train] epoch 102 Batch 34 Loss 0.17259325087070465
[Train] epoch 102 Batch 35 Loss 0.31376659870147705
[Train] epoch 102 Batch 36 Loss 0.2084895670413971
[Train] epoch 102 Batch 37 Loss 0.24756719172000885
[Train] epoch 102 Batch 38 Loss 0.2745589017868042
[Train] epoch 102 Batch 39 Loss 0.3416418433189392
[Train] epoch 102 Batch 40 Loss 0.17331019043922424
[Train] epoch 102 Batch 41 Loss 0.20413661003112793
[Train] epoch 102 Batch 42 Loss 0.14488554000854492
[Train] epoch 102 Batch 43 Loss 0.2083585560321808
[Train] epoch 102 Batch 44 Loss 0.22203408181667328
[Train] epoch 102 Batch 45 Loss 0.11013160645961761
[Train] epoch 102 Batch 46 Loss 0.14116236567497253
[Train] epoch 102 Batch 47 Loss 0.07869313657283783
[Train] epoch 103 Batch 0 Loss 0.0737251490354538
[Train] epoch 103 Batch 1 Loss 0.27854111790657043
[Train] epoch 103 Batch 2 Loss 0.19654180109500885
[Train] epoch 103 Batch 3 Loss 0.3147951364517212
[Train] epoch 103 Batch 4 Loss 0.04426560550928116
[Train] epoch 103 Batch 5 Loss 0.1468333899974823
[Train] epoch 103 Batch 6 Loss 0.17905662953853607
[Train] epoch 103 Batch 7 Loss 0.06109624356031418
[Train] epoch 103 Batch 8 Loss 0.07653301954269409
[Train] epoch 103 Batch 9 Loss 0.41446587443351746
[Train] epoch 103 Batch 10 Loss 0.11209765076637268
[Train] epoch 103 Batch 11 Loss 0.14169719815254211
[Train] epoch 103 Batch 12 Loss 0.2441878318786621
[Train] epoch 103 Batch 13 Loss 0.18519717454910278
[Train] epoch 103 Batch 14 Loss 0.2131311148405075
[Train] epoch 103 Batch 15 Loss 0.2788676917552948
[Train] epoch 103 Batch 16 Loss 0.2718924880027771
[Train] epoch 103 Batch 17 Loss 0.31349146366119385
[Train] epoch 103 Batch 18 Loss 0.04163995012640953
[Train] epoch 103 Batch 19 Loss 0.14274176955223083
[Train] epoch 103 Batch 20 Loss 0.08162927627563477
[Train] epoch 103 Batch 21 Loss 0.35012590885162354
[Train] epoch 103 Batch 22 Loss 0.14487135410308838
[Train] epoch 103 Batch 23 Loss 0.10610296577215195
[Train] epoch 103 Batch 24 Loss 0.04363296180963516
[Train] epoch 103 Batch 25 Loss 0.2175774872303009
[Train] epoch 103 Batch 26 Loss 0.3067726492881775
[Train] epoch 103 Batch 27 Loss 0.3466397523880005
[Train] epoch 103 Batch 28 Loss 0.11147435009479523
[Train] epoch 103 Batch 29 Loss 0.2091720700263977
[Train] epoch 103 Batch 30 Loss 0.1828349530696869
[Train] epoch 103 Batch 31 Loss 0.11139930039644241
[Train] epoch 103 Batch 32 Loss 0.11227479577064514
[Train] epoch 103 Batch 33 Loss 0.13800129294395447
[Train] epoch 103 Batch 34 Loss 0.17353621125221252
[Train] epoch 103 Batch 35 Loss 0.17339491844177246
[Train] epoch 103 Batch 36 Loss 0.2807074785232544
[Train] epoch 103 Batch 37 Loss 0.24972322583198547
[Train] epoch 103 Batch 38 Loss 0.11199308186769485
[Train] epoch 103 Batch 39 Loss 0.13790878653526306
[Train] epoch 103 Batch 40 Loss 0.2189176082611084
[Train] epoch 103 Batch 41 Loss 0.13814595341682434
[Train] epoch 103 Batch 42 Loss 0.2808825373649597
[Train] epoch 103 Batch 43 Loss 0.31160640716552734
[Train] epoch 103 Batch 44 Loss 0.10700128972530365
[Train] epoch 103 Batch 45 Loss 0.17854604125022888
[Train] epoch 103 Batch 46 Loss 0.24503177404403687
[Train] epoch 103 Batch 47 Loss 0.0760020837187767
[Train] epoch 104 Batch 0 Loss 0.1379426121711731
[Train] epoch 104 Batch 1 Loss 0.17355450987815857
[Train] epoch 104 Batch 2 Loss 0.11148785799741745
[Train] epoch 104 Batch 3 Loss 0.07575903832912445
[Train] epoch 104 Batch 4 Loss 0.11154548078775406
[Train] epoch 104 Batch 5 Loss 0.14691060781478882
[Train] epoch 104 Batch 6 Loss 0.2500402331352234
[Train] epoch 104 Batch 7 Loss 0.07574647665023804
[Train] epoch 104 Batch 8 Loss 0.17785444855690002
[Train] epoch 104 Batch 9 Loss 0.07995731383562088
[Train] epoch 104 Batch 10 Loss 0.1425299346446991
[Train] epoch 104 Batch 11 Loss 0.24435369670391083
[Train] epoch 104 Batch 12 Loss 0.2758539319038391
[Train] epoch 104 Batch 13 Loss 0.3115357756614685
[Train] epoch 104 Batch 14 Loss 0.24879439175128937
[Train] epoch 104 Batch 15 Loss 0.20948493480682373
[Train] epoch 104 Batch 16 Loss 0.2398703396320343
[Train] epoch 104 Batch 17 Loss 0.2086508721113205
[Train] epoch 104 Batch 18 Loss 0.17333050072193146
[Train] epoch 104 Batch 19 Loss 0.0357062965631485
[Train] epoch 104 Batch 20 Loss 0.37342244386672974
[Train] epoch 104 Batch 21 Loss 0.24848595261573792
[Train] epoch 104 Batch 22 Loss 0.30237406492233276
[Train] epoch 104 Batch 23 Loss 0.14618739485740662
[Train] epoch 104 Batch 24 Loss 0.07548665255308151
[Train] epoch 104 Batch 25 Loss 0.31505781412124634
[Train] epoch 104 Batch 26 Loss 0.10632608830928802
[Train] epoch 104 Batch 27 Loss 0.27497345209121704
[Train] epoch 104 Batch 28 Loss 0.07935445755720139
[Train] epoch 104 Batch 29 Loss 0.1812470555305481
[Train] epoch 104 Batch 30 Loss 0.14544188976287842
[Train] epoch 104 Batch 31 Loss 0.28392213582992554
[Train] epoch 104 Batch 32 Loss 0.07478465139865875
[Train] epoch 104 Batch 33 Loss 0.2042900025844574
[Train] epoch 104 Batch 34 Loss 0.2442687749862671
[Train] epoch 104 Batch 35 Loss 0.0790509432554245
[Train] epoch 104 Batch 36 Loss 0.00903632864356041
[Train] epoch 104 Batch 37 Loss 0.18532049655914307
[Train] epoch 104 Batch 38 Loss 0.17293785512447357
[Train] epoch 104 Batch 39 Loss 0.18465512990951538
[Train] epoch 104 Batch 40 Loss 0.34171706438064575
[Train] epoch 104 Batch 41 Loss 0.1104874461889267
[Train] epoch 104 Batch 42 Loss 0.38125449419021606
[Train] epoch 104 Batch 43 Loss 0.20887276530265808
[Train] epoch 104 Batch 44 Loss 0.11491280049085617
[Train] epoch 104 Batch 45 Loss 0.15409831702709198
[Train] epoch 104 Batch 46 Loss 0.13770847022533417
[Train] epoch 104 Batch 47 Loss 0.2353835105895996
[Train] epoch 105 Batch 0 Loss 0.25297680497169495
[Train] epoch 105 Batch 1 Loss 0.13784755766391754
[Train] epoch 105 Batch 2 Loss 0.24007314443588257
[Train] epoch 105 Batch 3 Loss 0.17320315539836884
[Train] epoch 105 Batch 4 Loss 0.24405476450920105
[Train] epoch 105 Batch 5 Loss 0.14633974432945251
[Train] epoch 105 Batch 6 Loss 0.13744580745697021
[Train] epoch 105 Batch 7 Loss 0.17732258141040802
[Train] epoch 105 Batch 8 Loss 0.008298812434077263
[Train] epoch 105 Batch 9 Loss 0.24372273683547974
[Train] epoch 105 Batch 10 Loss 0.23967230319976807
[Train] epoch 105 Batch 11 Loss 0.24003122746944427
[Train] epoch 105 Batch 12 Loss 0.07062779366970062
[Train] epoch 105 Batch 13 Loss 0.14998406171798706
[Train] epoch 105 Batch 14 Loss 0.03961189091205597
[Train] epoch 105 Batch 15 Loss 0.2706802785396576
[Train] epoch 105 Batch 16 Loss 0.20810332894325256
[Train] epoch 105 Batch 17 Loss 0.1412629783153534
[Train] epoch 105 Batch 18 Loss 0.13755562901496887
[Train] epoch 105 Batch 19 Loss 0.2156638205051422
[Train] epoch 105 Batch 20 Loss 0.18123692274093628
[Train] epoch 105 Batch 21 Loss 0.24832233786582947
[Train] epoch 105 Batch 22 Loss 0.18102654814720154
[Train] epoch 105 Batch 23 Loss 0.07435141503810883
[Train] epoch 105 Batch 24 Loss 0.10563796758651733
[Train] epoch 105 Batch 25 Loss 0.37263941764831543
[Train] epoch 105 Batch 26 Loss 0.10223258286714554
[Train] epoch 105 Batch 27 Loss 0.2740921080112457
[Train] epoch 105 Batch 28 Loss 0.27479636669158936
[Train] epoch 105 Batch 29 Loss 0.27799272537231445
[Train] epoch 105 Batch 30 Loss 0.2154596745967865
[Train] epoch 105 Batch 31 Loss 0.11705343425273895
[Train] epoch 105 Batch 32 Loss 0.2396107316017151
[Train] epoch 105 Batch 33 Loss 0.1768987476825714
[Train] epoch 105 Batch 34 Loss 0.14096635580062866
[Train] epoch 105 Batch 35 Loss 0.03924199938774109
[Train] epoch 105 Batch 36 Loss 0.23970797657966614
[Train] epoch 105 Batch 37 Loss 0.0747881680727005
[Train] epoch 105 Batch 38 Loss 0.14153920114040375
[Train] epoch 105 Batch 39 Loss 0.17695766687393188
[Train] epoch 105 Batch 40 Loss 0.31049108505249023
[Train] epoch 105 Batch 41 Loss 0.14578506350517273
[Train] epoch 105 Batch 42 Loss 0.2796242833137512
[Train] epoch 105 Batch 43 Loss 0.21662235260009766
[Train] epoch 105 Batch 44 Loss 0.1455860435962677
[Train] epoch 105 Batch 45 Loss 0.2085946798324585
[Train] epoch 105 Batch 46 Loss 0.07891890406608582
[Train] epoch 105 Batch 47 Loss 0.260175883769989
[Train] epoch 106 Batch 0 Loss 0.08284123241901398
[Train] epoch 106 Batch 1 Loss 0.2121228575706482
[Train] epoch 106 Batch 2 Loss 0.3498300015926361
[Train] epoch 106 Batch 3 Loss 0.1412907838821411
[Train] epoch 106 Batch 4 Loss 0.17272305488586426
[Train] epoch 106 Batch 5 Loss 0.18083426356315613
[Train] epoch 106 Batch 6 Loss 0.18078279495239258
[Train] epoch 106 Batch 7 Loss 0.14548100531101227
[Train] epoch 106 Batch 8 Loss 0.3411265015602112
[Train] epoch 106 Batch 9 Loss 0.23927217721939087
[Train] epoch 106 Batch 10 Loss 0.18029619753360748
[Train] epoch 106 Batch 11 Loss 0.08210869133472443
[Train] epoch 106 Batch 12 Loss 0.23942846059799194
[Train] epoch 106 Batch 13 Loss 0.4436965584754944
[Train] epoch 106 Batch 14 Loss 0.011037250980734825
[Train] epoch 106 Batch 15 Loss 0.17663291096687317
[Train] epoch 106 Batch 16 Loss 0.0709371492266655
[Train] epoch 106 Batch 17 Loss 0.11291971057653427
[Train] epoch 106 Batch 18 Loss 0.2701570987701416
[Train] epoch 106 Batch 19 Loss 0.1481492966413498
[Train] epoch 106 Batch 20 Loss 0.3134157657623291
[Train] epoch 106 Batch 21 Loss 0.21166396141052246
[Train] epoch 106 Batch 22 Loss 0.21071979403495789
[Train] epoch 106 Batch 23 Loss 0.11659251153469086
[Train] epoch 106 Batch 24 Loss 0.15615442395210266
[Train] epoch 106 Batch 25 Loss 0.2081027328968048
[Train] epoch 106 Batch 26 Loss 0.10606388747692108
[Train] epoch 106 Batch 27 Loss 0.2745862603187561
[Train] epoch 106 Batch 28 Loss 0.20378422737121582
[Train] epoch 106 Batch 29 Loss 0.10207229852676392
[Train] epoch 106 Batch 30 Loss 0.11766159534454346
[Train] epoch 106 Batch 31 Loss 0.17669689655303955
[Train] epoch 106 Batch 32 Loss 0.17284122109413147
[Train] epoch 106 Batch 33 Loss 0.07062606513500214
[Train] epoch 106 Batch 34 Loss 0.310016393661499
[Train] epoch 106 Batch 35 Loss 0.23932133615016937
[Train] epoch 106 Batch 36 Loss 0.2825036346912384
[Train] epoch 106 Batch 37 Loss 0.1415378749370575
[Train] epoch 106 Batch 38 Loss 0.17269891500473022
[Train] epoch 106 Batch 39 Loss 0.133334219455719
[Train] epoch 106 Batch 40 Loss 0.2077995240688324
[Train] epoch 106 Batch 41 Loss 0.26666736602783203
[Train] epoch 106 Batch 42 Loss 0.24699005484580994
[Train] epoch 106 Batch 43 Loss 0.07446971535682678
[Train] epoch 106 Batch 44 Loss 0.03920738399028778
[Train] epoch 106 Batch 45 Loss 0.10605063289403915
[Train] epoch 106 Batch 46 Loss 0.27456802129745483
[Train] epoch 106 Batch 47 Loss 0.03543240576982498
[Train] epoch 107 Batch 0 Loss 0.172687366604805
[Train] epoch 107 Batch 1 Loss 0.17669689655303955
[Train] epoch 107 Batch 2 Loss 0.24343498051166534
[Train] epoch 107 Batch 3 Loss 0.10541335493326187
[Train] epoch 107 Batch 4 Loss 0.10936218500137329
[Train] epoch 107 Batch 5 Loss 0.37619882822036743
[Train] epoch 107 Batch 6 Loss 0.14057084918022156
[Train] epoch 107 Batch 7 Loss 0.30631184577941895
[Train] epoch 107 Batch 8 Loss 0.13719631731510162
[Train] epoch 107 Batch 9 Loss 0.2783823609352112
[Train] epoch 107 Batch 10 Loss 0.0389615073800087
[Train] epoch 107 Batch 11 Loss 0.08118513971567154
[Train] epoch 107 Batch 12 Loss 0.11620958894491196
[Train] epoch 107 Batch 13 Loss 0.11247508227825165
[Train] epoch 107 Batch 14 Loss 0.235440194606781
[Train] epoch 107 Batch 15 Loss 0.2431039810180664
[Train] epoch 107 Batch 16 Loss 0.14095564186573029
[Train] epoch 107 Batch 17 Loss 0.3128473162651062
[Train] epoch 107 Batch 18 Loss 0.2106376588344574
[Train] epoch 107 Batch 19 Loss 0.2430768609046936
[Train] epoch 107 Batch 20 Loss 0.21513576805591583
[Train] epoch 107 Batch 21 Loss 0.10915609449148178
[Train] epoch 107 Batch 22 Loss 0.2118552327156067
[Train] epoch 107 Batch 23 Loss 0.17644479870796204
[Train] epoch 107 Batch 24 Loss 0.11007107049226761
[Train] epoch 107 Batch 25 Loss 0.1387374848127365
[Train] epoch 107 Batch 26 Loss 0.1413697600364685
[Train] epoch 107 Batch 27 Loss 0.15925420820713043
[Train] epoch 107 Batch 28 Loss 0.15025685727596283
[Train] epoch 107 Batch 29 Loss 0.18561691045761108
[Train] epoch 107 Batch 30 Loss 0.17320707440376282
[Train] epoch 107 Batch 31 Loss 0.1415727138519287
[Train] epoch 107 Batch 32 Loss 0.44770514965057373
[Train] epoch 107 Batch 33 Loss 0.06666764616966248
[Train] epoch 107 Batch 34 Loss 0.21250459551811218
[Train] epoch 107 Batch 35 Loss 0.0709666907787323
[Train] epoch 107 Batch 36 Loss 0.2117016613483429
[Train] epoch 107 Batch 37 Loss 0.1379844695329666
[Train] epoch 107 Batch 38 Loss 0.23961438238620758
[Train] epoch 107 Batch 39 Loss 0.31534069776535034
[Train] epoch 107 Batch 40 Loss 0.22164452075958252
[Train] epoch 107 Batch 41 Loss 0.17320044338703156
[Train] epoch 107 Batch 42 Loss 0.0799672082066536
[Train] epoch 107 Batch 43 Loss 1.0728851975727594e-06
[Train] epoch 107 Batch 44 Loss 0.17779040336608887
[Train] epoch 107 Batch 45 Loss 0.24413320422172546
[Train] epoch 107 Batch 46 Loss 0.23963680863380432
[Train] epoch 107 Batch 47 Loss 0.2445855736732483
[Train] epoch 108 Batch 0 Loss 0.13748961687088013
[Train] epoch 108 Batch 1 Loss 0.08002917468547821
[Train] epoch 108 Batch 2 Loss 0.41244763135910034
[Train] epoch 108 Batch 3 Loss 0.3109191656112671
[Train] epoch 108 Batch 4 Loss 0.2854871153831482
[Train] epoch 108 Batch 5 Loss 0.08024932444095612
[Train] epoch 108 Batch 6 Loss 0.2796785831451416
[Train] epoch 108 Batch 7 Loss 0.2171754240989685
[Train] epoch 108 Batch 8 Loss 0.1422877460718155
[Train] epoch 108 Batch 9 Loss 0.2435600757598877
[Train] epoch 108 Batch 10 Loss 0.0445505753159523
[Train] epoch 108 Batch 11 Loss 0.0798937976360321
[Train] epoch 108 Batch 12 Loss 0.3103257417678833
[Train] epoch 108 Batch 13 Loss 0.11497323215007782
[Train] epoch 108 Batch 14 Loss 0.1461067944765091
[Train] epoch 108 Batch 15 Loss 0.18521347641944885
[Train] epoch 108 Batch 16 Loss 0.24759702384471893
[Train] epoch 108 Batch 17 Loss 0.21242408454418182
[Train] epoch 108 Batch 18 Loss 0.24742500483989716
[Train] epoch 108 Batch 19 Loss 0.10202653706073761
[Train] epoch 108 Batch 20 Loss 0.13739922642707825
[Train] epoch 108 Batch 21 Loss 0.21601788699626923
[Train] epoch 108 Batch 22 Loss 0.23536035418510437
[Train] epoch 108 Batch 23 Loss 0.2433636337518692
[Train] epoch 108 Batch 24 Loss 0.03923850134015083
[Train] epoch 108 Batch 25 Loss 0.2390034794807434
[Train] epoch 108 Batch 26 Loss 0.30581197142601013
[Train] epoch 108 Batch 27 Loss 0.14843326807022095
[Train] epoch 108 Batch 28 Loss 0.13713541626930237
[Train] epoch 108 Batch 29 Loss 0.27871930599212646
[Train] epoch 108 Batch 30 Loss 0.10965696722269058
[Train] epoch 108 Batch 31 Loss 0.14084011316299438
[Train] epoch 108 Batch 32 Loss 0.06666764616966248
[Train] epoch 108 Batch 33 Loss 0.28641363978385925
[Train] epoch 108 Batch 34 Loss 0.2393629550933838
[Train] epoch 108 Batch 35 Loss 0.039461731910705566
[Train] epoch 108 Batch 36 Loss 0.14119425415992737
[Train] epoch 108 Batch 37 Loss 0.30981701612472534
[Train] epoch 108 Batch 38 Loss 0.2392432540655136
[Train] epoch 108 Batch 39 Loss 0.1372404545545578
[Train] epoch 108 Batch 40 Loss 0.14973758161067963
[Train] epoch 108 Batch 41 Loss 0.07466192543506622
[Train] epoch 108 Batch 42 Loss 0.2746986746788025
[Train] epoch 108 Batch 43 Loss 0.18123546242713928
[Train] epoch 108 Batch 44 Loss 0.07488720118999481
[Train] epoch 108 Batch 45 Loss 0.13761457800865173
[Train] epoch 108 Batch 46 Loss 0.24327750504016876
[Train] epoch 108 Batch 47 Loss 0.07064367085695267
[Train] epoch 109 Batch 0 Loss 0.34545132517814636
[Train] epoch 109 Batch 1 Loss 0.14148855209350586
[Train] epoch 109 Batch 2 Loss 0.2204757034778595
[Train] epoch 109 Batch 3 Loss 0.07470116019248962
[Train] epoch 109 Batch 4 Loss 0.1728132963180542
[Train] epoch 109 Batch 5 Loss 0.30603715777397156
[Train] epoch 109 Batch 6 Loss 0.3095090687274933
[Train] epoch 109 Batch 7 Loss 0.20804695785045624
[Train] epoch 109 Batch 8 Loss 0.20377925038337708
[Train] epoch 109 Batch 9 Loss 0.24333567917346954
[Train] epoch 109 Batch 10 Loss 0.17250967025756836
[Train] epoch 109 Batch 11 Loss 0.14463818073272705
[Train] epoch 109 Batch 12 Loss 0.24660716950893402
[Train] epoch 109 Batch 13 Loss 0.14122232794761658
[Train] epoch 109 Batch 14 Loss 0.038882866501808167
[Train] epoch 109 Batch 15 Loss 0.010869951918721199
[Train] epoch 109 Batch 16 Loss 0.17239122092723846
[Train] epoch 109 Batch 17 Loss 0.14096605777740479
[Train] epoch 109 Batch 18 Loss 0.1446959674358368
[Train] epoch 109 Batch 19 Loss 0.21111199259757996
[Train] epoch 109 Batch 20 Loss 0.10187962651252747
[Train] epoch 109 Batch 21 Loss 0.14088666439056396
[Train] epoch 109 Batch 22 Loss 0.20777732133865356
[Train] epoch 109 Batch 23 Loss 0.1441260129213333
[Train] epoch 109 Batch 24 Loss 0.17701351642608643
[Train] epoch 109 Batch 25 Loss 0.3102805018424988
[Train] epoch 109 Batch 26 Loss 0.218343585729599
[Train] epoch 109 Batch 27 Loss 0.2564350664615631
[Train] epoch 109 Batch 28 Loss 0.14442552626132965
[Train] epoch 109 Batch 29 Loss 0.17690059542655945
[Train] epoch 109 Batch 30 Loss 0.14497722685337067
[Train] epoch 109 Batch 31 Loss 0.20531216263771057
[Train] epoch 109 Batch 32 Loss 0.2592003047466278
[Train] epoch 109 Batch 33 Loss 0.17986232042312622
[Train] epoch 109 Batch 34 Loss 0.21744073927402496
[Train] epoch 109 Batch 35 Loss 0.24009695649147034
[Train] epoch 109 Batch 36 Loss 0.28087323904037476
[Train] epoch 109 Batch 37 Loss 0.15645982325077057
[Train] epoch 109 Batch 38 Loss 0.28732600808143616
[Train] epoch 109 Batch 39 Loss 0.2820807695388794
[Train] epoch 109 Batch 40 Loss 0.24558024108409882
[Train] epoch 109 Batch 41 Loss 0.2505780756473541
[Train] epoch 109 Batch 42 Loss 0.040405258536338806
[Train] epoch 109 Batch 43 Loss 0.17382177710533142
[Train] epoch 109 Batch 44 Loss 0.14280249178409576
[Train] epoch 109 Batch 45 Loss 0.11092762649059296
[Train] epoch 109 Batch 46 Loss 0.17852774262428284
[Train] epoch 109 Batch 47 Loss 0.1449010670185089
[Train] epoch 110 Batch 0 Loss 0.211224764585495
[Train] epoch 110 Batch 1 Loss 0.17362266778945923
[Train] epoch 110 Batch 2 Loss 0.2804839015007019
[Train] epoch 110 Batch 3 Loss 0.44377535581588745
[Train] epoch 110 Batch 4 Loss 0.051280975341796875
[Train] epoch 110 Batch 5 Loss 0.18014734983444214
[Train] epoch 110 Batch 6 Loss 0.21787917613983154
[Train] epoch 110 Batch 7 Loss 0.2811371684074402
[Train] epoch 110 Batch 8 Loss 0.10280488431453705
[Train] epoch 110 Batch 9 Loss 0.10977541655302048
[Train] epoch 110 Batch 10 Loss 0.11316047608852386
[Train] epoch 110 Batch 11 Loss 0.0706392377614975
[Train] epoch 110 Batch 12 Loss 0.17725688219070435
[Train] epoch 110 Batch 13 Loss 0.1695844829082489
[Train] epoch 110 Batch 14 Loss 0.2860448658466339
[Train] epoch 110 Batch 15 Loss 0.1925468146800995
[Train] epoch 110 Batch 16 Loss 0.07072652876377106
[Train] epoch 110 Batch 17 Loss 0.2090858817100525
[Train] epoch 110 Batch 18 Loss 0.18250255286693573
[Train] epoch 110 Batch 19 Loss 0.17856520414352417
[Train] epoch 110 Batch 20 Loss 0.039182208478450775
[Train] epoch 110 Batch 21 Loss 0.11020097881555557
[Train] epoch 110 Batch 22 Loss 0.28808560967445374
[Train] epoch 110 Batch 23 Loss 0.20591771602630615
[Train] epoch 110 Batch 24 Loss 0.133334219455719
[Train] epoch 110 Batch 25 Loss 0.18677322566509247
[Train] epoch 110 Batch 26 Loss 0.11081372201442719
[Train] epoch 110 Batch 27 Loss 0.3205946683883667
[Train] epoch 110 Batch 28 Loss 0.24716182053089142
[Train] epoch 110 Batch 29 Loss 0.039372123777866364
[Train] epoch 110 Batch 30 Loss 0.2572671175003052
[Train] epoch 110 Batch 31 Loss 0.11188636720180511
[Train] epoch 110 Batch 32 Loss 0.28418847918510437
[Train] epoch 110 Batch 33 Loss 0.11021541059017181
[Train] epoch 110 Batch 34 Loss 0.1477924883365631
[Train] epoch 110 Batch 35 Loss 0.10763704776763916
[Train] epoch 110 Batch 36 Loss 0.20766687393188477
[Train] epoch 110 Batch 37 Loss 0.07186324894428253
[Train] epoch 110 Batch 38 Loss 0.21132171154022217
[Train] epoch 110 Batch 39 Loss 0.3792222738265991
[Train] epoch 110 Batch 40 Loss 0.13818922638893127
[Train] epoch 110 Batch 41 Loss 0.169325053691864
[Train] epoch 110 Batch 42 Loss 0.12268882244825363
[Train] epoch 110 Batch 43 Loss 0.2865871787071228
[Train] epoch 110 Batch 44 Loss 0.2126287817955017
[Train] epoch 110 Batch 45 Loss 0.18521210551261902
[Train] epoch 110 Batch 46 Loss 0.3026701807975769
[Train] epoch 110 Batch 47 Loss 0.1804456263780594
[Train] epoch 111 Batch 0 Loss 0.2471260130405426
[Train] epoch 111 Batch 1 Loss 0.24732092022895813
[Train] epoch 111 Batch 2 Loss 0.10805001854896545
[Train] epoch 111 Batch 3 Loss 0.07804800570011139
[Train] epoch 111 Batch 4 Loss 0.10273215174674988
[Train] epoch 111 Batch 5 Loss 0.07757657766342163
[Train] epoch 111 Batch 6 Loss 0.15556807816028595
[Train] epoch 111 Batch 7 Loss 0.1446663737297058
[Train] epoch 111 Batch 8 Loss 0.19194482266902924
[Train] epoch 111 Batch 9 Loss 0.15519723296165466
[Train] epoch 111 Batch 10 Loss 0.18578237295150757
[Train] epoch 111 Batch 11 Loss 0.20531117916107178
[Train] epoch 111 Batch 12 Loss 0.18511049449443817
[Train] epoch 111 Batch 13 Loss 0.27756577730178833
[Train] epoch 111 Batch 14 Loss 0.13901683688163757
[Train] epoch 111 Batch 15 Loss 0.2270849645137787
[Train] epoch 111 Batch 16 Loss 0.2465578019618988
[Train] epoch 111 Batch 17 Loss 0.23649924993515015
[Train] epoch 111 Batch 18 Loss 0.13853713870048523
[Train] epoch 111 Batch 19 Loss 0.1440444439649582
[Train] epoch 111 Batch 20 Loss 0.21564960479736328
[Train] epoch 111 Batch 21 Loss 0.34909749031066895
[Train] epoch 111 Batch 22 Loss 0.24666324257850647
[Train] epoch 111 Batch 23 Loss 0.13834348320960999
[Train] epoch 111 Batch 24 Loss 0.17914825677871704
[Train] epoch 111 Batch 25 Loss 0.08675242960453033
[Train] epoch 111 Batch 26 Loss 0.2819502353668213
[Train] epoch 111 Batch 27 Loss 0.10726960748434067
[Train] epoch 111 Batch 28 Loss 0.24531468749046326
[Train] epoch 111 Batch 29 Loss 0.14808550477027893
[Train] epoch 111 Batch 30 Loss 0.2504732012748718
[Train] epoch 111 Batch 31 Loss 0.08131356537342072
[Train] epoch 111 Batch 32 Loss 0.30738765001296997
[Train] epoch 111 Batch 33 Loss 0.14870548248291016
[Train] epoch 111 Batch 34 Loss 0.20987042784690857
[Train] epoch 111 Batch 35 Loss 0.2757085859775543
[Train] epoch 111 Batch 36 Loss 0.14750541746616364
[Train] epoch 111 Batch 37 Loss 0.10693359375
[Train] epoch 111 Batch 38 Loss 0.20969824492931366
[Train] epoch 111 Batch 39 Loss 0.17743542790412903
[Train] epoch 111 Batch 40 Loss 0.110700324177742
[Train] epoch 111 Batch 41 Loss 0.3068992495536804
[Train] epoch 111 Batch 42 Loss 0.14707866311073303
[Train] epoch 111 Batch 43 Loss 0.14237308502197266
[Train] epoch 111 Batch 44 Loss 0.07498640567064285
[Train] epoch 111 Batch 45 Loss 0.20869998633861542
[Train] epoch 111 Batch 46 Loss 0.2495744824409485
[Train] epoch 111 Batch 47 Loss 0.24010953307151794
[Train] epoch 112 Batch 0 Loss 0.14548759162425995
[Train] epoch 112 Batch 1 Loss 0.13867725431919098
[Train] epoch 112 Batch 2 Loss 0.1104874536395073
[Train] epoch 112 Batch 3 Loss 0.24995329976081848
[Train] epoch 112 Batch 4 Loss 0.18485121428966522
[Train] epoch 112 Batch 5 Loss 0.17324453592300415
[Train] epoch 112 Batch 6 Loss 0.35631340742111206
[Train] epoch 112 Batch 7 Loss 0.17769938707351685
[Train] epoch 112 Batch 8 Loss 0.07873624563217163
[Train] epoch 112 Batch 9 Loss 0.10565929114818573
[Train] epoch 112 Batch 10 Loss 0.10639628767967224
[Train] epoch 112 Batch 11 Loss 0.07844897359609604
[Train] epoch 112 Batch 12 Loss 0.31443390250205994
[Train] epoch 112 Batch 13 Loss 0.4079284071922302
[Train] epoch 112 Batch 14 Loss 0.3070873022079468
[Train] epoch 112 Batch 15 Loss 0.03600020706653595
[Train] epoch 112 Batch 16 Loss 0.20789361000061035
[Train] epoch 112 Batch 17 Loss 0.10266302525997162
[Train] epoch 112 Batch 18 Loss 0.21769697964191437
[Train] epoch 112 Batch 19 Loss 0.06666764616966248
[Train] epoch 112 Batch 20 Loss 0.1499635875225067
[Train] epoch 112 Batch 21 Loss 0.10588925331830978
[Train] epoch 112 Batch 22 Loss 0.11582039296627045
[Train] epoch 112 Batch 23 Loss 0.19291159510612488
[Train] epoch 112 Batch 24 Loss 0.34813636541366577
[Train] epoch 112 Batch 25 Loss 0.2538083791732788
[Train] epoch 112 Batch 26 Loss 0.21479903161525726
[Train] epoch 112 Batch 27 Loss 0.08835151791572571
[Train] epoch 112 Batch 28 Loss 0.10842365026473999
[Train] epoch 112 Batch 29 Loss 0.17452466487884521
[Train] epoch 112 Batch 30 Loss 0.1081501841545105
[Train] epoch 112 Batch 31 Loss 0.2455478012561798
[Train] epoch 112 Batch 32 Loss 0.18483397364616394
[Train] epoch 112 Batch 33 Loss 0.20504194498062134
[Train] epoch 112 Batch 34 Loss 0.11221826076507568
[Train] epoch 112 Batch 35 Loss 0.21435661613941193
[Train] epoch 112 Batch 36 Loss 0.27137160301208496
[Train] epoch 112 Batch 37 Loss 0.13796626031398773
[Train] epoch 112 Batch 38 Loss 0.21374495327472687
[Train] epoch 112 Batch 39 Loss 0.21852827072143555
[Train] epoch 112 Batch 40 Loss 0.06666764616966248
[Train] epoch 112 Batch 41 Loss 0.040182389318943024
[Train] epoch 112 Batch 42 Loss 0.2846720218658447
[Train] epoch 112 Batch 43 Loss 0.18282699584960938
[Train] epoch 112 Batch 44 Loss 0.07522992789745331
[Train] epoch 112 Batch 45 Loss 0.24855254590511322
[Train] epoch 112 Batch 46 Loss 0.4044688045978546
[Train] epoch 112 Batch 47 Loss 0.31226009130477905
[Train] epoch 113 Batch 0 Loss 0.2828490436077118
[Train] epoch 113 Batch 1 Loss 0.2481258511543274
[Train] epoch 113 Batch 2 Loss 0.209385484457016
[Train] epoch 113 Batch 3 Loss 0.3552711606025696
[Train] epoch 113 Batch 4 Loss 0.17291446030139923
[Train] epoch 113 Batch 5 Loss 0.1215013712644577
[Train] epoch 113 Batch 6 Loss 1.0728851975727594e-06
[Train] epoch 113 Batch 7 Loss 0.10563194006681442
[Train] epoch 113 Batch 8 Loss 0.3809936046600342
[Train] epoch 113 Batch 9 Loss 0.1098053902387619
[Train] epoch 113 Batch 10 Loss 0.20432059466838837
[Train] epoch 113 Batch 11 Loss 0.3054966926574707
[Train] epoch 113 Batch 12 Loss 0.1018495038151741
[Train] epoch 113 Batch 13 Loss 0.24444328248500824
[Train] epoch 113 Batch 14 Loss 0.31026390194892883
[Train] epoch 113 Batch 15 Loss 0.03937562182545662
[Train] epoch 113 Batch 16 Loss 0.1796492487192154
[Train] epoch 113 Batch 17 Loss 0.2828921675682068
[Train] epoch 113 Batch 18 Loss 0.07852446287870407
[Train] epoch 113 Batch 19 Loss 0.18370364606380463
[Train] epoch 113 Batch 20 Loss 0.20339931547641754
[Train] epoch 113 Batch 21 Loss 0.16914695501327515
[Train] epoch 113 Batch 22 Loss 0.23915505409240723
[Train] epoch 113 Batch 23 Loss 0.14658424258232117
[Train] epoch 113 Batch 24 Loss 0.20906957983970642
[Train] epoch 113 Batch 25 Loss 0.2782009243965149
[Train] epoch 113 Batch 26 Loss 0.0800590068101883
[Train] epoch 113 Batch 27 Loss 0.14648182690143585
[Train] epoch 113 Batch 28 Loss 0.18185323476791382
[Train] epoch 113 Batch 29 Loss 0.2798391878604889
[Train] epoch 113 Batch 30 Loss 1.0728851975727594e-06
[Train] epoch 113 Batch 31 Loss 0.14129576086997986
[Train] epoch 113 Batch 32 Loss 0.14570869505405426
[Train] epoch 113 Batch 33 Loss 0.133334219455719
[Train] epoch 113 Batch 34 Loss 0.039506349712610245
[Train] epoch 113 Batch 35 Loss 0.11491558700799942
[Train] epoch 113 Batch 36 Loss 0.2355957180261612
[Train] epoch 113 Batch 37 Loss 0.3065383732318878
[Train] epoch 113 Batch 38 Loss 0.1465395987033844
[Train] epoch 113 Batch 39 Loss 0.21304228901863098
[Train] epoch 113 Batch 40 Loss 0.1820840835571289
[Train] epoch 113 Batch 41 Loss 0.27994322776794434
[Train] epoch 113 Batch 42 Loss 0.17775511741638184
[Train] epoch 113 Batch 43 Loss 0.13780292868614197
[Train] epoch 113 Batch 44 Loss 0.21344342827796936
[Train] epoch 113 Batch 45 Loss 0.1778395175933838
[Train] epoch 113 Batch 46 Loss 0.1775953769683838
[Train] epoch 113 Batch 47 Loss 0.10676153004169464
[Train] epoch 114 Batch 0 Loss 0.28459250926971436
[Train] epoch 114 Batch 1 Loss 0.18230602145195007
[Train] epoch 114 Batch 2 Loss 0.13769474625587463
[Train] epoch 114 Batch 3 Loss 0.1467854380607605
[Train] epoch 114 Batch 4 Loss 0.31118035316467285
[Train] epoch 114 Batch 5 Loss 0.2487511783838272
[Train] epoch 114 Batch 6 Loss 0.21307620406150818
[Train] epoch 114 Batch 7 Loss 0.17754171788692474
[Train] epoch 114 Batch 8 Loss 0.2087324559688568
[Train] epoch 114 Batch 9 Loss 0.14201699197292328
[Train] epoch 114 Batch 10 Loss 0.039819180965423584
[Train] epoch 114 Batch 11 Loss 0.315168559551239
[Train] epoch 114 Batch 12 Loss 0.10634005069732666
[Train] epoch 114 Batch 13 Loss 0.17316308617591858
[Train] epoch 114 Batch 14 Loss 0.14184102416038513
[Train] epoch 114 Batch 15 Loss 0.14155326783657074
[Train] epoch 114 Batch 16 Loss 0.14181289076805115
[Train] epoch 114 Batch 17 Loss 0.1728721708059311
[Train] epoch 114 Batch 18 Loss 0.10649402439594269
[Train] epoch 114 Batch 19 Loss 0.10216411203145981
[Train] epoch 114 Batch 20 Loss 0.23955297470092773
[Train] epoch 114 Batch 21 Loss 0.07462617009878159
[Train] epoch 114 Batch 22 Loss 0.0749237984418869
[Train] epoch 114 Batch 23 Loss 0.24766728281974792
[Train] epoch 114 Batch 24 Loss 0.08292539417743683
[Train] epoch 114 Batch 25 Loss 0.3851245045661926
[Train] epoch 114 Batch 26 Loss 0.2081933617591858
[Train] epoch 114 Batch 27 Loss 0.21607902646064758
[Train] epoch 114 Batch 28 Loss 0.30997347831726074
[Train] epoch 114 Batch 29 Loss 0.07074669003486633
[Train] epoch 114 Batch 30 Loss 0.18057632446289062
[Train] epoch 114 Batch 31 Loss 0.1093481183052063
[Train] epoch 114 Batch 32 Loss 0.2432170957326889
[Train] epoch 114 Batch 33 Loss 0.20366090536117554
[Train] epoch 114 Batch 34 Loss 0.14446014165878296
[Train] epoch 114 Batch 35 Loss 0.10584063827991486
[Train] epoch 114 Batch 36 Loss 0.14917747676372528
[Train] epoch 114 Batch 37 Loss 0.07466966658830643
[Train] epoch 114 Batch 38 Loss 0.1839565634727478
[Train] epoch 114 Batch 39 Loss 0.2702540159225464
[Train] epoch 114 Batch 40 Loss 0.07377948611974716
[Train] epoch 114 Batch 41 Loss 0.23509979248046875
[Train] epoch 114 Batch 42 Loss 0.2743716537952423
[Train] epoch 114 Batch 43 Loss 0.21135850250720978
[Train] epoch 114 Batch 44 Loss 0.2432469129562378
[Train] epoch 114 Batch 45 Loss 0.17939746379852295
[Train] epoch 114 Batch 46 Loss 0.20381540060043335
[Train] epoch 114 Batch 47 Loss 0.2810665965080261
[Train] epoch 115 Batch 0 Loss 0.17608413100242615
[Train] epoch 115 Batch 1 Loss 0.07099612802267075
[Train] epoch 115 Batch 2 Loss 0.1716485321521759
[Train] epoch 115 Batch 3 Loss 0.14038723707199097
[Train] epoch 115 Batch 4 Loss 0.2032584846019745
[Train] epoch 115 Batch 5 Loss 0.07326668500900269
[Train] epoch 115 Batch 6 Loss 0.2103453129529953
[Train] epoch 115 Batch 7 Loss 0.2420479655265808
[Train] epoch 115 Batch 8 Loss 0.3053131401538849
[Train] epoch 115 Batch 9 Loss 0.041961126029491425
[Train] epoch 115 Batch 10 Loss 0.1794952154159546
[Train] epoch 115 Batch 11 Loss 0.1365404576063156
[Train] epoch 115 Batch 12 Loss 0.041938040405511856
[Train] epoch 115 Batch 13 Loss 0.1445828676223755
[Train] epoch 115 Batch 14 Loss 0.17882290482521057
[Train] epoch 115 Batch 15 Loss 0.14200882613658905
[Train] epoch 115 Batch 16 Loss 0.17623749375343323
[Train] epoch 115 Batch 17 Loss 0.10909106582403183
[Train] epoch 115 Batch 18 Loss 0.03810443356633186
[Train] epoch 115 Batch 19 Loss 0.2416885793209076
[Train] epoch 115 Batch 20 Loss 0.2709168791770935
[Train] epoch 115 Batch 21 Loss 0.17924681305885315
[Train] epoch 115 Batch 22 Loss 0.21415385603904724
[Train] epoch 115 Batch 23 Loss 0.37295669317245483
[Train] epoch 115 Batch 24 Loss 0.0699545294046402
[Train] epoch 115 Batch 25 Loss 0.1084119901061058
[Train] epoch 115 Batch 26 Loss 0.17547360062599182
[Train] epoch 115 Batch 27 Loss 0.3405425548553467
[Train] epoch 115 Batch 28 Loss 0.3405908942222595
[Train] epoch 115 Batch 29 Loss 0.21058812737464905
[Train] epoch 115 Batch 30 Loss 0.3054879903793335
[Train] epoch 115 Batch 31 Loss 0.1123739629983902
[Train] epoch 115 Batch 32 Loss 0.21150116622447968
[Train] epoch 115 Batch 33 Loss 0.1097998172044754
[Train] epoch 115 Batch 34 Loss 0.10888523608446121
[Train] epoch 115 Batch 35 Loss 0.23975518345832825
[Train] epoch 115 Batch 36 Loss 0.21106576919555664
[Train] epoch 115 Batch 37 Loss 0.18686580657958984
[Train] epoch 115 Batch 38 Loss 0.37979555130004883
[Train] epoch 115 Batch 39 Loss 0.2747480273246765
[Train] epoch 115 Batch 40 Loss 0.14041098952293396
[Train] epoch 115 Batch 41 Loss 0.17972531914710999
[Train] epoch 115 Batch 42 Loss 0.14415086805820465
[Train] epoch 115 Batch 43 Loss 0.10859616100788116
[Train] epoch 115 Batch 44 Loss 0.17262375354766846
[Train] epoch 115 Batch 45 Loss 0.17462243139743805
[Train] epoch 115 Batch 46 Loss 0.211870938539505
[Train] epoch 115 Batch 47 Loss 0.14089131355285645
[Train] epoch 116 Batch 0 Loss 0.20862403512001038
[Train] epoch 116 Batch 1 Loss 0.18322008848190308
[Train] epoch 116 Batch 2 Loss 0.34341245889663696
[Train] epoch 116 Batch 3 Loss 0.0704011544585228
[Train] epoch 116 Batch 4 Loss 0.17633742094039917
[Train] epoch 116 Batch 5 Loss 0.07974813878536224
[Train] epoch 116 Batch 6 Loss 0.13958872854709625
[Train] epoch 116 Batch 7 Loss 0.24162280559539795
[Train] epoch 116 Batch 8 Loss 0.34125611186027527
[Train] epoch 116 Batch 9 Loss 0.2758951485157013
[Train] epoch 116 Batch 10 Loss 0.3452288806438446
[Train] epoch 116 Batch 11 Loss 0.1431938111782074
[Train] epoch 116 Batch 12 Loss 0.17562133073806763
[Train] epoch 116 Batch 13 Loss 0.10534357279539108
[Train] epoch 116 Batch 14 Loss 0.10158364474773407
[Train] epoch 116 Batch 15 Loss 0.27777916193008423
[Train] epoch 116 Batch 16 Loss 0.17539691925048828
[Train] epoch 116 Batch 17 Loss 0.035397354513406754
[Train] epoch 116 Batch 18 Loss 0.21160659193992615
[Train] epoch 116 Batch 19 Loss 0.17625990509986877
[Train] epoch 116 Batch 20 Loss 0.06666764616966248
[Train] epoch 116 Batch 21 Loss 0.23908573389053345
[Train] epoch 116 Batch 22 Loss 0.14446380734443665
[Train] epoch 116 Batch 23 Loss 0.24294936656951904
[Train] epoch 116 Batch 24 Loss 0.24913719296455383
[Train] epoch 116 Batch 25 Loss 0.07411199063062668
[Train] epoch 116 Batch 26 Loss 0.17587757110595703
[Train] epoch 116 Batch 27 Loss 0.11297529935836792
[Train] epoch 116 Batch 28 Loss 0.37540024518966675
[Train] epoch 116 Batch 29 Loss 0.2079748809337616
[Train] epoch 116 Batch 30 Loss 0.07002249360084534
[Train] epoch 116 Batch 31 Loss 0.20374777913093567
[Train] epoch 116 Batch 32 Loss 0.048608288168907166
[Train] epoch 116 Batch 33 Loss 0.2485382854938507
[Train] epoch 116 Batch 34 Loss 0.17594626545906067
[Train] epoch 116 Batch 35 Loss 0.2877192497253418
[Train] epoch 116 Batch 36 Loss 0.13714447617530823
[Train] epoch 116 Batch 37 Loss 0.27350878715515137
[Train] epoch 116 Batch 38 Loss 0.14558789134025574
[Train] epoch 116 Batch 39 Loss 0.14354684948921204
[Train] epoch 116 Batch 40 Loss 0.2381117343902588
[Train] epoch 116 Batch 41 Loss 0.1765398532152176
[Train] epoch 116 Batch 42 Loss 0.2077433168888092
[Train] epoch 116 Batch 43 Loss 0.1400938183069229
[Train] epoch 116 Batch 44 Loss 0.07397192716598511
[Train] epoch 116 Batch 45 Loss 0.1371867060661316
[Train] epoch 116 Batch 46 Loss 0.1727706491947174
[Train] epoch 116 Batch 47 Loss 0.1411331593990326
[Train] epoch 117 Batch 0 Loss 0.10560838133096695
[Train] epoch 117 Batch 1 Loss 0.2862928509712219
[Train] epoch 117 Batch 2 Loss 0.17586737871170044
[Train] epoch 117 Batch 3 Loss 0.20387107133865356
[Train] epoch 117 Batch 4 Loss 0.10878895223140717
[Train] epoch 117 Batch 5 Loss 0.1021556630730629
[Train] epoch 117 Batch 6 Loss 0.07761900126934052
[Train] epoch 117 Batch 7 Loss 0.1723618358373642
[Train] epoch 117 Batch 8 Loss 0.1419319212436676
[Train] epoch 117 Batch 9 Loss 0.07096028327941895
[Train] epoch 117 Batch 10 Loss 0.24249309301376343
[Train] epoch 117 Batch 11 Loss 0.18006500601768494
[Train] epoch 117 Batch 12 Loss 0.1485273241996765
[Train] epoch 117 Batch 13 Loss 0.1091831624507904
[Train] epoch 117 Batch 14 Loss 0.14070847630500793
[Train] epoch 117 Batch 15 Loss 0.1021357849240303
[Train] epoch 117 Batch 16 Loss 0.17923961579799652
[Train] epoch 117 Batch 17 Loss 0.14444077014923096
[Train] epoch 117 Batch 18 Loss 0.2781619429588318
[Train] epoch 117 Batch 19 Loss 0.2474280595779419
[Train] epoch 117 Batch 20 Loss 0.20425716042518616
[Train] epoch 117 Batch 21 Loss 0.14013360440731049
[Train] epoch 117 Batch 22 Loss 0.10598595440387726
[Train] epoch 117 Batch 23 Loss 0.3403870463371277
[Train] epoch 117 Batch 24 Loss 0.239214688539505
[Train] epoch 117 Batch 25 Loss 0.3409178555011749
[Train] epoch 117 Batch 26 Loss 0.21129749715328217
[Train] epoch 117 Batch 27 Loss 0.17165523767471313
[Train] epoch 117 Batch 28 Loss 0.178752601146698
[Train] epoch 117 Batch 29 Loss 0.20706085860729218
[Train] epoch 117 Batch 30 Loss 0.21410417556762695
[Train] epoch 117 Batch 31 Loss 0.21674907207489014
[Train] epoch 117 Batch 32 Loss 0.3478928208351135
[Train] epoch 117 Batch 33 Loss 0.10542096197605133
[Train] epoch 117 Batch 34 Loss 0.2000008225440979
[Train] epoch 117 Batch 35 Loss 0.03813978657126427
[Train] epoch 117 Batch 36 Loss 0.2761337161064148
[Train] epoch 117 Batch 37 Loss 0.1443536877632141
[Train] epoch 117 Batch 38 Loss 0.31741222739219666
[Train] epoch 117 Batch 39 Loss 0.2734726667404175
[Train] epoch 117 Batch 40 Loss 0.2067916989326477
[Train] epoch 117 Batch 41 Loss 0.2072989046573639
[Train] epoch 117 Batch 42 Loss 0.14255963265895844
[Train] epoch 117 Batch 43 Loss 0.13755355775356293
[Train] epoch 117 Batch 44 Loss 0.1729954481124878
[Train] epoch 117 Batch 45 Loss 0.13648200035095215
[Train] epoch 117 Batch 46 Loss 0.14307385683059692
[Train] epoch 117 Batch 47 Loss 0.08241546154022217
[Train] epoch 118 Batch 0 Loss 0.07396088540554047
[Train] epoch 118 Batch 1 Loss 0.14031864702701569
[Train] epoch 118 Batch 2 Loss 0.10572640597820282
[Train] epoch 118 Batch 3 Loss 0.14369183778762817
[Train] epoch 118 Batch 4 Loss 0.2739880084991455
[Train] epoch 118 Batch 5 Loss 0.2072872817516327
[Train] epoch 118 Batch 6 Loss 0.1370195895433426
[Train] epoch 118 Batch 7 Loss 0.2353665828704834
[Train] epoch 118 Batch 8 Loss 0.17680445313453674
[Train] epoch 118 Batch 9 Loss 0.20748579502105713
[Train] epoch 118 Batch 10 Loss 0.2422957718372345
[Train] epoch 118 Batch 11 Loss 0.34499549865722656
[Train] epoch 118 Batch 12 Loss 0.20372724533081055
[Train] epoch 118 Batch 13 Loss 0.10168558359146118
[Train] epoch 118 Batch 14 Loss 0.31318286061286926
[Train] epoch 118 Batch 15 Loss 0.14034609496593475
[Train] epoch 118 Batch 16 Loss 0.11297833919525146
[Train] epoch 118 Batch 17 Loss 0.2739427387714386
[Train] epoch 118 Batch 18 Loss 0.2847062349319458
[Train] epoch 118 Batch 19 Loss 0.14744089543819427
[Train] epoch 118 Batch 20 Loss 0.17940454185009003
[Train] epoch 118 Batch 21 Loss 0.168624147772789
[Train] epoch 118 Batch 22 Loss 0.14055687189102173
[Train] epoch 118 Batch 23 Loss 0.14070798456668854
[Train] epoch 118 Batch 24 Loss 0.17252202332019806
[Train] epoch 118 Batch 25 Loss 0.21062465012073517
[Train] epoch 118 Batch 26 Loss 0.1089094877243042
[Train] epoch 118 Batch 27 Loss 0.21430253982543945
[Train] epoch 118 Batch 28 Loss 0.2137840837240219
[Train] epoch 118 Batch 29 Loss 0.20360144972801208
[Train] epoch 118 Batch 30 Loss 0.2421056032180786
[Train] epoch 118 Batch 31 Loss 0.07025055587291718
[Train] epoch 118 Batch 32 Loss 0.20389947295188904
[Train] epoch 118 Batch 33 Loss 0.23884889483451843
[Train] epoch 118 Batch 34 Loss 0.10885055363178253
[Train] epoch 118 Batch 35 Loss 0.31151315569877625
[Train] epoch 118 Batch 36 Loss 0.10819896310567856
[Train] epoch 118 Batch 37 Loss 0.27689921855926514
[Train] epoch 118 Batch 38 Loss 0.20688164234161377
[Train] epoch 118 Batch 39 Loss 0.1086672693490982
[Train] epoch 118 Batch 40 Loss 0.24589255452156067
[Train] epoch 118 Batch 41 Loss 0.13984450697898865
[Train] epoch 118 Batch 42 Loss 0.012767973355948925
[Train] epoch 118 Batch 43 Loss 0.13681919872760773
[Train] epoch 118 Batch 44 Loss 0.1846805214881897
[Train] epoch 118 Batch 45 Loss 0.11093395948410034
[Train] epoch 118 Batch 46 Loss 0.17912839353084564
[Train] epoch 118 Batch 47 Loss 0.20390769839286804
[Train] epoch 119 Batch 0 Loss 0.20344245433807373
[Train] epoch 119 Batch 1 Loss 0.23528826236724854
[Train] epoch 119 Batch 2 Loss 0.21000197529792786
[Train] epoch 119 Batch 3 Loss 0.06666764616966248
[Train] epoch 119 Batch 4 Loss 0.10494909435510635
[Train] epoch 119 Batch 5 Loss 0.31426161527633667
[Train] epoch 119 Batch 6 Loss 0.03823183476924896
[Train] epoch 119 Batch 7 Loss 0.2417200356721878
[Train] epoch 119 Batch 8 Loss 0.24170228838920593
[Train] epoch 119 Batch 9 Loss 0.21233496069908142
[Train] epoch 119 Batch 10 Loss 0.14550235867500305
[Train] epoch 119 Batch 11 Loss 0.07590946555137634
[Train] epoch 119 Batch 12 Loss 0.21236462891101837
[Train] epoch 119 Batch 13 Loss 0.20676152408123016
[Train] epoch 119 Batch 14 Loss 0.10889197140932083
[Train] epoch 119 Batch 15 Loss 0.30878859758377075
[Train] epoch 119 Batch 16 Loss 0.10845130681991577
[Train] epoch 119 Batch 17 Loss 0.38170111179351807
[Train] epoch 119 Batch 18 Loss 0.1397126019001007
[Train] epoch 119 Batch 19 Loss 0.10593125969171524
[Train] epoch 119 Batch 20 Loss 0.07681728899478912
[Train] epoch 119 Batch 21 Loss 0.17527718842029572
[Train] epoch 119 Batch 22 Loss 0.24849647283554077
[Train] epoch 119 Batch 23 Loss 0.17877985537052155
[Train] epoch 119 Batch 24 Loss 0.07050550729036331
[Train] epoch 119 Batch 25 Loss 0.17916078865528107
[Train] epoch 119 Batch 26 Loss 0.37504613399505615
[Train] epoch 119 Batch 27 Loss 0.2385241985321045
[Train] epoch 119 Batch 28 Loss 0.0031752416398376226
[Train] epoch 119 Batch 29 Loss 0.2000008225440979
[Train] epoch 119 Batch 30 Loss 0.07983696460723877
[Train] epoch 119 Batch 31 Loss 0.21351651847362518
[Train] epoch 119 Batch 32 Loss 0.1717500239610672
[Train] epoch 119 Batch 33 Loss 0.1404077112674713
[Train] epoch 119 Batch 34 Loss 0.20353195071220398
[Train] epoch 119 Batch 35 Loss 0.17171356081962585
[Train] epoch 119 Batch 36 Loss 0.2800581455230713
[Train] epoch 119 Batch 37 Loss 0.07285384833812714
[Train] epoch 119 Batch 38 Loss 0.21043583750724792
[Train] epoch 119 Batch 39 Loss 0.17597240209579468
[Train] epoch 119 Batch 40 Loss 0.17568741738796234
[Train] epoch 119 Batch 41 Loss 0.31116732954978943
[Train] epoch 119 Batch 42 Loss 0.2031066119670868
[Train] epoch 119 Batch 43 Loss 0.1372324824333191
[Train] epoch 119 Batch 44 Loss 0.21302758157253265
[Train] epoch 119 Batch 45 Loss 0.21039962768554688
[Train] epoch 119 Batch 46 Loss 0.1712154597043991
[Train] epoch 119 Batch 47 Loss 0.13934773206710815
[Train] epoch 120 Batch 0 Loss 0.10741680860519409
[Train] epoch 120 Batch 1 Loss 0.17114722728729248
[Train] epoch 120 Batch 2 Loss 0.08495000004768372
[Train] epoch 120 Batch 3 Loss 0.4127551019191742
[Train] epoch 120 Batch 4 Loss 0.04063371941447258
[Train] epoch 120 Batch 5 Loss 0.31171298027038574
[Train] epoch 120 Batch 6 Loss 0.10435688495635986
[Train] epoch 120 Batch 7 Loss 0.24156199395656586
[Train] epoch 120 Batch 8 Loss 0.13691630959510803
[Train] epoch 120 Batch 9 Loss 0.07349514961242676
[Train] epoch 120 Batch 10 Loss 0.14021271467208862
[Train] epoch 120 Batch 11 Loss 0.20662514865398407
[Train] epoch 120 Batch 12 Loss 0.10940524190664291
[Train] epoch 120 Batch 13 Loss 0.2771233022212982
[Train] epoch 120 Batch 14 Loss 0.1477494239807129
[Train] epoch 120 Batch 15 Loss 0.1438196301460266
[Train] epoch 120 Batch 16 Loss 0.23520058393478394
[Train] epoch 120 Batch 17 Loss 0.1788215935230255
[Train] epoch 120 Batch 18 Loss 0.20762105286121368
[Train] epoch 120 Batch 19 Loss 0.20320698618888855
[Train] epoch 120 Batch 20 Loss 0.10896250605583191
[Train] epoch 120 Batch 21 Loss 0.07393364608287811
[Train] epoch 120 Batch 22 Loss 0.2807537615299225
[Train] epoch 120 Batch 23 Loss 0.13721784949302673
[Train] epoch 120 Batch 24 Loss 0.03527503460645676
[Train] epoch 120 Batch 25 Loss 0.14020755887031555
[Train] epoch 120 Batch 26 Loss 0.2386758029460907
[Train] epoch 120 Batch 27 Loss 0.21754927933216095
[Train] epoch 120 Batch 28 Loss 0.1471429020166397
[Train] epoch 120 Batch 29 Loss 0.17916204035282135
[Train] epoch 120 Batch 30 Loss 0.210356667637825
[Train] epoch 120 Batch 31 Loss 0.14020192623138428
[Train] epoch 120 Batch 32 Loss 0.2774260640144348
[Train] epoch 120 Batch 33 Loss 0.24549709260463715
[Train] epoch 120 Batch 34 Loss 0.13694395124912262
[Train] epoch 120 Batch 35 Loss 0.24210354685783386
[Train] epoch 120 Batch 36 Loss 0.2104724645614624
[Train] epoch 120 Batch 37 Loss 0.23526149988174438
[Train] epoch 120 Batch 38 Loss 0.14353537559509277
[Train] epoch 120 Batch 39 Loss 0.30512118339538574
[Train] epoch 120 Batch 40 Loss 0.20385655760765076
[Train] epoch 120 Batch 41 Loss 0.07703245431184769
[Train] epoch 120 Batch 42 Loss 0.2739884853363037
[Train] epoch 120 Batch 43 Loss 0.17531290650367737
[Train] epoch 120 Batch 44 Loss 0.20623978972434998
[Train] epoch 120 Batch 45 Loss 0.1403592824935913
[Train] epoch 120 Batch 46 Loss 0.21014246344566345
[Train] epoch 120 Batch 47 Loss 0.17139405012130737
[Train] epoch 121 Batch 0 Loss 0.2705070972442627
[Train] epoch 121 Batch 1 Loss 0.041407302021980286
[Train] epoch 121 Batch 2 Loss 0.27709466218948364
[Train] epoch 121 Batch 3 Loss 0.21185772120952606
[Train] epoch 121 Batch 4 Loss 0.10816728323698044
[Train] epoch 121 Batch 5 Loss 0.21019157767295837
[Train] epoch 121 Batch 6 Loss 0.1405743509531021
[Train] epoch 121 Batch 7 Loss 0.0700068324804306
[Train] epoch 121 Batch 8 Loss 0.07708628475666046
[Train] epoch 121 Batch 9 Loss 0.1754581183195114
[Train] epoch 121 Batch 10 Loss 0.13701684772968292
[Train] epoch 121 Batch 11 Loss 0.14057715237140656
[Train] epoch 121 Batch 12 Loss 0.15137730538845062
[Train] epoch 121 Batch 13 Loss 0.1369912028312683
[Train] epoch 121 Batch 14 Loss 0.23879393935203552
[Train] epoch 121 Batch 15 Loss 0.07761595398187637
[Train] epoch 121 Batch 16 Loss 0.10550889372825623
[Train] epoch 121 Batch 17 Loss 0.1018102616071701
[Train] epoch 121 Batch 18 Loss 0.21477262675762177
[Train] epoch 121 Batch 19 Loss 0.17579472064971924
[Train] epoch 121 Batch 20 Loss 0.14060115814208984
[Train] epoch 121 Batch 21 Loss 0.27758467197418213
[Train] epoch 121 Batch 22 Loss 0.17947348952293396
[Train] epoch 121 Batch 23 Loss 0.2461376190185547
[Train] epoch 121 Batch 24 Loss 0.30902183055877686
[Train] epoch 121 Batch 25 Loss 0.10546541213989258
[Train] epoch 121 Batch 26 Loss 0.07029886543750763
[Train] epoch 121 Batch 27 Loss 0.035128142684698105
[Train] epoch 121 Batch 28 Loss 0.24226415157318115
[Train] epoch 121 Batch 29 Loss 0.2071363776922226
[Train] epoch 121 Batch 30 Loss 0.14409160614013672
[Train] epoch 121 Batch 31 Loss 0.10894323885440826
[Train] epoch 121 Batch 32 Loss 0.31611278653144836
[Train] epoch 121 Batch 33 Loss 0.04221424087882042
[Train] epoch 121 Batch 34 Loss 0.21759511530399323
[Train] epoch 121 Batch 35 Loss 0.3122990131378174
[Train] epoch 121 Batch 36 Loss 0.21412481367588043
[Train] epoch 121 Batch 37 Loss 0.24549749493598938
[Train] epoch 121 Batch 38 Loss 0.2385166585445404
[Train] epoch 121 Batch 39 Loss 0.3051607012748718
[Train] epoch 121 Batch 40 Loss 0.13692829012870789
[Train] epoch 121 Batch 41 Loss 0.14683914184570312
[Train] epoch 121 Batch 42 Loss 0.23514053225517273
[Train] epoch 121 Batch 43 Loss 0.24165895581245422
[Train] epoch 121 Batch 44 Loss 0.21346229314804077
[Train] epoch 121 Batch 45 Loss 0.17185527086257935
[Train] epoch 121 Batch 46 Loss 0.30540895462036133
[Train] epoch 121 Batch 47 Loss 0.23855316638946533
[Train] epoch 122 Batch 0 Loss 0.04157335311174393
[Train] epoch 122 Batch 1 Loss 0.14632047712802887
[Train] epoch 122 Batch 2 Loss 0.35047370195388794
[Train] epoch 122 Batch 3 Loss 0.17541538178920746
[Train] epoch 122 Batch 4 Loss 0.10813800245523453
[Train] epoch 122 Batch 5 Loss 0.23847374320030212
[Train] epoch 122 Batch 6 Loss 0.14581800997257233
[Train] epoch 122 Batch 7 Loss 0.20691663026809692
[Train] epoch 122 Batch 8 Loss 0.24146988987922668
[Train] epoch 122 Batch 9 Loss 0.20304736495018005
[Train] epoch 122 Batch 10 Loss 0.07631305605173111
[Train] epoch 122 Batch 11 Loss 0.3395794630050659
[Train] epoch 122 Batch 12 Loss 0.0726199820637703
[Train] epoch 122 Batch 13 Loss 0.20625066757202148
[Train] epoch 122 Batch 14 Loss 0.273147851228714
[Train] epoch 122 Batch 15 Loss 0.2098015993833542
[Train] epoch 122 Batch 16 Loss 0.13914401829242706
[Train] epoch 122 Batch 17 Loss 0.17731574177742004
[Train] epoch 122 Batch 18 Loss 0.07535520195960999
[Train] epoch 122 Batch 19 Loss 0.11407672613859177
[Train] epoch 122 Batch 20 Loss 0.1394743025302887
[Train] epoch 122 Batch 21 Loss 0.20589517056941986
[Train] epoch 122 Batch 22 Loss 0.13965192437171936
[Train] epoch 122 Batch 23 Loss 0.4084547758102417
[Train] epoch 122 Batch 24 Loss 0.10161204636096954
[Train] epoch 122 Batch 25 Loss 0.2733008563518524
[Train] epoch 122 Batch 26 Loss 0.07705071568489075
[Train] epoch 122 Batch 27 Loss 0.13686317205429077
[Train] epoch 122 Batch 28 Loss 0.1755359172821045
[Train] epoch 122 Batch 29 Loss 0.0738639384508133
[Train] epoch 122 Batch 30 Loss 0.31252020597457886
[Train] epoch 122 Batch 31 Loss 0.21091236174106598
[Train] epoch 122 Batch 32 Loss 0.07766725867986679
[Train] epoch 122 Batch 33 Loss 0.20726366341114044
[Train] epoch 122 Batch 34 Loss 0.20734256505966187
[Train] epoch 122 Batch 35 Loss 0.3479958772659302
[Train] epoch 122 Batch 36 Loss 0.07043728232383728
[Train] epoch 122 Batch 37 Loss 0.27035510540008545
[Train] epoch 122 Batch 38 Loss 0.2351347655057907
[Train] epoch 122 Batch 39 Loss 0.10912919044494629
[Train] epoch 122 Batch 40 Loss 0.10548889636993408
[Train] epoch 122 Batch 41 Loss 0.10929125547409058
[Train] epoch 122 Batch 42 Loss 0.3054100275039673
[Train] epoch 122 Batch 43 Loss 0.2812498211860657
[Train] epoch 122 Batch 44 Loss 0.105535127222538
[Train] epoch 122 Batch 45 Loss 0.2388577163219452
[Train] epoch 122 Batch 46 Loss 0.18031197786331177
[Train] epoch 122 Batch 47 Loss 0.05269233137369156
[Train] epoch 123 Batch 0 Loss 0.07874661684036255
[Train] epoch 123 Batch 1 Loss 0.17186391353607178
[Train] epoch 123 Batch 2 Loss 0.20768481492996216
[Train] epoch 123 Batch 3 Loss 0.15227533876895905
[Train] epoch 123 Batch 4 Loss 0.1806543469429016
[Train] epoch 123 Batch 5 Loss 0.10533913969993591
[Train] epoch 123 Batch 6 Loss 0.2738710045814514
[Train] epoch 123 Batch 7 Loss 0.211408331990242
[Train] epoch 123 Batch 8 Loss 0.0702323168516159
[Train] epoch 123 Batch 9 Loss 0.17604434490203857
[Train] epoch 123 Batch 10 Loss 0.2815769910812378
[Train] epoch 123 Batch 11 Loss 0.30940157175064087
[Train] epoch 123 Batch 12 Loss 0.23878860473632812
[Train] epoch 123 Batch 13 Loss 0.2035227119922638
[Train] epoch 123 Batch 14 Loss 0.1753057986497879
[Train] epoch 123 Batch 15 Loss 0.3442399501800537
[Train] epoch 123 Batch 16 Loss 0.14072448015213013
[Train] epoch 123 Batch 17 Loss 0.23871539533138275
[Train] epoch 123 Batch 18 Loss 0.13700921833515167
[Train] epoch 123 Batch 19 Loss 0.2390110045671463
[Train] epoch 123 Batch 20 Loss 0.3129948377609253
[Train] epoch 123 Batch 21 Loss 0.24991686642169952
[Train] epoch 123 Batch 22 Loss 0.2739582061767578
[Train] epoch 123 Batch 23 Loss 0.25016021728515625
[Train] epoch 123 Batch 24 Loss 0.17554642260074615
[Train] epoch 123 Batch 25 Loss 0.2105562537908554
[Train] epoch 123 Batch 26 Loss 0.10910053551197052
[Train] epoch 123 Batch 27 Loss 0.10171179473400116
[Train] epoch 123 Batch 28 Loss 0.1435089260339737
[Train] epoch 123 Batch 29 Loss 0.23847071826457977
[Train] epoch 123 Batch 30 Loss 0.042230430990457535
[Train] epoch 123 Batch 31 Loss 0.1400708109140396
[Train] epoch 123 Batch 32 Loss 0.14023593068122864
[Train] epoch 123 Batch 33 Loss 0.10500098764896393
[Train] epoch 123 Batch 34 Loss 0.2065596580505371
[Train] epoch 123 Batch 35 Loss 0.21674126386642456
[Train] epoch 123 Batch 36 Loss 0.14001543819904327
[Train] epoch 123 Batch 37 Loss 0.1718100607395172
[Train] epoch 123 Batch 38 Loss 0.20668011903762817
[Train] epoch 123 Batch 39 Loss 0.24164240062236786
[Train] epoch 123 Batch 40 Loss 0.038166437298059464
[Train] epoch 123 Batch 41 Loss 0.17170819640159607
[Train] epoch 123 Batch 42 Loss 0.14320848882198334
[Train] epoch 123 Batch 43 Loss 0.0412805899977684
[Train] epoch 123 Batch 44 Loss 0.07622125744819641
[Train] epoch 123 Batch 45 Loss 0.24496015906333923
[Train] epoch 123 Batch 46 Loss 0.08262373507022858
[Train] epoch 123 Batch 47 Loss 0.3050054907798767
[Train] epoch 124 Batch 0 Loss 0.10506895184516907
[Train] epoch 124 Batch 1 Loss 0.2483186572790146
[Train] epoch 124 Batch 2 Loss 0.08029746264219284
[Train] epoch 124 Batch 3 Loss 0.10504160821437836
[Train] epoch 124 Batch 4 Loss 0.2383623719215393
[Train] epoch 124 Batch 5 Loss 0.17535942792892456
[Train] epoch 124 Batch 6 Loss 0.27357879281044006
[Train] epoch 124 Batch 7 Loss 0.1339167207479477
[Train] epoch 124 Batch 8 Loss 0.27347856760025024
[Train] epoch 124 Batch 9 Loss 0.2771434187889099
[Train] epoch 124 Batch 10 Loss 0.13997116684913635
[Train] epoch 124 Batch 11 Loss 0.14363810420036316
[Train] epoch 124 Batch 12 Loss 0.242086261510849
[Train] epoch 124 Batch 13 Loss 0.11358904838562012
[Train] epoch 124 Batch 14 Loss 0.24214254319667816
[Train] epoch 124 Batch 15 Loss 0.2770543098449707
[Train] epoch 124 Batch 16 Loss 0.20684456825256348
[Train] epoch 124 Batch 17 Loss 0.14357994496822357
[Train] epoch 124 Batch 18 Loss 0.2067687213420868
[Train] epoch 124 Batch 19 Loss 0.14032518863677979
[Train] epoch 124 Batch 20 Loss 0.17186781764030457
[Train] epoch 124 Batch 21 Loss 0.2419007420539856
[Train] epoch 124 Batch 22 Loss 0.33829420804977417
[Train] epoch 124 Batch 23 Loss 0.1811313033103943
[Train] epoch 124 Batch 24 Loss 0.14009034633636475
[Train] epoch 124 Batch 25 Loss 0.17511679232120514
[Train] epoch 124 Batch 26 Loss 0.12691420316696167
[Train] epoch 124 Batch 27 Loss 0.17887993156909943
[Train] epoch 124 Batch 28 Loss 0.21456846594810486
[Train] epoch 124 Batch 29 Loss 0.24608087539672852
[Train] epoch 124 Batch 30 Loss 0.1765875518321991
[Train] epoch 124 Batch 31 Loss 0.36722591519355774
[Train] epoch 124 Batch 32 Loss 0.1055561900138855
[Train] epoch 124 Batch 33 Loss 0.1760512888431549
[Train] epoch 124 Batch 34 Loss 0.14043626189231873
[Train] epoch 124 Batch 35 Loss 0.12223081290721893
[Train] epoch 124 Batch 36 Loss 0.37555813789367676
[Train] epoch 124 Batch 37 Loss 0.2074916809797287
[Train] epoch 124 Batch 38 Loss 0.2106805443763733
[Train] epoch 124 Batch 39 Loss 0.07366197556257248
[Train] epoch 124 Batch 40 Loss 0.14044785499572754
[Train] epoch 124 Batch 41 Loss 0.045601263642311096
[Train] epoch 124 Batch 42 Loss 0.14384682476520538
[Train] epoch 124 Batch 43 Loss 0.10776025056838989
[Train] epoch 124 Batch 44 Loss 0.07377105951309204
[Train] epoch 124 Batch 45 Loss 0.24977600574493408
[Train] epoch 124 Batch 46 Loss 0.038811199367046356
[Train] epoch 124 Batch 47 Loss 0.2453797608613968
[Train] epoch 125 Batch 0 Loss 0.31260043382644653
[Train] epoch 125 Batch 1 Loss 0.27787619829177856
[Train] epoch 125 Batch 2 Loss 0.20746055245399475
[Train] epoch 125 Batch 3 Loss 0.1762080192565918
[Train] epoch 125 Batch 4 Loss 0.14499326050281525
[Train] epoch 125 Batch 5 Loss 0.24200120568275452
[Train] epoch 125 Batch 6 Loss 0.11315495520830154
[Train] epoch 125 Batch 7 Loss 0.2072943150997162
[Train] epoch 125 Batch 8 Loss 0.10894250869750977
[Train] epoch 125 Batch 9 Loss 0.23862437903881073
[Train] epoch 125 Batch 10 Loss 0.14386464655399323
[Train] epoch 125 Batch 11 Loss 0.1720067858695984
[Train] epoch 125 Batch 12 Loss 0.34394025802612305
[Train] epoch 125 Batch 13 Loss 0.2421949803829193
[Train] epoch 125 Batch 14 Loss 0.010888667777180672
[Train] epoch 125 Batch 15 Loss 0.37200409173965454
[Train] epoch 125 Batch 16 Loss 0.17186908423900604
[Train] epoch 125 Batch 17 Loss 0.3402785062789917
[Train] epoch 125 Batch 18 Loss 0.17538514733314514
[Train] epoch 125 Batch 19 Loss 0.24266640841960907
[Train] epoch 125 Batch 20 Loss 0.21040229499340057
[Train] epoch 125 Batch 21 Loss 0.1718229055404663
[Train] epoch 125 Batch 22 Loss 0.04269891232252121
[Train] epoch 125 Batch 23 Loss 0.17563313245773315
[Train] epoch 125 Batch 24 Loss 0.17216728627681732
[Train] epoch 125 Batch 25 Loss 0.10594751685857773
[Train] epoch 125 Batch 26 Loss 0.0740518644452095
[Train] epoch 125 Batch 27 Loss 0.14094629883766174
[Train] epoch 125 Batch 28 Loss 0.2430310845375061
[Train] epoch 125 Batch 29 Loss 0.30542999505996704
[Train] epoch 125 Batch 30 Loss 0.11009564995765686
[Train] epoch 125 Batch 31 Loss 0.04308858513832092
[Train] epoch 125 Batch 32 Loss 0.13743668794631958
[Train] epoch 125 Batch 33 Loss 0.18388687074184418
[Train] epoch 125 Batch 34 Loss 0.14423882961273193
[Train] epoch 125 Batch 35 Loss 0.10190656781196594
[Train] epoch 125 Batch 36 Loss 0.10601658374071121
[Train] epoch 125 Batch 37 Loss 0.1137799620628357
[Train] epoch 125 Batch 38 Loss 0.07828330993652344
[Train] epoch 125 Batch 39 Loss 0.1755533218383789
[Train] epoch 125 Batch 40 Loss 0.2114705741405487
[Train] epoch 125 Batch 41 Loss 0.3050267696380615
[Train] epoch 125 Batch 42 Loss 0.17937469482421875
[Train] epoch 125 Batch 43 Loss 0.14004410803318024
[Train] epoch 125 Batch 44 Loss 0.2111649215221405
[Train] epoch 125 Batch 45 Loss 0.2421550750732422
[Train] epoch 125 Batch 46 Loss 0.1515776813030243
[Train] epoch 125 Batch 47 Loss 0.2035398930311203
[Train] epoch 126 Batch 0 Loss 0.21090593934059143
[Train] epoch 126 Batch 1 Loss 0.13670510053634644
[Train] epoch 126 Batch 2 Loss 0.10895469039678574
[Train] epoch 126 Batch 3 Loss 0.11574873328208923
[Train] epoch 126 Batch 4 Loss 0.23849105834960938
[Train] epoch 126 Batch 5 Loss 0.23839449882507324
[Train] epoch 126 Batch 6 Loss 0.11540930718183517
[Train] epoch 126 Batch 7 Loss 0.20403827726840973
[Train] epoch 126 Batch 8 Loss 0.2103414386510849
[Train] epoch 126 Batch 9 Loss 0.2068408876657486
[Train] epoch 126 Batch 10 Loss 0.24233829975128174
[Train] epoch 126 Batch 11 Loss 0.20683999359607697
[Train] epoch 126 Batch 12 Loss 0.11629174649715424
[Train] epoch 126 Batch 13 Loss 0.0740572139620781
[Train] epoch 126 Batch 14 Loss 0.2071451097726822
[Train] epoch 126 Batch 15 Loss 0.10922740399837494
[Train] epoch 126 Batch 16 Loss 0.10914576798677444
[Train] epoch 126 Batch 17 Loss 0.20685061812400818
[Train] epoch 126 Batch 18 Loss 0.15183530747890472
[Train] epoch 126 Batch 19 Loss 0.20693279802799225
[Train] epoch 126 Batch 20 Loss 0.20345917344093323
[Train] epoch 126 Batch 21 Loss 0.16829964518547058
[Train] epoch 126 Batch 22 Loss 0.24270020425319672
[Train] epoch 126 Batch 23 Loss 0.10946658998727798
[Train] epoch 126 Batch 24 Loss 0.2034374177455902
[Train] epoch 126 Batch 25 Loss 0.10925741493701935
[Train] epoch 126 Batch 26 Loss 0.03907005116343498
[Train] epoch 126 Batch 27 Loss 0.3118222951889038
[Train] epoch 126 Batch 28 Loss 0.10177291929721832
[Train] epoch 126 Batch 29 Loss 0.0738426223397255
[Train] epoch 126 Batch 30 Loss 0.20697841048240662
[Train] epoch 126 Batch 31 Loss 0.24552294611930847
[Train] epoch 126 Batch 32 Loss 0.23833875358104706
[Train] epoch 126 Batch 33 Loss 0.14371581375598907
[Train] epoch 126 Batch 34 Loss 0.14034190773963928
[Train] epoch 126 Batch 35 Loss 0.08063339442014694
[Train] epoch 126 Batch 36 Loss 0.20684154331684113
[Train] epoch 126 Batch 37 Loss 0.3718022108078003
[Train] epoch 126 Batch 38 Loss 0.1468382626771927
[Train] epoch 126 Batch 39 Loss 0.23827111721038818
[Train] epoch 126 Batch 40 Loss 0.3468642830848694
[Train] epoch 126 Batch 41 Loss 0.20997539162635803
[Train] epoch 126 Batch 42 Loss 0.13985462486743927
[Train] epoch 126 Batch 43 Loss 0.21002504229545593
[Train] epoch 126 Batch 44 Loss 0.17819581925868988
[Train] epoch 126 Batch 45 Loss 0.20991306006908417
[Train] epoch 126 Batch 46 Loss 0.23489603400230408
[Train] epoch 126 Batch 47 Loss 0.1747007966041565
[Train] epoch 127 Batch 0 Loss 0.17656712234020233
[Train] epoch 127 Batch 1 Loss 0.10483938455581665
[Train] epoch 127 Batch 2 Loss 0.0807659775018692
[Train] epoch 127 Batch 3 Loss 0.4032754898071289
[Train] epoch 127 Batch 4 Loss 0.24167445302009583
[Train] epoch 127 Batch 5 Loss 0.23501411080360413
[Train] epoch 127 Batch 6 Loss 0.2735004127025604
[Train] epoch 127 Batch 7 Loss 0.13992781937122345
[Train] epoch 127 Batch 8 Loss 0.11183516681194305
[Train] epoch 127 Batch 9 Loss 0.14352333545684814
[Train] epoch 127 Batch 10 Loss 0.21359354257583618
[Train] epoch 127 Batch 11 Loss 0.13679182529449463
[Train] epoch 127 Batch 12 Loss 0.2747454047203064
[Train] epoch 127 Batch 13 Loss 0.2035105675458908
[Train] epoch 127 Batch 14 Loss 0.1090298742055893
[Train] epoch 127 Batch 15 Loss 0.14052382111549377
[Train] epoch 127 Batch 16 Loss 0.21588069200515747
[Train] epoch 127 Batch 17 Loss 0.052891604602336884
[Train] epoch 127 Batch 18 Loss 0.1022784560918808
[Train] epoch 127 Batch 19 Loss 0.25161173939704895
[Train] epoch 127 Batch 20 Loss 0.18605723977088928
[Train] epoch 127 Batch 21 Loss 0.11708575487136841
[Train] epoch 127 Batch 22 Loss 0.3082135021686554
[Train] epoch 127 Batch 23 Loss 0.4097244143486023
[Train] epoch 127 Batch 24 Loss 0.14285153150558472
[Train] epoch 127 Batch 25 Loss 0.1054936870932579
[Train] epoch 127 Batch 26 Loss 0.17262482643127441
[Train] epoch 127 Batch 27 Loss 0.17296844720840454
[Train] epoch 127 Batch 28 Loss 0.3116006553173065
[Train] epoch 127 Batch 29 Loss 0.29854243993759155
[Train] epoch 127 Batch 30 Loss 0.2415136694908142
[Train] epoch 127 Batch 31 Loss 0.37619656324386597
[Train] epoch 127 Batch 32 Loss 0.14380738139152527
[Train] epoch 127 Batch 33 Loss 0.19836565852165222
[Train] epoch 127 Batch 34 Loss 0.15639838576316833
[Train] epoch 127 Batch 35 Loss 0.2038297951221466
[Train] epoch 127 Batch 36 Loss 1.0728851975727594e-06
[Train] epoch 127 Batch 37 Loss 0.239278644323349
[Train] epoch 127 Batch 38 Loss 0.22059443593025208
[Train] epoch 127 Batch 39 Loss 0.11085294187068939
[Train] epoch 127 Batch 40 Loss 0.24805939197540283
[Train] epoch 127 Batch 41 Loss 0.18699321150779724
[Train] epoch 127 Batch 42 Loss 0.17299550771713257
[Train] epoch 127 Batch 43 Loss 0.23980967700481415
[Train] epoch 127 Batch 44 Loss 0.0793616995215416
[Train] epoch 127 Batch 45 Loss 0.11057576537132263
[Train] epoch 127 Batch 46 Loss 0.10202039778232574
[Train] epoch 127 Batch 47 Loss 0.18184316158294678
[Train] epoch 128 Batch 0 Loss 0.17337080836296082
[Train] epoch 128 Batch 1 Loss 0.21274781227111816
[Train] epoch 128 Batch 2 Loss 0.11112960427999496
[Train] epoch 128 Batch 3 Loss 0.2466665506362915
[Train] epoch 128 Batch 4 Loss 0.203377366065979
[Train] epoch 128 Batch 5 Loss 0.10174939036369324
[Train] epoch 128 Batch 6 Loss 0.2777225375175476
[Train] epoch 128 Batch 7 Loss 0.21438199281692505
[Train] epoch 128 Batch 8 Loss 0.11135642975568771
[Train] epoch 128 Batch 9 Loss 0.11698697507381439
[Train] epoch 128 Batch 10 Loss 0.2821406126022339
[Train] epoch 128 Batch 11 Loss 0.18321488797664642
[Train] epoch 128 Batch 12 Loss 0.14833779633045197
[Train] epoch 128 Batch 13 Loss 0.13857105374336243
[Train] epoch 128 Batch 14 Loss 0.15144850313663483
[Train] epoch 128 Batch 15 Loss 0.04468471556901932
[Train] epoch 128 Batch 16 Loss 0.10905709862709045
[Train] epoch 128 Batch 17 Loss 0.21242991089820862
[Train] epoch 128 Batch 18 Loss 0.2431839406490326
[Train] epoch 128 Batch 19 Loss 0.1067446768283844
[Train] epoch 128 Batch 20 Loss 0.2099696397781372
[Train] epoch 128 Batch 21 Loss 0.1731770932674408
[Train] epoch 128 Batch 22 Loss 0.14159341156482697
[Train] epoch 128 Batch 23 Loss 0.37826207280158997
[Train] epoch 128 Batch 24 Loss 0.10934320837259293
[Train] epoch 128 Batch 25 Loss 0.21250255405902863
[Train] epoch 128 Batch 26 Loss 0.4080737233161926
[Train] epoch 128 Batch 27 Loss 0.133334219455719
[Train] epoch 128 Batch 28 Loss 0.18094958364963531
[Train] epoch 128 Batch 29 Loss 0.133334219455719
[Train] epoch 128 Batch 30 Loss 0.17406921088695526
[Train] epoch 128 Batch 31 Loss 0.11442795395851135
[Train] epoch 128 Batch 32 Loss 0.2126048356294632
[Train] epoch 128 Batch 33 Loss 0.1772424280643463
[Train] epoch 128 Batch 34 Loss 0.13756200671195984
[Train] epoch 128 Batch 35 Loss 0.23558974266052246
[Train] epoch 128 Batch 36 Loss 0.18143311142921448
[Train] epoch 128 Batch 37 Loss 0.23562091588974
[Train] epoch 128 Batch 38 Loss 0.14223308861255646
[Train] epoch 128 Batch 39 Loss 0.07837344706058502
[Train] epoch 128 Batch 40 Loss 0.315472275018692
[Train] epoch 128 Batch 41 Loss 0.14995288848876953
[Train] epoch 128 Batch 42 Loss 0.07854537665843964
[Train] epoch 128 Batch 43 Loss 0.2747425436973572
[Train] epoch 128 Batch 44 Loss 0.1065838634967804
[Train] epoch 128 Batch 45 Loss 0.16902217268943787
[Train] epoch 128 Batch 46 Loss 0.2756096422672272
[Train] epoch 128 Batch 47 Loss 0.23518593609333038
[Train] epoch 129 Batch 0 Loss 0.28301697969436646
[Train] epoch 129 Batch 1 Loss 0.3065645098686218
[Train] epoch 129 Batch 2 Loss 0.1737644076347351
[Train] epoch 129 Batch 3 Loss 0.17689581215381622
[Train] epoch 129 Batch 4 Loss 0.1721859872341156
[Train] epoch 129 Batch 5 Loss 0.18305441737174988
[Train] epoch 129 Batch 6 Loss 0.27914363145828247
[Train] epoch 129 Batch 7 Loss 0.18455883860588074
[Train] epoch 129 Batch 8 Loss 0.07792951166629791
[Train] epoch 129 Batch 9 Loss 0.31537455320358276
[Train] epoch 129 Batch 10 Loss 0.1767103374004364
[Train] epoch 129 Batch 11 Loss 0.18772149085998535
[Train] epoch 129 Batch 12 Loss 0.14494851231575012
[Train] epoch 129 Batch 13 Loss 0.13804937899112701
[Train] epoch 129 Batch 14 Loss 0.1551203578710556
[Train] epoch 129 Batch 15 Loss 0.31392017006874084
[Train] epoch 129 Batch 16 Loss 0.16901418566703796
[Train] epoch 129 Batch 17 Loss 0.14335361123085022
[Train] epoch 129 Batch 18 Loss 0.14801236987113953
[Train] epoch 129 Batch 19 Loss 0.07328762859106064
[Train] epoch 129 Batch 20 Loss 0.17298400402069092
[Train] epoch 129 Batch 21 Loss 0.11211077868938446
[Train] epoch 129 Batch 22 Loss 0.2046787440776825
[Train] epoch 129 Batch 23 Loss 0.17294403910636902
[Train] epoch 129 Batch 24 Loss 0.31096118688583374
[Train] epoch 129 Batch 25 Loss 0.10799673199653625
[Train] epoch 129 Batch 26 Loss 0.07133032381534576
[Train] epoch 129 Batch 27 Loss 0.10232428461313248
[Train] epoch 129 Batch 28 Loss 0.17290812730789185
[Train] epoch 129 Batch 29 Loss 0.341106116771698
[Train] epoch 129 Batch 30 Loss 0.133334219455719
[Train] epoch 129 Batch 31 Loss 0.1682175099849701
[Train] epoch 129 Batch 32 Loss 0.16897286474704742
[Train] epoch 129 Batch 33 Loss 0.17518989741802216
[Train] epoch 129 Batch 34 Loss 0.27744409441947937
[Train] epoch 129 Batch 35 Loss 0.27435144782066345
[Train] epoch 129 Batch 36 Loss 0.047115832567214966
[Train] epoch 129 Batch 37 Loss 0.27434462308883667
[Train] epoch 129 Batch 38 Loss 0.17508038878440857
[Train] epoch 129 Batch 39 Loss 0.14095251262187958
[Train] epoch 129 Batch 40 Loss 0.1439443826675415
[Train] epoch 129 Batch 41 Loss 0.20755797624588013
[Train] epoch 129 Batch 42 Loss 0.2438850998878479
[Train] epoch 129 Batch 43 Loss 0.136309415102005
[Train] epoch 129 Batch 44 Loss 0.13930705189704895
[Train] epoch 129 Batch 45 Loss 0.17565906047821045
[Train] epoch 129 Batch 46 Loss 0.136272132396698
[Train] epoch 129 Batch 47 Loss 0.1462998241186142
[Train] epoch 130 Batch 0 Loss 0.21573343873023987
[Train] epoch 130 Batch 1 Loss 0.17536121606826782
[Train] epoch 130 Batch 2 Loss 0.20727545022964478
[Train] epoch 130 Batch 3 Loss 0.1374763697385788
[Train] epoch 130 Batch 4 Loss 0.07413420081138611
[Train] epoch 130 Batch 5 Loss 0.2783612310886383
[Train] epoch 130 Batch 6 Loss 0.25117412209510803
[Train] epoch 130 Batch 7 Loss 0.17669877409934998
[Train] epoch 130 Batch 8 Loss 0.17696836590766907
[Train] epoch 130 Batch 9 Loss 0.07488156855106354
[Train] epoch 130 Batch 10 Loss 0.3417164981365204
[Train] epoch 130 Batch 11 Loss 0.1851770281791687
[Train] epoch 130 Batch 12 Loss 0.13921929895877838
[Train] epoch 130 Batch 13 Loss 0.14644962549209595
[Train] epoch 130 Batch 14 Loss 0.21371519565582275
[Train] epoch 130 Batch 15 Loss 0.10190623998641968
[Train] epoch 130 Batch 16 Loss 0.10671897232532501
[Train] epoch 130 Batch 17 Loss 0.17763209342956543
[Train] epoch 130 Batch 18 Loss 0.06666764616966248
[Train] epoch 130 Batch 19 Loss 0.27904632687568665
[Train] epoch 130 Batch 20 Loss 0.31526586413383484
[Train] epoch 130 Batch 21 Loss 0.3457309603691101
[Train] epoch 130 Batch 22 Loss 0.2439776062965393
[Train] epoch 130 Batch 23 Loss 0.07110327482223511
[Train] epoch 130 Batch 24 Loss 0.07087235152721405
[Train] epoch 130 Batch 25 Loss 0.2796780467033386
[Train] epoch 130 Batch 26 Loss 0.15005958080291748
[Train] epoch 130 Batch 27 Loss 0.1462121605873108
[Train] epoch 130 Batch 28 Loss 0.23550629615783691
[Train] epoch 130 Batch 29 Loss 0.07061260938644409
[Train] epoch 130 Batch 30 Loss 0.07062036544084549
[Train] epoch 130 Batch 31 Loss 0.2910495102405548
[Train] epoch 130 Batch 32 Loss 0.0434495247900486
[Train] epoch 130 Batch 33 Loss 0.14136123657226562
[Train] epoch 130 Batch 34 Loss 0.27473965287208557
[Train] epoch 130 Batch 35 Loss 0.34520792961120605
[Train] epoch 130 Batch 36 Loss 0.10989157855510712
[Train] epoch 130 Batch 37 Loss 0.14884641766548157
[Train] epoch 130 Batch 38 Loss 0.0783456489443779
[Train] epoch 130 Batch 39 Loss 0.13717569410800934
[Train] epoch 130 Batch 40 Loss 0.042687758803367615
[Train] epoch 130 Batch 41 Loss 0.27436771988868713
[Train] epoch 130 Batch 42 Loss 0.14135193824768066
[Train] epoch 130 Batch 43 Loss 0.24620017409324646
[Train] epoch 130 Batch 44 Loss 0.270488977432251
[Train] epoch 130 Batch 45 Loss 0.10201133787631989
[Train] epoch 130 Batch 46 Loss 0.24665701389312744
[Train] epoch 130 Batch 47 Loss 0.34779292345046997
[Train] epoch 131 Batch 0 Loss 0.17621879279613495
[Train] epoch 131 Batch 1 Loss 0.23915433883666992
[Train] epoch 131 Batch 2 Loss 0.14403948187828064
[Train] epoch 131 Batch 3 Loss 0.04230791702866554
[Train] epoch 131 Batch 4 Loss 0.06666764616966248
[Train] epoch 131 Batch 5 Loss 0.20403528213500977
[Train] epoch 131 Batch 6 Loss 0.20744654536247253
[Train] epoch 131 Batch 7 Loss 0.21081605553627014
[Train] epoch 131 Batch 8 Loss 0.07070142775774002
[Train] epoch 131 Batch 9 Loss 0.21066567301750183
[Train] epoch 131 Batch 10 Loss 0.20741739869117737
[Train] epoch 131 Batch 11 Loss 0.2492583990097046
[Train] epoch 131 Batch 12 Loss 0.20770713686943054
[Train] epoch 131 Batch 13 Loss 0.10862912982702255
[Train] epoch 131 Batch 14 Loss 0.340625524520874
[Train] epoch 131 Batch 15 Loss 0.2381604164838791
[Train] epoch 131 Batch 16 Loss 0.242558091878891
[Train] epoch 131 Batch 17 Loss 0.17917141318321228
[Train] epoch 131 Batch 18 Loss 0.1051768958568573
[Train] epoch 131 Batch 19 Loss 0.18175722658634186
[Train] epoch 131 Batch 20 Loss 0.2814546823501587
[Train] epoch 131 Batch 21 Loss 0.07339006662368774
[Train] epoch 131 Batch 22 Loss 0.06666764616966248
[Train] epoch 131 Batch 23 Loss 0.2446562945842743
[Train] epoch 131 Batch 24 Loss 0.10777340829372406
[Train] epoch 131 Batch 25 Loss 0.2101573646068573
[Train] epoch 131 Batch 26 Loss 0.10460955649614334
[Train] epoch 131 Batch 27 Loss 0.2101144641637802
[Train] epoch 131 Batch 28 Loss 0.03837555646896362
[Train] epoch 131 Batch 29 Loss 0.14335164427757263
[Train] epoch 131 Batch 30 Loss 0.3777177929878235
[Train] epoch 131 Batch 31 Loss 0.10199114680290222
[Train] epoch 131 Batch 32 Loss 0.30497682094573975
[Train] epoch 131 Batch 33 Loss 0.11086541414260864
[Train] epoch 131 Batch 34 Loss 0.24469023942947388
[Train] epoch 131 Batch 35 Loss 0.10493217408657074
[Train] epoch 131 Batch 36 Loss 0.14262655377388
[Train] epoch 131 Batch 37 Loss 0.210323303937912
[Train] epoch 131 Batch 38 Loss 0.26954036951065063
[Train] epoch 131 Batch 39 Loss 0.24506400525569916
[Train] epoch 131 Batch 40 Loss 0.20739072561264038
[Train] epoch 131 Batch 41 Loss 0.2563643157482147
[Train] epoch 131 Batch 42 Loss 0.17094922065734863
[Train] epoch 131 Batch 43 Loss 0.06947333365678787
[Train] epoch 131 Batch 44 Loss 0.17450760304927826
[Train] epoch 131 Batch 45 Loss 0.2067149579524994
[Train] epoch 131 Batch 46 Loss 0.2733532190322876
[Train] epoch 131 Batch 47 Loss 0.1081419438123703
[Train] epoch 132 Batch 0 Loss 0.14543843269348145
[Train] epoch 132 Batch 1 Loss 0.1748182773590088
[Train] epoch 132 Batch 2 Loss 0.08252311497926712
[Train] epoch 132 Batch 3 Loss 0.1786327362060547
[Train] epoch 132 Batch 4 Loss 0.14713431894779205
[Train] epoch 132 Batch 5 Loss 0.1719001978635788
[Train] epoch 132 Batch 6 Loss 0.17501354217529297
[Train] epoch 132 Batch 7 Loss 0.27628087997436523
[Train] epoch 132 Batch 8 Loss 0.20300786197185516
[Train] epoch 132 Batch 9 Loss 0.2788611352443695
[Train] epoch 132 Batch 10 Loss 0.17751912772655487
[Train] epoch 132 Batch 11 Loss 0.2733958065509796
[Train] epoch 132 Batch 12 Loss 0.27368903160095215
[Train] epoch 132 Batch 13 Loss 0.17539671063423157
[Train] epoch 132 Batch 14 Loss 0.23513224720954895
[Train] epoch 132 Batch 15 Loss 0.15227827429771423
[Train] epoch 132 Batch 16 Loss 0.10571768879890442
[Train] epoch 132 Batch 17 Loss 0.2465907335281372
[Train] epoch 132 Batch 18 Loss 0.10596176981925964
[Train] epoch 132 Batch 19 Loss 0.371962308883667
[Train] epoch 132 Batch 20 Loss 0.18181215226650238
[Train] epoch 132 Batch 21 Loss 0.24353009462356567
[Train] epoch 132 Batch 22 Loss 1.0728851975727594e-06
[Train] epoch 132 Batch 23 Loss 0.17321868240833282
[Train] epoch 132 Batch 24 Loss 0.1434287428855896
[Train] epoch 132 Batch 25 Loss 0.11488913744688034
[Train] epoch 132 Batch 26 Loss 0.2482987642288208
[Train] epoch 132 Batch 27 Loss 0.07452702522277832
[Train] epoch 132 Batch 28 Loss 0.13707253336906433
[Train] epoch 132 Batch 29 Loss 0.10939446091651917
[Train] epoch 132 Batch 30 Loss 0.07047343254089355
[Train] epoch 132 Batch 31 Loss 0.1760540008544922
[Train] epoch 132 Batch 32 Loss 0.37915661931037903
[Train] epoch 132 Batch 33 Loss 0.07403979450464249
[Train] epoch 132 Batch 34 Loss 0.04510081559419632
[Train] epoch 132 Batch 35 Loss 0.27036604285240173
[Train] epoch 132 Batch 36 Loss 0.17712339758872986
[Train] epoch 132 Batch 37 Loss 0.23899433016777039
[Train] epoch 132 Batch 38 Loss 0.1465100347995758
[Train] epoch 132 Batch 39 Loss 0.2067766934633255
[Train] epoch 132 Batch 40 Loss 0.21331655979156494
[Train] epoch 132 Batch 41 Loss 0.2039271891117096
[Train] epoch 132 Batch 42 Loss 0.17479504644870758
[Train] epoch 132 Batch 43 Loss 0.10504980385303497
[Train] epoch 132 Batch 44 Loss 0.07054071873426437
[Train] epoch 132 Batch 45 Loss 0.30499058961868286
[Train] epoch 132 Batch 46 Loss 0.2808458209037781
[Train] epoch 132 Batch 47 Loss 0.20642465353012085
[Train] epoch 133 Batch 0 Loss 0.07267644256353378
[Train] epoch 133 Batch 1 Loss 0.13714349269866943
[Train] epoch 133 Batch 2 Loss 0.10785329341888428
[Train] epoch 133 Batch 3 Loss 0.10822127759456635
[Train] epoch 133 Batch 4 Loss 0.24490076303482056
[Train] epoch 133 Batch 5 Loss 0.17440912127494812
[Train] epoch 133 Batch 6 Loss 0.1718955785036087
[Train] epoch 133 Batch 7 Loss 0.17725902795791626
[Train] epoch 133 Batch 8 Loss 0.07643033564090729
[Train] epoch 133 Batch 9 Loss 0.17224997282028198
[Train] epoch 133 Batch 10 Loss 0.24119821190834045
[Train] epoch 133 Batch 11 Loss 0.1079731434583664
[Train] epoch 133 Batch 12 Loss 0.3083222508430481
[Train] epoch 133 Batch 13 Loss 0.10522580146789551
[Train] epoch 133 Batch 14 Loss 0.2417421191930771
[Train] epoch 133 Batch 15 Loss 0.30825483798980713
[Train] epoch 133 Batch 16 Loss 0.21012458205223083
[Train] epoch 133 Batch 17 Loss 0.10508280247449875
[Train] epoch 133 Batch 18 Loss 0.1433873176574707
[Train] epoch 133 Batch 19 Loss 0.17507284879684448
[Train] epoch 133 Batch 20 Loss 0.10168531537055969
[Train] epoch 133 Batch 21 Loss 0.21370717883110046
[Train] epoch 133 Batch 22 Loss 0.17188160121440887
[Train] epoch 133 Batch 23 Loss 0.17177890241146088
[Train] epoch 133 Batch 24 Loss 0.3400903046131134
[Train] epoch 133 Batch 25 Loss 0.31543394923210144
[Train] epoch 133 Batch 26 Loss 0.2735161781311035
[Train] epoch 133 Batch 27 Loss 0.350303053855896
[Train] epoch 133 Batch 28 Loss 0.14013591408729553
[Train] epoch 133 Batch 29 Loss 0.2735419273376465
[Train] epoch 133 Batch 30 Loss 0.10503537952899933
[Train] epoch 133 Batch 31 Loss 0.21346062421798706
[Train] epoch 133 Batch 32 Loss 0.11171908676624298
[Train] epoch 133 Batch 33 Loss 0.20678365230560303
[Train] epoch 133 Batch 34 Loss 0.13988091051578522
[Train] epoch 133 Batch 35 Loss 0.31189706921577454
[Train] epoch 133 Batch 36 Loss 0.07337085157632828
[Train] epoch 133 Batch 37 Loss 0.16829442977905273
[Train] epoch 133 Batch 38 Loss 0.038165949285030365
[Train] epoch 133 Batch 39 Loss 0.2031719833612442
[Train] epoch 133 Batch 40 Loss 0.2795276641845703
[Train] epoch 133 Batch 41 Loss 0.17499186098575592
[Train] epoch 133 Batch 42 Loss 0.03803694248199463
[Train] epoch 133 Batch 43 Loss 0.2730643153190613
[Train] epoch 133 Batch 44 Loss 0.1051798090338707
[Train] epoch 133 Batch 45 Loss 0.1427781730890274
[Train] epoch 133 Batch 46 Loss 0.27624452114105225
[Train] epoch 133 Batch 47 Loss 0.07907842844724655
[Train] epoch 134 Batch 0 Loss 0.27640992403030396
[Train] epoch 134 Batch 1 Loss 0.13678736984729767
[Train] epoch 134 Batch 2 Loss 0.17140646278858185
[Train] epoch 134 Batch 3 Loss 0.20323485136032104
[Train] epoch 134 Batch 4 Loss 0.31115949153900146
[Train] epoch 134 Batch 5 Loss 0.03800864890217781
[Train] epoch 134 Batch 6 Loss 0.13973838090896606
[Train] epoch 134 Batch 7 Loss 0.27992865443229675
[Train] epoch 134 Batch 8 Loss 0.24433758854866028
[Train] epoch 134 Batch 9 Loss 0.1747458279132843
[Train] epoch 134 Batch 10 Loss 0.10751775652170181
[Train] epoch 134 Batch 11 Loss 0.1801767200231552
[Train] epoch 134 Batch 12 Loss 0.17438456416130066
[Train] epoch 134 Batch 13 Loss 0.2034265547990799
[Train] epoch 134 Batch 14 Loss 0.10537139326334
[Train] epoch 134 Batch 15 Loss 0.20890459418296814
[Train] epoch 134 Batch 16 Loss 0.28141188621520996
[Train] epoch 134 Batch 17 Loss 0.21803922951221466
[Train] epoch 134 Batch 18 Loss 0.2742806077003479
[Train] epoch 134 Batch 19 Loss 0.27662235498428345
[Train] epoch 134 Batch 20 Loss 0.2167574167251587
[Train] epoch 134 Batch 21 Loss 0.14119386672973633
[Train] epoch 134 Batch 22 Loss 0.2076505422592163
[Train] epoch 134 Batch 23 Loss 0.17997083067893982
[Train] epoch 134 Batch 24 Loss 0.11377540975809097
[Train] epoch 134 Batch 25 Loss 0.14006251096725464
[Train] epoch 134 Batch 26 Loss 0.24688221514225006
[Train] epoch 134 Batch 27 Loss 0.07060712575912476
[Train] epoch 134 Batch 28 Loss 0.14119981229305267
[Train] epoch 134 Batch 29 Loss 0.2706393599510193
[Train] epoch 134 Batch 30 Loss 0.20814651250839233
[Train] epoch 134 Batch 31 Loss 0.3145352303981781
[Train] epoch 134 Batch 32 Loss 0.07091408967971802
[Train] epoch 134 Batch 33 Loss 0.2037704586982727
[Train] epoch 134 Batch 34 Loss 0.16854800283908844
[Train] epoch 134 Batch 35 Loss 0.25205469131469727
[Train] epoch 134 Batch 36 Loss 0.17228883504867554
[Train] epoch 134 Batch 37 Loss 0.14156530797481537
[Train] epoch 134 Batch 38 Loss 0.14555011689662933
[Train] epoch 134 Batch 39 Loss 0.03995814919471741
[Train] epoch 134 Batch 40 Loss 0.24779626727104187
[Train] epoch 134 Batch 41 Loss 0.25321221351623535
[Train] epoch 134 Batch 42 Loss 0.15066248178482056
[Train] epoch 134 Batch 43 Loss 0.11506044864654541
[Train] epoch 134 Batch 44 Loss 0.14590239524841309
[Train] epoch 134 Batch 45 Loss 0.13769936561584473
[Train] epoch 134 Batch 46 Loss 0.10617741197347641
[Train] epoch 134 Batch 47 Loss 0.14563137292861938
[Train] epoch 135 Batch 0 Loss 0.1141899898648262
[Train] epoch 135 Batch 1 Loss 0.18484538793563843
[Train] epoch 135 Batch 2 Loss 0.21209324896335602
[Train] epoch 135 Batch 3 Loss 0.24702686071395874
[Train] epoch 135 Batch 4 Loss 0.24331563711166382
[Train] epoch 135 Batch 5 Loss 0.2742076516151428
[Train] epoch 135 Batch 6 Loss 0.11325917392969131
[Train] epoch 135 Batch 7 Loss 0.36857494711875916
[Train] epoch 135 Batch 8 Loss 0.04290046915411949
[Train] epoch 135 Batch 9 Loss 0.0704963281750679
[Train] epoch 135 Batch 10 Loss 0.07426151633262634
[Train] epoch 135 Batch 11 Loss 0.07038217037916183
[Train] epoch 135 Batch 12 Loss 0.3200794458389282
[Train] epoch 135 Batch 13 Loss 0.17606544494628906
[Train] epoch 135 Batch 14 Loss 0.07376754283905029
[Train] epoch 135 Batch 15 Loss 0.21063221991062164
[Train] epoch 135 Batch 16 Loss 0.13719400763511658
[Train] epoch 135 Batch 17 Loss 0.21066024899482727
[Train] epoch 135 Batch 18 Loss 0.3757365942001343
[Train] epoch 135 Batch 19 Loss 0.1756240427494049
[Train] epoch 135 Batch 20 Loss 0.14031943678855896
[Train] epoch 135 Batch 21 Loss 0.21083709597587585
[Train] epoch 135 Batch 22 Loss 0.07696978747844696
[Train] epoch 135 Batch 23 Loss 0.14359799027442932
[Train] epoch 135 Batch 24 Loss 0.23489350080490112
[Train] epoch 135 Batch 25 Loss 0.17833462357521057
[Train] epoch 135 Batch 26 Loss 0.2420399785041809
[Train] epoch 135 Batch 27 Loss 0.21032720804214478
[Train] epoch 135 Batch 28 Loss 0.10782010853290558
[Train] epoch 135 Batch 29 Loss 0.13721612095832825
[Train] epoch 135 Batch 30 Loss 0.13987350463867188
[Train] epoch 135 Batch 31 Loss 0.04098362475633621
[Train] epoch 135 Batch 32 Loss 0.3086295425891876
[Train] epoch 135 Batch 33 Loss 0.2771152853965759
[Train] epoch 135 Batch 34 Loss 0.3721301555633545
[Train] epoch 135 Batch 35 Loss 0.14654792845249176
[Train] epoch 135 Batch 36 Loss 0.0383853018283844
[Train] epoch 135 Batch 37 Loss 0.24629393219947815
[Train] epoch 135 Batch 38 Loss 0.3783408999443054
[Train] epoch 135 Batch 39 Loss 0.14401459693908691
[Train] epoch 135 Batch 40 Loss 0.140527606010437
[Train] epoch 135 Batch 41 Loss 0.07033756375312805
[Train] epoch 135 Batch 42 Loss 0.21084380149841309
[Train] epoch 135 Batch 43 Loss 1.0728851975727594e-06
[Train] epoch 135 Batch 44 Loss 0.21146893501281738
[Train] epoch 135 Batch 45 Loss 0.14101102948188782
[Train] epoch 135 Batch 46 Loss 0.3092566728591919
[Train] epoch 135 Batch 47 Loss 0.1686248779296875
[Train] epoch 136 Batch 0 Loss 0.14585593342781067
[Train] epoch 136 Batch 1 Loss 0.17660868167877197
[Train] epoch 136 Batch 2 Loss 0.1453227996826172
[Train] epoch 136 Batch 3 Loss 0.310647577047348
[Train] epoch 136 Batch 4 Loss 0.13757987320423126
[Train] epoch 136 Batch 5 Loss 0.14516083896160126
[Train] epoch 136 Batch 6 Loss 0.1770729422569275
[Train] epoch 136 Batch 7 Loss 0.2353895902633667
[Train] epoch 136 Batch 8 Loss 0.1762012094259262
[Train] epoch 136 Batch 9 Loss 0.3443969488143921
[Train] epoch 136 Batch 10 Loss 0.17277389764785767
[Train] epoch 136 Batch 11 Loss 0.24605458974838257
[Train] epoch 136 Batch 12 Loss 0.20825420320034027
[Train] epoch 136 Batch 13 Loss 0.14190681278705597
[Train] epoch 136 Batch 14 Loss 0.23920902609825134
[Train] epoch 136 Batch 15 Loss 0.181299090385437
[Train] epoch 136 Batch 16 Loss 0.10538280010223389
[Train] epoch 136 Batch 17 Loss 0.07444349676370621
[Train] epoch 136 Batch 18 Loss 0.17230018973350525
[Train] epoch 136 Batch 19 Loss 0.4109652042388916
[Train] epoch 136 Batch 20 Loss 0.07902102917432785
[Train] epoch 136 Batch 21 Loss 0.11329109966754913
[Train] epoch 136 Batch 22 Loss 0.10170012712478638
[Train] epoch 136 Batch 23 Loss 0.23843595385551453
[Train] epoch 136 Batch 24 Loss 0.17257419228553772
[Train] epoch 136 Batch 25 Loss 0.07408516854047775
[Train] epoch 136 Batch 26 Loss 0.2533183991909027
[Train] epoch 136 Batch 27 Loss 0.14091476798057556
[Train] epoch 136 Batch 28 Loss 0.13674461841583252
[Train] epoch 136 Batch 29 Loss 0.27359890937805176
[Train] epoch 136 Batch 30 Loss 0.2460673600435257
[Train] epoch 136 Batch 31 Loss 0.10931199789047241
[Train] epoch 136 Batch 32 Loss 0.23882150650024414
[Train] epoch 136 Batch 33 Loss 0.23854738473892212
[Train] epoch 136 Batch 34 Loss 0.21054351329803467
[Train] epoch 136 Batch 35 Loss 0.11276758462190628
[Train] epoch 136 Batch 36 Loss 0.04920152574777603
[Train] epoch 136 Batch 37 Loss 0.21035195887088776
[Train] epoch 136 Batch 38 Loss 0.1052921712398529
[Train] epoch 136 Batch 39 Loss 0.2105623483657837
[Train] epoch 136 Batch 40 Loss 0.16838416457176208
[Train] epoch 136 Batch 41 Loss 0.1401766836643219
[Train] epoch 136 Batch 42 Loss 0.1435822695493698
[Train] epoch 136 Batch 43 Loss 0.3185983896255493
[Train] epoch 136 Batch 44 Loss 0.06997609883546829
[Train] epoch 136 Batch 45 Loss 0.2066808044910431
[Train] epoch 136 Batch 46 Loss 0.238515704870224
[Train] epoch 136 Batch 47 Loss 0.1817159652709961
[Train] epoch 137 Batch 0 Loss 0.3748074769973755
[Train] epoch 137 Batch 1 Loss 0.24150428175926208
[Train] epoch 137 Batch 2 Loss 0.13994711637496948
[Train] epoch 137 Batch 3 Loss 0.07301345467567444
[Train] epoch 137 Batch 4 Loss 0.06666764616966248
[Train] epoch 137 Batch 5 Loss 0.2765406370162964
[Train] epoch 137 Batch 6 Loss 0.20944640040397644
[Train] epoch 137 Batch 7 Loss 0.1395159363746643
[Train] epoch 137 Batch 8 Loss 0.336631715297699
[Train] epoch 137 Batch 9 Loss 0.304933100938797
[Train] epoch 137 Batch 10 Loss 0.2060859352350235
[Train] epoch 137 Batch 11 Loss 0.44201600551605225
[Train] epoch 137 Batch 12 Loss 0.27616196870803833
[Train] epoch 137 Batch 13 Loss 0.27664002776145935
[Train] epoch 137 Batch 14 Loss 0.13658004999160767
[Train] epoch 137 Batch 15 Loss 0.10457781702280045
[Train] epoch 137 Batch 16 Loss 0.20614364743232727
[Train] epoch 137 Batch 17 Loss 0.11025846749544144
[Train] epoch 137 Batch 18 Loss 0.17739716172218323
[Train] epoch 137 Batch 19 Loss 0.28143447637557983
[Train] epoch 137 Batch 20 Loss 0.07271569967269897
[Train] epoch 137 Batch 21 Loss 0.03790726885199547
[Train] epoch 137 Batch 22 Loss 0.2757038176059723
[Train] epoch 137 Batch 23 Loss 0.10780444741249084
[Train] epoch 137 Batch 24 Loss 0.2760092318058014
[Train] epoch 137 Batch 25 Loss 0.14293363690376282
[Train] epoch 137 Batch 26 Loss 0.2445010244846344
[Train] epoch 137 Batch 27 Loss 0.04112828150391579
[Train] epoch 137 Batch 28 Loss 0.24460694193840027
[Train] epoch 137 Batch 29 Loss 0.07946255058050156
[Train] epoch 137 Batch 30 Loss 0.14000621438026428
[Train] epoch 137 Batch 31 Loss 0.2096196562051773
[Train] epoch 137 Batch 32 Loss 0.133334219455719
[Train] epoch 137 Batch 33 Loss 0.34613049030303955
[Train] epoch 137 Batch 34 Loss 0.038223762065172195
[Train] epoch 137 Batch 35 Loss 0.1464216411113739
[Train] epoch 137 Batch 36 Loss 0.14290601015090942
[Train] epoch 137 Batch 37 Loss 0.10804315656423569
[Train] epoch 137 Batch 38 Loss 0.04468940198421478
[Train] epoch 137 Batch 39 Loss 0.10478632152080536
[Train] epoch 137 Batch 40 Loss 0.23825234174728394
[Train] epoch 137 Batch 41 Loss 0.11113446950912476
[Train] epoch 137 Batch 42 Loss 0.10480456054210663
[Train] epoch 137 Batch 43 Loss 0.17149075865745544
[Train] epoch 137 Batch 44 Loss 0.3049061596393585
[Train] epoch 137 Batch 45 Loss 0.20618721842765808
[Train] epoch 137 Batch 46 Loss 0.10489882528781891
[Train] epoch 137 Batch 47 Loss 0.10770334303379059
[Train] epoch 138 Batch 0 Loss 0.1396690160036087
[Train] epoch 138 Batch 1 Loss 0.00305329542607069
[Train] epoch 138 Batch 2 Loss 0.10476167500019073
[Train] epoch 138 Batch 3 Loss 0.1745058298110962
[Train] epoch 138 Batch 4 Loss 0.1048882007598877
[Train] epoch 138 Batch 5 Loss 0.2730059027671814
[Train] epoch 138 Batch 6 Loss 0.20916295051574707
[Train] epoch 138 Batch 7 Loss 0.06982849538326263
[Train] epoch 138 Batch 8 Loss 0.13947802782058716
[Train] epoch 138 Batch 9 Loss 0.17458204925060272
[Train] epoch 138 Batch 10 Loss 0.2788020074367523
[Train] epoch 138 Batch 11 Loss 0.142558291554451
[Train] epoch 138 Batch 12 Loss 0.1774892956018448
[Train] epoch 138 Batch 13 Loss 0.06666764616966248
[Train] epoch 138 Batch 14 Loss 0.2409067451953888
[Train] epoch 138 Batch 15 Loss 0.07838477194309235
[Train] epoch 138 Batch 16 Loss 0.3048720359802246
[Train] epoch 138 Batch 17 Loss 0.1710747331380844
[Train] epoch 138 Batch 18 Loss 0.17121440172195435
[Train] epoch 138 Batch 19 Loss 0.2408854365348816
[Train] epoch 138 Batch 20 Loss 0.10487132519483566
[Train] epoch 138 Batch 21 Loss 0.27556073665618896
[Train] epoch 138 Batch 22 Loss 0.1362045705318451
[Train] epoch 138 Batch 23 Loss 0.2058497965335846
[Train] epoch 138 Batch 24 Loss 0.31089577078819275
[Train] epoch 138 Batch 25 Loss 0.3764849007129669
[Train] epoch 138 Batch 26 Loss 0.04165250435471535
[Train] epoch 138 Batch 27 Loss 0.14514045417308807
[Train] epoch 138 Batch 28 Loss 0.06967102736234665
[Train] epoch 138 Batch 29 Loss 0.3425867557525635
[Train] epoch 138 Batch 30 Loss 0.23781374096870422
[Train] epoch 138 Batch 31 Loss 0.037981972098350525
[Train] epoch 138 Batch 32 Loss 0.2820206880569458
[Train] epoch 138 Batch 33 Loss 0.23483219742774963
[Train] epoch 138 Batch 34 Loss 0.24113896489143372
[Train] epoch 138 Batch 35 Loss 0.24421702325344086
[Train] epoch 138 Batch 36 Loss 0.17451828718185425
[Train] epoch 138 Batch 37 Loss 0.24423082172870636
[Train] epoch 138 Batch 38 Loss 0.10469041764736176
[Train] epoch 138 Batch 39 Loss 0.14918503165245056
[Train] epoch 138 Batch 40 Loss 0.27939456701278687
[Train] epoch 138 Batch 41 Loss 0.3048481345176697
[Train] epoch 138 Batch 42 Loss 0.1046162098646164
[Train] epoch 138 Batch 43 Loss 0.2062872052192688
[Train] epoch 138 Batch 44 Loss 0.17456313967704773
[Train] epoch 138 Batch 45 Loss 0.10460615903139114
[Train] epoch 138 Batch 46 Loss 0.24730080366134644
[Train] epoch 138 Batch 47 Loss 0.00939534418284893
[Train] epoch 139 Batch 0 Loss 0.0380217507481575
[Train] epoch 139 Batch 1 Loss 0.10765333473682404
[Train] epoch 139 Batch 2 Loss 0.1776038110256195
[Train] epoch 139 Batch 3 Loss 0.07274225354194641
[Train] epoch 139 Batch 4 Loss 0.2788081169128418
[Train] epoch 139 Batch 5 Loss 0.20609283447265625
[Train] epoch 139 Batch 6 Loss 0.1834011971950531
[Train] epoch 139 Batch 7 Loss 0.07582438737154007
[Train] epoch 139 Batch 8 Loss 0.13947947323322296
[Train] epoch 139 Batch 9 Loss 0.17114347219467163
[Train] epoch 139 Batch 10 Loss 0.3364027738571167
[Train] epoch 139 Batch 11 Loss 0.10433664917945862
[Train] epoch 139 Batch 12 Loss 0.23776552081108093
[Train] epoch 139 Batch 13 Loss 0.2726852297782898
[Train] epoch 139 Batch 14 Loss 0.27241840958595276
[Train] epoch 139 Batch 15 Loss 0.1419835388660431
[Train] epoch 139 Batch 16 Loss 0.14214885234832764
[Train] epoch 139 Batch 17 Loss 0.28124138712882996
[Train] epoch 139 Batch 18 Loss 0.24045787751674652
[Train] epoch 139 Batch 19 Loss 0.17933037877082825
[Train] epoch 139 Batch 20 Loss 0.17128022015094757
[Train] epoch 139 Batch 21 Loss 0.10461451858282089
[Train] epoch 139 Batch 22 Loss 0.0376131497323513
[Train] epoch 139 Batch 23 Loss 0.043223343789577484
[Train] epoch 139 Batch 24 Loss 0.06666764616966248
[Train] epoch 139 Batch 25 Loss 0.06666764616966248
[Train] epoch 139 Batch 26 Loss 0.2115321159362793
[Train] epoch 139 Batch 27 Loss 0.2109268605709076
[Train] epoch 139 Batch 28 Loss 0.20260530710220337
[Train] epoch 139 Batch 29 Loss 0.17437374591827393
[Train] epoch 139 Batch 30 Loss 0.10423384606838226
[Train] epoch 139 Batch 31 Loss 0.2404322624206543
[Train] epoch 139 Batch 32 Loss 0.144115149974823
[Train] epoch 139 Batch 33 Loss 0.17910227179527283
[Train] epoch 139 Batch 34 Loss 0.1361459195613861
[Train] epoch 139 Batch 35 Loss 0.1015438586473465
[Train] epoch 139 Batch 36 Loss 0.2806936502456665
[Train] epoch 139 Batch 37 Loss 0.17503422498703003
[Train] epoch 139 Batch 38 Loss 0.10733455419540405
[Train] epoch 139 Batch 39 Loss 0.40607213973999023
[Train] epoch 139 Batch 40 Loss 0.10993057489395142
[Train] epoch 139 Batch 41 Loss 0.23881486058235168
[Train] epoch 139 Batch 42 Loss 0.2048192024230957
[Train] epoch 139 Batch 43 Loss 0.311702162027359
[Train] epoch 139 Batch 44 Loss 0.339638352394104
[Train] epoch 139 Batch 45 Loss 0.17194461822509766
[Train] epoch 139 Batch 46 Loss 0.2069028913974762
[Train] epoch 139 Batch 47 Loss 0.24184304475784302
[Train] epoch 140 Batch 0 Loss 0.16831852495670319
[Train] epoch 140 Batch 1 Loss 0.07407012581825256
[Train] epoch 140 Batch 2 Loss 0.17231380939483643
[Train] epoch 140 Batch 3 Loss 0.2807975113391876
[Train] epoch 140 Batch 4 Loss 0.2427331954240799
[Train] epoch 140 Batch 5 Loss 0.1090797632932663
[Train] epoch 140 Batch 6 Loss 0.31431955099105835
[Train] epoch 140 Batch 7 Loss 0.1792096197605133
[Train] epoch 140 Batch 8 Loss 0.3073257505893707
[Train] epoch 140 Batch 9 Loss 0.1470668613910675
[Train] epoch 140 Batch 10 Loss 0.13993802666664124
[Train] epoch 140 Batch 11 Loss 0.1430964171886444
[Train] epoch 140 Batch 12 Loss 0.2381909191608429
[Train] epoch 140 Batch 13 Loss 0.06991181522607803
[Train] epoch 140 Batch 14 Loss 0.13649475574493408
[Train] epoch 140 Batch 15 Loss 0.20948271453380585
[Train] epoch 140 Batch 16 Loss 0.27869564294815063
[Train] epoch 140 Batch 17 Loss 0.21193815767765045
[Train] epoch 140 Batch 18 Loss 0.1425790935754776
[Train] epoch 140 Batch 19 Loss 0.11594405025243759
[Train] epoch 140 Batch 20 Loss 0.23802149295806885
[Train] epoch 140 Batch 21 Loss 0.2000008225440979
[Train] epoch 140 Batch 22 Loss 0.17730775475502014
[Train] epoch 140 Batch 23 Loss 0.13935786485671997
[Train] epoch 140 Batch 24 Loss 0.17133861780166626
[Train] epoch 140 Batch 25 Loss 0.20942124724388123
[Train] epoch 140 Batch 26 Loss 0.1046309769153595
[Train] epoch 140 Batch 27 Loss 0.2062593400478363
[Train] epoch 140 Batch 28 Loss 0.21251225471496582
[Train] epoch 140 Batch 29 Loss 0.13958273828029633
[Train] epoch 140 Batch 30 Loss 0.14275524020195007
[Train] epoch 140 Batch 31 Loss 0.07293782383203506
[Train] epoch 140 Batch 32 Loss 0.07292595505714417
[Train] epoch 140 Batch 33 Loss 0.17764613032341003
[Train] epoch 140 Batch 34 Loss 0.1364174783229828
[Train] epoch 140 Batch 35 Loss 0.1109037771821022
[Train] epoch 140 Batch 36 Loss 0.3077235519886017
[Train] epoch 140 Batch 37 Loss 0.13640183210372925
[Train] epoch 140 Batch 38 Loss 0.13957414031028748
[Train] epoch 140 Batch 39 Loss 0.3743080496788025
[Train] epoch 140 Batch 40 Loss 0.1743573546409607
[Train] epoch 140 Batch 41 Loss 0.2789929211139679
[Train] epoch 140 Batch 42 Loss 0.17737938463687897
[Train] epoch 140 Batch 43 Loss 0.20611572265625
[Train] epoch 140 Batch 44 Loss 0.20914208889007568
[Train] epoch 140 Batch 45 Loss 0.10449081659317017
[Train] epoch 140 Batch 46 Loss 0.20600588619709015
[Train] epoch 140 Batch 47 Loss 0.17116791009902954
[Train] epoch 141 Batch 0 Loss 0.2696551978588104
[Train] epoch 141 Batch 1 Loss 0.14528679847717285
[Train] epoch 141 Batch 2 Loss 0.21779602766036987
[Train] epoch 141 Batch 3 Loss 0.13638196885585785
[Train] epoch 141 Batch 4 Loss 0.21177563071250916
[Train] epoch 141 Batch 5 Loss 0.20304444432258606
[Train] epoch 141 Batch 6 Loss 0.246529221534729
[Train] epoch 141 Batch 7 Loss 0.24627095460891724
[Train] epoch 141 Batch 8 Loss 0.13902099430561066
[Train] epoch 141 Batch 9 Loss 0.24054032564163208
[Train] epoch 141 Batch 10 Loss 0.10152389854192734
[Train] epoch 141 Batch 11 Loss 0.24066871404647827
[Train] epoch 141 Batch 12 Loss 0.24095001816749573
[Train] epoch 141 Batch 13 Loss 0.10994943976402283
[Train] epoch 141 Batch 14 Loss 0.3058551251888275
[Train] epoch 141 Batch 15 Loss 0.40883809328079224
[Train] epoch 141 Batch 16 Loss 0.2412249743938446
[Train] epoch 141 Batch 17 Loss 0.07418250292539597
[Train] epoch 141 Batch 18 Loss 0.17697501182556152
[Train] epoch 141 Batch 19 Loss 0.10443830490112305
[Train] epoch 141 Batch 20 Loss 0.17115488648414612
[Train] epoch 141 Batch 21 Loss 0.37740558385849
[Train] epoch 141 Batch 22 Loss 0.27627789974212646
[Train] epoch 141 Batch 23 Loss 0.1076488047838211
[Train] epoch 141 Batch 24 Loss 0.24134671688079834
[Train] epoch 141 Batch 25 Loss 0.27983298897743225
[Train] epoch 141 Batch 26 Loss 0.04197126626968384
[Train] epoch 141 Batch 27 Loss 0.18250146508216858
[Train] epoch 141 Batch 28 Loss 0.04248081520199776
[Train] epoch 141 Batch 29 Loss 0.035275090485811234
[Train] epoch 141 Batch 30 Loss 0.07852798700332642
[Train] epoch 141 Batch 31 Loss 0.1767231971025467
[Train] epoch 141 Batch 32 Loss 0.1795981526374817
[Train] epoch 141 Batch 33 Loss 0.23861029744148254
[Train] epoch 141 Batch 34 Loss 0.2385970950126648
[Train] epoch 141 Batch 35 Loss 0.1369941234588623
[Train] epoch 141 Batch 36 Loss 0.10900352895259857
[Train] epoch 141 Batch 37 Loss 0.14117294549942017
[Train] epoch 141 Batch 38 Loss 0.11002247035503387
[Train] epoch 141 Batch 39 Loss 0.13750451803207397
[Train] epoch 141 Batch 40 Loss 0.10532268136739731
[Train] epoch 141 Batch 41 Loss 0.14496594667434692
[Train] epoch 141 Batch 42 Loss 0.17612764239311218
[Train] epoch 141 Batch 43 Loss 0.17711323499679565
[Train] epoch 141 Batch 44 Loss 0.17242063581943512
[Train] epoch 141 Batch 45 Loss 0.2000008225440979
[Train] epoch 141 Batch 46 Loss 0.10608305782079697
[Train] epoch 141 Batch 47 Loss 0.23898941278457642
[Train] epoch 142 Batch 0 Loss 0.2385983020067215
[Train] epoch 142 Batch 1 Loss 0.20723435282707214
[Train] epoch 142 Batch 2 Loss 0.3441397547721863
[Train] epoch 142 Batch 3 Loss 0.14088468253612518
[Train] epoch 142 Batch 4 Loss 0.07779845595359802
[Train] epoch 142 Batch 5 Loss 0.14081045985221863
[Train] epoch 142 Batch 6 Loss 0.31288278102874756
[Train] epoch 142 Batch 7 Loss 0.24228927493095398
[Train] epoch 142 Batch 8 Loss 0.1016378253698349
[Train] epoch 142 Batch 9 Loss 0.2072737216949463
[Train] epoch 142 Batch 10 Loss 0.0463954396545887
[Train] epoch 142 Batch 11 Loss 0.14402391016483307
[Train] epoch 142 Batch 12 Loss 0.37901586294174194
[Train] epoch 142 Batch 13 Loss 0.07374051213264465
[Train] epoch 142 Batch 14 Loss 0.21420925855636597
[Train] epoch 142 Batch 15 Loss 0.10504518449306488
[Train] epoch 142 Batch 16 Loss 0.4102649688720703
[Train] epoch 142 Batch 17 Loss 0.1119825541973114
[Train] epoch 142 Batch 18 Loss 0.2418643832206726
[Train] epoch 142 Batch 19 Loss 0.2767198085784912
[Train] epoch 142 Batch 20 Loss 0.1433531492948532
[Train] epoch 142 Batch 21 Loss 0.13999706506729126
[Train] epoch 142 Batch 22 Loss 0.006565484218299389
[Train] epoch 142 Batch 23 Loss 0.3366667628288269
[Train] epoch 142 Batch 24 Loss 0.20979797840118408
[Train] epoch 142 Batch 25 Loss 0.24473920464515686
[Train] epoch 142 Batch 26 Loss 0.24153012037277222
[Train] epoch 142 Batch 27 Loss 0.2063908725976944
[Train] epoch 142 Batch 28 Loss 0.10157759487628937
[Train] epoch 142 Batch 29 Loss 0.2413235455751419
[Train] epoch 142 Batch 30 Loss 0.27643901109695435
[Train] epoch 142 Batch 31 Loss 0.14278768002986908
[Train] epoch 142 Batch 32 Loss 0.07285400480031967
[Train] epoch 142 Batch 33 Loss 0.30772924423217773
[Train] epoch 142 Batch 34 Loss 0.1457238495349884
[Train] epoch 142 Batch 35 Loss 1.0728851975727594e-06
[Train] epoch 142 Batch 36 Loss 0.1080089882016182
[Train] epoch 142 Batch 37 Loss 0.11658254265785217
[Train] epoch 142 Batch 38 Loss 0.2695434093475342
[Train] epoch 142 Batch 39 Loss 0.11058714985847473
[Train] epoch 142 Batch 40 Loss 0.2789064049720764
[Train] epoch 142 Batch 41 Loss 0.3016810417175293
[Train] epoch 142 Batch 42 Loss 0.13668280839920044
[Train] epoch 142 Batch 43 Loss 1.0728851975727594e-06
[Train] epoch 142 Batch 44 Loss 0.17365145683288574
[Train] epoch 142 Batch 45 Loss 0.040282126516103745
[Train] epoch 142 Batch 46 Loss 0.10475403815507889
[Train] epoch 142 Batch 47 Loss 0.20950596034526825
[Train] epoch 143 Batch 0 Loss 0.16834571957588196
[Train] epoch 143 Batch 1 Loss 0.1360601782798767
[Train] epoch 143 Batch 2 Loss 0.13638071715831757
[Train] epoch 143 Batch 3 Loss 0.21145381033420563
[Train] epoch 143 Batch 4 Loss 0.10678710788488388
[Train] epoch 143 Batch 5 Loss 0.1360103189945221
[Train] epoch 143 Batch 6 Loss 0.2171231061220169
[Train] epoch 143 Batch 7 Loss 0.10734455287456512
[Train] epoch 143 Batch 8 Loss 0.30503037571907043
[Train] epoch 143 Batch 9 Loss 0.11033915728330612
[Train] epoch 143 Batch 10 Loss 0.10468219220638275
[Train] epoch 143 Batch 11 Loss 0.27878108620643616
[Train] epoch 143 Batch 12 Loss 0.20557060837745667
[Train] epoch 143 Batch 13 Loss 0.20609068870544434
[Train] epoch 143 Batch 14 Loss 0.1682913601398468
[Train] epoch 143 Batch 15 Loss 0.17135745286941528
[Train] epoch 143 Batch 16 Loss 0.1772640347480774
[Train] epoch 143 Batch 17 Loss 0.27899354696273804
[Train] epoch 143 Batch 18 Loss 0.20606085658073425
[Train] epoch 143 Batch 19 Loss 0.2063693404197693
[Train] epoch 143 Batch 20 Loss 0.37142613530158997
[Train] epoch 143 Batch 21 Loss 0.20308122038841248
[Train] epoch 143 Batch 22 Loss 0.07285188138484955
[Train] epoch 143 Batch 23 Loss 0.04101376608014107
[Train] epoch 143 Batch 24 Loss 0.33636772632598877
[Train] epoch 143 Batch 25 Loss 0.04411115497350693
[Train] epoch 143 Batch 26 Loss 0.17743000388145447
[Train] epoch 143 Batch 27 Loss 0.17440858483314514
[Train] epoch 143 Batch 28 Loss 0.21529918909072876
[Train] epoch 143 Batch 29 Loss 0.31076526641845703
[Train] epoch 143 Batch 30 Loss 0.2758534848690033
[Train] epoch 143 Batch 31 Loss 0.0060703326016664505
[Train] epoch 143 Batch 32 Loss 0.17122244834899902
[Train] epoch 143 Batch 33 Loss 0.17414142191410065
[Train] epoch 143 Batch 34 Loss 0.20919223129749298
[Train] epoch 143 Batch 35 Loss 0.2816883325576782
[Train] epoch 143 Batch 36 Loss 0.13938114047050476
[Train] epoch 143 Batch 37 Loss 0.30740344524383545
[Train] epoch 143 Batch 38 Loss 0.23781132698059082
[Train] epoch 143 Batch 39 Loss 0.10722804069519043
[Train] epoch 143 Batch 40 Loss 0.2059984803199768
[Train] epoch 143 Batch 41 Loss 0.17382779717445374
[Train] epoch 143 Batch 42 Loss 0.07245993614196777
[Train] epoch 143 Batch 43 Loss 0.17418360710144043
[Train] epoch 143 Batch 44 Loss 0.10732177644968033
[Train] epoch 143 Batch 45 Loss 0.17134961485862732
[Train] epoch 143 Batch 46 Loss 0.10711351037025452
[Train] epoch 143 Batch 47 Loss 0.13919270038604736
[Train] epoch 144 Batch 0 Loss 0.14747117459774017
[Train] epoch 144 Batch 1 Loss 0.17134875059127808
[Train] epoch 144 Batch 2 Loss 0.17384476959705353
[Train] epoch 144 Batch 3 Loss 0.10405127704143524
[Train] epoch 144 Batch 4 Loss 0.20579659938812256
[Train] epoch 144 Batch 5 Loss 0.17642658948898315
[Train] epoch 144 Batch 6 Loss 0.1793423593044281
[Train] epoch 144 Batch 7 Loss 0.13621097803115845
[Train] epoch 144 Batch 8 Loss 0.17616379261016846
[Train] epoch 144 Batch 9 Loss 0.1070672795176506
[Train] epoch 144 Batch 10 Loss 0.13882464170455933
[Train] epoch 144 Batch 11 Loss 0.17083194851875305
[Train] epoch 144 Batch 12 Loss 0.2754575312137604
[Train] epoch 144 Batch 13 Loss 0.06925679743289948
[Train] epoch 144 Batch 14 Loss 0.23774240911006927
[Train] epoch 144 Batch 15 Loss 0.04252985119819641
[Train] epoch 144 Batch 16 Loss 0.06919602304697037
[Train] epoch 144 Batch 17 Loss 0.10632646828889847
[Train] epoch 144 Batch 18 Loss 0.13644404709339142
[Train] epoch 144 Batch 19 Loss 0.13909485936164856
[Train] epoch 144 Batch 20 Loss 0.3040964603424072
[Train] epoch 144 Batch 21 Loss 0.10389687120914459
[Train] epoch 144 Batch 22 Loss 0.10949958860874176
[Train] epoch 144 Batch 23 Loss 0.14143389463424683
[Train] epoch 144 Batch 24 Loss 0.14210520684719086
[Train] epoch 144 Batch 25 Loss 0.07782728224992752
[Train] epoch 144 Batch 26 Loss 0.2695545554161072
[Train] epoch 144 Batch 27 Loss 0.24354562163352966
[Train] epoch 144 Batch 28 Loss 0.2028914988040924
[Train] epoch 144 Batch 29 Loss 0.2407224476337433
[Train] epoch 144 Batch 30 Loss 0.2056768238544464
[Train] epoch 144 Batch 31 Loss 0.2463202178478241
[Train] epoch 144 Batch 32 Loss 0.13625410199165344
[Train] epoch 144 Batch 33 Loss 0.20865601301193237
[Train] epoch 144 Batch 34 Loss 0.2435566484928131
[Train] epoch 144 Batch 35 Loss 0.24341917037963867
[Train] epoch 144 Batch 36 Loss 0.21443194150924683
[Train] epoch 144 Batch 37 Loss 0.3014337420463562
[Train] epoch 144 Batch 38 Loss 0.30722060799598694
[Train] epoch 144 Batch 39 Loss 0.20582076907157898
[Train] epoch 144 Batch 40 Loss 0.3392167389392853
[Train] epoch 144 Batch 41 Loss 0.24056783318519592
[Train] epoch 144 Batch 42 Loss 0.07522223889827728
[Train] epoch 144 Batch 43 Loss 0.17107313871383667
[Train] epoch 144 Batch 44 Loss 0.14187543094158173
[Train] epoch 144 Batch 45 Loss 0.1042468324303627
[Train] epoch 144 Batch 46 Loss 0.10146494209766388
[Train] epoch 144 Batch 47 Loss 0.34174489974975586
[Train] epoch 145 Batch 0 Loss 0.41139233112335205
[Train] epoch 145 Batch 1 Loss 0.2695935368537903
[Train] epoch 145 Batch 2 Loss 0.17087122797966003
[Train] epoch 145 Batch 3 Loss 0.1709499955177307
[Train] epoch 145 Batch 4 Loss 0.3098677396774292
[Train] epoch 145 Batch 5 Loss 0.07211296260356903
[Train] epoch 145 Batch 6 Loss 0.10677213966846466
[Train] epoch 145 Batch 7 Loss 0.17364737391471863
[Train] epoch 145 Batch 8 Loss 0.27775999903678894
[Train] epoch 145 Batch 9 Loss 0.13624972105026245
[Train] epoch 145 Batch 10 Loss 0.1470714509487152
[Train] epoch 145 Batch 11 Loss 0.37368565797805786
[Train] epoch 145 Batch 12 Loss 0.24272586405277252
[Train] epoch 145 Batch 13 Loss 0.17352037131786346
[Train] epoch 145 Batch 14 Loss 0.339011549949646
[Train] epoch 145 Batch 15 Loss 0.30697983503341675
[Train] epoch 145 Batch 16 Loss 0.30906206369400024
[Train] epoch 145 Batch 17 Loss 0.005160483065992594
[Train] epoch 145 Batch 18 Loss 0.27232298254966736
[Train] epoch 145 Batch 19 Loss 0.10401742160320282
[Train] epoch 145 Batch 20 Loss 0.17339012026786804
[Train] epoch 145 Batch 21 Loss 0.1731746792793274
[Train] epoch 145 Batch 22 Loss 0.2102593332529068
[Train] epoch 145 Batch 23 Loss 0.3068579435348511
[Train] epoch 145 Batch 24 Loss 0.13582196831703186
[Train] epoch 145 Batch 25 Loss 0.03975421190261841
[Train] epoch 145 Batch 26 Loss 0.170585498213768
[Train] epoch 145 Batch 27 Loss 0.10435660183429718
[Train] epoch 145 Batch 28 Loss 0.21027514338493347
[Train] epoch 145 Batch 29 Loss 0.2080306112766266
[Train] epoch 145 Batch 30 Loss 0.07397399842739105
[Train] epoch 145 Batch 31 Loss 0.3030843436717987
[Train] epoch 145 Batch 32 Loss 0.21010635793209076
[Train] epoch 145 Batch 33 Loss 0.20504230260849
[Train] epoch 145 Batch 34 Loss 0.045033711940050125
[Train] epoch 145 Batch 35 Loss 0.1414746344089508
[Train] epoch 145 Batch 36 Loss 0.10942526161670685
[Train] epoch 145 Batch 37 Loss 0.17074820399284363
[Train] epoch 145 Batch 38 Loss 0.037425559014081955
[Train] epoch 145 Batch 39 Loss 0.13609257340431213
[Train] epoch 145 Batch 40 Loss 0.10140126943588257
[Train] epoch 145 Batch 41 Loss 0.1361301839351654
[Train] epoch 145 Batch 42 Loss 0.10415732860565186
[Train] epoch 145 Batch 43 Loss 0.0347287543118
[Train] epoch 145 Batch 44 Loss 0.13889282941818237
[Train] epoch 145 Batch 45 Loss 0.2722312808036804
[Train] epoch 145 Batch 46 Loss 0.21394793689250946
[Train] epoch 145 Batch 47 Loss 0.0750511884689331
[Train] epoch 146 Batch 0 Loss 0.2402697503566742
[Train] epoch 146 Batch 1 Loss 0.20835959911346436
[Train] epoch 146 Batch 2 Loss 0.14167484641075134
[Train] epoch 146 Batch 3 Loss 0.20276936888694763
[Train] epoch 146 Batch 4 Loss 0.2083541452884674
[Train] epoch 146 Batch 5 Loss 0.13609780371189117
[Train] epoch 146 Batch 6 Loss 0.10416702181100845
[Train] epoch 146 Batch 7 Loss 0.17083069682121277
[Train] epoch 146 Batch 8 Loss 0.10137338936328888
[Train] epoch 146 Batch 9 Loss 0.31241393089294434
[Train] epoch 146 Batch 10 Loss 0.10411792248487473
[Train] epoch 146 Batch 11 Loss 0.04019904136657715
[Train] epoch 146 Batch 12 Loss 0.17349793016910553
[Train] epoch 146 Batch 13 Loss 0.21090492606163025
[Train] epoch 146 Batch 14 Loss 0.14151152968406677
[Train] epoch 146 Batch 15 Loss 0.141447052359581
[Train] epoch 146 Batch 16 Loss 0.10405746102333069
[Train] epoch 146 Batch 17 Loss 0.20799492299556732
[Train] epoch 146 Batch 18 Loss 0.06936586648225784
[Train] epoch 146 Batch 19 Loss 0.1040070429444313
[Train] epoch 146 Batch 20 Loss 0.2374565303325653
[Train] epoch 146 Batch 21 Loss 0.14656266570091248
[Train] epoch 146 Batch 22 Loss 0.3067339062690735
[Train] epoch 146 Batch 23 Loss 0.16804274916648865
[Train] epoch 146 Batch 24 Loss 0.10909055173397064
[Train] epoch 146 Batch 25 Loss 0.13589760661125183
[Train] epoch 146 Batch 26 Loss 0.4772651791572571
[Train] epoch 146 Batch 27 Loss 0.1412544846534729
[Train] epoch 146 Batch 28 Loss 0.27955272793769836
[Train] epoch 146 Batch 29 Loss 0.1705537736415863
[Train] epoch 146 Batch 30 Loss 0.27191099524497986
[Train] epoch 146 Batch 31 Loss 0.2694219946861267
[Train] epoch 146 Batch 32 Loss 0.17051836848258972
[Train] epoch 146 Batch 33 Loss 0.03702746331691742
[Train] epoch 146 Batch 34 Loss 0.17525310814380646
[Train] epoch 146 Batch 35 Loss 0.03714790195226669
[Train] epoch 146 Batch 36 Loss 0.2720119059085846
[Train] epoch 146 Batch 37 Loss 0.2345448136329651
[Train] epoch 146 Batch 38 Loss 0.10413146018981934
[Train] epoch 146 Batch 39 Loss 0.14089274406433105
[Train] epoch 146 Batch 40 Loss 0.20789200067520142
[Train] epoch 146 Batch 41 Loss 0.24460449814796448
[Train] epoch 146 Batch 42 Loss 0.10613972693681717
[Train] epoch 146 Batch 43 Loss 0.10865867137908936
[Train] epoch 146 Batch 44 Loss 0.2692139744758606
[Train] epoch 146 Batch 45 Loss 0.37313970923423767
[Train] epoch 146 Batch 46 Loss 0.14777907729148865
[Train] epoch 146 Batch 47 Loss 0.14664927124977112
[Train] epoch 147 Batch 0 Loss 0.11537277698516846
[Train] epoch 147 Batch 1 Loss 0.17629316449165344
[Train] epoch 147 Batch 2 Loss 0.19116950035095215
[Train] epoch 147 Batch 3 Loss 0.23820289969444275
[Train] epoch 147 Batch 4 Loss 0.13949322700500488
[Train] epoch 147 Batch 5 Loss 0.24906542897224426
[Train] epoch 147 Batch 6 Loss 0.17909805476665497
[Train] epoch 147 Batch 7 Loss 0.272892028093338
[Train] epoch 147 Batch 8 Loss 0.17125791311264038
[Train] epoch 147 Batch 9 Loss 0.15896441042423248
[Train] epoch 147 Batch 10 Loss 0.33653950691223145
[Train] epoch 147 Batch 11 Loss 0.24676403403282166
[Train] epoch 147 Batch 12 Loss 0.14217263460159302
[Train] epoch 147 Batch 13 Loss 0.14519160985946655
[Train] epoch 147 Batch 14 Loss 0.24930545687675476
[Train] epoch 147 Batch 15 Loss 0.10438834875822067
[Train] epoch 147 Batch 16 Loss 0.2724973261356354
[Train] epoch 147 Batch 17 Loss 0.13903313875198364
[Train] epoch 147 Batch 18 Loss 0.07877296209335327
[Train] epoch 147 Batch 19 Loss 0.10437750071287155
[Train] epoch 147 Batch 20 Loss 0.17914536595344543
[Train] epoch 147 Batch 21 Loss 0.1391107439994812
[Train] epoch 147 Batch 22 Loss 0.20483791828155518
[Train] epoch 147 Batch 23 Loss 0.1395474076271057
[Train] epoch 147 Batch 24 Loss 0.1779063642024994
[Train] epoch 147 Batch 25 Loss 0.07728609442710876
[Train] epoch 147 Batch 26 Loss 0.06666764616966248
[Train] epoch 147 Batch 27 Loss 0.20698080956935883
[Train] epoch 147 Batch 28 Loss 0.3450215458869934
[Train] epoch 147 Batch 29 Loss 0.27903878688812256
[Train] epoch 147 Batch 30 Loss 0.14617298543453217
[Train] epoch 147 Batch 31 Loss 0.14171957969665527
[Train] epoch 147 Batch 32 Loss 0.13816197216510773
[Train] epoch 147 Batch 33 Loss 0.17568150162696838
[Train] epoch 147 Batch 34 Loss 0.3717251420021057
[Train] epoch 147 Batch 35 Loss 0.18735560774803162
[Train] epoch 147 Batch 36 Loss 0.17354372143745422
[Train] epoch 147 Batch 37 Loss 0.18088757991790771
[Train] epoch 147 Batch 38 Loss 0.2035670131444931
[Train] epoch 147 Batch 39 Loss 0.21062487363815308
[Train] epoch 147 Batch 40 Loss 0.1403777301311493
[Train] epoch 147 Batch 41 Loss 0.18326245248317719
[Train] epoch 147 Batch 42 Loss 0.1883901208639145
[Train] epoch 147 Batch 43 Loss 0.13702799379825592
[Train] epoch 147 Batch 44 Loss 0.2870212495326996
[Train] epoch 147 Batch 45 Loss 0.10220202058553696
[Train] epoch 147 Batch 46 Loss 0.31090083718299866
[Train] epoch 147 Batch 47 Loss 0.10597273707389832
[Train] epoch 148 Batch 0 Loss 0.37647855281829834
[Train] epoch 148 Batch 1 Loss 0.11557219922542572
[Train] epoch 148 Batch 2 Loss 0.06666764616966248
[Train] epoch 148 Batch 3 Loss 0.17253531515598297
[Train] epoch 148 Batch 4 Loss 0.10185787081718445
[Train] epoch 148 Batch 5 Loss 0.18180802464485168
[Train] epoch 148 Batch 6 Loss 0.24447651207447052
[Train] epoch 148 Batch 7 Loss 0.18217706680297852
[Train] epoch 148 Batch 8 Loss 0.14134114980697632
[Train] epoch 148 Batch 9 Loss 0.1774289608001709
[Train] epoch 148 Batch 10 Loss 0.31520506739616394
[Train] epoch 148 Batch 11 Loss 0.30682772397994995
[Train] epoch 148 Batch 12 Loss 0.21659424901008606
[Train] epoch 148 Batch 13 Loss 0.21211016178131104
[Train] epoch 148 Batch 14 Loss 0.24340179562568665
[Train] epoch 148 Batch 15 Loss 0.17675602436065674
[Train] epoch 148 Batch 16 Loss 0.2076898217201233
[Train] epoch 148 Batch 17 Loss 0.16865718364715576
[Train] epoch 148 Batch 18 Loss 0.07042746245861053
[Train] epoch 148 Batch 19 Loss 0.17613255977630615
[Train] epoch 148 Batch 20 Loss 0.20800884068012238
[Train] epoch 148 Batch 21 Loss 0.2391359806060791
[Train] epoch 148 Batch 22 Loss 0.24295777082443237
[Train] epoch 148 Batch 23 Loss 0.2000008225440979
[Train] epoch 148 Batch 24 Loss 0.11339893192052841
[Train] epoch 148 Batch 25 Loss 0.14461958408355713
[Train] epoch 148 Batch 26 Loss 0.14852294325828552
[Train] epoch 148 Batch 27 Loss 0.109428271651268
[Train] epoch 148 Batch 28 Loss 0.07009418308734894
[Train] epoch 148 Batch 29 Loss 0.24583709239959717
[Train] epoch 148 Batch 30 Loss 0.23902228474617004
[Train] epoch 148 Batch 31 Loss 0.17633414268493652
[Train] epoch 148 Batch 32 Loss 0.03822311386466026
[Train] epoch 148 Batch 33 Loss 0.34334808588027954
[Train] epoch 148 Batch 34 Loss 0.24259057641029358
[Train] epoch 148 Batch 35 Loss 0.34360653162002563
[Train] epoch 148 Batch 36 Loss 0.21128998696804047
[Train] epoch 148 Batch 37 Loss 0.03877486661076546
[Train] epoch 148 Batch 38 Loss 0.04190811887383461
[Train] epoch 148 Batch 39 Loss 0.17498169839382172
[Train] epoch 148 Batch 40 Loss 0.10205412656068802
[Train] epoch 148 Batch 41 Loss 0.11573504656553268
[Train] epoch 148 Batch 42 Loss 0.18155741691589355
[Train] epoch 148 Batch 43 Loss 0.17861370742321014
[Train] epoch 148 Batch 44 Loss 0.24605520069599152
[Train] epoch 148 Batch 45 Loss 0.0354490652680397
[Train] epoch 148 Batch 46 Loss 0.17841759324073792
[Train] epoch 148 Batch 47 Loss 0.2767214775085449
[Train] epoch 149 Batch 0 Loss 0.11102381348609924
[Train] epoch 149 Batch 1 Loss 0.10596709698438644
[Train] epoch 149 Batch 2 Loss 0.20666444301605225
[Train] epoch 149 Batch 3 Loss 0.24105548858642578
[Train] epoch 149 Batch 4 Loss 0.1402207911014557
[Train] epoch 149 Batch 5 Loss 0.07317083328962326
[Train] epoch 149 Batch 6 Loss 0.17194688320159912
[Train] epoch 149 Batch 7 Loss 0.2742026150226593
[Train] epoch 149 Batch 8 Loss 0.13683724403381348
[Train] epoch 149 Batch 9 Loss 0.2736503779888153
[Train] epoch 149 Batch 10 Loss 0.24798443913459778
[Train] epoch 149 Batch 11 Loss 0.27370303869247437
[Train] epoch 149 Batch 12 Loss 0.11270315945148468
[Train] epoch 149 Batch 13 Loss 0.03873472288250923
[Train] epoch 149 Batch 14 Loss 0.34440547227859497
[Train] epoch 149 Batch 15 Loss 0.24233821034431458
[Train] epoch 149 Batch 16 Loss 0.11532365530729294
[Train] epoch 149 Batch 17 Loss 0.07709595561027527
[Train] epoch 149 Batch 18 Loss 0.17933408915996552
[Train] epoch 149 Batch 19 Loss 0.14093159139156342
[Train] epoch 149 Batch 20 Loss 0.24299365282058716
[Train] epoch 149 Batch 21 Loss 0.10876897722482681
[Train] epoch 149 Batch 22 Loss 0.07424910366535187
[Train] epoch 149 Batch 23 Loss 0.14591728150844574
[Train] epoch 149 Batch 24 Loss 0.31585901975631714
[Train] epoch 149 Batch 25 Loss 0.17644964158535004
[Train] epoch 149 Batch 26 Loss 0.14088477194309235
[Train] epoch 149 Batch 27 Loss 0.07377994060516357
[Train] epoch 149 Batch 28 Loss 0.3409822881221771
[Train] epoch 149 Batch 29 Loss 0.2798740267753601
[Train] epoch 149 Batch 30 Loss 0.1720377802848816
[Train] epoch 149 Batch 31 Loss 0.102102130651474
[Train] epoch 149 Batch 32 Loss 0.04202822968363762
[Train] epoch 149 Batch 33 Loss 0.1408100575208664
[Train] epoch 149 Batch 34 Loss 0.3687441647052765
[Train] epoch 149 Batch 35 Loss 0.20787771046161652
[Train] epoch 149 Batch 36 Loss 0.21025091409683228
[Train] epoch 149 Batch 37 Loss 0.1370164453983307
[Train] epoch 149 Batch 38 Loss 0.17610162496566772
[Train] epoch 149 Batch 39 Loss 0.1061706617474556
[Train] epoch 149 Batch 40 Loss 0.10205523669719696
[Train] epoch 149 Batch 41 Loss 0.21098560094833374
[Train] epoch 149 Batch 42 Loss 0.20689906179904938
[Train] epoch 149 Batch 43 Loss 0.18430769443511963
[Train] epoch 149 Batch 44 Loss 0.23856022953987122
[Train] epoch 149 Batch 45 Loss 0.2812817692756653
[Train] epoch 149 Batch 46 Loss 0.23809990286827087
[Train] epoch 149 Batch 47 Loss 0.18490833044052124
[Train] epoch 150 Batch 0 Loss 0.17850130796432495
[Train] epoch 150 Batch 1 Loss 0.10202382504940033
[Train] epoch 150 Batch 2 Loss 0.1757843792438507
[Train] epoch 150 Batch 3 Loss 0.2070985734462738
[Train] epoch 150 Batch 4 Loss 0.23839512467384338
[Train] epoch 150 Batch 5 Loss 0.034850187599658966
[Train] epoch 150 Batch 6 Loss 0.041434019804000854
[Train] epoch 150 Batch 7 Loss 0.2105097770690918
[Train] epoch 150 Batch 8 Loss 0.2766730785369873
[Train] epoch 150 Batch 9 Loss 0.1462825983762741
[Train] epoch 150 Batch 10 Loss 0.2800421118736267
[Train] epoch 150 Batch 11 Loss 0.10786426067352295
[Train] epoch 150 Batch 12 Loss 0.17500945925712585
[Train] epoch 150 Batch 13 Loss 0.04108762741088867
[Train] epoch 150 Batch 14 Loss 0.10489028692245483
[Train] epoch 150 Batch 15 Loss 0.10772793740034103
[Train] epoch 150 Batch 16 Loss 0.3772105574607849
[Train] epoch 150 Batch 17 Loss 0.14240048825740814
[Train] epoch 150 Batch 18 Loss 0.30482110381126404
[Train] epoch 150 Batch 19 Loss 0.2140991985797882
[Train] epoch 150 Batch 20 Loss 0.17480246722698212
[Train] epoch 150 Batch 21 Loss 0.20422303676605225
[Train] epoch 150 Batch 22 Loss 0.3749377131462097
[Train] epoch 150 Batch 23 Loss 0.10837569087743759
[Train] epoch 150 Batch 24 Loss 0.3748359680175781
[Train] epoch 150 Batch 25 Loss 0.11221043765544891
[Train] epoch 150 Batch 26 Loss 0.20364946126937866
[Train] epoch 150 Batch 27 Loss 0.07774026691913605
[Train] epoch 150 Batch 28 Loss 0.17997732758522034
[Train] epoch 150 Batch 29 Loss 0.2864093780517578
[Train] epoch 150 Batch 30 Loss 0.043139439076185226
[Train] epoch 150 Batch 31 Loss 0.13659672439098358
[Train] epoch 150 Batch 32 Loss 0.31320443749427795
[Train] epoch 150 Batch 33 Loss 0.1799219250679016
[Train] epoch 150 Batch 34 Loss 0.20357352495193481
[Train] epoch 150 Batch 35 Loss 0.20354528725147247
[Train] epoch 150 Batch 36 Loss 0.10514730215072632
[Train] epoch 150 Batch 37 Loss 0.2421066015958786
[Train] epoch 150 Batch 38 Loss 0.24492013454437256
[Train] epoch 150 Batch 39 Loss 0.17493405938148499
[Train] epoch 150 Batch 40 Loss 0.17782378196716309
[Train] epoch 150 Batch 41 Loss 0.17228499054908752
[Train] epoch 150 Batch 42 Loss 0.1771087646484375
[Train] epoch 150 Batch 43 Loss 0.06666764616966248
[Train] epoch 150 Batch 44 Loss 0.1746533364057541
[Train] epoch 150 Batch 45 Loss 0.1372031420469284
[Train] epoch 150 Batch 46 Loss 0.20654195547103882
[Train] epoch 150 Batch 47 Loss 0.17539355158805847
[Train] epoch 151 Batch 0 Loss 0.17513833940029144
[Train] epoch 151 Batch 1 Loss 0.11122384667396545
[Train] epoch 151 Batch 2 Loss 0.1390708088874817
[Train] epoch 151 Batch 3 Loss 0.1747426986694336
[Train] epoch 151 Batch 4 Loss 0.24420666694641113
[Train] epoch 151 Batch 5 Loss 0.20635977387428284
[Train] epoch 151 Batch 6 Loss 0.3087000250816345
[Train] epoch 151 Batch 7 Loss 0.3395959734916687
[Train] epoch 151 Batch 8 Loss 0.20670077204704285
[Train] epoch 151 Batch 9 Loss 0.1746823787689209
[Train] epoch 151 Batch 10 Loss 0.10810873657464981
[Train] epoch 151 Batch 11 Loss 0.21020463109016418
[Train] epoch 151 Batch 12 Loss 0.17816829681396484
[Train] epoch 151 Batch 13 Loss 0.13676902651786804
[Train] epoch 151 Batch 14 Loss 0.24499545991420746
[Train] epoch 151 Batch 15 Loss 0.07007439434528351
[Train] epoch 151 Batch 16 Loss 0.07003205269575119
[Train] epoch 151 Batch 17 Loss 0.4033682346343994
[Train] epoch 151 Batch 18 Loss 0.2450276017189026
[Train] epoch 151 Batch 19 Loss 0.10825426876544952
[Train] epoch 151 Batch 20 Loss 0.07990144938230515
[Train] epoch 151 Batch 21 Loss 0.17168459296226501
[Train] epoch 151 Batch 22 Loss 0.06666764616966248
[Train] epoch 151 Batch 23 Loss 0.04152432084083557
[Train] epoch 151 Batch 24 Loss 0.07641564309597015
[Train] epoch 151 Batch 25 Loss 0.3049788475036621
[Train] epoch 151 Batch 26 Loss 0.20984578132629395
[Train] epoch 151 Batch 27 Loss 0.25108063220977783
[Train] epoch 151 Batch 28 Loss 0.2766348719596863
[Train] epoch 151 Batch 29 Loss 0.24150732159614563
[Train] epoch 151 Batch 30 Loss 0.1778407245874405
[Train] epoch 151 Batch 31 Loss 0.03500233590602875
[Train] epoch 151 Batch 32 Loss 0.2825869917869568
[Train] epoch 151 Batch 33 Loss 0.2729579210281372
[Train] epoch 151 Batch 34 Loss 0.17764991521835327
[Train] epoch 151 Batch 35 Loss 0.13954216241836548
[Train] epoch 151 Batch 36 Loss 0.21206259727478027
[Train] epoch 151 Batch 37 Loss 0.14551226794719696
[Train] epoch 151 Batch 38 Loss 0.1399921029806137
[Train] epoch 151 Batch 39 Loss 0.2728250324726105
[Train] epoch 151 Batch 40 Loss 0.10439484566450119
[Train] epoch 151 Batch 41 Loss 0.10435234010219574
[Train] epoch 151 Batch 42 Loss 0.17720696330070496
[Train] epoch 151 Batch 43 Loss 0.16833309829235077
[Train] epoch 151 Batch 44 Loss 0.20666460692882538
[Train] epoch 151 Batch 45 Loss 0.2347428947687149
[Train] epoch 151 Batch 46 Loss 0.14205896854400635
[Train] epoch 151 Batch 47 Loss 0.10166621208190918
[Train] epoch 152 Batch 0 Loss 0.04053900018334389
[Train] epoch 152 Batch 1 Loss 0.0377650111913681
[Train] epoch 152 Batch 2 Loss 0.20639795064926147
[Train] epoch 152 Batch 3 Loss 0.1360568106174469
[Train] epoch 152 Batch 4 Loss 0.13968732953071594
[Train] epoch 152 Batch 5 Loss 0.24104687571525574
[Train] epoch 152 Batch 6 Loss 0.17071695625782013
[Train] epoch 152 Batch 7 Loss 0.2783810794353485
[Train] epoch 152 Batch 8 Loss 0.07538101822137833
[Train] epoch 152 Batch 9 Loss 0.27564242482185364
[Train] epoch 152 Batch 10 Loss 0.21127688884735107
[Train] epoch 152 Batch 11 Loss 0.10762409120798111
[Train] epoch 152 Batch 12 Loss 0.14225172996520996
[Train] epoch 152 Batch 13 Loss 0.2026655673980713
[Train] epoch 152 Batch 14 Loss 0.07222344726324081
[Train] epoch 152 Batch 15 Loss 0.31086504459381104
[Train] epoch 152 Batch 16 Loss 0.24273154139518738
[Train] epoch 152 Batch 17 Loss 0.24306681752204895
[Train] epoch 152 Batch 18 Loss 0.14174239337444305
[Train] epoch 152 Batch 19 Loss 0.20801502466201782
[Train] epoch 152 Batch 20 Loss 0.1038411557674408
[Train] epoch 152 Batch 21 Loss 0.2724854350090027
[Train] epoch 152 Batch 22 Loss 0.2061723917722702
[Train] epoch 152 Batch 23 Loss 0.2732256352901459
[Train] epoch 152 Batch 24 Loss 0.20655134320259094
[Train] epoch 152 Batch 25 Loss 0.24045515060424805
[Train] epoch 152 Batch 26 Loss 0.14130137860774994
[Train] epoch 152 Batch 27 Loss 0.07506552338600159
[Train] epoch 152 Batch 28 Loss 0.20264418423175812
[Train] epoch 152 Batch 29 Loss 0.07225710898637772
[Train] epoch 152 Batch 30 Loss 0.0778009295463562
[Train] epoch 152 Batch 31 Loss 0.24062296748161316
[Train] epoch 152 Batch 32 Loss 0.2751700282096863
[Train] epoch 152 Batch 33 Loss 0.20310480892658234
[Train] epoch 152 Batch 34 Loss 0.47260722517967224
[Train] epoch 152 Batch 35 Loss 0.13641797006130219
[Train] epoch 152 Batch 36 Loss 0.2088456153869629
[Train] epoch 152 Batch 37 Loss 0.0725637748837471
[Train] epoch 152 Batch 38 Loss 0.11007146537303925
[Train] epoch 152 Batch 39 Loss 0.10728517919778824
[Train] epoch 152 Batch 40 Loss 0.21466708183288574
[Train] epoch 152 Batch 41 Loss 0.07827659696340561
[Train] epoch 152 Batch 42 Loss 0.1044975072145462
[Train] epoch 152 Batch 43 Loss 0.2028905302286148
[Train] epoch 152 Batch 44 Loss 0.20572520792484283
[Train] epoch 152 Batch 45 Loss 0.23764139413833618
[Train] epoch 152 Batch 46 Loss 0.16810733079910278
[Train] epoch 152 Batch 47 Loss 0.24055975675582886
[Train] epoch 153 Batch 0 Loss 0.272303968667984
[Train] epoch 153 Batch 1 Loss 0.17951765656471252
[Train] epoch 153 Batch 2 Loss 0.3128092288970947
[Train] epoch 153 Batch 3 Loss 0.20874238014221191
[Train] epoch 153 Batch 4 Loss 0.2781558632850647
[Train] epoch 153 Batch 5 Loss 0.14445973932743073
[Train] epoch 153 Batch 6 Loss 0.10455550998449326
[Train] epoch 153 Batch 7 Loss 0.1710793823003769
[Train] epoch 153 Batch 8 Loss 0.07205771654844284
[Train] epoch 153 Batch 9 Loss 0.06970474869012833
[Train] epoch 153 Batch 10 Loss 0.24300867319107056
[Train] epoch 153 Batch 11 Loss 0.20265822112560272
[Train] epoch 153 Batch 12 Loss 0.10703418403863907
[Train] epoch 153 Batch 13 Loss 0.17910552024841309
[Train] epoch 153 Batch 14 Loss 0.20828169584274292
[Train] epoch 153 Batch 15 Loss 0.20800623297691345
[Train] epoch 153 Batch 16 Loss 0.3363707661628723
[Train] epoch 153 Batch 17 Loss 0.17588144540786743
[Train] epoch 153 Batch 18 Loss 0.27201274037361145
[Train] epoch 153 Batch 19 Loss 0.0747397169470787
[Train] epoch 153 Batch 20 Loss 0.1361229419708252
[Train] epoch 153 Batch 21 Loss 0.17069895565509796
[Train] epoch 153 Batch 22 Loss 0.13637018203735352
[Train] epoch 153 Batch 23 Loss 0.4074758291244507
[Train] epoch 153 Batch 24 Loss 0.03703703358769417
[Train] epoch 153 Batch 25 Loss 0.24281355738639832
[Train] epoch 153 Batch 26 Loss 0.1385006159543991
[Train] epoch 153 Batch 27 Loss 0.20791032910346985
[Train] epoch 153 Batch 28 Loss 0.14154651761054993
[Train] epoch 153 Batch 29 Loss 0.16818483173847198
[Train] epoch 153 Batch 30 Loss 0.07418541610240936
[Train] epoch 153 Batch 31 Loss 0.1384231001138687
[Train] epoch 153 Batch 32 Loss 0.005481709726154804
[Train] epoch 153 Batch 33 Loss 0.13821591436862946
[Train] epoch 153 Batch 34 Loss 0.2029927372932434
[Train] epoch 153 Batch 35 Loss 0.133334219455719
[Train] epoch 153 Batch 36 Loss 0.24054956436157227
[Train] epoch 153 Batch 37 Loss 0.20834064483642578
[Train] epoch 153 Batch 38 Loss 0.2068159282207489
[Train] epoch 153 Batch 39 Loss 0.17080625891685486
[Train] epoch 153 Batch 40 Loss 0.20536674559116364
[Train] epoch 153 Batch 41 Loss 0.2400514930486679
[Train] epoch 153 Batch 42 Loss 0.13885453343391418
[Train] epoch 153 Batch 43 Loss 0.17666864395141602
[Train] epoch 153 Batch 44 Loss 0.17086434364318848
[Train] epoch 153 Batch 45 Loss 0.17383302748203278
[Train] epoch 153 Batch 46 Loss 0.24586617946624756
[Train] epoch 153 Batch 47 Loss 0.14172503352165222
[Train] epoch 154 Batch 0 Loss 0.03750794380903244
[Train] epoch 154 Batch 1 Loss 0.06666764616966248
[Train] epoch 154 Batch 2 Loss 0.10969875752925873
[Train] epoch 154 Batch 3 Loss 0.07484334707260132
[Train] epoch 154 Batch 4 Loss 0.1413709819316864
[Train] epoch 154 Batch 5 Loss 0.20267769694328308
[Train] epoch 154 Batch 6 Loss 0.3045409023761749
[Train] epoch 154 Batch 7 Loss 0.17362698912620544
[Train] epoch 154 Batch 8 Loss 0.10398073494434357
[Train] epoch 154 Batch 9 Loss 0.21092712879180908
[Train] epoch 154 Batch 10 Loss 0.10388683527708054
[Train] epoch 154 Batch 11 Loss 0.17620587348937988
[Train] epoch 154 Batch 12 Loss 0.20542284846305847
[Train] epoch 154 Batch 13 Loss 0.11207272112369537
[Train] epoch 154 Batch 14 Loss 0.10663081705570221
[Train] epoch 154 Batch 15 Loss 0.17330411076545715
[Train] epoch 154 Batch 16 Loss 0.10709645599126816
[Train] epoch 154 Batch 17 Loss 0.07702263444662094
[Train] epoch 154 Batch 18 Loss 0.20305439829826355
[Train] epoch 154 Batch 19 Loss 0.17348402738571167
[Train] epoch 154 Batch 20 Loss 0.23791798949241638
[Train] epoch 154 Batch 21 Loss 0.14104309678077698
[Train] epoch 154 Batch 22 Loss 0.37340301275253296
[Train] epoch 154 Batch 23 Loss 0.1754922866821289
[Train] epoch 154 Batch 24 Loss 0.21039023995399475
[Train] epoch 154 Batch 25 Loss 0.13847249746322632
[Train] epoch 154 Batch 26 Loss 0.10602127015590668
[Train] epoch 154 Batch 27 Loss 0.23791953921318054
[Train] epoch 154 Batch 28 Loss 0.13604605197906494
[Train] epoch 154 Batch 29 Loss 0.23957699537277222
[Train] epoch 154 Batch 30 Loss 0.27443933486938477
[Train] epoch 154 Batch 31 Loss 0.03685741126537323
[Train] epoch 154 Batch 32 Loss 0.2027108371257782
[Train] epoch 154 Batch 33 Loss 0.2399103045463562
[Train] epoch 154 Batch 34 Loss 0.20575779676437378
[Train] epoch 154 Batch 35 Loss 0.10669521987438202
[Train] epoch 154 Batch 36 Loss 0.07171246409416199
[Train] epoch 154 Batch 37 Loss 0.3787280321121216
[Train] epoch 154 Batch 38 Loss 0.1782299280166626
[Train] epoch 154 Batch 39 Loss 0.17314159870147705
[Train] epoch 154 Batch 40 Loss 0.10421676933765411
[Train] epoch 154 Batch 41 Loss 0.1392151266336441
[Train] epoch 154 Batch 42 Loss 0.17105619609355927
[Train] epoch 154 Batch 43 Loss 0.3388859033584595
[Train] epoch 154 Batch 44 Loss 0.2403731346130371
[Train] epoch 154 Batch 45 Loss 0.26955676078796387
[Train] epoch 154 Batch 46 Loss 0.27497363090515137
[Train] epoch 154 Batch 47 Loss 0.34438827633857727
[Train] epoch 155 Batch 0 Loss 0.23754066228866577
[Train] epoch 155 Batch 1 Loss 0.20274916291236877
[Train] epoch 155 Batch 2 Loss 0.20831535756587982
[Train] epoch 155 Batch 3 Loss 0.23756439983844757
[Train] epoch 155 Batch 4 Loss 0.045151203870773315
[Train] epoch 155 Batch 5 Loss 0.2695083022117615
[Train] epoch 155 Batch 6 Loss 0.074851393699646
[Train] epoch 155 Batch 7 Loss 0.2054031491279602
[Train] epoch 155 Batch 8 Loss 0.10677099227905273
[Train] epoch 155 Batch 9 Loss 0.21104803681373596
[Train] epoch 155 Batch 10 Loss 0.0374571830034256
[Train] epoch 155 Batch 11 Loss 0.14415758848190308
[Train] epoch 155 Batch 12 Loss 0.1761491596698761
[Train] epoch 155 Batch 13 Loss 0.3469798266887665
[Train] epoch 155 Batch 14 Loss 0.11471910029649734
[Train] epoch 155 Batch 15 Loss 0.24267101287841797
[Train] epoch 155 Batch 16 Loss 0.3042108714580536
[Train] epoch 155 Batch 17 Loss 0.17321686446666718
[Train] epoch 155 Batch 18 Loss 0.2075132131576538
[Train] epoch 155 Batch 19 Loss 0.14352144300937653
[Train] epoch 155 Batch 20 Loss 0.17338059842586517
[Train] epoch 155 Batch 21 Loss 0.10640518367290497
[Train] epoch 155 Batch 22 Loss 0.10913741588592529
[Train] epoch 155 Batch 23 Loss 0.27801620960235596
[Train] epoch 155 Batch 24 Loss 0.10122016817331314
[Train] epoch 155 Batch 25 Loss 0.17293451726436615
[Train] epoch 155 Batch 26 Loss 0.23721832036972046
[Train] epoch 155 Batch 27 Loss 0.13632333278656006
[Train] epoch 155 Batch 28 Loss 0.17021961510181427
[Train] epoch 155 Batch 29 Loss 0.03460107743740082
[Train] epoch 155 Batch 30 Loss 0.10651864111423492
[Train] epoch 155 Batch 31 Loss 0.1753523349761963
[Train] epoch 155 Batch 32 Loss 0.14104866981506348
[Train] epoch 155 Batch 33 Loss 0.17088532447814941
[Train] epoch 155 Batch 34 Loss 0.1705322265625
[Train] epoch 155 Batch 35 Loss 0.17079530656337738
[Train] epoch 155 Batch 36 Loss 0.1707562953233719
[Train] epoch 155 Batch 37 Loss 0.14148832857608795
[Train] epoch 155 Batch 38 Loss 0.07434581220149994
[Train] epoch 155 Batch 39 Loss 0.27445685863494873
[Train] epoch 155 Batch 40 Loss 0.10124336183071136
[Train] epoch 155 Batch 41 Loss 0.2717013359069824
[Train] epoch 155 Batch 42 Loss 0.10406426340341568
[Train] epoch 155 Batch 43 Loss 0.30639952421188354
[Train] epoch 155 Batch 44 Loss 0.24238625168800354
[Train] epoch 155 Batch 45 Loss 0.20256945490837097
[Train] epoch 155 Batch 46 Loss 0.2717234492301941
[Train] epoch 155 Batch 47 Loss 0.3040679395198822
[Train] epoch 156 Batch 0 Loss 0.17062519490718842
[Train] epoch 156 Batch 1 Loss 0.17292165756225586
[Train] epoch 156 Batch 2 Loss 0.1730365753173828
[Train] epoch 156 Batch 3 Loss 0.27175000309944153
[Train] epoch 156 Batch 4 Loss 0.17025834321975708
[Train] epoch 156 Batch 5 Loss 0.10366792976856232
[Train] epoch 156 Batch 6 Loss 0.2025294303894043
[Train] epoch 156 Batch 7 Loss 0.16788294911384583
[Train] epoch 156 Batch 8 Loss 0.11077682673931122
[Train] epoch 156 Batch 9 Loss 0.17295175790786743
[Train] epoch 156 Batch 10 Loss 0.30135577917099
[Train] epoch 156 Batch 11 Loss 0.1407882124185562
[Train] epoch 156 Batch 12 Loss 0.20510411262512207
[Train] epoch 156 Batch 13 Loss 0.11289356648921967
[Train] epoch 156 Batch 14 Loss 0.11098431795835495
[Train] epoch 156 Batch 15 Loss 0.18286937475204468
[Train] epoch 156 Batch 16 Loss 0.13582873344421387
[Train] epoch 156 Batch 17 Loss 0.20777970552444458
[Train] epoch 156 Batch 18 Loss 0.20575645565986633
[Train] epoch 156 Batch 19 Loss 0.17066121101379395
[Train] epoch 156 Batch 20 Loss 0.20262321829795837
[Train] epoch 156 Batch 21 Loss 0.17612957954406738
[Train] epoch 156 Batch 22 Loss 0.10131794214248657
[Train] epoch 156 Batch 23 Loss 0.27744370698928833
[Train] epoch 156 Batch 24 Loss 0.005258158780634403
[Train] epoch 156 Batch 25 Loss 0.1760229766368866
[Train] epoch 156 Batch 26 Loss 0.17326119542121887
[Train] epoch 156 Batch 27 Loss 0.03991659730672836
[Train] epoch 156 Batch 28 Loss 0.20575779676437378
[Train] epoch 156 Batch 29 Loss 0.4052104949951172
[Train] epoch 156 Batch 30 Loss 0.2401588261127472
[Train] epoch 156 Batch 31 Loss 0.20543226599693298
[Train] epoch 156 Batch 32 Loss 0.373386949300766
[Train] epoch 156 Batch 33 Loss 0.13876144587993622
[Train] epoch 156 Batch 34 Loss 0.20524296164512634
[Train] epoch 156 Batch 35 Loss 0.242967426776886
[Train] epoch 156 Batch 36 Loss 0.10125952959060669
[Train] epoch 156 Batch 37 Loss 0.10573972761631012
[Train] epoch 156 Batch 38 Loss 0.27761924266815186
[Train] epoch 156 Batch 39 Loss 0.005344422068446875
[Train] epoch 156 Batch 40 Loss 0.1762581169605255
[Train] epoch 156 Batch 41 Loss 0.24314811825752258
[Train] epoch 156 Batch 42 Loss 0.10423050820827484
[Train] epoch 156 Batch 43 Loss 0.2028721570968628
[Train] epoch 156 Batch 44 Loss 0.14772987365722656
[Train] epoch 156 Batch 45 Loss 0.23474687337875366
[Train] epoch 156 Batch 46 Loss 0.07243648916482925
[Train] epoch 156 Batch 47 Loss 0.2786305248737335
[Train] epoch 157 Batch 0 Loss 0.14541444182395935
[Train] epoch 157 Batch 1 Loss 0.24377548694610596
[Train] epoch 157 Batch 2 Loss 0.27234795689582825
[Train] epoch 157 Batch 3 Loss 0.14200416207313538
[Train] epoch 157 Batch 4 Loss 1.0728851975727594e-06
[Train] epoch 157 Batch 5 Loss 0.1394014060497284
[Train] epoch 157 Batch 6 Loss 0.16815990209579468
[Train] epoch 157 Batch 7 Loss 0.20876982808113098
[Train] epoch 157 Batch 8 Loss 0.23781798779964447
[Train] epoch 157 Batch 9 Loss 0.07280208170413971
[Train] epoch 157 Batch 10 Loss 0.20303493738174438
[Train] epoch 157 Batch 11 Loss 0.14220526814460754
[Train] epoch 157 Batch 12 Loss 0.1769198179244995
[Train] epoch 157 Batch 13 Loss 0.17081527411937714
[Train] epoch 157 Batch 14 Loss 0.13900135457515717
[Train] epoch 157 Batch 15 Loss 0.17118939757347107
[Train] epoch 157 Batch 16 Loss 0.17712751030921936
[Train] epoch 157 Batch 17 Loss 0.17684514820575714
[Train] epoch 157 Batch 18 Loss 0.20576702058315277
[Train] epoch 157 Batch 19 Loss 0.17378687858581543
[Train] epoch 157 Batch 20 Loss 0.1709206998348236
[Train] epoch 157 Batch 21 Loss 0.17666631937026978
[Train] epoch 157 Batch 22 Loss 0.10723920166492462
[Train] epoch 157 Batch 23 Loss 0.10713351517915726
[Train] epoch 157 Batch 24 Loss 0.07508064806461334
[Train] epoch 157 Batch 25 Loss 0.2375137209892273
[Train] epoch 157 Batch 26 Loss 0.10415934026241302
[Train] epoch 157 Batch 27 Loss 0.3069069981575012
[Train] epoch 157 Batch 28 Loss 0.37358683347702026
[Train] epoch 157 Batch 29 Loss 0.3736043870449066
[Train] epoch 157 Batch 30 Loss 0.17625124752521515
[Train] epoch 157 Batch 31 Loss 0.17345674335956573
[Train] epoch 157 Batch 32 Loss 0.13610848784446716
[Train] epoch 157 Batch 33 Loss 0.20546668767929077
[Train] epoch 157 Batch 34 Loss 0.20812839269638062
[Train] epoch 157 Batch 35 Loss 0.44294822216033936
[Train] epoch 157 Batch 36 Loss 0.2748391330242157
[Train] epoch 157 Batch 37 Loss 0.10930871963500977
[Train] epoch 157 Batch 38 Loss 0.10658859461545944
[Train] epoch 157 Batch 39 Loss 0.20775528252124786
[Train] epoch 157 Batch 40 Loss 0.1731024831533432
[Train] epoch 157 Batch 41 Loss 0.3066865801811218
[Train] epoch 157 Batch 42 Loss 0.07433333247900009
[Train] epoch 157 Batch 43 Loss 0.1386592984199524
[Train] epoch 157 Batch 44 Loss 0.10392189025878906
[Train] epoch 157 Batch 45 Loss 0.10904315114021301
[Train] epoch 157 Batch 46 Loss 0.2399943470954895
[Train] epoch 157 Batch 47 Loss 0.03706633672118187
[Train] epoch 158 Batch 0 Loss 0.14106212556362152
[Train] epoch 158 Batch 1 Loss 0.1433977484703064
[Train] epoch 158 Batch 2 Loss 0.13851210474967957
[Train] epoch 158 Batch 3 Loss 0.2024381309747696
[Train] epoch 158 Batch 4 Loss 0.26666736602783203
[Train] epoch 158 Batch 5 Loss 0.26944518089294434
[Train] epoch 158 Batch 6 Loss 0.03923085331916809
[Train] epoch 158 Batch 7 Loss 0.17571711540222168
[Train] epoch 158 Batch 8 Loss 0.10629846155643463
[Train] epoch 158 Batch 9 Loss 0.23961104452610016
[Train] epoch 158 Batch 10 Loss 0.2051265835762024
[Train] epoch 158 Batch 11 Loss 0.2074112892150879
[Train] epoch 158 Batch 12 Loss 0.06895719468593597
[Train] epoch 158 Batch 13 Loss 0.27635955810546875
[Train] epoch 158 Batch 14 Loss 0.07207445055246353
[Train] epoch 158 Batch 15 Loss 0.20493444800376892
[Train] epoch 158 Batch 16 Loss 0.17283444106578827
[Train] epoch 158 Batch 17 Loss 0.23468726873397827
[Train] epoch 158 Batch 18 Loss 0.20258644223213196
[Train] epoch 158 Batch 19 Loss 0.07188522815704346
[Train] epoch 158 Batch 20 Loss 0.1386064887046814
[Train] epoch 158 Batch 21 Loss 0.1360277235507965
[Train] epoch 158 Batch 22 Loss 0.1386912614107132
[Train] epoch 158 Batch 23 Loss 0.1733325719833374
[Train] epoch 158 Batch 24 Loss 0.03464384377002716
[Train] epoch 158 Batch 25 Loss 0.2747880220413208
[Train] epoch 158 Batch 26 Loss 0.3094296455383301
[Train] epoch 158 Batch 27 Loss 0.173526793718338
[Train] epoch 158 Batch 28 Loss 0.2751547396183014
[Train] epoch 158 Batch 29 Loss 0.20273573696613312
[Train] epoch 158 Batch 30 Loss 0.31837743520736694
[Train] epoch 158 Batch 31 Loss 0.10129006206989288
[Train] epoch 158 Batch 32 Loss 0.20800606906414032
[Train] epoch 158 Batch 33 Loss 0.10687665641307831
[Train] epoch 158 Batch 34 Loss 0.43743330240249634
[Train] epoch 158 Batch 35 Loss 0.037657856941223145
[Train] epoch 158 Batch 36 Loss 0.24285808205604553
[Train] epoch 158 Batch 37 Loss 0.10671515762805939
[Train] epoch 158 Batch 38 Loss 0.18217507004737854
[Train] epoch 158 Batch 39 Loss 0.07789412885904312
[Train] epoch 158 Batch 40 Loss 0.11226151883602142
[Train] epoch 158 Batch 41 Loss 0.07771460711956024
[Train] epoch 158 Batch 42 Loss 0.1386806070804596
[Train] epoch 158 Batch 43 Loss 0.20526739954948425
[Train] epoch 158 Batch 44 Loss 0.23729529976844788
[Train] epoch 158 Batch 45 Loss 0.21336215734481812
[Train] epoch 158 Batch 46 Loss 0.1705898940563202
[Train] epoch 158 Batch 47 Loss 0.33860647678375244
[Train] epoch 159 Batch 0 Loss 0.2692500948905945
[Train] epoch 159 Batch 1 Loss 0.07193859666585922
[Train] epoch 159 Batch 2 Loss 0.14369630813598633
[Train] epoch 159 Batch 3 Loss 0.14111027121543884
[Train] epoch 159 Batch 4 Loss 0.1730651557445526
[Train] epoch 159 Batch 5 Loss 0.14101693034172058
[Train] epoch 159 Batch 6 Loss 0.10638178139925003
[Train] epoch 159 Batch 7 Loss 0.13589638471603394
[Train] epoch 159 Batch 8 Loss 0.27176138758659363
[Train] epoch 159 Batch 9 Loss 0.2741546630859375
[Train] epoch 159 Batch 10 Loss 0.10386824607849121
[Train] epoch 159 Batch 11 Loss 0.17289412021636963
[Train] epoch 159 Batch 12 Loss 0.23965831100940704
[Train] epoch 159 Batch 13 Loss 0.20739847421646118
[Train] epoch 159 Batch 14 Loss 0.13835088908672333
[Train] epoch 159 Batch 15 Loss 0.10365606099367142
[Train] epoch 159 Batch 16 Loss 0.20504646003246307
[Train] epoch 159 Batch 17 Loss 0.2071806788444519
[Train] epoch 159 Batch 18 Loss 0.17279595136642456
[Train] epoch 159 Batch 19 Loss 0.06924453377723694
[Train] epoch 159 Batch 20 Loss 0.13814371824264526
[Train] epoch 159 Batch 21 Loss 0.3382643163204193
[Train] epoch 159 Batch 22 Loss 0.23936551809310913
[Train] epoch 159 Batch 23 Loss 0.2025759518146515
[Train] epoch 159 Batch 24 Loss 0.34310609102249146
[Train] epoch 159 Batch 25 Loss 0.1426597535610199
[Train] epoch 159 Batch 26 Loss 0.03917907550930977
[Train] epoch 159 Batch 27 Loss 0.20925372838974
[Train] epoch 159 Batch 28 Loss 0.2022537887096405
[Train] epoch 159 Batch 29 Loss 0.13801974058151245
[Train] epoch 159 Batch 30 Loss 0.17229275405406952
[Train] epoch 159 Batch 31 Loss 0.17002302408218384
[Train] epoch 159 Batch 32 Loss 0.24158740043640137
[Train] epoch 159 Batch 33 Loss 0.0022297732066363096
[Train] epoch 159 Batch 34 Loss 0.13809403777122498
[Train] epoch 159 Batch 35 Loss 0.16994452476501465
[Train] epoch 159 Batch 36 Loss 0.20913434028625488
[Train] epoch 159 Batch 37 Loss 0.20473158359527588
[Train] epoch 159 Batch 38 Loss 0.10560528934001923
[Train] epoch 159 Batch 39 Loss 0.30321669578552246
[Train] epoch 159 Batch 40 Loss 0.13783332705497742
[Train] epoch 159 Batch 41 Loss 0.07111909240484238
[Train] epoch 159 Batch 42 Loss 0.30810457468032837
[Train] epoch 159 Batch 43 Loss 0.3129769265651703
[Train] epoch 159 Batch 44 Loss 0.2395428866147995
[Train] epoch 159 Batch 45 Loss 0.13587582111358643
[Train] epoch 159 Batch 46 Loss 0.0736076682806015
[Train] epoch 159 Batch 47 Loss 0.241839200258255
[Train] epoch 160 Batch 0 Loss 0.14050251245498657
[Train] epoch 160 Batch 1 Loss 0.3059014081954956
[Train] epoch 160 Batch 2 Loss 0.10854855179786682
[Train] epoch 160 Batch 3 Loss 0.07656805962324142
[Train] epoch 160 Batch 4 Loss 0.21104122698307037
[Train] epoch 160 Batch 5 Loss 0.10828214883804321
[Train] epoch 160 Batch 6 Loss 0.26912030577659607
[Train] epoch 160 Batch 7 Loss 0.10605266690254211
[Train] epoch 160 Batch 8 Loss 0.13823536038398743
[Train] epoch 160 Batch 9 Loss 0.3035847544670105
[Train] epoch 160 Batch 10 Loss 0.1383848637342453
[Train] epoch 160 Batch 11 Loss 0.17075687646865845
[Train] epoch 160 Batch 12 Loss 0.26666736602783203
[Train] epoch 160 Batch 13 Loss 0.26666736602783203
[Train] epoch 160 Batch 14 Loss 0.14090721309185028
[Train] epoch 160 Batch 15 Loss 0.1758282482624054
[Train] epoch 160 Batch 16 Loss 0.1752651035785675
[Train] epoch 160 Batch 17 Loss 0.23957642912864685
[Train] epoch 160 Batch 18 Loss 0.17044270038604736
[Train] epoch 160 Batch 19 Loss 0.24007055163383484
[Train] epoch 160 Batch 20 Loss 0.27155226469039917
[Train] epoch 160 Batch 21 Loss 0.24211204051971436
[Train] epoch 160 Batch 22 Loss 0.1406380534172058
[Train] epoch 160 Batch 23 Loss 0.2767794728279114
[Train] epoch 160 Batch 24 Loss 0.14573585987091064
[Train] epoch 160 Batch 25 Loss 0.10606187582015991
[Train] epoch 160 Batch 26 Loss 0.23951292037963867
[Train] epoch 160 Batch 27 Loss 0.27155160903930664
[Train] epoch 160 Batch 28 Loss 0.20995667576789856
[Train] epoch 160 Batch 29 Loss 0.13847334682941437
[Train] epoch 160 Batch 30 Loss 0.07403893023729324
[Train] epoch 160 Batch 31 Loss 0.3087546229362488
[Train] epoch 160 Batch 32 Loss 0.2716998755931854
[Train] epoch 160 Batch 33 Loss 0.14324317872524261
[Train] epoch 160 Batch 34 Loss 0.10379204154014587
[Train] epoch 160 Batch 35 Loss 0.07180319726467133
[Train] epoch 160 Batch 36 Loss 0.06920108199119568
[Train] epoch 160 Batch 37 Loss 0.10388633608818054
[Train] epoch 160 Batch 38 Loss 0.21614308655261993
[Train] epoch 160 Batch 39 Loss 0.26938897371292114
[Train] epoch 160 Batch 40 Loss 0.07507309317588806
[Train] epoch 160 Batch 41 Loss 0.03769237548112869
[Train] epoch 160 Batch 42 Loss 0.0720168873667717
[Train] epoch 160 Batch 43 Loss 0.20499274134635925
[Train] epoch 160 Batch 44 Loss 0.33909499645233154
[Train] epoch 160 Batch 45 Loss 0.272314190864563
[Train] epoch 160 Batch 46 Loss 0.10712610185146332
[Train] epoch 160 Batch 47 Loss 0.06666764616966248
[Train] epoch 161 Batch 0 Loss 0.13874009251594543
[Train] epoch 161 Batch 1 Loss 0.2725643515586853
[Train] epoch 161 Batch 2 Loss 0.3761683404445648
[Train] epoch 161 Batch 3 Loss 0.27207204699516296
[Train] epoch 161 Batch 4 Loss 0.1767352670431137
[Train] epoch 161 Batch 5 Loss 0.17395542562007904
[Train] epoch 161 Batch 6 Loss 0.14116732776165009
[Train] epoch 161 Batch 7 Loss 0.20490053296089172
[Train] epoch 161 Batch 8 Loss 0.03455808386206627
[Train] epoch 161 Batch 9 Loss 0.10122427344322205
[Train] epoch 161 Batch 10 Loss 0.16788998246192932
[Train] epoch 161 Batch 11 Loss 0.30998843908309937
[Train] epoch 161 Batch 12 Loss 0.20507723093032837
[Train] epoch 161 Batch 13 Loss 0.3386561870574951
[Train] epoch 161 Batch 14 Loss 0.10686659812927246
[Train] epoch 161 Batch 15 Loss 0.3385367691516876
[Train] epoch 161 Batch 16 Loss 0.14436732232570648
[Train] epoch 161 Batch 17 Loss 0.2081894725561142
[Train] epoch 161 Batch 18 Loss 0.1732528656721115
[Train] epoch 161 Batch 19 Loss 0.04296671599149704
[Train] epoch 161 Batch 20 Loss 0.27195048332214355
[Train] epoch 161 Batch 21 Loss 0.17052260041236877
[Train] epoch 161 Batch 22 Loss 0.1359003484249115
[Train] epoch 161 Batch 23 Loss 0.1359298825263977
[Train] epoch 161 Batch 24 Loss 0.14119374752044678
[Train] epoch 161 Batch 25 Loss 0.17318955063819885
[Train] epoch 161 Batch 26 Loss 0.18092183768749237
[Train] epoch 161 Batch 27 Loss 0.10391494631767273
[Train] epoch 161 Batch 28 Loss 0.10642461478710175
[Train] epoch 161 Batch 29 Loss 0.1754903793334961
[Train] epoch 161 Batch 30 Loss 0.06918784976005554
[Train] epoch 161 Batch 31 Loss 0.24468323588371277
[Train] epoch 161 Batch 32 Loss 0.2715298533439636
[Train] epoch 161 Batch 33 Loss 0.27424710988998413
[Train] epoch 161 Batch 34 Loss 0.1780066192150116
[Train] epoch 161 Batch 35 Loss 0.13829028606414795
[Train] epoch 161 Batch 36 Loss 0.1729159653186798
[Train] epoch 161 Batch 37 Loss 0.1704382598400116
[Train] epoch 161 Batch 38 Loss 0.20742379128932953
[Train] epoch 161 Batch 39 Loss 0.23947270214557648
[Train] epoch 161 Batch 40 Loss 0.10127514600753784
[Train] epoch 161 Batch 41 Loss 0.10849957168102264
[Train] epoch 161 Batch 42 Loss 0.07400353252887726
[Train] epoch 161 Batch 43 Loss 0.33834487199783325
[Train] epoch 161 Batch 44 Loss 0.20488286018371582
[Train] epoch 161 Batch 45 Loss 0.009542497806251049
[Train] epoch 161 Batch 46 Loss 0.2047640085220337
[Train] epoch 161 Batch 47 Loss 0.06911198794841766
[Train] epoch 162 Batch 0 Loss 0.3062079846858978
[Train] epoch 162 Batch 1 Loss 0.11290616542100906
[Train] epoch 162 Batch 2 Loss 0.06919487565755844
[Train] epoch 162 Batch 3 Loss 0.2095445841550827
[Train] epoch 162 Batch 4 Loss 0.14264321327209473
[Train] epoch 162 Batch 5 Loss 0.06907012313604355
[Train] epoch 162 Batch 6 Loss 0.10126322507858276
[Train] epoch 162 Batch 7 Loss 0.17455218732357025
[Train] epoch 162 Batch 8 Loss 0.2046276181936264
[Train] epoch 162 Batch 9 Loss 0.13585814833641052
[Train] epoch 162 Batch 10 Loss 0.10364867746829987
[Train] epoch 162 Batch 11 Loss 0.07342027127742767
[Train] epoch 162 Batch 12 Loss 0.14027594029903412
[Train] epoch 162 Batch 13 Loss 0.13992485404014587
[Train] epoch 162 Batch 14 Loss 0.24820013344287872
[Train] epoch 162 Batch 15 Loss 0.2045021951198578
[Train] epoch 162 Batch 16 Loss 0.2048587203025818
[Train] epoch 162 Batch 17 Loss 0.14032217860221863
[Train] epoch 162 Batch 18 Loss 0.3035740256309509
[Train] epoch 162 Batch 19 Loss 0.20504340529441833
[Train] epoch 162 Batch 20 Loss 0.14239326119422913
[Train] epoch 162 Batch 21 Loss 0.0343918576836586
[Train] epoch 162 Batch 22 Loss 0.10541313141584396
[Train] epoch 162 Batch 23 Loss 0.20682913064956665
[Train] epoch 162 Batch 24 Loss 0.3357897996902466
[Train] epoch 162 Batch 25 Loss 0.2737967371940613
[Train] epoch 162 Batch 26 Loss 0.20726680755615234
[Train] epoch 162 Batch 27 Loss 0.2394201159477234
[Train] epoch 162 Batch 28 Loss 0.1727730631828308
[Train] epoch 162 Batch 29 Loss 0.037047915160655975
[Train] epoch 162 Batch 30 Loss 0.17024171352386475
[Train] epoch 162 Batch 31 Loss 0.3407887816429138
[Train] epoch 162 Batch 32 Loss 0.17034471035003662
[Train] epoch 162 Batch 33 Loss 0.2741195261478424
[Train] epoch 162 Batch 34 Loss 0.17315298318862915
[Train] epoch 162 Batch 35 Loss 0.2346632182598114
[Train] epoch 162 Batch 36 Loss 0.13582362234592438
[Train] epoch 162 Batch 37 Loss 0.2051851451396942
[Train] epoch 162 Batch 38 Loss 0.20502373576164246
[Train] epoch 162 Batch 39 Loss 0.0720343366265297
[Train] epoch 162 Batch 40 Loss 0.2770659923553467
[Train] epoch 162 Batch 41 Loss 0.11193685233592987
[Train] epoch 162 Batch 42 Loss 0.30116334557533264
[Train] epoch 162 Batch 43 Loss 0.07969517260789871
[Train] epoch 162 Batch 44 Loss 0.13565793633460999
[Train] epoch 162 Batch 45 Loss 0.3013288378715515
[Train] epoch 162 Batch 46 Loss 0.13847245275974274
[Train] epoch 162 Batch 47 Loss 0.20790241658687592
[Train] epoch 163 Batch 0 Loss 0.14108839631080627
[Train] epoch 163 Batch 1 Loss 0.03449653089046478
[Train] epoch 163 Batch 2 Loss 0.20232555270195007
[Train] epoch 163 Batch 3 Loss 0.06925655901432037
[Train] epoch 163 Batch 4 Loss 0.17286068201065063
[Train] epoch 163 Batch 5 Loss 0.06922702491283417
[Train] epoch 163 Batch 6 Loss 0.34066930413246155
[Train] epoch 163 Batch 7 Loss 0.20720049738883972
[Train] epoch 163 Batch 8 Loss 0.3062141537666321
[Train] epoch 163 Batch 9 Loss 0.10881981253623962
[Train] epoch 163 Batch 10 Loss 0.17516012489795685
[Train] epoch 163 Batch 11 Loss 0.10368351638317108
[Train] epoch 163 Batch 12 Loss 0.13574083149433136
[Train] epoch 163 Batch 13 Loss 0.0714910700917244
[Train] epoch 163 Batch 14 Loss 0.2369517683982849
[Train] epoch 163 Batch 15 Loss 0.138142928481102
[Train] epoch 163 Batch 16 Loss 0.20237863063812256
[Train] epoch 163 Batch 17 Loss 0.07628125697374344
[Train] epoch 163 Batch 18 Loss 0.17508164048194885
[Train] epoch 163 Batch 19 Loss 0.4761052131652832
[Train] epoch 163 Batch 20 Loss 0.3035207986831665
[Train] epoch 163 Batch 21 Loss 0.10594689846038818
[Train] epoch 163 Batch 22 Loss 0.17016731202602386
[Train] epoch 163 Batch 23 Loss 0.13566073775291443
[Train] epoch 163 Batch 24 Loss 0.17950913310050964
[Train] epoch 163 Batch 25 Loss 0.24376939237117767
[Train] epoch 163 Batch 26 Loss 0.0367928184568882
[Train] epoch 163 Batch 27 Loss 0.33791452646255493
[Train] epoch 163 Batch 28 Loss 0.10343290865421295
[Train] epoch 163 Batch 29 Loss 0.1700712889432907
[Train] epoch 163 Batch 30 Loss 0.13790316879749298
[Train] epoch 163 Batch 31 Loss 0.20462943613529205
[Train] epoch 163 Batch 32 Loss 0.24337217211723328
[Train] epoch 163 Batch 33 Loss 0.24116791784763336
[Train] epoch 163 Batch 34 Loss 0.20455633103847504
[Train] epoch 163 Batch 35 Loss 0.10763496905565262
[Train] epoch 163 Batch 36 Loss 0.20450253784656525
[Train] epoch 163 Batch 37 Loss 0.2713639736175537
[Train] epoch 163 Batch 38 Loss 0.07104907929897308
[Train] epoch 163 Batch 39 Loss 0.07539650797843933
[Train] epoch 163 Batch 40 Loss 0.40423738956451416
[Train] epoch 163 Batch 41 Loss 0.2068297564983368
[Train] epoch 163 Batch 42 Loss 0.1722974181175232
[Train] epoch 163 Batch 43 Loss 0.2368575930595398
[Train] epoch 163 Batch 44 Loss 0.06875090301036835
[Train] epoch 163 Batch 45 Loss 0.17213097214698792
[Train] epoch 163 Batch 46 Loss 0.10735247284173965
[Train] epoch 163 Batch 47 Loss 0.20893965661525726
[Train] epoch 164 Batch 0 Loss 0.10306696593761444
[Train] epoch 164 Batch 1 Loss 0.27089908719062805
[Train] epoch 164 Batch 2 Loss 0.37002140283584595
[Train] epoch 164 Batch 3 Loss 0.1353554129600525
[Train] epoch 164 Batch 4 Loss 0.17841655015945435
[Train] epoch 164 Batch 5 Loss 0.10302837193012238
[Train] epoch 164 Batch 6 Loss 0.20450744032859802
[Train] epoch 164 Batch 7 Loss 0.2090795934200287
[Train] epoch 164 Batch 8 Loss 0.23883944749832153
[Train] epoch 164 Batch 9 Loss 0.27141690254211426
[Train] epoch 164 Batch 10 Loss 0.10698233544826508
[Train] epoch 164 Batch 11 Loss 0.0764206051826477
[Train] epoch 164 Batch 12 Loss 0.1750941276550293
[Train] epoch 164 Batch 13 Loss 0.10676774382591248
[Train] epoch 164 Batch 14 Loss 0.21290969848632812
[Train] epoch 164 Batch 15 Loss 0.17278054356575012
[Train] epoch 164 Batch 16 Loss 0.13580024242401123
[Train] epoch 164 Batch 17 Loss 0.2023467719554901
[Train] epoch 164 Batch 18 Loss 0.22270417213439941
[Train] epoch 164 Batch 19 Loss 0.10340899229049683
[Train] epoch 164 Batch 20 Loss 0.23681585490703583
[Train] epoch 164 Batch 21 Loss 0.21027545630931854
[Train] epoch 164 Batch 22 Loss 0.3057960569858551
[Train] epoch 164 Batch 23 Loss 0.1057080328464508
[Train] epoch 164 Batch 24 Loss 0.0735546350479126
[Train] epoch 164 Batch 25 Loss 0.2366877794265747
[Train] epoch 164 Batch 26 Loss 0.2708160877227783
[Train] epoch 164 Batch 27 Loss 0.13788259029388428
[Train] epoch 164 Batch 28 Loss 0.13800489902496338
[Train] epoch 164 Batch 29 Loss 0.2415434569120407
[Train] epoch 164 Batch 30 Loss 0.17499038577079773
[Train] epoch 164 Batch 31 Loss 0.177669957280159
[Train] epoch 164 Batch 32 Loss 0.1704919934272766
[Train] epoch 164 Batch 33 Loss 0.17294645309448242
[Train] epoch 164 Batch 34 Loss 0.13834211230278015
[Train] epoch 164 Batch 35 Loss 0.034532155841588974
[Train] epoch 164 Batch 36 Loss 0.20238977670669556
[Train] epoch 164 Batch 37 Loss 0.17307230830192566
[Train] epoch 164 Batch 38 Loss 0.2158612757921219
[Train] epoch 164 Batch 39 Loss 0.17309489846229553
[Train] epoch 164 Batch 40 Loss 0.04248349368572235
[Train] epoch 164 Batch 41 Loss 0.2368924766778946
[Train] epoch 164 Batch 42 Loss 0.133334219455719
[Train] epoch 164 Batch 43 Loss 0.17269712686538696
[Train] epoch 164 Batch 44 Loss 0.3751831650733948
[Train] epoch 164 Batch 45 Loss 0.13827820122241974
[Train] epoch 164 Batch 46 Loss 0.17284177243709564
[Train] epoch 164 Batch 47 Loss 0.14069315791130066
[Train] epoch 165 Batch 0 Loss 0.23961886763572693
[Train] epoch 165 Batch 1 Loss 0.1409025639295578
[Train] epoch 165 Batch 2 Loss 0.2075851559638977
[Train] epoch 165 Batch 3 Loss 0.17277556657791138
[Train] epoch 165 Batch 4 Loss 0.0736449733376503
[Train] epoch 165 Batch 5 Loss 0.1033770814538002
[Train] epoch 165 Batch 6 Loss 0.1379401534795761
[Train] epoch 165 Batch 7 Loss 0.10391350090503693
[Train] epoch 165 Batch 8 Loss 0.07362280040979385
[Train] epoch 165 Batch 9 Loss 0.3060370087623596
[Train] epoch 165 Batch 10 Loss 0.24166740477085114
[Train] epoch 165 Batch 11 Loss 0.1728334128856659
[Train] epoch 165 Batch 12 Loss 0.1371651589870453
[Train] epoch 165 Batch 13 Loss 0.2145281732082367
[Train] epoch 165 Batch 14 Loss 0.2028573602437973
[Train] epoch 165 Batch 15 Loss 0.21705476939678192
[Train] epoch 165 Batch 16 Loss 0.07395537197589874
[Train] epoch 165 Batch 17 Loss 0.0385262705385685
[Train] epoch 165 Batch 18 Loss 0.20474332571029663
[Train] epoch 165 Batch 19 Loss 0.06900578737258911
[Train] epoch 165 Batch 20 Loss 0.2690090239048004
[Train] epoch 165 Batch 21 Loss 0.27419769763946533
[Train] epoch 165 Batch 22 Loss 0.07451936602592468
[Train] epoch 165 Batch 23 Loss 0.27157992124557495
[Train] epoch 165 Batch 24 Loss 0.23985570669174194
[Train] epoch 165 Batch 25 Loss 0.1042151004076004
[Train] epoch 165 Batch 26 Loss 0.17923998832702637
[Train] epoch 165 Batch 27 Loss 0.17335650324821472
[Train] epoch 165 Batch 28 Loss 0.14122110605239868
[Train] epoch 165 Batch 29 Loss 0.17306587100028992
[Train] epoch 165 Batch 30 Loss 0.1680135428905487
[Train] epoch 165 Batch 31 Loss 0.03736729174852371
[Train] epoch 165 Batch 32 Loss 0.20497696101665497
[Train] epoch 165 Batch 33 Loss 0.1678519994020462
[Train] epoch 165 Batch 34 Loss 0.2715730667114258
[Train] epoch 165 Batch 35 Loss 0.17346569895744324
[Train] epoch 165 Batch 36 Loss 0.274711936712265
[Train] epoch 165 Batch 37 Loss 0.21033847332000732
[Train] epoch 165 Batch 38 Loss 0.26666736602783203
[Train] epoch 165 Batch 39 Loss 0.17363284528255463
[Train] epoch 165 Batch 40 Loss 0.3062288165092468
[Train] epoch 165 Batch 41 Loss 0.2104598879814148
[Train] epoch 165 Batch 42 Loss 0.14152070879936218
[Train] epoch 165 Batch 43 Loss 0.10681948065757751
[Train] epoch 165 Batch 44 Loss 0.33838170766830444
[Train] epoch 165 Batch 45 Loss 0.07175338268280029
[Train] epoch 165 Batch 46 Loss 0.20780092477798462
[Train] epoch 165 Batch 47 Loss 0.24219179153442383
[Train] epoch 166 Batch 0 Loss 0.20476843416690826
[Train] epoch 166 Batch 1 Loss 0.1756000816822052
[Train] epoch 166 Batch 2 Loss 0.1409633457660675
[Train] epoch 166 Batch 3 Loss 0.21004493534564972
[Train] epoch 166 Batch 4 Loss 0.1383247971534729
[Train] epoch 166 Batch 5 Loss 0.2717491388320923
[Train] epoch 166 Batch 6 Loss 0.16786186397075653
[Train] epoch 166 Batch 7 Loss 0.17277328670024872
[Train] epoch 166 Batch 8 Loss 0.13826008141040802
[Train] epoch 166 Batch 9 Loss 0.1381467580795288
[Train] epoch 166 Batch 10 Loss 0.20482409000396729
[Train] epoch 166 Batch 11 Loss 0.20716598629951477
[Train] epoch 166 Batch 12 Loss 0.1702708601951599
[Train] epoch 166 Batch 13 Loss 0.13803714513778687
[Train] epoch 166 Batch 14 Loss 0.10834459960460663
[Train] epoch 166 Batch 15 Loss 0.14073756337165833
[Train] epoch 166 Batch 16 Loss 0.10606379806995392
[Train] epoch 166 Batch 17 Loss 0.13579440116882324
[Train] epoch 166 Batch 18 Loss 0.20987218618392944
[Train] epoch 166 Batch 19 Loss 0.1705152988433838
[Train] epoch 166 Batch 20 Loss 0.17059224843978882
[Train] epoch 166 Batch 21 Loss 0.1435401290655136
[Train] epoch 166 Batch 22 Loss 0.34108036756515503
[Train] epoch 166 Batch 23 Loss 0.21011880040168762
[Train] epoch 166 Batch 24 Loss 0.3386176526546478
[Train] epoch 166 Batch 25 Loss 0.20482689142227173
[Train] epoch 166 Batch 26 Loss 0.24245598912239075
[Train] epoch 166 Batch 27 Loss 0.4396008253097534
[Train] epoch 166 Batch 28 Loss 0.10683496296405792
[Train] epoch 166 Batch 29 Loss 0.23990359902381897
[Train] epoch 166 Batch 30 Loss 0.14413997530937195
[Train] epoch 166 Batch 31 Loss 0.13790133595466614
[Train] epoch 166 Batch 32 Loss 0.2051694393157959
[Train] epoch 166 Batch 33 Loss 0.1441468894481659
[Train] epoch 166 Batch 34 Loss 0.37265658378601074
[Train] epoch 166 Batch 35 Loss 0.13876613974571228
[Train] epoch 166 Batch 36 Loss 0.10935703665018082
[Train] epoch 166 Batch 37 Loss 0.10392411053180695
[Train] epoch 166 Batch 38 Loss 0.10424091666936874
[Train] epoch 166 Batch 39 Loss 0.1700727641582489
[Train] epoch 166 Batch 40 Loss 0.07478709518909454
[Train] epoch 166 Batch 41 Loss 0.1416759490966797
[Train] epoch 166 Batch 42 Loss 0.20227110385894775
[Train] epoch 166 Batch 43 Loss 0.17049846053123474
[Train] epoch 166 Batch 44 Loss 0.06934784352779388
[Train] epoch 166 Batch 45 Loss 0.23983269929885864
[Train] epoch 166 Batch 46 Loss 0.10626209527254105
[Train] epoch 166 Batch 47 Loss 0.17046791315078735
[Train] epoch 167 Batch 0 Loss 0.13579407334327698
[Train] epoch 167 Batch 1 Loss 0.27166688442230225
[Train] epoch 167 Batch 2 Loss 0.1700747311115265
[Train] epoch 167 Batch 3 Loss 0.1700761318206787
[Train] epoch 167 Batch 4 Loss 0.2790212035179138
[Train] epoch 167 Batch 5 Loss 0.1357191652059555
[Train] epoch 167 Batch 6 Loss 0.20497483015060425
[Train] epoch 167 Batch 7 Loss 0.30363893508911133
[Train] epoch 167 Batch 8 Loss 0.14339011907577515
[Train] epoch 167 Batch 9 Loss 0.23960557579994202
[Train] epoch 167 Batch 10 Loss 0.133334219455719
[Train] epoch 167 Batch 11 Loss 0.04188966006040573
[Train] epoch 167 Batch 12 Loss 0.13575264811515808
[Train] epoch 167 Batch 13 Loss 0.20463091135025024
[Train] epoch 167 Batch 14 Loss 0.34266287088394165
[Train] epoch 167 Batch 15 Loss 0.04408174753189087
[Train] epoch 167 Batch 16 Loss 0.2070000022649765
[Train] epoch 167 Batch 17 Loss 0.27591991424560547
[Train] epoch 167 Batch 18 Loss 0.10574222356081009
[Train] epoch 167 Batch 19 Loss 0.2758810222148895
[Train] epoch 167 Batch 20 Loss 0.17468100786209106
[Train] epoch 167 Batch 21 Loss 0.3034399151802063
[Train] epoch 167 Batch 22 Loss 0.1723122000694275
[Train] epoch 167 Batch 23 Loss 0.17226994037628174
[Train] epoch 167 Batch 24 Loss 0.13556811213493347
[Train] epoch 167 Batch 25 Loss 0.20448434352874756
[Train] epoch 167 Batch 26 Loss 0.07116685062646866
[Train] epoch 167 Batch 27 Loss 0.13772499561309814
[Train] epoch 167 Batch 28 Loss 0.18132035434246063
[Train] epoch 167 Batch 29 Loss 0.20672108232975006
[Train] epoch 167 Batch 30 Loss 0.2390713095664978
[Train] epoch 167 Batch 31 Loss 0.23670139908790588
[Train] epoch 167 Batch 32 Loss 0.10601367801427841
[Train] epoch 167 Batch 33 Loss 0.10355721414089203
[Train] epoch 167 Batch 34 Loss 0.17235848307609558
[Train] epoch 167 Batch 35 Loss 0.1380656659603119
[Train] epoch 167 Batch 36 Loss 0.03988667577505112
[Train] epoch 167 Batch 37 Loss 0.23950430750846863
[Train] epoch 167 Batch 38 Loss 0.23699630796909332
[Train] epoch 167 Batch 39 Loss 0.20976850390434265
[Train] epoch 167 Batch 40 Loss 1.0728851975727594e-06
[Train] epoch 167 Batch 41 Loss 0.0690208300948143
[Train] epoch 167 Batch 42 Loss 0.17277340590953827
[Train] epoch 167 Batch 43 Loss 0.03698224946856499
[Train] epoch 167 Batch 44 Loss 0.37273675203323364
[Train] epoch 167 Batch 45 Loss 0.3084920048713684
[Train] epoch 167 Batch 46 Loss 0.10849669575691223
[Train] epoch 167 Batch 47 Loss 0.20247158408164978
[Train] epoch 168 Batch 0 Loss 0.17519083619117737
[Train] epoch 168 Batch 1 Loss 0.10839813947677612
[Train] epoch 168 Batch 2 Loss 0.1382824182510376
[Train] epoch 168 Batch 3 Loss 0.2762995958328247
[Train] epoch 168 Batch 4 Loss 0.10539107024669647
[Train] epoch 168 Batch 5 Loss 0.03698156774044037
[Train] epoch 168 Batch 6 Loss 0.10375376045703888
[Train] epoch 168 Batch 7 Loss 0.14095419645309448
[Train] epoch 168 Batch 8 Loss 0.20781496167182922
[Train] epoch 168 Batch 9 Loss 0.23994575440883636
[Train] epoch 168 Batch 10 Loss 0.17349809408187866
[Train] epoch 168 Batch 11 Loss 0.2691177725791931
[Train] epoch 168 Batch 12 Loss 0.2719230651855469
[Train] epoch 168 Batch 13 Loss 0.10649938136339188
[Train] epoch 168 Batch 14 Loss 0.13864924013614655
[Train] epoch 168 Batch 15 Loss 0.2773115038871765
[Train] epoch 168 Batch 16 Loss 0.2752212882041931
[Train] epoch 168 Batch 17 Loss 0.2429119050502777
[Train] epoch 168 Batch 18 Loss 0.13844913244247437
[Train] epoch 168 Batch 19 Loss 0.34793800115585327
[Train] epoch 168 Batch 20 Loss 0.10685794800519943
[Train] epoch 168 Batch 21 Loss 0.2345389425754547
[Train] epoch 168 Batch 22 Loss 0.40535610914230347
[Train] epoch 168 Batch 23 Loss 0.069582998752594
[Train] epoch 168 Batch 24 Loss 0.36787039041519165
[Train] epoch 168 Batch 25 Loss 0.03749939799308777
[Train] epoch 168 Batch 26 Loss 0.3129739761352539
[Train] epoch 168 Batch 27 Loss 0.06960137188434601
[Train] epoch 168 Batch 28 Loss 0.13840268552303314
[Train] epoch 168 Batch 29 Loss 0.133334219455719
[Train] epoch 168 Batch 30 Loss 0.04630276560783386
[Train] epoch 168 Batch 31 Loss 0.07192355394363403
[Train] epoch 168 Batch 32 Loss 0.21087679266929626
[Train] epoch 168 Batch 33 Loss 0.10981106758117676
[Train] epoch 168 Batch 34 Loss 0.10361481457948685
[Train] epoch 168 Batch 35 Loss 0.17062553763389587
[Train] epoch 168 Batch 36 Loss 0.3120325803756714
[Train] epoch 168 Batch 37 Loss 0.10121004283428192
[Train] epoch 168 Batch 38 Loss 0.1732621043920517
[Train] epoch 168 Batch 39 Loss 0.10398253798484802
[Train] epoch 168 Batch 40 Loss 0.03730010986328125
[Train] epoch 168 Batch 41 Loss 0.10906875133514404
[Train] epoch 168 Batch 42 Loss 0.24206769466400146
[Train] epoch 168 Batch 43 Loss 0.2421388179063797
[Train] epoch 168 Batch 44 Loss 0.2049073576927185
[Train] epoch 168 Batch 45 Loss 0.1384100317955017
[Train] epoch 168 Batch 46 Loss 0.3382261395454407
[Train] epoch 168 Batch 47 Loss 0.23953592777252197
[Train] epoch 169 Batch 0 Loss 0.23702217638492584
[Train] epoch 169 Batch 1 Loss 0.27646178007125854
[Train] epoch 169 Batch 2 Loss 0.20975591242313385
[Train] epoch 169 Batch 3 Loss 0.33820563554763794
[Train] epoch 169 Batch 4 Loss 0.17268191277980804
[Train] epoch 169 Batch 5 Loss 0.07388827204704285
[Train] epoch 169 Batch 6 Loss 0.1059482991695404
[Train] epoch 169 Batch 7 Loss 0.17025017738342285
[Train] epoch 169 Batch 8 Loss 0.30366140604019165
[Train] epoch 169 Batch 9 Loss 0.13564792275428772
[Train] epoch 169 Batch 10 Loss 0.10366284847259521
[Train] epoch 169 Batch 11 Loss 0.11274782568216324
[Train] epoch 169 Batch 12 Loss 0.17252415418624878
[Train] epoch 169 Batch 13 Loss 0.10565720498561859
[Train] epoch 169 Batch 14 Loss 0.1402433216571808
[Train] epoch 169 Batch 15 Loss 0.17462679743766785
[Train] epoch 169 Batch 16 Loss 0.17231464385986328
[Train] epoch 169 Batch 17 Loss 0.20218124985694885
[Train] epoch 169 Batch 18 Loss 0.34026333689689636
[Train] epoch 169 Batch 19 Loss 0.14026525616645813
[Train] epoch 169 Batch 20 Loss 0.2414473295211792
[Train] epoch 169 Batch 21 Loss 0.17233490943908691
[Train] epoch 169 Batch 22 Loss 0.04082506522536278
[Train] epoch 169 Batch 23 Loss 0.0712297260761261
[Train] epoch 169 Batch 24 Loss 0.24088826775550842
[Train] epoch 169 Batch 25 Loss 0.10853341221809387
[Train] epoch 169 Batch 26 Loss 0.0733204185962677
[Train] epoch 169 Batch 27 Loss 0.27354711294174194
[Train] epoch 169 Batch 28 Loss 0.30353593826293945
[Train] epoch 169 Batch 29 Loss 0.20472727715969086
[Train] epoch 169 Batch 30 Loss 0.27618324756622314
[Train] epoch 169 Batch 31 Loss 0.17513403296470642
[Train] epoch 169 Batch 32 Loss 0.07153695821762085
[Train] epoch 169 Batch 33 Loss 0.30379706621170044
[Train] epoch 169 Batch 34 Loss 0.23921972513198853
[Train] epoch 169 Batch 35 Loss 0.17528614401817322
[Train] epoch 169 Batch 36 Loss 0.16781747341156006
[Train] epoch 169 Batch 37 Loss 0.13577702641487122
[Train] epoch 169 Batch 38 Loss 0.03729035705327988
[Train] epoch 169 Batch 39 Loss 0.10378281027078629
[Train] epoch 169 Batch 40 Loss 0.23981663584709167
[Train] epoch 169 Batch 41 Loss 0.17294958233833313
[Train] epoch 169 Batch 42 Loss 0.13581189513206482
[Train] epoch 169 Batch 43 Loss 0.17048555612564087
[Train] epoch 169 Batch 44 Loss 0.20722505450248718
[Train] epoch 169 Batch 45 Loss 0.3040425181388855
[Train] epoch 169 Batch 46 Loss 0.0689295083284378
[Train] epoch 169 Batch 47 Loss 0.17046937346458435
[Train] epoch 170 Batch 0 Loss 0.20515191555023193
[Train] epoch 170 Batch 1 Loss 0.03979836031794548
[Train] epoch 170 Batch 2 Loss 0.2022523283958435
[Train] epoch 170 Batch 3 Loss 0.3113069534301758
[Train] epoch 170 Batch 4 Loss 0.23446056246757507
[Train] epoch 170 Batch 5 Loss 0.1730661392211914
[Train] epoch 170 Batch 6 Loss 0.10881853103637695
[Train] epoch 170 Batch 7 Loss 0.17299211025238037
[Train] epoch 170 Batch 8 Loss 0.2739450931549072
[Train] epoch 170 Batch 9 Loss 0.13814705610275269
[Train] epoch 170 Batch 10 Loss 0.3011249899864197
[Train] epoch 170 Batch 11 Loss 0.07416504621505737
[Train] epoch 170 Batch 12 Loss 0.3081715404987335
[Train] epoch 170 Batch 13 Loss 0.20477664470672607
[Train] epoch 170 Batch 14 Loss 0.17028498649597168
[Train] epoch 170 Batch 15 Loss 0.17280396819114685
[Train] epoch 170 Batch 16 Loss 0.2418021410703659
[Train] epoch 170 Batch 17 Loss 0.16779206693172455
[Train] epoch 170 Batch 18 Loss 0.0740237683057785
[Train] epoch 170 Batch 19 Loss 0.2047814428806305
[Train] epoch 170 Batch 20 Loss 0.17012906074523926
[Train] epoch 170 Batch 21 Loss 0.13800252974033356
[Train] epoch 170 Batch 22 Loss 0.20479795336723328
[Train] epoch 170 Batch 23 Loss 0.33571916818618774
[Train] epoch 170 Batch 24 Loss 0.204504132270813
[Train] epoch 170 Batch 25 Loss 0.140333890914917
[Train] epoch 170 Batch 26 Loss 0.20923727750778198
[Train] epoch 170 Batch 27 Loss 0.20685648918151855
[Train] epoch 170 Batch 28 Loss 0.10806078463792801
[Train] epoch 170 Batch 29 Loss 0.14020133018493652
[Train] epoch 170 Batch 30 Loss 0.17231939733028412
[Train] epoch 170 Batch 31 Loss 0.1723238080739975
[Train] epoch 170 Batch 32 Loss 0.0711706131696701
[Train] epoch 170 Batch 33 Loss 0.10560405999422073
[Train] epoch 170 Batch 34 Loss 0.3100648522377014
[Train] epoch 170 Batch 35 Loss 0.20441557466983795
[Train] epoch 170 Batch 36 Loss 0.002209331840276718
[Train] epoch 170 Batch 37 Loss 0.2021905779838562
[Train] epoch 170 Batch 38 Loss 0.27108025550842285
[Train] epoch 170 Batch 39 Loss 0.16991554200649261
[Train] epoch 170 Batch 40 Loss 0.13767513632774353
[Train] epoch 170 Batch 41 Loss 0.1399289220571518
[Train] epoch 170 Batch 42 Loss 0.10545891523361206
[Train] epoch 170 Batch 43 Loss 0.1011287271976471
[Train] epoch 170 Batch 44 Loss 0.24296605587005615
[Train] epoch 170 Batch 45 Loss 0.17424100637435913
[Train] epoch 170 Batch 46 Loss 0.17405365407466888
[Train] epoch 170 Batch 47 Loss 0.17400160431861877
[Train] epoch 171 Batch 0 Loss 0.370047926902771
[Train] epoch 171 Batch 1 Loss 0.13752222061157227
[Train] epoch 171 Batch 2 Loss 0.040455352514982224
[Train] epoch 171 Batch 3 Loss 0.26880261301994324
[Train] epoch 171 Batch 4 Loss 0.20439571142196655
[Train] epoch 171 Batch 5 Loss 0.03647875413298607
[Train] epoch 171 Batch 6 Loss 0.10298880934715271
[Train] epoch 171 Batch 7 Loss 0.004689487628638744
[Train] epoch 171 Batch 8 Loss 0.0689062774181366
[Train] epoch 171 Batch 9 Loss 0.10328194499015808
[Train] epoch 171 Batch 10 Loss 0.23878857493400574
[Train] epoch 171 Batch 11 Loss 0.23445475101470947
[Train] epoch 171 Batch 12 Loss 0.10338929295539856
[Train] epoch 171 Batch 13 Loss 0.20225435495376587
[Train] epoch 171 Batch 14 Loss 0.1769605278968811
[Train] epoch 171 Batch 15 Loss 0.23453962802886963
[Train] epoch 171 Batch 16 Loss 0.17726582288742065
[Train] epoch 171 Batch 17 Loss 0.2712966203689575
[Train] epoch 171 Batch 18 Loss 0.2711293697357178
[Train] epoch 171 Batch 19 Loss 0.1432643085718155
[Train] epoch 171 Batch 20 Loss 0.1677820086479187
[Train] epoch 171 Batch 21 Loss 0.20708128809928894
[Train] epoch 171 Batch 22 Loss 0.14037859439849854
[Train] epoch 171 Batch 23 Loss 0.2434988021850586
[Train] epoch 171 Batch 24 Loss 0.14007729291915894
[Train] epoch 171 Batch 25 Loss 0.1766093373298645
[Train] epoch 171 Batch 26 Loss 0.17429091036319733
[Train] epoch 171 Batch 27 Loss 0.10337748378515244
[Train] epoch 171 Batch 28 Loss 0.27542412281036377
[Train] epoch 171 Batch 29 Loss 0.24069005250930786
[Train] epoch 171 Batch 30 Loss 0.33761924505233765
[Train] epoch 171 Batch 31 Loss 0.2364450991153717
[Train] epoch 171 Batch 32 Loss 0.10895495861768723
[Train] epoch 171 Batch 33 Loss 0.16811364889144897
[Train] epoch 171 Batch 34 Loss 0.03846669942140579
[Train] epoch 171 Batch 35 Loss 0.2730427384376526
[Train] epoch 171 Batch 36 Loss 0.0729665458202362
[Train] epoch 171 Batch 37 Loss 0.10333013534545898
[Train] epoch 171 Batch 38 Loss 0.3721757233142853
[Train] epoch 171 Batch 39 Loss 0.10111840069293976
[Train] epoch 171 Batch 40 Loss 0.2779684066772461
[Train] epoch 171 Batch 41 Loss 0.20460321009159088
[Train] epoch 171 Batch 42 Loss 0.06666764616966248
[Train] epoch 171 Batch 43 Loss 0.1380212903022766
[Train] epoch 171 Batch 44 Loss 0.13796037435531616
[Train] epoch 171 Batch 45 Loss 0.20456834137439728
[Train] epoch 171 Batch 46 Loss 0.3423130512237549
[Train] epoch 171 Batch 47 Loss 0.11293160915374756
[Train] epoch 172 Batch 0 Loss 0.13552892208099365
[Train] epoch 172 Batch 1 Loss 0.0705433189868927
[Train] epoch 172 Batch 2 Loss 0.14032940566539764
[Train] epoch 172 Batch 3 Loss 0.20458021759986877
[Train] epoch 172 Batch 4 Loss 0.0529840886592865
[Train] epoch 172 Batch 5 Loss 0.10827435553073883
[Train] epoch 172 Batch 6 Loss 0.2021406590938568
[Train] epoch 172 Batch 7 Loss 0.08713938295841217
[Train] epoch 172 Batch 8 Loss 0.1730567216873169
[Train] epoch 172 Batch 9 Loss 0.2047927975654602
[Train] epoch 172 Batch 10 Loss 0.1405034065246582
[Train] epoch 172 Batch 11 Loss 0.1748964786529541
[Train] epoch 172 Batch 12 Loss 0.2711578607559204
[Train] epoch 172 Batch 13 Loss 0.1403682678937912
[Train] epoch 172 Batch 14 Loss 0.3085445165634155
[Train] epoch 172 Batch 15 Loss 0.2737232446670532
[Train] epoch 172 Batch 16 Loss 0.06666764616966248
[Train] epoch 172 Batch 17 Loss 0.23683002591133118
[Train] epoch 172 Batch 18 Loss 0.2416447103023529
[Train] epoch 172 Batch 19 Loss 0.17965339124202728
[Train] epoch 172 Batch 20 Loss 0.072768434882164
[Train] epoch 172 Batch 21 Loss 0.20457500219345093
[Train] epoch 172 Batch 22 Loss 0.23674480617046356
[Train] epoch 172 Batch 23 Loss 0.31073451042175293
[Train] epoch 172 Batch 24 Loss 0.24277392029762268
[Train] epoch 172 Batch 25 Loss 0.10399080067873001
[Train] epoch 172 Batch 26 Loss 0.14097122848033905
[Train] epoch 172 Batch 27 Loss 0.13545063138008118
[Train] epoch 172 Batch 28 Loss 0.1414591372013092
[Train] epoch 172 Batch 29 Loss 0.3412174582481384
[Train] epoch 172 Batch 30 Loss 0.13792264461517334
[Train] epoch 172 Batch 31 Loss 0.240371972322464
[Train] epoch 172 Batch 32 Loss 0.3356552720069885
[Train] epoch 172 Batch 33 Loss 0.1733909398317337
[Train] epoch 172 Batch 34 Loss 0.24991032481193542
[Train] epoch 172 Batch 35 Loss 0.2576456069946289
[Train] epoch 172 Batch 36 Loss 0.10424630343914032
[Train] epoch 172 Batch 37 Loss 0.04199671000242233
[Train] epoch 172 Batch 38 Loss 0.11680445820093155
[Train] epoch 172 Batch 39 Loss 0.3617514669895172
[Train] epoch 172 Batch 40 Loss 0.27512887120246887
[Train] epoch 172 Batch 41 Loss 0.24093928933143616
[Train] epoch 172 Batch 42 Loss 0.3055907189846039
[Train] epoch 172 Batch 43 Loss 0.25760746002197266
[Train] epoch 172 Batch 44 Loss 0.10862374305725098
[Train] epoch 172 Batch 45 Loss 0.36819082498550415
[Train] epoch 172 Batch 46 Loss 0.14261972904205322
[Train] epoch 172 Batch 47 Loss 0.21977409720420837
[Train] epoch 173 Batch 0 Loss 0.4228106737136841
[Train] epoch 173 Batch 1 Loss 0.2036639004945755
[Train] epoch 173 Batch 2 Loss 0.1423364281654358
[Train] epoch 173 Batch 3 Loss 0.1405256986618042
[Train] epoch 173 Batch 4 Loss 0.2818469703197479
[Train] epoch 173 Batch 5 Loss 0.31003379821777344
[Train] epoch 173 Batch 6 Loss 0.1918129026889801
[Train] epoch 173 Batch 7 Loss 0.035531919449567795
[Train] epoch 173 Batch 8 Loss 0.04567062109708786
[Train] epoch 173 Batch 9 Loss 0.24937717616558075
[Train] epoch 173 Batch 10 Loss 0.10501327365636826
[Train] epoch 173 Batch 11 Loss 0.07050427049398422
[Train] epoch 173 Batch 12 Loss 0.18710550665855408
[Train] epoch 173 Batch 13 Loss 0.10201945155858994
[Train] epoch 173 Batch 14 Loss 0.17984718084335327
[Train] epoch 173 Batch 15 Loss 0.17994321882724762
[Train] epoch 173 Batch 16 Loss 0.2210637927055359
[Train] epoch 173 Batch 17 Loss 0.2528111934661865
[Train] epoch 173 Batch 18 Loss 0.10326101630926132
[Train] epoch 173 Batch 19 Loss 0.24978303909301758
[Train] epoch 173 Batch 20 Loss 0.2079569697380066
[Train] epoch 173 Batch 21 Loss 0.14512459933757782
[Train] epoch 173 Batch 22 Loss 0.07651476562023163
[Train] epoch 173 Batch 23 Loss 0.24445569515228271
[Train] epoch 173 Batch 24 Loss 0.2613625228404999
[Train] epoch 173 Batch 25 Loss 0.21135275065898895
[Train] epoch 173 Batch 26 Loss 0.10153838992118835
[Train] epoch 173 Batch 27 Loss 0.13698093593120575
[Train] epoch 173 Batch 28 Loss 0.17306555807590485
[Train] epoch 173 Batch 29 Loss 0.21464931964874268
[Train] epoch 173 Batch 30 Loss 0.2000008225440979
[Train] epoch 173 Batch 31 Loss 0.24051931500434875
[Train] epoch 173 Batch 32 Loss 0.24633026123046875
[Train] epoch 173 Batch 33 Loss 0.1797482669353485
[Train] epoch 173 Batch 34 Loss 0.14942073822021484
[Train] epoch 173 Batch 35 Loss 0.24158772826194763
[Train] epoch 173 Batch 36 Loss 0.22190415859222412
[Train] epoch 173 Batch 37 Loss 0.2164689600467682
[Train] epoch 173 Batch 38 Loss 0.2106827348470688
[Train] epoch 173 Batch 39 Loss 0.1026235967874527
[Train] epoch 173 Batch 40 Loss 0.21034575998783112
[Train] epoch 173 Batch 41 Loss 0.0717659592628479
[Train] epoch 173 Batch 42 Loss 0.3024880886077881
[Train] epoch 173 Batch 43 Loss 0.44096624851226807
[Train] epoch 173 Batch 44 Loss 0.08585631847381592
[Train] epoch 173 Batch 45 Loss 0.21465975046157837
[Train] epoch 173 Batch 46 Loss 0.14299869537353516
[Train] epoch 173 Batch 47 Loss 0.24880188703536987
[Train] epoch 174 Batch 0 Loss 0.1879507452249527
[Train] epoch 174 Batch 1 Loss 0.2845279276371002
[Train] epoch 174 Batch 2 Loss 0.24823567271232605
[Train] epoch 174 Batch 3 Loss 0.3422410786151886
[Train] epoch 174 Batch 4 Loss 0.10921713709831238
[Train] epoch 174 Batch 5 Loss 0.11688891798257828
[Train] epoch 174 Batch 6 Loss 0.14457276463508606
[Train] epoch 174 Batch 7 Loss 0.07681866735219955
[Train] epoch 174 Batch 8 Loss 0.21041318774223328
[Train] epoch 174 Batch 9 Loss 0.07410050928592682
[Train] epoch 174 Batch 10 Loss 0.1725265383720398
[Train] epoch 174 Batch 11 Loss 0.14117562770843506
[Train] epoch 174 Batch 12 Loss 0.1799764484167099
[Train] epoch 174 Batch 13 Loss 0.08024178445339203
[Train] epoch 174 Batch 14 Loss 0.1789764016866684
[Train] epoch 174 Batch 15 Loss 0.14077961444854736
[Train] epoch 174 Batch 16 Loss 0.25014036893844604
[Train] epoch 174 Batch 17 Loss 0.2739437222480774
[Train] epoch 174 Batch 18 Loss 0.23920699954032898
[Train] epoch 174 Batch 19 Loss 0.10522027313709259
[Train] epoch 174 Batch 20 Loss 0.07020150125026703
[Train] epoch 174 Batch 21 Loss 0.0733831524848938
[Train] epoch 174 Batch 22 Loss 0.06977342069149017
[Train] epoch 174 Batch 23 Loss 0.17487093806266785
[Train] epoch 174 Batch 24 Loss 0.17166605591773987
[Train] epoch 174 Batch 25 Loss 0.20940561592578888
[Train] epoch 174 Batch 26 Loss 0.16799379885196686
[Train] epoch 174 Batch 27 Loss 0.2445557415485382
[Train] epoch 174 Batch 28 Loss 0.06666764616966248
[Train] epoch 174 Batch 29 Loss 0.17446252703666687
[Train] epoch 174 Batch 30 Loss 0.04070616513490677
[Train] epoch 174 Batch 31 Loss 0.21605545282363892
[Train] epoch 174 Batch 32 Loss 0.07522789388895035
[Train] epoch 174 Batch 33 Loss 0.1365642547607422
[Train] epoch 174 Batch 34 Loss 0.20757122337818146
[Train] epoch 174 Batch 35 Loss 0.30269479751586914
[Train] epoch 174 Batch 36 Loss 0.21211422979831696
[Train] epoch 174 Batch 37 Loss 0.10782855749130249
[Train] epoch 174 Batch 38 Loss 0.33693939447402954
[Train] epoch 174 Batch 39 Loss 0.20680084824562073
[Train] epoch 174 Batch 40 Loss 0.21021276712417603
[Train] epoch 174 Batch 41 Loss 0.2072542905807495
[Train] epoch 174 Batch 42 Loss 0.2498701512813568
[Train] epoch 174 Batch 43 Loss 0.24244114756584167
[Train] epoch 174 Batch 44 Loss 0.37692275643348694
[Train] epoch 174 Batch 45 Loss 0.23963326215744019
[Train] epoch 174 Batch 46 Loss 0.18090790510177612
[Train] epoch 174 Batch 47 Loss 0.20332443714141846
[Train] epoch 175 Batch 0 Loss 0.040650319308042526
[Train] epoch 175 Batch 1 Loss 0.20854336023330688
[Train] epoch 175 Batch 2 Loss 0.13737478852272034
[Train] epoch 175 Batch 3 Loss 0.10651335120201111
[Train] epoch 175 Batch 4 Loss 0.14134478569030762
[Train] epoch 175 Batch 5 Loss 0.21624970436096191
[Train] epoch 175 Batch 6 Loss 0.21159248054027557
[Train] epoch 175 Batch 7 Loss 0.21962109208106995
[Train] epoch 175 Batch 8 Loss 0.10167405009269714
[Train] epoch 175 Batch 9 Loss 0.34372496604919434
[Train] epoch 175 Batch 10 Loss 0.2839297354221344
[Train] epoch 175 Batch 11 Loss 0.06994982063770294
[Train] epoch 175 Batch 12 Loss 0.20354893803596497
[Train] epoch 175 Batch 13 Loss 0.24217751622200012
[Train] epoch 175 Batch 14 Loss 0.07365038990974426
[Train] epoch 175 Batch 15 Loss 0.24174949526786804
[Train] epoch 175 Batch 16 Loss 0.21351328492164612
[Train] epoch 175 Batch 17 Loss 0.2066061794757843
[Train] epoch 175 Batch 18 Loss 0.133334219455719
[Train] epoch 175 Batch 19 Loss 0.1044919341802597
[Train] epoch 175 Batch 20 Loss 0.3047601580619812
[Train] epoch 175 Batch 21 Loss 0.1079663634300232
[Train] epoch 175 Batch 22 Loss 0.10480120033025742
[Train] epoch 175 Batch 23 Loss 0.04419729858636856
[Train] epoch 175 Batch 24 Loss 0.24131707847118378
[Train] epoch 175 Batch 25 Loss 0.1398787647485733
[Train] epoch 175 Batch 26 Loss 0.13944661617279053
[Train] epoch 175 Batch 27 Loss 0.21215662360191345
[Train] epoch 175 Batch 28 Loss 0.24113139510154724
[Train] epoch 175 Batch 29 Loss 0.24383017420768738
[Train] epoch 175 Batch 30 Loss 0.13973218202590942
[Train] epoch 175 Batch 31 Loss 0.3390643000602722
[Train] epoch 175 Batch 32 Loss 0.27254900336265564
[Train] epoch 175 Batch 33 Loss 0.10172821581363678
[Train] epoch 175 Batch 34 Loss 0.176884263753891
[Train] epoch 175 Batch 35 Loss 0.17104294896125793
[Train] epoch 175 Batch 36 Loss 0.1420518159866333
[Train] epoch 175 Batch 37 Loss 0.5082948207855225
[Train] epoch 175 Batch 38 Loss 0.2086450159549713
[Train] epoch 175 Batch 39 Loss 0.04022686928510666
[Train] epoch 175 Batch 40 Loss 0.14171822369098663
[Train] epoch 175 Batch 41 Loss 0.20834150910377502
[Train] epoch 175 Batch 42 Loss 0.21210040152072906
[Train] epoch 175 Batch 43 Loss 0.1387481987476349
[Train] epoch 175 Batch 44 Loss 0.10726194083690643
[Train] epoch 175 Batch 45 Loss 0.21392351388931274
[Train] epoch 175 Batch 46 Loss 0.17442893981933594
[Train] epoch 175 Batch 47 Loss 0.10171052813529968
[Train] epoch 176 Batch 0 Loss 0.20285528898239136
[Train] epoch 176 Batch 1 Loss 0.14759592711925507
[Train] epoch 176 Batch 2 Loss 0.20839284360408783
[Train] epoch 176 Batch 3 Loss 0.20340295135974884
[Train] epoch 176 Batch 4 Loss 0.17033207416534424
[Train] epoch 176 Batch 5 Loss 0.33925139904022217
[Train] epoch 176 Batch 6 Loss 0.3046441972255707
[Train] epoch 176 Batch 7 Loss 0.10419668257236481
[Train] epoch 176 Batch 8 Loss 0.27475276589393616
[Train] epoch 176 Batch 9 Loss 0.2128913402557373
[Train] epoch 176 Batch 10 Loss 0.13670101761817932
[Train] epoch 176 Batch 11 Loss 0.1741723120212555
[Train] epoch 176 Batch 12 Loss 0.10444658994674683
[Train] epoch 176 Batch 13 Loss 0.14464996755123138
[Train] epoch 176 Batch 14 Loss 0.1770796924829483
[Train] epoch 176 Batch 15 Loss 0.13549058139324188
[Train] epoch 176 Batch 16 Loss 0.2089466154575348
[Train] epoch 176 Batch 17 Loss 0.30393338203430176
[Train] epoch 176 Batch 18 Loss 0.23725661635398865
[Train] epoch 176 Batch 19 Loss 0.17011231184005737
[Train] epoch 176 Batch 20 Loss 0.23736527562141418
[Train] epoch 176 Batch 21 Loss 0.1366451531648636
[Train] epoch 176 Batch 22 Loss 0.10859604179859161
[Train] epoch 176 Batch 23 Loss 0.10622192919254303
[Train] epoch 176 Batch 24 Loss 0.2710927128791809
[Train] epoch 176 Batch 25 Loss 0.2032979428768158
[Train] epoch 176 Batch 26 Loss 0.13992314040660858
[Train] epoch 176 Batch 27 Loss 0.07117275893688202
[Train] epoch 176 Batch 28 Loss 0.10394994914531708
[Train] epoch 176 Batch 29 Loss 0.1765584647655487
[Train] epoch 176 Batch 30 Loss 0.2465602457523346
[Train] epoch 176 Batch 31 Loss 0.24169808626174927
[Train] epoch 176 Batch 32 Loss 0.1086307168006897
[Train] epoch 176 Batch 33 Loss 0.10683555901050568
[Train] epoch 176 Batch 34 Loss 0.34386274218559265
[Train] epoch 176 Batch 35 Loss 0.2031254768371582
[Train] epoch 176 Batch 36 Loss 0.16821080446243286
[Train] epoch 176 Batch 37 Loss 0.173838809132576
[Train] epoch 176 Batch 38 Loss 0.16818062961101532
[Train] epoch 176 Batch 39 Loss 0.20575116574764252
[Train] epoch 176 Batch 40 Loss 0.21260812878608704
[Train] epoch 176 Batch 41 Loss 0.13967475295066833
[Train] epoch 176 Batch 42 Loss 0.17456187307834625
[Train] epoch 176 Batch 43 Loss 0.18149176239967346
[Train] epoch 176 Batch 44 Loss 0.2096005082130432
[Train] epoch 176 Batch 45 Loss 0.080015629529953
[Train] epoch 176 Batch 46 Loss 0.10515378415584564
[Train] epoch 176 Batch 47 Loss 0.041970737278461456
[Train] epoch 177 Batch 0 Loss 0.20287899672985077
[Train] epoch 177 Batch 1 Loss 0.27607184648513794
[Train] epoch 177 Batch 2 Loss 0.30780720710754395
[Train] epoch 177 Batch 3 Loss 0.11532501876354218
[Train] epoch 177 Batch 4 Loss 0.1428518444299698
[Train] epoch 177 Batch 5 Loss 0.07428738474845886
[Train] epoch 177 Batch 6 Loss 0.23760241270065308
[Train] epoch 177 Batch 7 Loss 0.23825138807296753
[Train] epoch 177 Batch 8 Loss 0.17459484934806824
[Train] epoch 177 Batch 9 Loss 0.20283742249011993
[Train] epoch 177 Batch 10 Loss 0.10470728576183319
[Train] epoch 177 Batch 11 Loss 0.27322763204574585
[Train] epoch 177 Batch 12 Loss 0.03846484795212746
[Train] epoch 177 Batch 13 Loss 0.20326435565948486
[Train] epoch 177 Batch 14 Loss 0.03490384668111801
[Train] epoch 177 Batch 15 Loss 0.1853341907262802
[Train] epoch 177 Batch 16 Loss 0.14289984107017517
[Train] epoch 177 Batch 17 Loss 0.14953424036502838
[Train] epoch 177 Batch 18 Loss 0.3080376982688904
[Train] epoch 177 Batch 19 Loss 1.0728851975727594e-06
[Train] epoch 177 Batch 20 Loss 0.30773282051086426
[Train] epoch 177 Batch 21 Loss 0.27651137113571167
[Train] epoch 177 Batch 22 Loss 0.276123046875
[Train] epoch 177 Batch 23 Loss 0.4409681558609009
[Train] epoch 177 Batch 24 Loss 0.24093689024448395
[Train] epoch 177 Batch 25 Loss 0.10426576435565948
[Train] epoch 177 Batch 26 Loss 0.17420829832553864
[Train] epoch 177 Batch 27 Loss 0.1394478678703308
[Train] epoch 177 Batch 28 Loss 0.24082320928573608
[Train] epoch 177 Batch 29 Loss 0.13936461508274078
[Train] epoch 177 Batch 30 Loss 0.17108602821826935
[Train] epoch 177 Batch 31 Loss 0.06966371089220047
[Train] epoch 177 Batch 32 Loss 0.07591885328292847
[Train] epoch 177 Batch 33 Loss 0.20565155148506165
[Train] epoch 177 Batch 34 Loss 0.21157997846603394
[Train] epoch 177 Batch 35 Loss 0.21164295077323914
[Train] epoch 177 Batch 36 Loss 0.14215216040611267
[Train] epoch 177 Batch 37 Loss 0.06949139386415482
[Train] epoch 177 Batch 38 Loss 0.07527197152376175
[Train] epoch 177 Batch 39 Loss 0.2695590853691101
[Train] epoch 177 Batch 40 Loss 0.10434192419052124
[Train] epoch 177 Batch 41 Loss 0.10691595077514648
[Train] epoch 177 Batch 42 Loss 0.14734452962875366
[Train] epoch 177 Batch 43 Loss 0.2429567277431488
[Train] epoch 177 Batch 44 Loss 0.20816144347190857
[Train] epoch 177 Batch 45 Loss 0.20281925797462463
[Train] epoch 177 Batch 46 Loss 0.10925152897834778
[Train] epoch 177 Batch 47 Loss 0.2748579978942871
[Train] epoch 178 Batch 0 Loss 0.20804640650749207
[Train] epoch 178 Batch 1 Loss 0.17634700238704681
[Train] epoch 178 Batch 2 Loss 0.10134536027908325
[Train] epoch 178 Batch 3 Loss 0.24246206879615784
[Train] epoch 178 Batch 4 Loss 0.1356903463602066
[Train] epoch 178 Batch 5 Loss 0.10404890775680542
[Train] epoch 178 Batch 6 Loss 0.30908411741256714
[Train] epoch 178 Batch 7 Loss 0.20271825790405273
[Train] epoch 178 Batch 8 Loss 0.23990048468112946
[Train] epoch 178 Batch 9 Loss 0.3361753821372986
[Train] epoch 178 Batch 10 Loss 0.07445115596055984
[Train] epoch 178 Batch 11 Loss 0.1731712520122528
[Train] epoch 178 Batch 12 Loss 0.20254772901535034
[Train] epoch 178 Batch 13 Loss 0.37838250398635864
[Train] epoch 178 Batch 14 Loss 0.2424430549144745
[Train] epoch 178 Batch 15 Loss 0.1355542540550232
[Train] epoch 178 Batch 16 Loss 0.41041940450668335
[Train] epoch 178 Batch 17 Loss 0.10607010126113892
[Train] epoch 178 Batch 18 Loss 0.2398993819952011
[Train] epoch 178 Batch 19 Loss 0.1381453573703766
[Train] epoch 178 Batch 20 Loss 0.30874916911125183
[Train] epoch 178 Batch 21 Loss 0.2051125466823578
[Train] epoch 178 Batch 22 Loss 0.1083526611328125
[Train] epoch 178 Batch 23 Loss 0.10107176005840302
[Train] epoch 178 Batch 24 Loss 0.07885390520095825
[Train] epoch 178 Batch 25 Loss 0.21202348172664642
[Train] epoch 178 Batch 26 Loss 0.1724092960357666
[Train] epoch 178 Batch 27 Loss 0.10595434904098511
[Train] epoch 178 Batch 28 Loss 0.039375752210617065
[Train] epoch 178 Batch 29 Loss 0.13615819811820984
[Train] epoch 178 Batch 30 Loss 0.1701451539993286
[Train] epoch 178 Batch 31 Loss 0.170357346534729
[Train] epoch 178 Batch 32 Loss 0.14030370116233826
[Train] epoch 178 Batch 33 Loss 0.21405881643295288
[Train] epoch 178 Batch 34 Loss 0.2694888114929199
[Train] epoch 178 Batch 35 Loss 0.274433970451355
[Train] epoch 178 Batch 36 Loss 0.03908294439315796
[Train] epoch 178 Batch 37 Loss 0.17551591992378235
[Train] epoch 178 Batch 38 Loss 0.1032017320394516
[Train] epoch 178 Batch 39 Loss 0.13991688191890717
[Train] epoch 178 Batch 40 Loss 0.1680738627910614
[Train] epoch 178 Batch 41 Loss 0.20207512378692627
[Train] epoch 178 Batch 42 Loss 0.2072642743587494
[Train] epoch 178 Batch 43 Loss 0.24002915620803833
[Train] epoch 178 Batch 44 Loss 0.03688887134194374
[Train] epoch 178 Batch 45 Loss 0.07118870317935944
[Train] epoch 178 Batch 46 Loss 0.2000008225440979
[Train] epoch 178 Batch 47 Loss 0.1403006613254547
[Train] epoch 179 Batch 0 Loss 0.10598821938037872
[Train] epoch 179 Batch 1 Loss 0.17230476438999176
[Train] epoch 179 Batch 2 Loss 0.13544762134552002
[Train] epoch 179 Batch 3 Loss 0.1059548631310463
[Train] epoch 179 Batch 4 Loss 0.1401360183954239
[Train] epoch 179 Batch 5 Loss 0.1389102041721344
[Train] epoch 179 Batch 6 Loss 0.1745792031288147
[Train] epoch 179 Batch 7 Loss 0.07343246042728424
[Train] epoch 179 Batch 8 Loss 0.140265554189682
[Train] epoch 179 Batch 9 Loss 0.21167224645614624
[Train] epoch 179 Batch 10 Loss 0.20842307806015015
[Train] epoch 179 Batch 11 Loss 0.23713383078575134
[Train] epoch 179 Batch 12 Loss 0.03872359171509743
[Train] epoch 179 Batch 13 Loss 0.13805332779884338
[Train] epoch 179 Batch 14 Loss 0.2390614151954651
[Train] epoch 179 Batch 15 Loss 0.10534696280956268
[Train] epoch 179 Batch 16 Loss 0.30965638160705566
[Train] epoch 179 Batch 17 Loss 0.20459973812103271
[Train] epoch 179 Batch 18 Loss 0.07920774072408676
[Train] epoch 179 Batch 19 Loss 0.17287711799144745
[Train] epoch 179 Batch 20 Loss 0.2414567768573761
[Train] epoch 179 Batch 21 Loss 0.03441062197089195
[Train] epoch 179 Batch 22 Loss 0.06666764616966248
[Train] epoch 179 Batch 23 Loss 0.1730693280696869
[Train] epoch 179 Batch 24 Loss 0.44238191843032837
[Train] epoch 179 Batch 25 Loss 0.30635926127433777
[Train] epoch 179 Batch 26 Loss 0.21071456372737885
[Train] epoch 179 Batch 27 Loss 0.24096006155014038
[Train] epoch 179 Batch 28 Loss 0.1807083785533905
[Train] epoch 179 Batch 29 Loss 0.06932559609413147
[Train] epoch 179 Batch 30 Loss 0.1740950047969818
[Train] epoch 179 Batch 31 Loss 0.27230799198150635
[Train] epoch 179 Batch 32 Loss 0.14189955592155457
[Train] epoch 179 Batch 33 Loss 0.20567351579666138
[Train] epoch 179 Batch 34 Loss 0.06940992176532745
[Train] epoch 179 Batch 35 Loss 0.17116495966911316
[Train] epoch 179 Batch 36 Loss 0.20573502779006958
[Train] epoch 179 Batch 37 Loss 0.3045133054256439
[Train] epoch 179 Batch 38 Loss 0.10136527568101883
[Train] epoch 179 Batch 39 Loss 0.20278149843215942
[Train] epoch 179 Batch 40 Loss 0.03785151243209839
[Train] epoch 179 Batch 41 Loss 0.3421775698661804
[Train] epoch 179 Batch 42 Loss 0.13938069343566895
[Train] epoch 179 Batch 43 Loss 0.2780812084674835
[Train] epoch 179 Batch 44 Loss 0.1737738847732544
[Train] epoch 179 Batch 45 Loss 0.20866215229034424
[Train] epoch 179 Batch 46 Loss 0.2755703330039978
[Train] epoch 179 Batch 47 Loss 0.20871306955814362
[Train] epoch 180 Batch 0 Loss 0.04652036353945732
[Train] epoch 180 Batch 1 Loss 0.20555594563484192
[Train] epoch 180 Batch 2 Loss 0.3071986436843872
[Train] epoch 180 Batch 3 Loss 0.17380064725875854
[Train] epoch 180 Batch 4 Loss 0.17673473060131073
[Train] epoch 180 Batch 5 Loss 0.07234930992126465
[Train] epoch 180 Batch 6 Loss 0.10715758055448532
[Train] epoch 180 Batch 7 Loss 0.10983014106750488
[Train] epoch 180 Batch 8 Loss 0.1739606261253357
[Train] epoch 180 Batch 9 Loss 0.2403588593006134
[Train] epoch 180 Batch 10 Loss 0.2722797393798828
[Train] epoch 180 Batch 11 Loss 0.06954386830329895
[Train] epoch 180 Batch 12 Loss 0.07201030850410461
[Train] epoch 180 Batch 13 Loss 0.2830013334751129
[Train] epoch 180 Batch 14 Loss 0.17344284057617188
[Train] epoch 180 Batch 15 Loss 0.1678684949874878
[Train] epoch 180 Batch 16 Loss 0.27724823355674744
[Train] epoch 180 Batch 17 Loss 0.13633140921592712
[Train] epoch 180 Batch 18 Loss 0.16876214742660522
[Train] epoch 180 Batch 19 Loss 0.10671208053827286
[Train] epoch 180 Batch 20 Loss 0.4055112898349762
[Train] epoch 180 Batch 21 Loss 0.14431840181350708
[Train] epoch 180 Batch 22 Loss 0.3707733750343323
[Train] epoch 180 Batch 23 Loss 0.2054838091135025
[Train] epoch 180 Batch 24 Loss 0.10688668489456177
[Train] epoch 180 Batch 25 Loss 0.13881392776966095
[Train] epoch 180 Batch 26 Loss 0.2347692996263504
[Train] epoch 180 Batch 27 Loss 0.2027236819267273
[Train] epoch 180 Batch 28 Loss 0.10985331237316132
[Train] epoch 180 Batch 29 Loss 0.03760354593396187
[Train] epoch 180 Batch 30 Loss 0.07506093382835388
[Train] epoch 180 Batch 31 Loss 0.2428278923034668
[Train] epoch 180 Batch 32 Loss 0.17647865414619446
[Train] epoch 180 Batch 33 Loss 0.14171522855758667
[Train] epoch 180 Batch 34 Loss 0.34139546751976013
[Train] epoch 180 Batch 35 Loss 0.20500443875789642
[Train] epoch 180 Batch 36 Loss 0.240291565656662
[Train] epoch 180 Batch 37 Loss 0.06970945000648499
[Train] epoch 180 Batch 38 Loss 0.2429957389831543
[Train] epoch 180 Batch 39 Loss 0.10430222749710083
[Train] epoch 180 Batch 40 Loss 0.133334219455719
[Train] epoch 180 Batch 41 Loss 0.10667861998081207
[Train] epoch 180 Batch 42 Loss 0.3094251751899719
[Train] epoch 180 Batch 43 Loss 0.17330536246299744
[Train] epoch 180 Batch 44 Loss 0.17325064539909363
[Train] epoch 180 Batch 45 Loss 0.21051794290542603
[Train] epoch 180 Batch 46 Loss 0.03464796394109726
[Train] epoch 180 Batch 47 Loss 0.3413164019584656
[Train] epoch 181 Batch 0 Loss 0.17549949884414673
[Train] epoch 181 Batch 1 Loss 0.07167349755764008
[Train] epoch 181 Batch 2 Loss 0.1754070222377777
[Train] epoch 181 Batch 3 Loss 0.2050737887620926
[Train] epoch 181 Batch 4 Loss 0.2026250958442688
[Train] epoch 181 Batch 5 Loss 0.23948462307453156
[Train] epoch 181 Batch 6 Loss 0.3090067505836487
[Train] epoch 181 Batch 7 Loss 0.07862523198127747
[Train] epoch 181 Batch 8 Loss 0.03448886051774025
[Train] epoch 181 Batch 9 Loss 0.10606797784566879
[Train] epoch 181 Batch 10 Loss 0.17532561719417572
[Train] epoch 181 Batch 11 Loss 0.13608810305595398
[Train] epoch 181 Batch 12 Loss 0.27192625403404236
[Train] epoch 181 Batch 13 Loss 0.1403508335351944
[Train] epoch 181 Batch 14 Loss 0.3063643276691437
[Train] epoch 181 Batch 15 Loss 0.07128860056400299
[Train] epoch 181 Batch 16 Loss 0.16776394844055176
[Train] epoch 181 Batch 17 Loss 0.17519208788871765
[Train] epoch 181 Batch 18 Loss 0.13828033208847046
[Train] epoch 181 Batch 19 Loss 0.1708332896232605
[Train] epoch 181 Batch 20 Loss 0.1354844868183136
[Train] epoch 181 Batch 21 Loss 0.13793595135211945
[Train] epoch 181 Batch 22 Loss 0.20491236448287964
[Train] epoch 181 Batch 23 Loss 0.2742202877998352
[Train] epoch 181 Batch 24 Loss 0.2097562551498413
[Train] epoch 181 Batch 25 Loss 0.23970761895179749
[Train] epoch 181 Batch 26 Loss 0.1703498661518097
[Train] epoch 181 Batch 27 Loss 0.17486903071403503
[Train] epoch 181 Batch 28 Loss 0.2388940155506134
[Train] epoch 181 Batch 29 Loss 0.1057313084602356
[Train] epoch 181 Batch 30 Loss 0.06883113086223602
[Train] epoch 181 Batch 31 Loss 0.17477932572364807
[Train] epoch 181 Batch 32 Loss 0.2760496735572815
[Train] epoch 181 Batch 33 Loss 0.10138511657714844
[Train] epoch 181 Batch 34 Loss 0.1381380558013916
[Train] epoch 181 Batch 35 Loss 0.06943240016698837
[Train] epoch 181 Batch 36 Loss 0.17439287900924683
[Train] epoch 181 Batch 37 Loss 0.2417791485786438
[Train] epoch 181 Batch 38 Loss 0.2734526991844177
[Train] epoch 181 Batch 39 Loss 0.10622835159301758
[Train] epoch 181 Batch 40 Loss 0.37526190280914307
[Train] epoch 181 Batch 41 Loss 0.20661507546901703
[Train] epoch 181 Batch 42 Loss 0.10306509584188461
[Train] epoch 181 Batch 43 Loss 0.1399076282978058
[Train] epoch 181 Batch 44 Loss 0.10532023012638092
[Train] epoch 181 Batch 45 Loss 0.30882492661476135
[Train] epoch 181 Batch 46 Loss 0.10676251351833344
[Train] epoch 181 Batch 47 Loss 0.36800268292427063
[Train] epoch 182 Batch 0 Loss 0.1679733395576477
[Train] epoch 182 Batch 1 Loss 0.07197277247905731
[Train] epoch 182 Batch 2 Loss 0.10377959907054901
[Train] epoch 182 Batch 3 Loss 0.18014585971832275
[Train] epoch 182 Batch 4 Loss 0.17034481465816498
[Train] epoch 182 Batch 5 Loss 0.11078690737485886
[Train] epoch 182 Batch 6 Loss 0.1785704642534256
[Train] epoch 182 Batch 7 Loss 0.12540113925933838
[Train] epoch 182 Batch 8 Loss 0.133334219455719
[Train] epoch 182 Batch 9 Loss 0.24436131119728088
[Train] epoch 182 Batch 10 Loss 0.2083933800458908
[Train] epoch 182 Batch 11 Loss 0.10677524656057358
[Train] epoch 182 Batch 12 Loss 0.17089521884918213
[Train] epoch 182 Batch 13 Loss 0.2029007077217102
[Train] epoch 182 Batch 14 Loss 0.10622724145650864
[Train] epoch 182 Batch 15 Loss 0.07356885075569153
[Train] epoch 182 Batch 16 Loss 0.20745262503623962
[Train] epoch 182 Batch 17 Loss 0.23811352252960205
[Train] epoch 182 Batch 18 Loss 0.37880951166152954
[Train] epoch 182 Batch 19 Loss 0.24475184082984924
[Train] epoch 182 Batch 20 Loss 0.24243515729904175
[Train] epoch 182 Batch 21 Loss 0.17000636458396912
[Train] epoch 182 Batch 22 Loss 0.23446859419345856
[Train] epoch 182 Batch 23 Loss 0.30455073714256287
[Train] epoch 182 Batch 24 Loss 0.06888322532176971
[Train] epoch 182 Batch 25 Loss 0.2744021415710449
[Train] epoch 182 Batch 26 Loss 0.17297786474227905
[Train] epoch 182 Batch 27 Loss 0.23885071277618408
[Train] epoch 182 Batch 28 Loss 0.2721855938434601
[Train] epoch 182 Batch 29 Loss 0.06666764616966248
[Train] epoch 182 Batch 30 Loss 0.10804963111877441
[Train] epoch 182 Batch 31 Loss 0.2402348816394806
[Train] epoch 182 Batch 32 Loss 0.20759734511375427
[Train] epoch 182 Batch 33 Loss 0.1398726999759674
[Train] epoch 182 Batch 34 Loss 0.30901676416397095
[Train] epoch 182 Batch 35 Loss 0.30143070220947266
[Train] epoch 182 Batch 36 Loss 0.07134389877319336
[Train] epoch 182 Batch 37 Loss 0.14452111721038818
[Train] epoch 182 Batch 38 Loss 0.2462053894996643
[Train] epoch 182 Batch 39 Loss 0.17238493263721466
[Train] epoch 182 Batch 40 Loss 0.16773830354213715
[Train] epoch 182 Batch 41 Loss 0.14112788438796997
[Train] epoch 182 Batch 42 Loss 0.06879347562789917
[Train] epoch 182 Batch 43 Loss 0.13545331358909607
[Train] epoch 182 Batch 44 Loss 0.2368488907814026
[Train] epoch 182 Batch 45 Loss 0.10351593792438507
[Train] epoch 182 Batch 46 Loss 0.24384215474128723
[Train] epoch 182 Batch 47 Loss 0.10767043381929398
[Train] epoch 183 Batch 0 Loss 0.036816682666540146
[Train] epoch 183 Batch 1 Loss 0.1382022351026535
[Train] epoch 183 Batch 2 Loss 0.17050082981586456
[Train] epoch 183 Batch 3 Loss 0.24090790748596191
[Train] epoch 183 Batch 4 Loss 0.17737357318401337
[Train] epoch 183 Batch 5 Loss 0.13537749648094177
[Train] epoch 183 Batch 6 Loss 0.1034221202135086
[Train] epoch 183 Batch 7 Loss 0.4072144031524658
[Train] epoch 183 Batch 8 Loss 0.138137549161911
[Train] epoch 183 Batch 9 Loss 0.17169678211212158
[Train] epoch 183 Batch 10 Loss 0.14012080430984497
[Train] epoch 183 Batch 11 Loss 0.10636864602565765
[Train] epoch 183 Batch 12 Loss 0.14066565036773682
[Train] epoch 183 Batch 13 Loss 0.2048284411430359
[Train] epoch 183 Batch 14 Loss 0.1755380630493164
[Train] epoch 183 Batch 15 Loss 0.17593315243721008
[Train] epoch 183 Batch 16 Loss 0.3360366225242615
[Train] epoch 183 Batch 17 Loss 0.20873653888702393
[Train] epoch 183 Batch 18 Loss 0.17733855545520782
[Train] epoch 183 Batch 19 Loss 0.13984224200248718
[Train] epoch 183 Batch 20 Loss 0.3071957230567932
[Train] epoch 183 Batch 21 Loss 0.2112981528043747
[Train] epoch 183 Batch 22 Loss 0.27331793308258057
[Train] epoch 183 Batch 23 Loss 0.13945698738098145
[Train] epoch 183 Batch 24 Loss 0.1715957224369049
[Train] epoch 183 Batch 25 Loss 0.10183969140052795
[Train] epoch 183 Batch 26 Loss 0.24195057153701782
[Train] epoch 183 Batch 27 Loss 0.06922385096549988
[Train] epoch 183 Batch 28 Loss 0.20568957924842834
[Train] epoch 183 Batch 29 Loss 0.11488151550292969
[Train] epoch 183 Batch 30 Loss 0.1359044313430786
[Train] epoch 183 Batch 31 Loss 0.3117189407348633
[Train] epoch 183 Batch 32 Loss 0.10494124889373779
[Train] epoch 183 Batch 33 Loss 0.2754673957824707
[Train] epoch 183 Batch 34 Loss 0.24958045780658722
[Train] epoch 183 Batch 35 Loss 0.3430808186531067
[Train] epoch 183 Batch 36 Loss 0.17409808933734894
[Train] epoch 183 Batch 37 Loss 0.1043495163321495
[Train] epoch 183 Batch 38 Loss 0.23810990154743195
[Train] epoch 183 Batch 39 Loss 0.104754239320755
[Train] epoch 183 Batch 40 Loss 0.2064349502325058
[Train] epoch 183 Batch 41 Loss 0.13971638679504395
[Train] epoch 183 Batch 42 Loss 0.07339204102754593
[Train] epoch 183 Batch 43 Loss 0.18128909170627594
[Train] epoch 183 Batch 44 Loss 0.1742202788591385
[Train] epoch 183 Batch 45 Loss 0.24470308423042297
[Train] epoch 183 Batch 46 Loss 0.003204223234206438
[Train] epoch 183 Batch 47 Loss 0.2115926742553711
[Train] epoch 184 Batch 0 Loss 0.16798478364944458
[Train] epoch 184 Batch 1 Loss 0.17704786360263824
[Train] epoch 184 Batch 2 Loss 0.20569893717765808
[Train] epoch 184 Batch 3 Loss 0.07272394746541977
[Train] epoch 184 Batch 4 Loss 0.17415380477905273
[Train] epoch 184 Batch 5 Loss 0.17110943794250488
[Train] epoch 184 Batch 6 Loss 0.27238789200782776
[Train] epoch 184 Batch 7 Loss 0.2403382658958435
[Train] epoch 184 Batch 8 Loss 0.037530481815338135
[Train] epoch 184 Batch 9 Loss 0.13883116841316223
[Train] epoch 184 Batch 10 Loss 0.10687925666570663
[Train] epoch 184 Batch 11 Loss 0.20272813737392426
[Train] epoch 184 Batch 12 Loss 0.14430321753025055
[Train] epoch 184 Batch 13 Loss 0.24286092817783356
[Train] epoch 184 Batch 14 Loss 0.07747708261013031
[Train] epoch 184 Batch 15 Loss 0.06936109066009521
[Train] epoch 184 Batch 16 Loss 0.07201331853866577
[Train] epoch 184 Batch 17 Loss 0.2399595081806183
[Train] epoch 184 Batch 18 Loss 0.173242449760437
[Train] epoch 184 Batch 19 Loss 0.06934557110071182
[Train] epoch 184 Batch 20 Loss 0.27451103925704956
[Train] epoch 184 Batch 21 Loss 0.30914306640625
[Train] epoch 184 Batch 22 Loss 0.27188247442245483
[Train] epoch 184 Batch 23 Loss 0.20519492030143738
[Train] epoch 184 Batch 24 Loss 0.1088433489203453
[Train] epoch 184 Batch 25 Loss 0.0716385766863823
[Train] epoch 184 Batch 26 Loss 0.17562641203403473
[Train] epoch 184 Batch 27 Loss 0.004898287821561098
[Train] epoch 184 Batch 28 Loss 0.10632741451263428
[Train] epoch 184 Batch 29 Loss 0.10134166479110718
[Train] epoch 184 Batch 30 Loss 0.43975090980529785
[Train] epoch 184 Batch 31 Loss 0.24465438723564148
[Train] epoch 184 Batch 32 Loss 0.4026809632778168
[Train] epoch 184 Batch 33 Loss 0.2764027714729309
[Train] epoch 184 Batch 34 Loss 0.1408577710390091
[Train] epoch 184 Batch 35 Loss 0.204649418592453
[Train] epoch 184 Batch 36 Loss 0.2764587104320526
[Train] epoch 184 Batch 37 Loss 0.40993732213974
[Train] epoch 184 Batch 38 Loss 0.23962341248989105
[Train] epoch 184 Batch 39 Loss 0.1405426263809204
[Train] epoch 184 Batch 40 Loss 0.13558760285377502
[Train] epoch 184 Batch 41 Loss 0.14070375263690948
[Train] epoch 184 Batch 42 Loss 0.13800941407680511
[Train] epoch 184 Batch 43 Loss 0.07576884329319
[Train] epoch 184 Batch 44 Loss 0.23687314987182617
[Train] epoch 184 Batch 45 Loss 0.10133016109466553
[Train] epoch 184 Batch 46 Loss 0.20265963673591614
[Train] epoch 184 Batch 47 Loss 0.10784681141376495
[Train] epoch 185 Batch 0 Loss 0.20648187398910522
[Train] epoch 185 Batch 1 Loss 0.24375692009925842
[Train] epoch 185 Batch 2 Loss 0.1402662992477417
[Train] epoch 185 Batch 3 Loss 0.20663681626319885
[Train] epoch 185 Batch 4 Loss 0.10344569385051727
[Train] epoch 185 Batch 5 Loss 0.23914040625095367
[Train] epoch 185 Batch 6 Loss 0.24623382091522217
[Train] epoch 185 Batch 7 Loss 0.03465951979160309
[Train] epoch 185 Batch 8 Loss 0.06931636482477188
[Train] epoch 185 Batch 9 Loss 0.03435841575264931
[Train] epoch 185 Batch 10 Loss 0.239054873585701
[Train] epoch 185 Batch 11 Loss 0.23933890461921692
[Train] epoch 185 Batch 12 Loss 0.23434701561927795
[Train] epoch 185 Batch 13 Loss 0.16969673335552216
[Train] epoch 185 Batch 14 Loss 0.07070373743772507
[Train] epoch 185 Batch 15 Loss 0.33797335624694824
[Train] epoch 185 Batch 16 Loss 0.20864051580429077
[Train] epoch 185 Batch 17 Loss 0.17826229333877563
[Train] epoch 185 Batch 18 Loss 0.06865092366933823
[Train] epoch 185 Batch 19 Loss 0.10526064038276672
[Train] epoch 185 Batch 20 Loss 0.3408905565738678
[Train] epoch 185 Batch 21 Loss 0.3055626451969147
[Train] epoch 185 Batch 22 Loss 0.17221640050411224
[Train] epoch 185 Batch 23 Loss 0.30325430631637573
[Train] epoch 185 Batch 24 Loss 0.1035853698849678
[Train] epoch 185 Batch 25 Loss 0.27312546968460083
[Train] epoch 185 Batch 26 Loss 0.2045322060585022
[Train] epoch 185 Batch 27 Loss 0.1032208502292633
[Train] epoch 185 Batch 28 Loss 0.04189161956310272
[Train] epoch 185 Batch 29 Loss 0.2429252713918686
[Train] epoch 185 Batch 30 Loss 0.20710405707359314
[Train] epoch 185 Batch 31 Loss 0.337077260017395
[Train] epoch 185 Batch 32 Loss 0.133334219455719
[Train] epoch 185 Batch 33 Loss 0.2759692668914795
[Train] epoch 185 Batch 34 Loss 0.14200946688652039
[Train] epoch 185 Batch 35 Loss 0.17209447920322418
[Train] epoch 185 Batch 36 Loss 0.20257940888404846
[Train] epoch 185 Batch 37 Loss 0.1699216663837433
[Train] epoch 185 Batch 38 Loss 0.10100031644105911
[Train] epoch 185 Batch 39 Loss 0.04072318971157074
[Train] epoch 185 Batch 40 Loss 0.169764906167984
[Train] epoch 185 Batch 41 Loss 0.3358650207519531
[Train] epoch 185 Batch 42 Loss 0.036700539290905
[Train] epoch 185 Batch 43 Loss 0.20716622471809387
[Train] epoch 185 Batch 44 Loss 0.24119454622268677
[Train] epoch 185 Batch 45 Loss 0.10556033253669739
[Train] epoch 185 Batch 46 Loss 0.17258623242378235
[Train] epoch 185 Batch 47 Loss 0.038931842893362045
[Train] epoch 186 Batch 0 Loss 0.1032768040895462
[Train] epoch 186 Batch 1 Loss 0.23660233616828918
[Train] epoch 186 Batch 2 Loss 0.2735356390476227
[Train] epoch 186 Batch 3 Loss 0.13991393148899078
[Train] epoch 186 Batch 4 Loss 0.2369118630886078
[Train] epoch 186 Batch 5 Loss 0.0688595101237297
[Train] epoch 186 Batch 6 Loss 0.23690074682235718
[Train] epoch 186 Batch 7 Loss 0.1057557687163353
[Train] epoch 186 Batch 8 Loss 0.30807751417160034
[Train] epoch 186 Batch 9 Loss 0.13798196613788605
[Train] epoch 186 Batch 10 Loss 0.0043525006622076035
[Train] epoch 186 Batch 11 Loss 0.2410847246646881
[Train] epoch 186 Batch 12 Loss 0.06913243979215622
[Train] epoch 186 Batch 13 Loss 0.07128766179084778
[Train] epoch 186 Batch 14 Loss 0.004304354079067707
[Train] epoch 186 Batch 15 Loss 0.20691294968128204
[Train] epoch 186 Batch 16 Loss 0.2439253032207489
[Train] epoch 186 Batch 17 Loss 0.30827200412750244
[Train] epoch 186 Batch 18 Loss 0.337912917137146
[Train] epoch 186 Batch 19 Loss 0.17017781734466553
[Train] epoch 186 Batch 20 Loss 0.13773739337921143
[Train] epoch 186 Batch 21 Loss 0.07527171075344086
[Train] epoch 186 Batch 22 Loss 0.3357783555984497
[Train] epoch 186 Batch 23 Loss 0.04066939279437065
[Train] epoch 186 Batch 24 Loss 0.13995300233364105
[Train] epoch 186 Batch 25 Loss 0.3722198009490967
[Train] epoch 186 Batch 26 Loss 0.10329499840736389
[Train] epoch 186 Batch 27 Loss 0.2364301234483719
[Train] epoch 186 Batch 28 Loss 0.17422592639923096
[Train] epoch 186 Batch 29 Loss 0.10958904027938843
[Train] epoch 186 Batch 30 Loss 0.2069038450717926
[Train] epoch 186 Batch 31 Loss 0.06869234144687653
[Train] epoch 186 Batch 32 Loss 0.30970147252082825
[Train] epoch 186 Batch 33 Loss 0.07289907336235046
[Train] epoch 186 Batch 34 Loss 0.07265345752239227
[Train] epoch 186 Batch 35 Loss 0.1716284155845642
[Train] epoch 186 Batch 36 Loss 0.2688658833503723
[Train] epoch 186 Batch 37 Loss 0.2710557281970978
[Train] epoch 186 Batch 38 Loss 0.1703108549118042
[Train] epoch 186 Batch 39 Loss 0.13770368695259094
[Train] epoch 186 Batch 40 Loss 0.171750009059906
[Train] epoch 186 Batch 41 Loss 0.20628204941749573
[Train] epoch 186 Batch 42 Loss 0.10313303023576736
[Train] epoch 186 Batch 43 Loss 0.139329731464386
[Train] epoch 186 Batch 44 Loss 0.3354947865009308
[Train] epoch 186 Batch 45 Loss 0.23643934726715088
[Train] epoch 186 Batch 46 Loss 0.16976694762706757
[Train] epoch 186 Batch 47 Loss 0.2107589840888977
[Train] epoch 187 Batch 0 Loss 0.10468770563602448
[Train] epoch 187 Batch 1 Loss 0.40670275688171387
[Train] epoch 187 Batch 2 Loss 0.20185980200767517
[Train] epoch 187 Batch 3 Loss 0.03639531135559082
[Train] epoch 187 Batch 4 Loss 0.20426271855831146
[Train] epoch 187 Batch 5 Loss 0.23793406784534454
[Train] epoch 187 Batch 6 Loss 0.10729304701089859
[Train] epoch 187 Batch 7 Loss 0.26907747983932495
[Train] epoch 187 Batch 8 Loss 0.3718031048774719
[Train] epoch 187 Batch 9 Loss 0.03635285049676895
[Train] epoch 187 Batch 10 Loss 0.1699734479188919
[Train] epoch 187 Batch 11 Loss 0.20781749486923218
[Train] epoch 187 Batch 12 Loss 0.10269971191883087
[Train] epoch 187 Batch 13 Loss 0.14289747178554535
[Train] epoch 187 Batch 14 Loss 0.07231627404689789
[Train] epoch 187 Batch 15 Loss 0.20385953783988953
[Train] epoch 187 Batch 16 Loss 0.2362976372241974
[Train] epoch 187 Batch 17 Loss 0.10519447922706604
[Train] epoch 187 Batch 18 Loss 0.23452317714691162
[Train] epoch 187 Batch 19 Loss 0.07075370848178864
[Train] epoch 187 Batch 20 Loss 0.1760098785161972
[Train] epoch 187 Batch 21 Loss 0.17949670553207397
[Train] epoch 187 Batch 22 Loss 0.18004153668880463
[Train] epoch 187 Batch 23 Loss 0.1399022340774536
[Train] epoch 187 Batch 24 Loss 0.27371886372566223
[Train] epoch 187 Batch 25 Loss 0.23677685856819153
[Train] epoch 187 Batch 26 Loss 0.20935292541980743
[Train] epoch 187 Batch 27 Loss 0.17016109824180603
[Train] epoch 187 Batch 28 Loss 0.2023724764585495
[Train] epoch 187 Batch 29 Loss 0.039176687598228455
[Train] epoch 187 Batch 30 Loss 0.17030400037765503
[Train] epoch 187 Batch 31 Loss 0.2715637981891632
[Train] epoch 187 Batch 32 Loss 0.3454124331474304
[Train] epoch 187 Batch 33 Loss 0.07133197784423828
[Train] epoch 187 Batch 34 Loss 0.10359759628772736
[Train] epoch 187 Batch 35 Loss 0.03459784388542175
[Train] epoch 187 Batch 36 Loss 0.2370387613773346
[Train] epoch 187 Batch 37 Loss 0.24171727895736694
[Train] epoch 187 Batch 38 Loss 0.0691075399518013
[Train] epoch 187 Batch 39 Loss 0.17260846495628357
[Train] epoch 187 Batch 40 Loss 0.3082748055458069
[Train] epoch 187 Batch 41 Loss 0.13810226321220398
[Train] epoch 187 Batch 42 Loss 0.17527541518211365
[Train] epoch 187 Batch 43 Loss 0.17270833253860474
[Train] epoch 187 Batch 44 Loss 0.13564340770244598
[Train] epoch 187 Batch 45 Loss 0.13590434193611145
[Train] epoch 187 Batch 46 Loss 0.17039112746715546
[Train] epoch 187 Batch 47 Loss 0.2761245369911194
[Train] epoch 188 Batch 0 Loss 0.10342402011156082
[Train] epoch 188 Batch 1 Loss 0.21199464797973633
[Train] epoch 188 Batch 2 Loss 0.039172857999801636
[Train] epoch 188 Batch 3 Loss 0.1033884584903717
[Train] epoch 188 Batch 4 Loss 0.13591310381889343
[Train] epoch 188 Batch 5 Loss 0.10129034519195557
[Train] epoch 188 Batch 6 Loss 0.27130815386772156
[Train] epoch 188 Batch 7 Loss 0.268901526927948
[Train] epoch 188 Batch 8 Loss 0.1703566312789917
[Train] epoch 188 Batch 9 Loss 0.10795451700687408
[Train] epoch 188 Batch 10 Loss 0.17679816484451294
[Train] epoch 188 Batch 11 Loss 0.1379333734512329
[Train] epoch 188 Batch 12 Loss 0.13791626691818237
[Train] epoch 188 Batch 13 Loss 0.23918724060058594
[Train] epoch 188 Batch 14 Loss 0.10129226744174957
[Train] epoch 188 Batch 15 Loss 0.3727065920829773
[Train] epoch 188 Batch 16 Loss 0.11250101029872894
[Train] epoch 188 Batch 17 Loss 0.23677396774291992
[Train] epoch 188 Batch 18 Loss 0.24125757813453674
[Train] epoch 188 Batch 19 Loss 0.27160343527793884
[Train] epoch 188 Batch 20 Loss 0.2115209847688675
[Train] epoch 188 Batch 21 Loss 0.23954716324806213
[Train] epoch 188 Batch 22 Loss 0.13778522610664368
[Train] epoch 188 Batch 23 Loss 0.17448574304580688
[Train] epoch 188 Batch 24 Loss 0.24113056063652039
[Train] epoch 188 Batch 25 Loss 0.1723596453666687
[Train] epoch 188 Batch 26 Loss 0.20853488147258759
[Train] epoch 188 Batch 27 Loss 0.20644442737102509
[Train] epoch 188 Batch 28 Loss 0.10333709418773651
[Train] epoch 188 Batch 29 Loss 0.1376858949661255
[Train] epoch 188 Batch 30 Loss 0.20920035243034363
[Train] epoch 188 Batch 31 Loss 0.20432376861572266
[Train] epoch 188 Batch 32 Loss 0.17454206943511963
[Train] epoch 188 Batch 33 Loss 0.07095873355865479
[Train] epoch 188 Batch 34 Loss 0.06666764616966248
[Train] epoch 188 Batch 35 Loss 0.30782362818717957
[Train] epoch 188 Batch 36 Loss 0.20454344153404236
[Train] epoch 188 Batch 37 Loss 0.16991955041885376
[Train] epoch 188 Batch 38 Loss 0.14180275797843933
[Train] epoch 188 Batch 39 Loss 0.2100677490234375
[Train] epoch 188 Batch 40 Loss 0.30105865001678467
[Train] epoch 188 Batch 41 Loss 0.20463545620441437
[Train] epoch 188 Batch 42 Loss 0.20969858765602112
[Train] epoch 188 Batch 43 Loss 0.20247900485992432
[Train] epoch 188 Batch 44 Loss 0.1358722448348999
[Train] epoch 188 Batch 45 Loss 0.005742370150983334
[Train] epoch 188 Batch 46 Loss 0.20496389269828796
[Train] epoch 188 Batch 47 Loss 0.18696482479572296
[Train] epoch 189 Batch 0 Loss 0.03761734813451767
[Train] epoch 189 Batch 1 Loss 0.23710358142852783
[Train] epoch 189 Batch 2 Loss 0.17037248611450195
[Train] epoch 189 Batch 3 Loss 0.06893712282180786
[Train] epoch 189 Batch 4 Loss 0.27388685941696167
[Train] epoch 189 Batch 5 Loss 0.14251533150672913
[Train] epoch 189 Batch 6 Loss 0.26859530806541443
[Train] epoch 189 Batch 7 Loss 0.17284110188484192
[Train] epoch 189 Batch 8 Loss 0.14220941066741943
[Train] epoch 189 Batch 9 Loss 0.07075011730194092
[Train] epoch 189 Batch 10 Loss 0.20044909417629242
[Train] epoch 189 Batch 11 Loss 0.3047553300857544
[Train] epoch 189 Batch 12 Loss 0.0733485072851181
[Train] epoch 189 Batch 13 Loss 0.138096421957016
[Train] epoch 189 Batch 14 Loss 0.3432621955871582
[Train] epoch 189 Batch 15 Loss 0.20772214233875275
[Train] epoch 189 Batch 16 Loss 0.11227816343307495
[Train] epoch 189 Batch 17 Loss 0.2000008225440979
[Train] epoch 189 Batch 18 Loss 0.20708037912845612
[Train] epoch 189 Batch 19 Loss 0.17612960934638977
[Train] epoch 189 Batch 20 Loss 0.23957118391990662
[Train] epoch 189 Batch 21 Loss 0.2766342759132385
[Train] epoch 189 Batch 22 Loss 0.1357971727848053
[Train] epoch 189 Batch 23 Loss 0.03895307704806328
[Train] epoch 189 Batch 24 Loss 0.204813152551651
[Train] epoch 189 Batch 25 Loss 0.036759596318006516
[Train] epoch 189 Batch 26 Loss 0.1740683913230896
[Train] epoch 189 Batch 27 Loss 0.13570673763751984
[Train] epoch 189 Batch 28 Loss 0.17611584067344666
[Train] epoch 189 Batch 29 Loss 0.20655328035354614
[Train] epoch 189 Batch 30 Loss 0.1356557160615921
[Train] epoch 189 Batch 31 Loss 0.27460741996765137
[Train] epoch 189 Batch 32 Loss 0.036543507128953934
[Train] epoch 189 Batch 33 Loss 0.23652911186218262
[Train] epoch 189 Batch 34 Loss 0.1728276163339615
[Train] epoch 189 Batch 35 Loss 0.17122723162174225
[Train] epoch 189 Batch 36 Loss 0.174701526761055
[Train] epoch 189 Batch 37 Loss 0.13550931215286255
[Train] epoch 189 Batch 38 Loss 0.20412978529930115
[Train] epoch 189 Batch 39 Loss 0.27736616134643555
[Train] epoch 189 Batch 40 Loss 0.13775141537189484
[Train] epoch 189 Batch 41 Loss 0.17123648524284363
[Train] epoch 189 Batch 42 Loss 0.23900072276592255
[Train] epoch 189 Batch 43 Loss 0.20212322473526
[Train] epoch 189 Batch 44 Loss 0.17191119492053986
[Train] epoch 189 Batch 45 Loss 0.17182795703411102
[Train] epoch 189 Batch 46 Loss 0.26848000288009644
[Train] epoch 189 Batch 47 Loss 0.2722422480583191
[Train] epoch 190 Batch 0 Loss 0.13506188988685608
[Train] epoch 190 Batch 1 Loss 0.2385076880455017
[Train] epoch 190 Batch 2 Loss 0.2710310220718384
[Train] epoch 190 Batch 3 Loss 0.20473405718803406
[Train] epoch 190 Batch 4 Loss 0.16977031528949738
[Train] epoch 190 Batch 5 Loss 0.33549365401268005
[Train] epoch 190 Batch 6 Loss 0.0038884859532117844
[Train] epoch 190 Batch 7 Loss 0.2434801161289215
[Train] epoch 190 Batch 8 Loss 0.07298364490270615
[Train] epoch 190 Batch 9 Loss 0.20425784587860107
[Train] epoch 190 Batch 10 Loss 0.2447589635848999
[Train] epoch 190 Batch 11 Loss 0.34224429726600647
[Train] epoch 190 Batch 12 Loss 0.17202824354171753
[Train] epoch 190 Batch 13 Loss 0.17213314771652222
[Train] epoch 190 Batch 14 Loss 0.10344552993774414
[Train] epoch 190 Batch 15 Loss 0.17430399358272552
[Train] epoch 190 Batch 16 Loss 0.1698525846004486
[Train] epoch 190 Batch 17 Loss 0.23677241802215576
[Train] epoch 190 Batch 18 Loss 0.16768231987953186
[Train] epoch 190 Batch 19 Loss 0.23616495728492737
[Train] epoch 190 Batch 20 Loss 0.04022140055894852
[Train] epoch 190 Batch 21 Loss 0.24343031644821167
[Train] epoch 190 Batch 22 Loss 0.13953572511672974
[Train] epoch 190 Batch 23 Loss 0.20800170302391052
[Train] epoch 190 Batch 24 Loss 0.0748586356639862
[Train] epoch 190 Batch 25 Loss 0.10325795412063599
[Train] epoch 190 Batch 26 Loss 0.13783925771713257
[Train] epoch 190 Batch 27 Loss 0.1054941713809967
[Train] epoch 190 Batch 28 Loss 0.2686498761177063
[Train] epoch 190 Batch 29 Loss 0.23422512412071228
[Train] epoch 190 Batch 30 Loss 0.2059864103794098
[Train] epoch 190 Batch 31 Loss 0.20697104930877686
[Train] epoch 190 Batch 32 Loss 0.17184174060821533
[Train] epoch 190 Batch 33 Loss 0.13769447803497314
[Train] epoch 190 Batch 34 Loss 0.24244990944862366
[Train] epoch 190 Batch 35 Loss 0.30530858039855957
[Train] epoch 190 Batch 36 Loss 0.10290154814720154
[Train] epoch 190 Batch 37 Loss 0.13958139717578888
[Train] epoch 190 Batch 38 Loss 0.3401515483856201
[Train] epoch 190 Batch 39 Loss 0.2363961637020111
[Train] epoch 190 Batch 40 Loss 0.10314811766147614
[Train] epoch 190 Batch 41 Loss 0.03419226035475731
[Train] epoch 190 Batch 42 Loss 0.10643547773361206
[Train] epoch 190 Batch 43 Loss 0.13770706951618195
[Train] epoch 190 Batch 44 Loss 0.20248818397521973
[Train] epoch 190 Batch 45 Loss 0.17374370992183685
[Train] epoch 190 Batch 46 Loss 0.13783666491508484
[Train] epoch 190 Batch 47 Loss 0.10564503818750381
[Train] epoch 191 Batch 0 Loss 0.2022375911474228
[Train] epoch 191 Batch 1 Loss 0.07109266519546509
[Train] epoch 191 Batch 2 Loss 0.13324761390686035
[Train] epoch 191 Batch 3 Loss 0.1046605184674263
[Train] epoch 191 Batch 4 Loss 0.10497140884399414
[Train] epoch 191 Batch 5 Loss 0.27809563279151917
[Train] epoch 191 Batch 6 Loss 0.20452959835529327
[Train] epoch 191 Batch 7 Loss 0.23923107981681824
[Train] epoch 191 Batch 8 Loss 0.10366169363260269
[Train] epoch 191 Batch 9 Loss 0.31061995029449463
[Train] epoch 191 Batch 10 Loss 0.10341949760913849
[Train] epoch 191 Batch 11 Loss 0.17256379127502441
[Train] epoch 191 Batch 12 Loss 0.27382102608680725
[Train] epoch 191 Batch 13 Loss 0.14051076769828796
[Train] epoch 191 Batch 14 Loss 0.20249663293361664
[Train] epoch 191 Batch 15 Loss 0.06900230795145035
[Train] epoch 191 Batch 16 Loss 0.3112463653087616
[Train] epoch 191 Batch 17 Loss 0.27404364943504333
[Train] epoch 191 Batch 18 Loss 0.13802652060985565
[Train] epoch 191 Batch 19 Loss 0.20491623878479004
[Train] epoch 191 Batch 20 Loss 0.28139588236808777
[Train] epoch 191 Batch 21 Loss 0.1704569160938263
[Train] epoch 191 Batch 22 Loss 0.1382370889186859
[Train] epoch 191 Batch 23 Loss 0.1751939356327057
[Train] epoch 191 Batch 24 Loss 0.1382073611021042
[Train] epoch 191 Batch 25 Loss 0.3702387809753418
[Train] epoch 191 Batch 26 Loss 0.13832317292690277
[Train] epoch 191 Batch 27 Loss 0.1359153389930725
[Train] epoch 191 Batch 28 Loss 0.20474770665168762
[Train] epoch 191 Batch 29 Loss 0.002249268814921379
[Train] epoch 191 Batch 30 Loss 0.10591490566730499
[Train] epoch 191 Batch 31 Loss 0.038848720490932465
[Train] epoch 191 Batch 32 Loss 0.20469723641872406
[Train] epoch 191 Batch 33 Loss 0.3425709009170532
[Train] epoch 191 Batch 34 Loss 0.17276492714881897
[Train] epoch 191 Batch 35 Loss 0.10569129884243011
[Train] epoch 191 Batch 36 Loss 0.07377609610557556
[Train] epoch 191 Batch 37 Loss 0.07114946097135544
[Train] epoch 191 Batch 38 Loss 0.07370178401470184
[Train] epoch 191 Batch 39 Loss 0.30633825063705444
[Train] epoch 191 Batch 40 Loss 0.1061694547533989
[Train] epoch 191 Batch 41 Loss 0.2387896180152893
[Train] epoch 191 Batch 42 Loss 0.24149101972579956
[Train] epoch 191 Batch 43 Loss 0.2738047242164612
[Train] epoch 191 Batch 44 Loss 0.1400899589061737
[Train] epoch 191 Batch 45 Loss 0.24347089231014252
[Train] epoch 191 Batch 46 Loss 0.17017069458961487
[Train] epoch 191 Batch 47 Loss 0.2740514874458313
[Train] epoch 192 Batch 0 Loss 0.37055808305740356
[Train] epoch 192 Batch 1 Loss 0.06925936788320541
[Train] epoch 192 Batch 2 Loss 0.1012958511710167
[Train] epoch 192 Batch 3 Loss 0.13786977529525757
[Train] epoch 192 Batch 4 Loss 0.23656558990478516
[Train] epoch 192 Batch 5 Loss 0.07107194513082504
[Train] epoch 192 Batch 6 Loss 0.23462560772895813
[Train] epoch 192 Batch 7 Loss 0.1723482608795166
[Train] epoch 192 Batch 8 Loss 0.2045994997024536
[Train] epoch 192 Batch 9 Loss 0.204244464635849
[Train] epoch 192 Batch 10 Loss 0.24132215976715088
[Train] epoch 192 Batch 11 Loss 0.20457811653614044
[Train] epoch 192 Batch 12 Loss 0.20879802107810974
[Train] epoch 192 Batch 13 Loss 0.07122720032930374
[Train] epoch 192 Batch 14 Loss 0.24287059903144836
[Train] epoch 192 Batch 15 Loss 0.23877575993537903
[Train] epoch 192 Batch 16 Loss 0.3773684501647949
[Train] epoch 192 Batch 17 Loss 0.036681365221738815
[Train] epoch 192 Batch 18 Loss 0.10750474035739899
[Train] epoch 192 Batch 19 Loss 0.1395285725593567
[Train] epoch 192 Batch 20 Loss 0.1418038010597229
[Train] epoch 192 Batch 21 Loss 0.23919636011123657
[Train] epoch 192 Batch 22 Loss 0.1372765302658081
[Train] epoch 192 Batch 23 Loss 0.07095703482627869
[Train] epoch 192 Batch 24 Loss 0.1718616783618927
[Train] epoch 192 Batch 25 Loss 0.133334219455719
[Train] epoch 192 Batch 26 Loss 0.33768707513809204
[Train] epoch 192 Batch 27 Loss 0.20415012538433075
[Train] epoch 192 Batch 28 Loss 0.17613035440444946
[Train] epoch 192 Batch 29 Loss 0.21013006567955017
[Train] epoch 192 Batch 30 Loss 0.07078664749860764
[Train] epoch 192 Batch 31 Loss 0.034606244415044785
[Train] epoch 192 Batch 32 Loss 0.13548916578292847
[Train] epoch 192 Batch 33 Loss 0.14159619808197021
[Train] epoch 192 Batch 34 Loss 0.2706587314605713
[Train] epoch 192 Batch 35 Loss 0.33984968066215515
[Train] epoch 192 Batch 36 Loss 0.07255217432975769
[Train] epoch 192 Batch 37 Loss 0.33729350566864014
[Train] epoch 192 Batch 38 Loss 0.13768351078033447
[Train] epoch 192 Batch 39 Loss 0.037985894829034805
[Train] epoch 192 Batch 40 Loss 0.17227253317832947
[Train] epoch 192 Batch 41 Loss 0.13807307183742523
[Train] epoch 192 Batch 42 Loss 0.1395290195941925
[Train] epoch 192 Batch 43 Loss 0.1395348310470581
[Train] epoch 192 Batch 44 Loss 0.30304980278015137
[Train] epoch 192 Batch 45 Loss 0.24007253348827362
[Train] epoch 192 Batch 46 Loss 0.1413218080997467
[Train] epoch 192 Batch 47 Loss 0.20210856199264526
[Train] epoch 193 Batch 0 Loss 0.07098415493965149
[Train] epoch 193 Batch 1 Loss 0.1036309078335762
[Train] epoch 193 Batch 2 Loss 0.2041994333267212
[Train] epoch 193 Batch 3 Loss 0.20826661586761475
[Train] epoch 193 Batch 4 Loss 0.07039900869131088
[Train] epoch 193 Batch 5 Loss 0.06851053237915039
[Train] epoch 193 Batch 6 Loss 0.24246132373809814
[Train] epoch 193 Batch 7 Loss 0.20399817824363708
[Train] epoch 193 Batch 8 Loss 0.2727404534816742
[Train] epoch 193 Batch 9 Loss 0.3069970905780792
[Train] epoch 193 Batch 10 Loss 0.40445464849472046
[Train] epoch 193 Batch 11 Loss 0.13911166787147522
[Train] epoch 193 Batch 12 Loss 0.3393363952636719
[Train] epoch 193 Batch 13 Loss 0.07082726061344147
[Train] epoch 193 Batch 14 Loss 0.10272900015115738
[Train] epoch 193 Batch 15 Loss 0.07266125828027725
[Train] epoch 193 Batch 16 Loss 0.20647881925106049
[Train] epoch 193 Batch 17 Loss 0.2000008225440979
[Train] epoch 193 Batch 18 Loss 0.2365623563528061
[Train] epoch 193 Batch 19 Loss 0.23448950052261353
[Train] epoch 193 Batch 20 Loss 0.16962894797325134
[Train] epoch 193 Batch 21 Loss 0.17193135619163513
[Train] epoch 193 Batch 22 Loss 0.10864300280809402
[Train] epoch 193 Batch 23 Loss 0.20768076181411743
[Train] epoch 193 Batch 24 Loss 0.17755284905433655
[Train] epoch 193 Batch 25 Loss 0.2723068296909332
[Train] epoch 193 Batch 26 Loss 0.2727789580821991
[Train] epoch 193 Batch 27 Loss 0.2745385468006134
[Train] epoch 193 Batch 28 Loss 0.03624942898750305
[Train] epoch 193 Batch 29 Loss 0.06666764616966248
[Train] epoch 193 Batch 30 Loss 0.17334511876106262
[Train] epoch 193 Batch 31 Loss 0.16780927777290344
[Train] epoch 193 Batch 32 Loss 0.13535311818122864
[Train] epoch 193 Batch 33 Loss 0.24227014183998108
[Train] epoch 193 Batch 34 Loss 0.23967573046684265
[Train] epoch 193 Batch 35 Loss 0.10315059125423431
[Train] epoch 193 Batch 36 Loss 0.07212148606777191
[Train] epoch 193 Batch 37 Loss 0.06666764616966248
[Train] epoch 193 Batch 38 Loss 0.07011928409337997
[Train] epoch 193 Batch 39 Loss 0.20398364961147308
[Train] epoch 193 Batch 40 Loss 0.1694948971271515
[Train] epoch 193 Batch 41 Loss 0.10283493995666504
[Train] epoch 193 Batch 42 Loss 0.10283023118972778
[Train] epoch 193 Batch 43 Loss 0.27035510540008545
[Train] epoch 193 Batch 44 Loss 0.24077945947647095
[Train] epoch 193 Batch 45 Loss 0.10432016849517822
[Train] epoch 193 Batch 46 Loss 0.27219849824905396
[Train] epoch 193 Batch 47 Loss 0.27426064014434814
[Train] epoch 194 Batch 0 Loss 0.036256756633520126
[Train] epoch 194 Batch 1 Loss 0.20222550630569458
[Train] epoch 194 Batch 2 Loss 0.13963283598423004
[Train] epoch 194 Batch 3 Loss 0.20577356219291687
[Train] epoch 194 Batch 4 Loss 0.16761592030525208
[Train] epoch 194 Batch 5 Loss 0.133334219455719
[Train] epoch 194 Batch 6 Loss 0.13716891407966614
[Train] epoch 194 Batch 7 Loss 0.0705183669924736
[Train] epoch 194 Batch 8 Loss 0.23443028330802917
[Train] epoch 194 Batch 9 Loss 0.14134857058525085
[Train] epoch 194 Batch 10 Loss 0.10706866532564163
[Train] epoch 194 Batch 11 Loss 0.137479767203331
[Train] epoch 194 Batch 12 Loss 0.23843422532081604
[Train] epoch 194 Batch 13 Loss 0.07071489840745926
[Train] epoch 194 Batch 14 Loss 0.4019417464733124
[Train] epoch 194 Batch 15 Loss 0.2059864103794098
[Train] epoch 194 Batch 16 Loss 0.20414724946022034
[Train] epoch 194 Batch 17 Loss 0.2710162103176117
[Train] epoch 194 Batch 18 Loss 0.10293284058570862
[Train] epoch 194 Batch 19 Loss 0.2058803141117096
[Train] epoch 194 Batch 20 Loss 0.16970080137252808
[Train] epoch 194 Batch 21 Loss 0.07077910006046295
[Train] epoch 194 Batch 22 Loss 0.369800865650177
[Train] epoch 194 Batch 23 Loss 0.27066171169281006
[Train] epoch 194 Batch 24 Loss 0.24021388590335846
[Train] epoch 194 Batch 25 Loss 0.2727043032646179
[Train] epoch 194 Batch 26 Loss 0.0724763497710228
[Train] epoch 194 Batch 27 Loss 0.169653058052063
[Train] epoch 194 Batch 28 Loss 0.06869788467884064
[Train] epoch 194 Batch 29 Loss 0.2823779582977295
[Train] epoch 194 Batch 30 Loss 0.10298536717891693
[Train] epoch 194 Batch 31 Loss 0.14334821701049805
[Train] epoch 194 Batch 32 Loss 0.1414351910352707
[Train] epoch 194 Batch 33 Loss 0.2400726079940796
[Train] epoch 194 Batch 34 Loss 0.10093995183706284
[Train] epoch 194 Batch 35 Loss 0.07256283611059189
[Train] epoch 194 Batch 36 Loss 0.17159919440746307
[Train] epoch 194 Batch 37 Loss 0.005550134927034378
[Train] epoch 194 Batch 38 Loss 0.13765385746955872
[Train] epoch 194 Batch 39 Loss 0.30323904752731323
[Train] epoch 194 Batch 40 Loss 0.2726280689239502
[Train] epoch 194 Batch 41 Loss 0.23988711833953857
[Train] epoch 194 Batch 42 Loss 0.3389410376548767
[Train] epoch 194 Batch 43 Loss 0.3050351142883301
[Train] epoch 194 Batch 44 Loss 0.17187967896461487
[Train] epoch 194 Batch 45 Loss 0.10503125935792923
[Train] epoch 194 Batch 46 Loss 0.17149069905281067
[Train] epoch 194 Batch 47 Loss 0.10464677214622498
[Train] epoch 195 Batch 0 Loss 0.30302852392196655
[Train] epoch 195 Batch 1 Loss 0.13902878761291504
[Train] epoch 195 Batch 2 Loss 0.07214472442865372
[Train] epoch 195 Batch 3 Loss 0.1352796107530594
[Train] epoch 195 Batch 4 Loss 0.1390041708946228
[Train] epoch 195 Batch 5 Loss 0.20370377600193024
[Train] epoch 195 Batch 6 Loss 0.30688440799713135
[Train] epoch 195 Batch 7 Loss 0.1694742739200592
[Train] epoch 195 Batch 8 Loss 0.2705465853214264
[Train] epoch 195 Batch 9 Loss 0.07358825951814651
[Train] epoch 195 Batch 10 Loss 0.14065977931022644
[Train] epoch 195 Batch 11 Loss 0.13547073304653168
[Train] epoch 195 Batch 12 Loss 0.10641314089298248
[Train] epoch 195 Batch 13 Loss 0.23611125349998474
[Train] epoch 195 Batch 14 Loss 0.1042528748512268
[Train] epoch 195 Batch 15 Loss 0.2021339237689972
[Train] epoch 195 Batch 16 Loss 0.1727936863899231
[Train] epoch 195 Batch 17 Loss 0.16941970586776733
[Train] epoch 195 Batch 18 Loss 0.3404970169067383
[Train] epoch 195 Batch 19 Loss 0.13522684574127197
[Train] epoch 195 Batch 20 Loss 0.23605859279632568
[Train] epoch 195 Batch 21 Loss 0.20166516304016113
[Train] epoch 195 Batch 22 Loss 0.20708119869232178
[Train] epoch 195 Batch 23 Loss 0.23958951234817505
[Train] epoch 195 Batch 24 Loss 0.2744649648666382
[Train] epoch 195 Batch 25 Loss 0.16936498880386353
[Train] epoch 195 Batch 26 Loss 0.17098842561244965
[Train] epoch 195 Batch 27 Loss 0.136586993932724
[Train] epoch 195 Batch 28 Loss 0.1698540449142456
[Train] epoch 195 Batch 29 Loss 0.13844197988510132
[Train] epoch 195 Batch 30 Loss 0.3077733516693115
[Train] epoch 195 Batch 31 Loss 0.17280352115631104
[Train] epoch 195 Batch 32 Loss 0.133334219455719
[Train] epoch 195 Batch 33 Loss 0.07331080734729767
[Train] epoch 195 Batch 34 Loss 0.17436319589614868
[Train] epoch 195 Batch 35 Loss 0.2740943133831024
[Train] epoch 195 Batch 36 Loss 0.1711612045764923
[Train] epoch 195 Batch 37 Loss 0.16976818442344666
[Train] epoch 195 Batch 38 Loss 0.06877681612968445
[Train] epoch 195 Batch 39 Loss 0.13519588112831116
[Train] epoch 195 Batch 40 Loss 0.239582821726799
[Train] epoch 195 Batch 41 Loss 0.17148175835609436
[Train] epoch 195 Batch 42 Loss 0.1371210366487503
[Train] epoch 195 Batch 43 Loss 0.10466108471155167
[Train] epoch 195 Batch 44 Loss 0.13566294312477112
[Train] epoch 195 Batch 45 Loss 0.23420079052448273
[Train] epoch 195 Batch 46 Loss 0.1354386806488037
[Train] epoch 195 Batch 47 Loss 0.17355309426784515
[Train] epoch 196 Batch 0 Loss 0.20719198882579803
[Train] epoch 196 Batch 1 Loss 0.13704949617385864
[Train] epoch 196 Batch 2 Loss 0.06842836737632751
[Train] epoch 196 Batch 3 Loss 0.13921239972114563
[Train] epoch 196 Batch 4 Loss 0.20568636059761047
[Train] epoch 196 Batch 5 Loss 0.10263709723949432
[Train] epoch 196 Batch 6 Loss 0.10502830147743225
[Train] epoch 196 Batch 7 Loss 0.37367698550224304
[Train] epoch 196 Batch 8 Loss 0.20196545124053955
[Train] epoch 196 Batch 9 Loss 0.03791852295398712
[Train] epoch 196 Batch 10 Loss 0.20371492207050323
[Train] epoch 196 Batch 11 Loss 0.07061208784580231
[Train] epoch 196 Batch 12 Loss 0.23642171919345856
[Train] epoch 196 Batch 13 Loss 0.23838958144187927
[Train] epoch 196 Batch 14 Loss 0.37172359228134155
[Train] epoch 196 Batch 15 Loss 0.30678966641426086
[Train] epoch 196 Batch 16 Loss 0.2393644154071808
[Train] epoch 196 Batch 17 Loss 0.17145606875419617
[Train] epoch 196 Batch 18 Loss 0.20537477731704712
[Train] epoch 196 Batch 19 Loss 0.20196130871772766
[Train] epoch 196 Batch 20 Loss 0.2430117279291153
[Train] epoch 196 Batch 21 Loss 0.20177781581878662
[Train] epoch 196 Batch 22 Loss 0.10091942548751831
[Train] epoch 196 Batch 23 Loss 0.20204156637191772
[Train] epoch 196 Batch 24 Loss 0.27894920110702515
[Train] epoch 196 Batch 25 Loss 0.10311439633369446
[Train] epoch 196 Batch 26 Loss 0.2063433825969696
[Train] epoch 196 Batch 27 Loss 0.10108253359794617
[Train] epoch 196 Batch 28 Loss 0.2731565237045288
[Train] epoch 196 Batch 29 Loss 0.204347163438797
[Train] epoch 196 Batch 30 Loss 0.06877259165048599
[Train] epoch 196 Batch 31 Loss 0.1421821415424347
[Train] epoch 196 Batch 32 Loss 0.10104697942733765
[Train] epoch 196 Batch 33 Loss 0.07364527881145477
[Train] epoch 196 Batch 34 Loss 0.07142314314842224
[Train] epoch 196 Batch 35 Loss 0.11068546772003174
[Train] epoch 196 Batch 36 Loss 0.2388838529586792
[Train] epoch 196 Batch 37 Loss 0.23680244386196136
[Train] epoch 196 Batch 38 Loss 0.10123179852962494
[Train] epoch 196 Batch 39 Loss 0.20453405380249023
[Train] epoch 196 Batch 40 Loss 0.40412768721580505
[Train] epoch 196 Batch 41 Loss 0.13560447096824646
[Train] epoch 196 Batch 42 Loss 0.10351701080799103
[Train] epoch 196 Batch 43 Loss 0.10867531597614288
[Train] epoch 196 Batch 44 Loss 0.0716267004609108
[Train] epoch 196 Batch 45 Loss 0.1751289665699005
[Train] epoch 196 Batch 46 Loss 0.24586643278598785
[Train] epoch 196 Batch 47 Loss 0.2067512571811676
[Train] epoch 197 Batch 0 Loss 0.10593084245920181
[Train] epoch 197 Batch 1 Loss 0.17726397514343262
[Train] epoch 197 Batch 2 Loss 0.2392057180404663
[Train] epoch 197 Batch 3 Loss 0.34259381890296936
[Train] epoch 197 Batch 4 Loss 0.20223280787467957
[Train] epoch 197 Batch 5 Loss 0.20445004105567932
[Train] epoch 197 Batch 6 Loss 0.10592801123857498
[Train] epoch 197 Batch 7 Loss 0.20472386479377747
[Train] epoch 197 Batch 8 Loss 0.2710763216018677
[Train] epoch 197 Batch 9 Loss 0.3074607849121094
[Train] epoch 197 Batch 10 Loss 0.039003487676382065
[Train] epoch 197 Batch 11 Loss 0.17216414213180542
[Train] epoch 197 Batch 12 Loss 0.10781416296958923
[Train] epoch 197 Batch 13 Loss 0.20444750785827637
[Train] epoch 197 Batch 14 Loss 0.10330483317375183
[Train] epoch 197 Batch 15 Loss 0.07097205519676208
[Train] epoch 197 Batch 16 Loss 0.2688218355178833
[Train] epoch 197 Batch 17 Loss 0.20213380455970764
[Train] epoch 197 Batch 18 Loss 0.20214343070983887
[Train] epoch 197 Batch 19 Loss 0.10324910283088684
[Train] epoch 197 Batch 20 Loss 0.20653358101844788
[Train] epoch 197 Batch 21 Loss 0.27098461985588074
[Train] epoch 197 Batch 22 Loss 0.036555707454681396
[Train] epoch 197 Batch 23 Loss 0.16984963417053223
[Train] epoch 197 Batch 24 Loss 0.1762436330318451
[Train] epoch 197 Batch 25 Loss 0.30954650044441223
[Train] epoch 197 Batch 26 Loss 0.10323107242584229
[Train] epoch 197 Batch 27 Loss 0.20628097653388977
[Train] epoch 197 Batch 28 Loss 0.2687225341796875
[Train] epoch 197 Batch 29 Loss 0.17192509770393372
[Train] epoch 197 Batch 30 Loss 0.07087947428226471
[Train] epoch 197 Batch 31 Loss 0.27288931608200073
[Train] epoch 197 Batch 32 Loss 0.10937658697366714
[Train] epoch 197 Batch 33 Loss 0.10520166158676147
[Train] epoch 197 Batch 34 Loss 0.10720937699079514
[Train] epoch 197 Batch 35 Loss 0.20411401987075806
[Train] epoch 197 Batch 36 Loss 0.20614337921142578
[Train] epoch 197 Batch 37 Loss 0.2000008225440979
[Train] epoch 197 Batch 38 Loss 0.14142096042633057
[Train] epoch 197 Batch 39 Loss 0.17579838633537292
[Train] epoch 197 Batch 40 Loss 0.0686621367931366
[Train] epoch 197 Batch 41 Loss 0.30712735652923584
[Train] epoch 197 Batch 42 Loss 0.10102877020835876
[Train] epoch 197 Batch 43 Loss 0.20393699407577515
[Train] epoch 197 Batch 44 Loss 0.27273863554000854
[Train] epoch 197 Batch 45 Loss 0.2727384567260742
[Train] epoch 197 Batch 46 Loss 0.06666764616966248
[Train] epoch 197 Batch 47 Loss 0.1068962961435318
[Train] epoch 198 Batch 0 Loss 0.1736101508140564
[Train] epoch 198 Batch 1 Loss 0.1676931381225586
[Train] epoch 198 Batch 2 Loss 0.13724517822265625
[Train] epoch 198 Batch 3 Loss 0.13914445042610168
[Train] epoch 198 Batch 4 Loss 0.038182348012924194
[Train] epoch 198 Batch 5 Loss 0.13721296191215515
[Train] epoch 198 Batch 6 Loss 0.07052327692508698
[Train] epoch 198 Batch 7 Loss 0.40992459654808044
[Train] epoch 198 Batch 8 Loss 0.20392510294914246
[Train] epoch 198 Batch 9 Loss 0.1715257167816162
[Train] epoch 198 Batch 10 Loss 0.03615029528737068
[Train] epoch 198 Batch 11 Loss 0.07040667533874512
[Train] epoch 198 Batch 12 Loss 0.10306665301322937
[Train] epoch 198 Batch 13 Loss 0.10491136461496353
[Train] epoch 198 Batch 14 Loss 0.23822757601737976
[Train] epoch 198 Batch 15 Loss 0.26870864629745483
[Train] epoch 198 Batch 16 Loss 0.07045075297355652
[Train] epoch 198 Batch 17 Loss 0.13537295162677765
[Train] epoch 198 Batch 18 Loss 0.16951969265937805
[Train] epoch 198 Batch 19 Loss 0.40759485960006714
[Train] epoch 198 Batch 20 Loss 0.16972112655639648
[Train] epoch 198 Batch 21 Loss 0.13515490293502808
[Train] epoch 198 Batch 22 Loss 0.1030508428812027
[Train] epoch 198 Batch 23 Loss 0.10304880142211914
[Train] epoch 198 Batch 24 Loss 0.17140063643455505
[Train] epoch 198 Batch 25 Loss 0.17295363545417786
[Train] epoch 198 Batch 26 Loss 0.10280560702085495
[Train] epoch 198 Batch 27 Loss 0.17139074206352234
[Train] epoch 198 Batch 28 Loss 0.3712449073791504
[Train] epoch 198 Batch 29 Loss 0.2038021683692932
[Train] epoch 198 Batch 30 Loss 0.27400970458984375
[Train] epoch 198 Batch 31 Loss 0.16958078742027283
[Train] epoch 198 Batch 32 Loss 0.14395549893379211
[Train] epoch 198 Batch 33 Loss 0.3369733393192291
[Train] epoch 198 Batch 34 Loss 0.10641321539878845
[Train] epoch 198 Batch 35 Loss 0.13696575164794922
[Train] epoch 198 Batch 36 Loss 0.30650585889816284
[Train] epoch 198 Batch 37 Loss 0.06666764616966248
[Train] epoch 198 Batch 38 Loss 0.20894324779510498
[Train] epoch 198 Batch 39 Loss 0.1369381695985794
[Train] epoch 198 Batch 40 Loss 0.0754198357462883
[Train] epoch 198 Batch 41 Loss 0.06852471828460693
[Train] epoch 198 Batch 42 Loss 0.23945096135139465
[Train] epoch 198 Batch 43 Loss 0.13842111825942993
[Train] epoch 198 Batch 44 Loss 0.33856308460235596
[Train] epoch 198 Batch 45 Loss 0.3715502619743347
[Train] epoch 198 Batch 46 Loss 0.16916988790035248
[Train] epoch 198 Batch 47 Loss 0.2703512907028198
[Train] epoch 199 Batch 0 Loss 0.13869155943393707
[Train] epoch 199 Batch 1 Loss 0.1695086658000946
[Train] epoch 199 Batch 2 Loss 0.24314585328102112
[Train] epoch 199 Batch 3 Loss 0.17298072576522827
[Train] epoch 199 Batch 4 Loss 0.13699688017368317
[Train] epoch 199 Batch 5 Loss 0.13680478930473328
[Train] epoch 199 Batch 6 Loss 0.33659785985946655
[Train] epoch 199 Batch 7 Loss 0.20181390643119812
[Train] epoch 199 Batch 8 Loss 0.2702900171279907
[Train] epoch 199 Batch 9 Loss 0.13514244556427002
[Train] epoch 199 Batch 10 Loss 0.1690834015607834
[Train] epoch 199 Batch 11 Loss 0.10583777725696564
[Train] epoch 199 Batch 12 Loss 0.13513535261154175
[Train] epoch 199 Batch 13 Loss 0.20680740475654602
[Train] epoch 199 Batch 14 Loss 0.13875186443328857
[Train] epoch 199 Batch 15 Loss 0.10461153835058212
[Train] epoch 199 Batch 16 Loss 0.0015919674187898636
[Train] epoch 199 Batch 17 Loss 0.20831136405467987
[Train] epoch 199 Batch 18 Loss 0.27183249592781067
[Train] epoch 199 Batch 19 Loss 0.2031477391719818
[Train] epoch 199 Batch 20 Loss 0.17081773281097412
[Train] epoch 199 Batch 21 Loss 0.1366719901561737
[Train] epoch 199 Batch 22 Loss 0.07022783160209656
[Train] epoch 199 Batch 23 Loss 0.3389057517051697
[Train] epoch 199 Batch 24 Loss 0.2048902064561844
[Train] epoch 199 Batch 25 Loss 0.17299409210681915
[Train] epoch 199 Batch 26 Loss 0.16766923666000366
[Train] epoch 199 Batch 27 Loss 0.10537746548652649
[Train] epoch 199 Batch 28 Loss 0.3364027738571167
[Train] epoch 199 Batch 29 Loss 0.1692037731409073
[Train] epoch 199 Batch 30 Loss 0.23609119653701782
[Train] epoch 199 Batch 31 Loss 0.16918668150901794
[Train] epoch 199 Batch 32 Loss 0.14140987396240234
[Train] epoch 199 Batch 33 Loss 0.1348448097705841
[Train] epoch 199 Batch 34 Loss 0.17268937826156616
[Train] epoch 199 Batch 35 Loss 0.1691785752773285
[Train] epoch 199 Batch 36 Loss 0.33483386039733887
[Train] epoch 199 Batch 37 Loss 0.1383398175239563
[Train] epoch 199 Batch 38 Loss 0.20349690318107605
[Train] epoch 199 Batch 39 Loss 0.10099856555461884
[Train] epoch 199 Batch 40 Loss 0.10571473836898804
[Train] epoch 199 Batch 41 Loss 0.20322656631469727
[Train] epoch 199 Batch 42 Loss 0.17036235332489014
[Train] epoch 199 Batch 43 Loss 0.0372900515794754
[Train] epoch 199 Batch 44 Loss 0.13731856644153595
[Train] epoch 199 Batch 45 Loss 0.3059180676937103
[Train] epoch 199 Batch 46 Loss 0.13532452285289764
[Train] epoch 199 Batch 47 Loss 0.24097473919391632
[Train] epoch 200 Batch 0 Loss 0.17058363556861877
[Train] epoch 200 Batch 1 Loss 0.20543940365314484
[Train] epoch 200 Batch 2 Loss 0.13650506734848022
[Train] epoch 200 Batch 3 Loss 0.2066093236207962
[Train] epoch 200 Batch 4 Loss 0.17228393256664276
[Train] epoch 200 Batch 5 Loss 0.13477961719036102
[Train] epoch 200 Batch 6 Loss 0.03405937924981117
[Train] epoch 200 Batch 7 Loss 0.26954713463783264
[Train] epoch 200 Batch 8 Loss 0.10243559628725052
[Train] epoch 200 Batch 9 Loss 0.1024235263466835
[Train] epoch 200 Batch 10 Loss 0.3038516044616699
[Train] epoch 200 Batch 11 Loss 0.1736408770084381
[Train] epoch 200 Batch 12 Loss 0.3381665050983429
[Train] epoch 200 Batch 13 Loss 0.13853168487548828
[Train] epoch 200 Batch 14 Loss 0.10413685441017151
[Train] epoch 200 Batch 15 Loss 0.30246269702911377
[Train] epoch 200 Batch 16 Loss 0.10525697469711304
[Train] epoch 200 Batch 17 Loss 0.13680674135684967
[Train] epoch 200 Batch 18 Loss 0.26856932044029236
[Train] epoch 200 Batch 19 Loss 0.13703595101833344
[Train] epoch 200 Batch 20 Loss 0.17252299189567566
[Train] epoch 200 Batch 21 Loss 0.17231784760951996
[Train] epoch 200 Batch 22 Loss 0.1025659441947937
[Train] epoch 200 Batch 23 Loss 0.14001527428627014
[Train] epoch 200 Batch 24 Loss 0.10101285576820374
[Train] epoch 200 Batch 25 Loss 0.17081856727600098
[Train] epoch 200 Batch 26 Loss 0.0700206607580185
[Train] epoch 200 Batch 27 Loss 0.20541100203990936
[Train] epoch 200 Batch 28 Loss 0.23568493127822876
[Train] epoch 200 Batch 29 Loss 0.20519009232521057
[Train] epoch 200 Batch 30 Loss 0.0700409859418869
[Train] epoch 200 Batch 31 Loss 0.07187223434448242
[Train] epoch 200 Batch 32 Loss 0.17368412017822266
[Train] epoch 200 Batch 33 Loss 0.3062359094619751
[Train] epoch 200 Batch 34 Loss 0.13515928387641907
[Train] epoch 200 Batch 35 Loss 0.27194902300834656
[Train] epoch 200 Batch 36 Loss 0.07025499641895294
[Train] epoch 200 Batch 37 Loss 0.342254638671875
[Train] epoch 200 Batch 38 Loss 0.203699991106987
[Train] epoch 200 Batch 39 Loss 0.26841479539871216
[Train] epoch 200 Batch 40 Loss 0.17282319068908691
[Train] epoch 200 Batch 41 Loss 0.34236469864845276
[Train] epoch 200 Batch 42 Loss 0.13510829210281372
[Train] epoch 200 Batch 43 Loss 0.268561452627182
[Train] epoch 200 Batch 44 Loss 0.03428645804524422
[Train] epoch 200 Batch 45 Loss 0.07323572784662247
[Train] epoch 200 Batch 46 Loss 0.2381320297718048
[Train] epoch 200 Batch 47 Loss 0.20383617281913757
[Train] epoch 201 Batch 0 Loss 0.30451101064682007
[Train] epoch 201 Batch 1 Loss 0.3043442964553833
[Train] epoch 201 Batch 2 Loss 0.16939839720726013
[Train] epoch 201 Batch 3 Loss 0.17310181260108948
[Train] epoch 201 Batch 4 Loss 0.10450459271669388
[Train] epoch 201 Batch 5 Loss 0.16961203515529633
[Train] epoch 201 Batch 6 Loss 0.20687586069107056
[Train] epoch 201 Batch 7 Loss 0.2396039366722107
[Train] epoch 201 Batch 8 Loss 0.1727285385131836
[Train] epoch 201 Batch 9 Loss 1.0728851975727594e-06
[Train] epoch 201 Batch 10 Loss 0.23973797261714935
[Train] epoch 201 Batch 11 Loss 0.14217588305473328
[Train] epoch 201 Batch 12 Loss 0.23952578008174896
[Train] epoch 201 Batch 13 Loss 0.33944350481033325
[Train] epoch 201 Batch 14 Loss 0.16762199997901917
[Train] epoch 201 Batch 15 Loss 0.06666764616966248
[Train] epoch 201 Batch 16 Loss 0.10528431087732315
[Train] epoch 201 Batch 17 Loss 0.20410630106925964
[Train] epoch 201 Batch 18 Loss 0.11949686706066132
[Train] epoch 201 Batch 19 Loss 0.10323800146579742
[Train] epoch 201 Batch 20 Loss 0.17025618255138397
[Train] epoch 201 Batch 21 Loss 0.10794010758399963
[Train] epoch 201 Batch 22 Loss 0.07376359403133392
[Train] epoch 201 Batch 23 Loss 0.14205500483512878
[Train] epoch 201 Batch 24 Loss 0.0742238238453865
[Train] epoch 201 Batch 25 Loss 0.20602333545684814
[Train] epoch 201 Batch 26 Loss 0.20652107894420624
[Train] epoch 201 Batch 27 Loss 0.17271043360233307
[Train] epoch 201 Batch 28 Loss 0.1762753129005432
[Train] epoch 201 Batch 29 Loss 0.16977953910827637
[Train] epoch 201 Batch 30 Loss 0.16976897418498993
[Train] epoch 201 Batch 31 Loss 0.06873123347759247
[Train] epoch 201 Batch 32 Loss 0.27290114760398865
[Train] epoch 201 Batch 33 Loss 0.2433648556470871
[Train] epoch 201 Batch 34 Loss 0.20458252727985382
[Train] epoch 201 Batch 35 Loss 0.27329492568969727
[Train] epoch 201 Batch 36 Loss 0.3030751347541809
[Train] epoch 201 Batch 37 Loss 0.034358274191617966
[Train] epoch 201 Batch 38 Loss 0.30778923630714417
[Train] epoch 201 Batch 39 Loss 0.1697443127632141
[Train] epoch 201 Batch 40 Loss 0.10738681256771088
[Train] epoch 201 Batch 41 Loss 0.3030712604522705
[Train] epoch 201 Batch 42 Loss 0.16786137223243713
[Train] epoch 201 Batch 43 Loss 0.07280296087265015
[Train] epoch 201 Batch 44 Loss 0.3698851764202118
[Train] epoch 201 Batch 45 Loss 0.20625783503055573
[Train] epoch 201 Batch 46 Loss 0.1701747626066208
[Train] epoch 201 Batch 47 Loss 0.03838144615292549
[Train] epoch 202 Batch 0 Loss 0.2063385397195816
[Train] epoch 202 Batch 1 Loss 0.20416291058063507
[Train] epoch 202 Batch 2 Loss 0.07297511398792267
[Train] epoch 202 Batch 3 Loss 0.23649753630161285
[Train] epoch 202 Batch 4 Loss 0.23846763372421265
[Train] epoch 202 Batch 5 Loss 0.034453269094228745
[Train] epoch 202 Batch 6 Loss 0.10310857743024826
[Train] epoch 202 Batch 7 Loss 0.16768240928649902
[Train] epoch 202 Batch 8 Loss 0.13726678490638733
[Train] epoch 202 Batch 9 Loss 0.10501755774021149
[Train] epoch 202 Batch 10 Loss 0.24057188630104065
[Train] epoch 202 Batch 11 Loss 0.1697339415550232
[Train] epoch 202 Batch 12 Loss 0.2708030343055725
[Train] epoch 202 Batch 13 Loss 0.270664781332016
[Train] epoch 202 Batch 14 Loss 0.07262066751718521
[Train] epoch 202 Batch 15 Loss 0.17349721491336823
[Train] epoch 202 Batch 16 Loss 0.20775803923606873
[Train] epoch 202 Batch 17 Loss 0.20405983924865723
[Train] epoch 202 Batch 18 Loss 0.20416007936000824
[Train] epoch 202 Batch 19 Loss 0.3372226357460022
[Train] epoch 202 Batch 20 Loss 0.1429012417793274
[Train] epoch 202 Batch 21 Loss 0.10666629672050476
[Train] epoch 202 Batch 22 Loss 0.20396964251995087
[Train] epoch 202 Batch 23 Loss 0.1393309235572815
[Train] epoch 202 Batch 24 Loss 0.10101345181465149
[Train] epoch 202 Batch 25 Loss 0.1391928344964981
[Train] epoch 202 Batch 26 Loss 0.137161523103714
[Train] epoch 202 Batch 27 Loss 0.27227962017059326
[Train] epoch 202 Batch 28 Loss 0.33714595437049866
[Train] epoch 202 Batch 29 Loss 0.10303187370300293
[Train] epoch 202 Batch 30 Loss 0.23801712691783905
[Train] epoch 202 Batch 31 Loss 0.1351090371608734
[Train] epoch 202 Batch 32 Loss 0.20567533373832703
[Train] epoch 202 Batch 33 Loss 0.2343420684337616
[Train] epoch 202 Batch 34 Loss 0.07053562253713608
[Train] epoch 202 Batch 35 Loss 0.20742227137088776
[Train] epoch 202 Batch 36 Loss 0.20748049020767212
[Train] epoch 202 Batch 37 Loss 0.20559090375900269
[Train] epoch 202 Batch 38 Loss 0.20379197597503662
[Train] epoch 202 Batch 39 Loss 0.16968634724617004
[Train] epoch 202 Batch 40 Loss 0.1692432314157486
[Train] epoch 202 Batch 41 Loss 0.17314526438713074
[Train] epoch 202 Batch 42 Loss 0.16953307390213013
[Train] epoch 202 Batch 43 Loss 0.17135155200958252
[Train] epoch 202 Batch 44 Loss 0.1711553931236267
[Train] epoch 202 Batch 45 Loss 0.1728571355342865
[Train] epoch 202 Batch 46 Loss 0.1078275516629219
[Train] epoch 202 Batch 47 Loss 0.17153583467006683
[Train] epoch 203 Batch 0 Loss 0.1731998473405838
[Train] epoch 203 Batch 1 Loss 0.13875293731689453
[Train] epoch 203 Batch 2 Loss 0.37508130073547363
[Train] epoch 203 Batch 3 Loss 0.2361561805009842
[Train] epoch 203 Batch 4 Loss 0.10446114838123322
[Train] epoch 203 Batch 5 Loss 0.16920512914657593
[Train] epoch 203 Batch 6 Loss 0.20743006467819214
[Train] epoch 203 Batch 7 Loss 0.2720019817352295
[Train] epoch 203 Batch 8 Loss 0.3043176829814911
[Train] epoch 203 Batch 9 Loss 0.10261306166648865
[Train] epoch 203 Batch 10 Loss 0.24150891602039337
[Train] epoch 203 Batch 11 Loss 0.20187941193580627
[Train] epoch 203 Batch 12 Loss 0.17105765640735626
[Train] epoch 203 Batch 13 Loss 0.20346535742282867
[Train] epoch 203 Batch 14 Loss 0.1698022037744522
[Train] epoch 203 Batch 15 Loss 0.2701035141944885
[Train] epoch 203 Batch 16 Loss 0.1676541268825531
[Train] epoch 203 Batch 17 Loss 0.2381141185760498
[Train] epoch 203 Batch 18 Loss 0.1029043197631836
[Train] epoch 203 Batch 19 Loss 0.1389138400554657
[Train] epoch 203 Batch 20 Loss 0.27234315872192383
[Train] epoch 203 Batch 21 Loss 0.20561516284942627
[Train] epoch 203 Batch 22 Loss 0.2039262056350708
[Train] epoch 203 Batch 23 Loss 0.23815548419952393
[Train] epoch 203 Batch 24 Loss 0.14119210839271545
[Train] epoch 203 Batch 25 Loss 0.2037891298532486
[Train] epoch 203 Batch 26 Loss 0.10297511518001556
[Train] epoch 203 Batch 27 Loss 0.040252551436424255
[Train] epoch 203 Batch 28 Loss 0.24002991616725922
[Train] epoch 203 Batch 29 Loss 0.20381304621696472
[Train] epoch 203 Batch 30 Loss 0.07253968715667725
[Train] epoch 203 Batch 31 Loss 0.14116790890693665
[Train] epoch 203 Batch 32 Loss 0.1390935778617859
[Train] epoch 203 Batch 33 Loss 0.10301433503627777
[Train] epoch 203 Batch 34 Loss 0.2685791254043579
[Train] epoch 203 Batch 35 Loss 0.13731560111045837
[Train] epoch 203 Batch 36 Loss 0.03428122401237488
[Train] epoch 203 Batch 37 Loss 0.20396822690963745
[Train] epoch 203 Batch 38 Loss 0.20585037767887115
[Train] epoch 203 Batch 39 Loss 0.03427964076399803
[Train] epoch 203 Batch 40 Loss 0.13740022480487823
[Train] epoch 203 Batch 41 Loss 0.10297203063964844
[Train] epoch 203 Batch 42 Loss 0.1734425127506256
[Train] epoch 203 Batch 43 Loss 0.10484885424375534
[Train] epoch 203 Batch 44 Loss 0.20389699935913086
[Train] epoch 203 Batch 45 Loss 0.23628215491771698
[Train] epoch 203 Batch 46 Loss 0.24050918221473694
[Train] epoch 203 Batch 47 Loss 0.13919369876384735
[Train] epoch 204 Batch 0 Loss 0.1046987995505333
[Train] epoch 204 Batch 1 Loss 0.30293217301368713
[Train] epoch 204 Batch 2 Loss 0.14110404253005981
[Train] epoch 204 Batch 3 Loss 0.13529343903064728
[Train] epoch 204 Batch 4 Loss 0.20586943626403809
[Train] epoch 204 Batch 5 Loss 0.10668466985225677
[Train] epoch 204 Batch 6 Loss 0.20367999374866486
[Train] epoch 204 Batch 7 Loss 0.13707341253757477
[Train] epoch 204 Batch 8 Loss 0.207598477602005
[Train] epoch 204 Batch 9 Loss 0.169412761926651
[Train] epoch 204 Batch 10 Loss 0.10279074311256409
[Train] epoch 204 Batch 11 Loss 0.13898909091949463
[Train] epoch 204 Batch 12 Loss 0.23809130489826202
[Train] epoch 204 Batch 13 Loss 0.13704590499401093
[Train] epoch 204 Batch 14 Loss 0.10284432768821716
[Train] epoch 204 Batch 15 Loss 0.27226030826568604
[Train] epoch 204 Batch 16 Loss 0.07016739249229431
[Train] epoch 204 Batch 17 Loss 0.23790493607521057
[Train] epoch 204 Batch 18 Loss 0.3028251826763153
[Train] epoch 204 Batch 19 Loss 0.13523289561271667
[Train] epoch 204 Batch 20 Loss 0.2703656852245331
[Train] epoch 204 Batch 21 Loss 0.10274434089660645
[Train] epoch 204 Batch 22 Loss 0.10266081243753433
[Train] epoch 204 Batch 23 Loss 0.3062480688095093
[Train] epoch 204 Batch 24 Loss 0.23606908321380615
[Train] epoch 204 Batch 25 Loss 0.17136405408382416
[Train] epoch 204 Batch 26 Loss 0.27193954586982727
[Train] epoch 204 Batch 27 Loss 0.16760510206222534
[Train] epoch 204 Batch 28 Loss 0.3403681814670563
[Train] epoch 204 Batch 29 Loss 0.1712477058172226
[Train] epoch 204 Batch 30 Loss 0.30093711614608765
[Train] epoch 204 Batch 31 Loss 0.2701156735420227
[Train] epoch 204 Batch 32 Loss 0.2070576548576355
[Train] epoch 204 Batch 33 Loss 0.036019548773765564
[Train] epoch 204 Batch 34 Loss 0.3045318126678467
[Train] epoch 204 Batch 35 Loss 0.07367565482854843
[Train] epoch 204 Batch 36 Loss 0.10272907465696335
[Train] epoch 204 Batch 37 Loss 0.07018087804317474
[Train] epoch 204 Batch 38 Loss 0.10273861885070801
[Train] epoch 204 Batch 39 Loss 0.07010254263877869
[Train] epoch 204 Batch 40 Loss 0.13878124952316284
[Train] epoch 204 Batch 41 Loss 0.1742660403251648
[Train] epoch 204 Batch 42 Loss 0.140020489692688
[Train] epoch 204 Batch 43 Loss 0.23774537444114685
[Train] epoch 204 Batch 44 Loss 0.10744424164295197
[Train] epoch 204 Batch 45 Loss 0.27170515060424805
[Train] epoch 204 Batch 46 Loss 0.1025267094373703
[Train] epoch 204 Batch 47 Loss 0.20497781038284302
[Train] epoch 205 Batch 0 Loss 0.10093295574188232
[Train] epoch 205 Batch 1 Loss 0.23605915904045105
[Train] epoch 205 Batch 2 Loss 0.2391221523284912
[Train] epoch 205 Batch 3 Loss 0.17102664709091187
[Train] epoch 205 Batch 4 Loss 0.1383870393037796
[Train] epoch 205 Batch 5 Loss 0.20349088311195374
[Train] epoch 205 Batch 6 Loss 0.13511008024215698
[Train] epoch 205 Batch 7 Loss 0.17107385396957397
[Train] epoch 205 Batch 8 Loss 0.1367131471633911
[Train] epoch 205 Batch 9 Loss 0.2732958197593689
[Train] epoch 205 Batch 10 Loss 0.0015990985557436943
[Train] epoch 205 Batch 11 Loss 0.2032873034477234
[Train] epoch 205 Batch 12 Loss 0.0713978260755539
[Train] epoch 205 Batch 13 Loss 0.13788387179374695
[Train] epoch 205 Batch 14 Loss 0.1043316200375557
[Train] epoch 205 Batch 15 Loss 0.20830292999744415
[Train] epoch 205 Batch 16 Loss 0.13679549098014832
[Train] epoch 205 Batch 17 Loss 0.16940920054912567
[Train] epoch 205 Batch 18 Loss 0.23762348294258118
[Train] epoch 205 Batch 19 Loss 0.23952575027942657
[Train] epoch 205 Batch 20 Loss 0.10447325557470322
[Train] epoch 205 Batch 21 Loss 0.13352161645889282
[Train] epoch 205 Batch 22 Loss 0.3369867503643036
[Train] epoch 205 Batch 23 Loss 0.20361816883087158
[Train] epoch 205 Batch 24 Loss 0.16959530115127563
[Train] epoch 205 Batch 25 Loss 0.2722170650959015
[Train] epoch 205 Batch 26 Loss 0.1695328652858734
[Train] epoch 205 Batch 27 Loss 0.3044613003730774
[Train] epoch 205 Batch 28 Loss 0.30288925766944885
[Train] epoch 205 Batch 29 Loss 0.3048308491706848
[Train] epoch 205 Batch 30 Loss 0.13682566583156586
[Train] epoch 205 Batch 31 Loss 0.1712203025817871
[Train] epoch 205 Batch 32 Loss 0.17326611280441284
[Train] epoch 205 Batch 33 Loss 0.10454438626766205
[Train] epoch 205 Batch 34 Loss 0.34103941917419434
[Train] epoch 205 Batch 35 Loss 0.2000008225440979
[Train] epoch 205 Batch 36 Loss 0.07227367907762527
[Train] epoch 205 Batch 37 Loss 0.37118810415267944
[Train] epoch 205 Batch 38 Loss 0.07031966745853424
[Train] epoch 205 Batch 39 Loss 0.1727871149778366
[Train] epoch 205 Batch 40 Loss 0.17509418725967407
[Train] epoch 205 Batch 41 Loss 0.30643975734710693
[Train] epoch 205 Batch 42 Loss 0.10478195548057556
[Train] epoch 205 Batch 43 Loss 0.17505870759487152
[Train] epoch 205 Batch 44 Loss 0.07035163789987564
[Train] epoch 205 Batch 45 Loss 0.07009246200323105
[Train] epoch 205 Batch 46 Loss 0.1028437614440918
[Train] epoch 205 Batch 47 Loss 0.07198861986398697
[Train] epoch 206 Batch 0 Loss 0.20558255910873413
[Train] epoch 206 Batch 1 Loss 0.1062166839838028
[Train] epoch 206 Batch 2 Loss 0.3368839621543884
[Train] epoch 206 Batch 3 Loss 0.07028897106647491
[Train] epoch 206 Batch 4 Loss 0.13697916269302368
[Train] epoch 206 Batch 5 Loss 0.27391427755355835
[Train] epoch 206 Batch 6 Loss 0.1351521611213684
[Train] epoch 206 Batch 7 Loss 0.23812633752822876
[Train] epoch 206 Batch 8 Loss 0.1059911772608757
[Train] epoch 206 Batch 9 Loss 0.3371577262878418
[Train] epoch 206 Batch 10 Loss 0.23754142224788666
[Train] epoch 206 Batch 11 Loss 0.16955403983592987
[Train] epoch 206 Batch 12 Loss 0.17439797520637512
[Train] epoch 206 Batch 13 Loss 0.17113129794597626
[Train] epoch 206 Batch 14 Loss 0.06666764616966248
[Train] epoch 206 Batch 15 Loss 0.2719775438308716
[Train] epoch 206 Batch 16 Loss 0.10571905225515366
[Train] epoch 206 Batch 17 Loss 0.1705850064754486
[Train] epoch 206 Batch 18 Loss 0.10777092725038528
[Train] epoch 206 Batch 19 Loss 0.23603704571723938
[Train] epoch 206 Batch 20 Loss 0.16922184824943542
[Train] epoch 206 Batch 21 Loss 0.2050066739320755
[Train] epoch 206 Batch 22 Loss 0.2686755061149597
[Train] epoch 206 Batch 23 Loss 0.23818594217300415
[Train] epoch 206 Batch 24 Loss 0.20704492926597595
[Train] epoch 206 Batch 25 Loss 0.17086011171340942
[Train] epoch 206 Batch 26 Loss 0.17078357934951782
[Train] epoch 206 Batch 27 Loss 0.20200438797473907
[Train] epoch 206 Batch 28 Loss 0.1350923478603363
[Train] epoch 206 Batch 29 Loss 0.2697545886039734
[Train] epoch 206 Batch 30 Loss 0.10578200966119766
[Train] epoch 206 Batch 31 Loss 0.3401554226875305
[Train] epoch 206 Batch 32 Loss 0.20319151878356934
[Train] epoch 206 Batch 33 Loss 0.10255742073059082
[Train] epoch 206 Batch 34 Loss 0.13637596368789673
[Train] epoch 206 Batch 35 Loss 0.04145163297653198
[Train] epoch 206 Batch 36 Loss 0.2737548053264618
[Train] epoch 206 Batch 37 Loss 0.1352357715368271
[Train] epoch 206 Batch 38 Loss 0.06853217631578445
[Train] epoch 206 Batch 39 Loss 0.3376254141330719
[Train] epoch 206 Batch 40 Loss 0.27049699425697327
[Train] epoch 206 Batch 41 Loss 0.18813768029212952
[Train] epoch 206 Batch 42 Loss 0.036300111562013626
[Train] epoch 206 Batch 43 Loss 0.04812822863459587
[Train] epoch 206 Batch 44 Loss 0.07004588842391968
[Train] epoch 206 Batch 45 Loss 0.2520178556442261
[Train] epoch 206 Batch 46 Loss 0.3048636317253113
[Train] epoch 206 Batch 47 Loss 0.03877151757478714
[Train] epoch 207 Batch 0 Loss 0.10488379746675491
[Train] epoch 207 Batch 1 Loss 0.0685902088880539
[Train] epoch 207 Batch 2 Loss 0.2344050407409668
[Train] epoch 207 Batch 3 Loss 0.029401328414678574
[Train] epoch 207 Batch 4 Loss 0.15568757057189941
[Train] epoch 207 Batch 5 Loss 0.11125922203063965
[Train] epoch 207 Batch 6 Loss 0.3077154755592346
[Train] epoch 207 Batch 7 Loss 0.3379095792770386
[Train] epoch 207 Batch 8 Loss 0.23679134249687195
[Train] epoch 207 Batch 9 Loss 0.03747723996639252
[Train] epoch 207 Batch 10 Loss 0.20219773054122925
[Train] epoch 207 Batch 11 Loss 0.23807719349861145
[Train] epoch 207 Batch 12 Loss 0.24272465705871582
[Train] epoch 207 Batch 13 Loss 0.1415242850780487
[Train] epoch 207 Batch 14 Loss 0.10870836675167084
[Train] epoch 207 Batch 15 Loss 0.33883172273635864
[Train] epoch 207 Batch 16 Loss 0.34016987681388855
[Train] epoch 207 Batch 17 Loss 0.24094100296497345
[Train] epoch 207 Batch 18 Loss 0.17035570740699768
[Train] epoch 207 Batch 19 Loss 0.24009904265403748
[Train] epoch 207 Batch 20 Loss 0.23722940683364868
[Train] epoch 207 Batch 21 Loss 0.23744884133338928
[Train] epoch 207 Batch 22 Loss 0.23740404844284058
[Train] epoch 207 Batch 23 Loss 0.17908875644207
[Train] epoch 207 Batch 24 Loss 0.2347675859928131
[Train] epoch 207 Batch 25 Loss 0.23756015300750732
[Train] epoch 207 Batch 26 Loss 0.24054066836833954
[Train] epoch 207 Batch 27 Loss 0.1769048422574997
[Train] epoch 207 Batch 28 Loss 0.1134200319647789
[Train] epoch 207 Batch 29 Loss 0.07573671638965607
[Train] epoch 207 Batch 30 Loss 0.20920658111572266
[Train] epoch 207 Batch 31 Loss 0.2728104591369629
[Train] epoch 207 Batch 32 Loss 0.14267247915267944
[Train] epoch 207 Batch 33 Loss 0.03796999901533127
[Train] epoch 207 Batch 34 Loss 0.25321823358535767
[Train] epoch 207 Batch 35 Loss 0.10444919764995575
[Train] epoch 207 Batch 36 Loss 0.13903486728668213
[Train] epoch 207 Batch 37 Loss 0.11326822638511658
[Train] epoch 207 Batch 38 Loss 0.1449977606534958
[Train] epoch 207 Batch 39 Loss 0.14199906587600708
[Train] epoch 207 Batch 40 Loss 0.20560961961746216
[Train] epoch 207 Batch 41 Loss 0.3417366147041321
[Train] epoch 207 Batch 42 Loss 0.07504278421401978
[Train] epoch 207 Batch 43 Loss 0.10139179974794388
[Train] epoch 207 Batch 44 Loss 0.17615187168121338
[Train] epoch 207 Batch 45 Loss 0.13866236805915833
[Train] epoch 207 Batch 46 Loss 0.17069126665592194
[Train] epoch 207 Batch 47 Loss 0.03459727391600609
[Train] epoch 208 Batch 0 Loss 0.10900962352752686
[Train] epoch 208 Batch 1 Loss 0.17587070167064667
[Train] epoch 208 Batch 2 Loss 0.071799635887146
[Train] epoch 208 Batch 3 Loss 0.2080429196357727
[Train] epoch 208 Batch 4 Loss 0.30679601430892944
[Train] epoch 208 Batch 5 Loss 0.1777731478214264
[Train] epoch 208 Batch 6 Loss 0.3089047074317932
[Train] epoch 208 Batch 7 Loss 0.2074548602104187
[Train] epoch 208 Batch 8 Loss 0.13817991316318512
[Train] epoch 208 Batch 9 Loss 0.13787896931171417
[Train] epoch 208 Batch 10 Loss 0.10616686940193176
[Train] epoch 208 Batch 11 Loss 0.2764139473438263
[Train] epoch 208 Batch 12 Loss 0.23692269623279572
[Train] epoch 208 Batch 13 Loss 0.0694386214017868
[Train] epoch 208 Batch 14 Loss 0.2396548092365265
[Train] epoch 208 Batch 15 Loss 0.13795697689056396
[Train] epoch 208 Batch 16 Loss 0.07123956084251404
[Train] epoch 208 Batch 17 Loss 0.20697498321533203
[Train] epoch 208 Batch 18 Loss 0.14063295722007751
[Train] epoch 208 Batch 19 Loss 0.17291001975536346
[Train] epoch 208 Batch 20 Loss 0.14203546941280365
[Train] epoch 208 Batch 21 Loss 0.23948705196380615
[Train] epoch 208 Batch 22 Loss 0.10377752780914307
[Train] epoch 208 Batch 23 Loss 0.17215199768543243
[Train] epoch 208 Batch 24 Loss 0.13569971919059753
[Train] epoch 208 Batch 25 Loss 0.0710362121462822
[Train] epoch 208 Batch 26 Loss 0.1360584795475006
[Train] epoch 208 Batch 27 Loss 0.24035607278347015
[Train] epoch 208 Batch 28 Loss 0.3064115047454834
[Train] epoch 208 Batch 29 Loss 0.10368672013282776
[Train] epoch 208 Batch 30 Loss 0.13729842007160187
[Train] epoch 208 Batch 31 Loss 0.3048882484436035
[Train] epoch 208 Batch 32 Loss 0.1719450056552887
[Train] epoch 208 Batch 33 Loss 0.13603413105010986
[Train] epoch 208 Batch 34 Loss 0.1009712666273117
[Train] epoch 208 Batch 35 Loss 0.17186197638511658
[Train] epoch 208 Batch 36 Loss 0.27588069438934326
[Train] epoch 208 Batch 37 Loss 0.23620647192001343
[Train] epoch 208 Batch 38 Loss 0.07043880224227905
[Train] epoch 208 Batch 39 Loss 0.27042216062545776
[Train] epoch 208 Batch 40 Loss 0.1360176056623459
[Train] epoch 208 Batch 41 Loss 0.16944687068462372
[Train] epoch 208 Batch 42 Loss 0.20864194631576538
[Train] epoch 208 Batch 43 Loss 0.24478083848953247
[Train] epoch 208 Batch 44 Loss 0.17124246060848236
[Train] epoch 208 Batch 45 Loss 0.0018434608355164528
[Train] epoch 208 Batch 46 Loss 0.26848268508911133
[Train] epoch 208 Batch 47 Loss 0.3400803804397583
[Train] epoch 209 Batch 0 Loss 0.13782235980033875
[Train] epoch 209 Batch 1 Loss 0.03781617805361748
[Train] epoch 209 Batch 2 Loss 0.2360164225101471
[Train] epoch 209 Batch 3 Loss 0.14311128854751587
[Train] epoch 209 Batch 4 Loss 0.2710769772529602
[Train] epoch 209 Batch 5 Loss 0.2137339860200882
[Train] epoch 209 Batch 6 Loss 0.27279818058013916
[Train] epoch 209 Batch 7 Loss 0.16799619793891907
[Train] epoch 209 Batch 8 Loss 0.24033606052398682
[Train] epoch 209 Batch 9 Loss 0.23767614364624023
[Train] epoch 209 Batch 10 Loss 0.038114339113235474
[Train] epoch 209 Batch 11 Loss 0.4060690701007843
[Train] epoch 209 Batch 12 Loss 0.30303484201431274
[Train] epoch 209 Batch 13 Loss 0.20480504631996155
[Train] epoch 209 Batch 14 Loss 0.10301800072193146
[Train] epoch 209 Batch 15 Loss 0.17183977365493774
[Train] epoch 209 Batch 16 Loss 0.13930287957191467
[Train] epoch 209 Batch 17 Loss 0.23728647828102112
[Train] epoch 209 Batch 18 Loss 0.23745742440223694
[Train] epoch 209 Batch 19 Loss 0.206916943192482
[Train] epoch 209 Batch 20 Loss 0.27355578541755676
[Train] epoch 209 Batch 21 Loss 0.1371038556098938
[Train] epoch 209 Batch 22 Loss 0.07042844593524933
[Train] epoch 209 Batch 23 Loss 0.20211026072502136
[Train] epoch 209 Batch 24 Loss 0.10293889045715332
[Train] epoch 209 Batch 25 Loss 0.17170310020446777
[Train] epoch 209 Batch 26 Loss 0.10550949722528458
[Train] epoch 209 Batch 27 Loss 0.133334219455719
[Train] epoch 209 Batch 28 Loss 0.17489805817604065
[Train] epoch 209 Batch 29 Loss 0.20677050948143005
[Train] epoch 209 Batch 30 Loss 0.20578867197036743
[Train] epoch 209 Batch 31 Loss 0.03941430151462555
[Train] epoch 209 Batch 32 Loss 0.06873979419469833
[Train] epoch 209 Batch 33 Loss 0.10448048263788223
[Train] epoch 209 Batch 34 Loss 0.2346150279045105
[Train] epoch 209 Batch 35 Loss 0.20364877581596375
[Train] epoch 209 Batch 36 Loss 0.03619582951068878
[Train] epoch 209 Batch 37 Loss 0.2036205381155014
[Train] epoch 209 Batch 38 Loss 0.06871641427278519
[Train] epoch 209 Batch 39 Loss 0.3069516718387604
[Train] epoch 209 Batch 40 Loss 0.23820286989212036
[Train] epoch 209 Batch 41 Loss 0.33742427825927734
[Train] epoch 209 Batch 42 Loss 0.17260470986366272
[Train] epoch 209 Batch 43 Loss 0.13896581530570984
[Train] epoch 209 Batch 44 Loss 0.17149747908115387
[Train] epoch 209 Batch 45 Loss 0.10279810428619385
[Train] epoch 209 Batch 46 Loss 0.13841797411441803
[Train] epoch 209 Batch 47 Loss 0.1714828908443451
[Train] epoch 210 Batch 0 Loss 0.06869305670261383
[Train] epoch 210 Batch 1 Loss 0.2361222505569458
[Train] epoch 210 Batch 2 Loss 0.03763139620423317
[Train] epoch 210 Batch 3 Loss 0.1353483498096466
[Train] epoch 210 Batch 4 Loss 0.23659715056419373
[Train] epoch 210 Batch 5 Loss 0.10074645280838013
[Train] epoch 210 Batch 6 Loss 0.37368232011795044
[Train] epoch 210 Batch 7 Loss 0.07070595771074295
[Train] epoch 210 Batch 8 Loss 0.16993248462677002
[Train] epoch 210 Batch 9 Loss 0.17165237665176392
[Train] epoch 210 Batch 10 Loss 0.13512414693832397
[Train] epoch 210 Batch 11 Loss 0.2063121199607849
[Train] epoch 210 Batch 12 Loss 0.14137150347232819
[Train] epoch 210 Batch 13 Loss 0.17212681472301483
[Train] epoch 210 Batch 14 Loss 0.17215017974376678
[Train] epoch 210 Batch 15 Loss 0.14191630482673645
[Train] epoch 210 Batch 16 Loss 0.002090320223942399
[Train] epoch 210 Batch 17 Loss 0.26886868476867676
[Train] epoch 210 Batch 18 Loss 0.20442867279052734
[Train] epoch 210 Batch 19 Loss 0.10329416394233704
[Train] epoch 210 Batch 20 Loss 0.10336078703403473
[Train] epoch 210 Batch 21 Loss 0.10779216885566711
[Train] epoch 210 Batch 22 Loss 0.2711125612258911
[Train] epoch 210 Batch 23 Loss 0.271134614944458
[Train] epoch 210 Batch 24 Loss 0.16778314113616943
[Train] epoch 210 Batch 25 Loss 0.3700675666332245
[Train] epoch 210 Batch 26 Loss 0.20674985647201538
[Train] epoch 210 Batch 27 Loss 0.3790976405143738
[Train] epoch 210 Batch 28 Loss 0.10797521471977234
[Train] epoch 210 Batch 29 Loss 0.07574190199375153
[Train] epoch 210 Batch 30 Loss 0.13560107350349426
[Train] epoch 210 Batch 31 Loss 0.33557745814323425
[Train] epoch 210 Batch 32 Loss 0.23893120884895325
[Train] epoch 210 Batch 33 Loss 0.1722005307674408
[Train] epoch 210 Batch 34 Loss 0.1078389436006546
[Train] epoch 210 Batch 35 Loss 0.3078061640262604
[Train] epoch 210 Batch 36 Loss 0.07114629447460175
[Train] epoch 210 Batch 37 Loss 0.20661801099777222
[Train] epoch 210 Batch 38 Loss 0.23881947994232178
[Train] epoch 210 Batch 39 Loss 0.17872972786426544
[Train] epoch 210 Batch 40 Loss 0.2387930154800415
[Train] epoch 210 Batch 41 Loss 0.17639502882957458
[Train] epoch 210 Batch 42 Loss 0.13978703320026398
[Train] epoch 210 Batch 43 Loss 0.10539169609546661
[Train] epoch 210 Batch 44 Loss 0.2064976692199707
[Train] epoch 210 Batch 45 Loss 0.1375986933708191
[Train] epoch 210 Batch 46 Loss 0.10530248284339905
[Train] epoch 210 Batch 47 Loss 0.23647433519363403
[Train] epoch 211 Batch 0 Loss 0.13552771508693695
[Train] epoch 211 Batch 1 Loss 0.3074714243412018
[Train] epoch 211 Batch 2 Loss 0.2103223353624344
[Train] epoch 211 Batch 3 Loss 0.1740187555551529
[Train] epoch 211 Batch 4 Loss 0.16978096961975098
[Train] epoch 211 Batch 5 Loss 0.2041986584663391
[Train] epoch 211 Batch 6 Loss 0.13942328095436096
[Train] epoch 211 Batch 7 Loss 0.10512807220220566
[Train] epoch 211 Batch 8 Loss 0.20624011754989624
[Train] epoch 211 Batch 9 Loss 0.06861429661512375
[Train] epoch 211 Batch 10 Loss 0.2687181830406189
[Train] epoch 211 Batch 11 Loss 0.33730679750442505
[Train] epoch 211 Batch 12 Loss 0.1010909378528595
[Train] epoch 211 Batch 13 Loss 0.3032691478729248
[Train] epoch 211 Batch 14 Loss 0.1411043405532837
[Train] epoch 211 Batch 15 Loss 0.17375120520591736
[Train] epoch 211 Batch 16 Loss 0.13523530960083008
[Train] epoch 211 Batch 17 Loss 0.20405255258083344
[Train] epoch 211 Batch 18 Loss 0.0037549736443907022
[Train] epoch 211 Batch 19 Loss 0.036118488758802414
[Train] epoch 211 Batch 20 Loss 0.2059088796377182
[Train] epoch 211 Batch 21 Loss 0.2040146291255951
[Train] epoch 211 Batch 22 Loss 0.20418265461921692
[Train] epoch 211 Batch 23 Loss 0.24023064970970154
[Train] epoch 211 Batch 24 Loss 0.17157725989818573
[Train] epoch 211 Batch 25 Loss 0.1045316606760025
[Train] epoch 211 Batch 26 Loss 0.33877044916152954
[Train] epoch 211 Batch 27 Loss 0.3734992742538452
[Train] epoch 211 Batch 28 Loss 0.13549800217151642
[Train] epoch 211 Batch 29 Loss 0.13728106021881104
[Train] epoch 211 Batch 30 Loss 0.13884827494621277
[Train] epoch 211 Batch 31 Loss 0.20413358509540558
[Train] epoch 211 Batch 32 Loss 0.14082294702529907
[Train] epoch 211 Batch 33 Loss 0.17125695943832397
[Train] epoch 211 Batch 34 Loss 0.0017621596343815327
[Train] epoch 211 Batch 35 Loss 0.2705797255039215
[Train] epoch 211 Batch 36 Loss 0.20410680770874023
[Train] epoch 211 Batch 37 Loss 0.07015174627304077
[Train] epoch 211 Batch 38 Loss 0.10279963910579681
[Train] epoch 211 Batch 39 Loss 0.2378423511981964
[Train] epoch 211 Batch 40 Loss 0.10299824923276901
[Train] epoch 211 Batch 41 Loss 0.10618787258863449
[Train] epoch 211 Batch 42 Loss 0.1713828444480896
[Train] epoch 211 Batch 43 Loss 0.24185146391391754
[Train] epoch 211 Batch 44 Loss 0.1711253821849823
[Train] epoch 211 Batch 45 Loss 0.13693290948867798
[Train] epoch 211 Batch 46 Loss 0.272169828414917
[Train] epoch 211 Batch 47 Loss 0.23917439579963684
[Train] epoch 212 Batch 0 Loss 0.13522779941558838
[Train] epoch 212 Batch 1 Loss 0.14235186576843262
[Train] epoch 212 Batch 2 Loss 0.2059268057346344
[Train] epoch 212 Batch 3 Loss 0.10410696268081665
[Train] epoch 212 Batch 4 Loss 0.3385027348995209
[Train] epoch 212 Batch 5 Loss 0.07016754150390625
[Train] epoch 212 Batch 6 Loss 0.30458417534828186
[Train] epoch 212 Batch 7 Loss 0.3043062090873718
[Train] epoch 212 Batch 8 Loss 0.2381531000137329
[Train] epoch 212 Batch 9 Loss 0.1693347841501236
[Train] epoch 212 Batch 10 Loss 0.17280441522598267
[Train] epoch 212 Batch 11 Loss 0.27384182810783386
[Train] epoch 212 Batch 12 Loss 0.3367670774459839
[Train] epoch 212 Batch 13 Loss 0.13863065838813782
[Train] epoch 212 Batch 14 Loss 0.23595616221427917
[Train] epoch 212 Batch 15 Loss 0.13831865787506104
[Train] epoch 212 Batch 16 Loss 0.003147568553686142
[Train] epoch 212 Batch 17 Loss 0.13886982202529907
[Train] epoch 212 Batch 18 Loss 0.10078158974647522
[Train] epoch 212 Batch 19 Loss 0.30500832200050354
[Train] epoch 212 Batch 20 Loss 0.10288398712873459
[Train] epoch 212 Batch 21 Loss 0.1726308912038803
[Train] epoch 212 Batch 22 Loss 0.23805266618728638
[Train] epoch 212 Batch 23 Loss 0.24013453722000122
[Train] epoch 212 Batch 24 Loss 0.17413108050823212
[Train] epoch 212 Batch 25 Loss 0.10533637553453445
[Train] epoch 212 Batch 26 Loss 0.10258212685585022
[Train] epoch 212 Batch 27 Loss 0.16772055625915527
[Train] epoch 212 Batch 28 Loss 0.133334219455719
[Train] epoch 212 Batch 29 Loss 0.0711854100227356
[Train] epoch 212 Batch 30 Loss 0.16921591758728027
[Train] epoch 212 Batch 31 Loss 0.07265226542949677
[Train] epoch 212 Batch 32 Loss 0.16771751642227173
[Train] epoch 212 Batch 33 Loss 0.17218077182769775
[Train] epoch 212 Batch 34 Loss 0.23616579174995422
[Train] epoch 212 Batch 35 Loss 0.23826098442077637
[Train] epoch 212 Batch 36 Loss 0.1691998541355133
[Train] epoch 212 Batch 37 Loss 0.3028358221054077
[Train] epoch 212 Batch 38 Loss 0.13838066160678864
[Train] epoch 212 Batch 39 Loss 0.1028296947479248
[Train] epoch 212 Batch 40 Loss 0.23584838211536407
[Train] epoch 212 Batch 41 Loss 0.23905442655086517
[Train] epoch 212 Batch 42 Loss 0.10573635250329971
[Train] epoch 212 Batch 43 Loss 0.2731090188026428
[Train] epoch 212 Batch 44 Loss 0.1697934865951538
[Train] epoch 212 Batch 45 Loss 0.069562166929245
[Train] epoch 212 Batch 46 Loss 0.20464149117469788
[Train] epoch 212 Batch 47 Loss 0.06842925399541855
[Train] epoch 213 Batch 0 Loss 0.20352014899253845
[Train] epoch 213 Batch 1 Loss 0.10214701294898987
[Train] epoch 213 Batch 2 Loss 0.3077137768268585
[Train] epoch 213 Batch 3 Loss 0.2701610326766968
[Train] epoch 213 Batch 4 Loss 0.23611953854560852
[Train] epoch 213 Batch 5 Loss 0.23643933236598969
[Train] epoch 213 Batch 6 Loss 0.10529185831546783
[Train] epoch 213 Batch 7 Loss 0.17183350026607513
[Train] epoch 213 Batch 8 Loss 0.3333339989185333
[Train] epoch 213 Batch 9 Loss 0.20736226439476013
[Train] epoch 213 Batch 10 Loss 0.20420041680335999
[Train] epoch 213 Batch 11 Loss 0.13473111391067505
[Train] epoch 213 Batch 12 Loss 0.3041536808013916
[Train] epoch 213 Batch 13 Loss 0.03855302929878235
[Train] epoch 213 Batch 14 Loss 0.20828142762184143
[Train] epoch 213 Batch 15 Loss 0.10551664978265762
[Train] epoch 213 Batch 16 Loss 0.238505020737648
[Train] epoch 213 Batch 17 Loss 0.1718270480632782
[Train] epoch 213 Batch 18 Loss 0.10273011028766632
[Train] epoch 213 Batch 19 Loss 0.06941051781177521
[Train] epoch 213 Batch 20 Loss 0.13503384590148926
[Train] epoch 213 Batch 21 Loss 0.33857262134552
[Train] epoch 213 Batch 22 Loss 0.37390488386154175
[Train] epoch 213 Batch 23 Loss 0.16908204555511475
[Train] epoch 213 Batch 24 Loss 0.23606622219085693
[Train] epoch 213 Batch 25 Loss 0.10247689485549927
[Train] epoch 213 Batch 26 Loss 0.17089572548866272
[Train] epoch 213 Batch 27 Loss 0.1040026918053627
[Train] epoch 213 Batch 28 Loss 0.07170668989419937
[Train] epoch 213 Batch 29 Loss 0.27019351720809937
[Train] epoch 213 Batch 30 Loss 0.17448478937149048
[Train] epoch 213 Batch 31 Loss 0.03898421302437782
[Train] epoch 213 Batch 32 Loss 0.2035447657108307
[Train] epoch 213 Batch 33 Loss 0.20197120308876038
[Train] epoch 213 Batch 34 Loss 0.10433249175548553
[Train] epoch 213 Batch 35 Loss 0.1384420096874237
[Train] epoch 213 Batch 36 Loss 0.10218372941017151
[Train] epoch 213 Batch 37 Loss 0.23432707786560059
[Train] epoch 213 Batch 38 Loss 0.23613309860229492
[Train] epoch 213 Batch 39 Loss 0.3028056025505066
[Train] epoch 213 Batch 40 Loss 0.10570115596055984
[Train] epoch 213 Batch 41 Loss 0.2046515792608261
[Train] epoch 213 Batch 42 Loss 0.1692473590373993
[Train] epoch 213 Batch 43 Loss 0.10689394921064377
[Train] epoch 213 Batch 44 Loss 0.17107458412647247
[Train] epoch 213 Batch 45 Loss 0.07032735645771027
[Train] epoch 213 Batch 46 Loss 0.16956263780593872
[Train] epoch 213 Batch 47 Loss 0.03407870978116989
[Train] epoch 214 Batch 0 Loss 0.17072945833206177
[Train] epoch 214 Batch 1 Loss 0.10703209042549133
[Train] epoch 214 Batch 2 Loss 0.20769858360290527
[Train] epoch 214 Batch 3 Loss 0.17439977824687958
[Train] epoch 214 Batch 4 Loss 0.06963306665420532
[Train] epoch 214 Batch 5 Loss 0.133334219455719
[Train] epoch 214 Batch 6 Loss 0.1370166391134262
[Train] epoch 214 Batch 7 Loss 0.10216613858938217
[Train] epoch 214 Batch 8 Loss 0.1376994103193283
[Train] epoch 214 Batch 9 Loss 0.1040484756231308
[Train] epoch 214 Batch 10 Loss 0.23960742354393005
[Train] epoch 214 Batch 11 Loss 0.10227882117033005
[Train] epoch 214 Batch 12 Loss 0.13520365953445435
[Train] epoch 214 Batch 13 Loss 0.17087268829345703
[Train] epoch 214 Batch 14 Loss 0.27448558807373047
[Train] epoch 214 Batch 15 Loss 0.20508551597595215
[Train] epoch 214 Batch 16 Loss 0.034416407346725464
[Train] epoch 214 Batch 17 Loss 0.06882578879594803
[Train] epoch 214 Batch 18 Loss 0.3081756830215454
[Train] epoch 214 Batch 19 Loss 0.304134339094162
[Train] epoch 214 Batch 20 Loss 0.20356398820877075
[Train] epoch 214 Batch 21 Loss 0.33737117052078247
[Train] epoch 214 Batch 22 Loss 0.06856844574213028
[Train] epoch 214 Batch 23 Loss 0.17284585535526276
[Train] epoch 214 Batch 24 Loss 0.034397613257169724
[Train] epoch 214 Batch 25 Loss 0.1386675238609314
[Train] epoch 214 Batch 26 Loss 0.20724239945411682
[Train] epoch 214 Batch 27 Loss 0.135452002286911
[Train] epoch 214 Batch 28 Loss 0.2704724073410034
[Train] epoch 214 Batch 29 Loss 0.1408076137304306
[Train] epoch 214 Batch 30 Loss 0.13926050066947937
[Train] epoch 214 Batch 31 Loss 0.17266403138637543
[Train] epoch 214 Batch 32 Loss 0.10275845229625702
[Train] epoch 214 Batch 33 Loss 0.23610354959964752
[Train] epoch 214 Batch 34 Loss 0.20896658301353455
[Train] epoch 214 Batch 35 Loss 0.23968437314033508
[Train] epoch 214 Batch 36 Loss 0.2051132470369339
[Train] epoch 214 Batch 37 Loss 0.20170488953590393
[Train] epoch 214 Batch 38 Loss 0.1406942903995514
[Train] epoch 214 Batch 39 Loss 0.3081783652305603
[Train] epoch 214 Batch 40 Loss 0.16960379481315613
[Train] epoch 214 Batch 41 Loss 0.23856142163276672
[Train] epoch 214 Batch 42 Loss 0.3354228138923645
[Train] epoch 214 Batch 43 Loss 0.2379181981086731
[Train] epoch 214 Batch 44 Loss 0.27229833602905273
[Train] epoch 214 Batch 45 Loss 0.0685417503118515
[Train] epoch 214 Batch 46 Loss 0.2000008225440979
[Train] epoch 214 Batch 47 Loss 0.133334219455719
[Train] epoch 215 Batch 0 Loss 0.1370532512664795
[Train] epoch 215 Batch 1 Loss 0.33725789189338684
[Train] epoch 215 Batch 2 Loss 0.07015343010425568
[Train] epoch 215 Batch 3 Loss 0.20370489358901978
[Train] epoch 215 Batch 4 Loss 0.17120146751403809
[Train] epoch 215 Batch 5 Loss 0.2037077695131302
[Train] epoch 215 Batch 6 Loss 0.0699312835931778
[Train] epoch 215 Batch 7 Loss 0.27036383748054504
[Train] epoch 215 Batch 8 Loss 0.3395150601863861
[Train] epoch 215 Batch 9 Loss 0.17277134954929352
[Train] epoch 215 Batch 10 Loss 0.07150459289550781
[Train] epoch 215 Batch 11 Loss 0.2707744240760803
[Train] epoch 215 Batch 12 Loss 0.27009502053260803
[Train] epoch 215 Batch 13 Loss 0.10606023669242859
[Train] epoch 215 Batch 14 Loss 0.2070828229188919
[Train] epoch 215 Batch 15 Loss 0.2018260806798935
[Train] epoch 215 Batch 16 Loss 0.16745585203170776
[Train] epoch 215 Batch 17 Loss 0.17404265701770782
[Train] epoch 215 Batch 18 Loss 0.06847217679023743
[Train] epoch 215 Batch 19 Loss 0.035931337624788284
[Train] epoch 215 Batch 20 Loss 0.33987337350845337
[Train] epoch 215 Batch 21 Loss 0.10282677412033081
[Train] epoch 215 Batch 22 Loss 0.20382873713970184
[Train] epoch 215 Batch 23 Loss 0.16948598623275757
[Train] epoch 215 Batch 24 Loss 0.10412773489952087
[Train] epoch 215 Batch 25 Loss 0.23745164275169373
[Train] epoch 215 Batch 26 Loss 0.03590836748480797
[Train] epoch 215 Batch 27 Loss 0.37053096294403076
[Train] epoch 215 Batch 28 Loss 0.2055932730436325
[Train] epoch 215 Batch 29 Loss 0.10537992417812347
[Train] epoch 215 Batch 30 Loss 0.20535114407539368
[Train] epoch 215 Batch 31 Loss 0.3056138753890991
[Train] epoch 215 Batch 32 Loss 0.23586536943912506
[Train] epoch 215 Batch 33 Loss 0.1043134555220604
[Train] epoch 215 Batch 34 Loss 0.17425712943077087
[Train] epoch 215 Batch 35 Loss 0.1709403693675995
[Train] epoch 215 Batch 36 Loss 0.13836702704429626
[Train] epoch 215 Batch 37 Loss 0.03734938055276871
[Train] epoch 215 Batch 38 Loss 0.4017598330974579
[Train] epoch 215 Batch 39 Loss 0.0015004053711891174
[Train] epoch 215 Batch 40 Loss 0.13657286763191223
[Train] epoch 215 Batch 41 Loss 0.06988829374313354
[Train] epoch 215 Batch 42 Loss 0.5370824337005615
[Train] epoch 215 Batch 43 Loss 0.071095772087574
[Train] epoch 215 Batch 44 Loss 0.16888684034347534
[Train] epoch 215 Batch 45 Loss 0.1368168741464615
[Train] epoch 215 Batch 46 Loss 0.105943463742733
[Train] epoch 215 Batch 47 Loss 0.07279524207115173
[Train] epoch 216 Batch 0 Loss 0.13706278800964355
[Train] epoch 216 Batch 1 Loss 0.17058727145195007
[Train] epoch 216 Batch 2 Loss 0.07156943529844284
[Train] epoch 216 Batch 3 Loss 0.2718355655670166
[Train] epoch 216 Batch 4 Loss 0.2068844735622406
[Train] epoch 216 Batch 5 Loss 0.06838825345039368
[Train] epoch 216 Batch 6 Loss 0.30243784189224243
[Train] epoch 216 Batch 7 Loss 0.06838299334049225
[Train] epoch 216 Batch 8 Loss 0.3393141031265259
[Train] epoch 216 Batch 9 Loss 0.06809606403112411
[Train] epoch 216 Batch 10 Loss 0.23602858185768127
[Train] epoch 216 Batch 11 Loss 0.1718994826078415
[Train] epoch 216 Batch 12 Loss 0.1035269945859909
[Train] epoch 216 Batch 13 Loss 0.20931875705718994
[Train] epoch 216 Batch 14 Loss 0.23601718246936798
[Train] epoch 216 Batch 15 Loss 0.10269002616405487
[Train] epoch 216 Batch 16 Loss 0.10547268390655518
[Train] epoch 216 Batch 17 Loss 0.13782018423080444
[Train] epoch 216 Batch 18 Loss 0.03710493817925453
[Train] epoch 216 Batch 19 Loss 0.06974393129348755
[Train] epoch 216 Batch 20 Loss 0.17013287544250488
[Train] epoch 216 Batch 21 Loss 0.2056419849395752
[Train] epoch 216 Batch 22 Loss 0.33729127049446106
[Train] epoch 216 Batch 23 Loss 0.03677300736308098
[Train] epoch 216 Batch 24 Loss 0.16932904720306396
[Train] epoch 216 Batch 25 Loss 0.23703530430793762
[Train] epoch 216 Batch 26 Loss 0.237354576587677
[Train] epoch 216 Batch 27 Loss 0.20603561401367188
[Train] epoch 216 Batch 28 Loss 0.3363425135612488
[Train] epoch 216 Batch 29 Loss 0.1346902847290039
[Train] epoch 216 Batch 30 Loss 0.3029509484767914
[Train] epoch 216 Batch 31 Loss 0.34025782346725464
[Train] epoch 216 Batch 32 Loss 0.16867411136627197
[Train] epoch 216 Batch 33 Loss 0.17063912749290466
[Train] epoch 216 Batch 34 Loss 0.17001470923423767
[Train] epoch 216 Batch 35 Loss 0.23728671669960022
[Train] epoch 216 Batch 36 Loss 0.2702639698982239
[Train] epoch 216 Batch 37 Loss 0.16732700169086456
[Train] epoch 216 Batch 38 Loss 0.13630138337612152
[Train] epoch 216 Batch 39 Loss 0.10526907444000244
[Train] epoch 216 Batch 40 Loss 0.06962575018405914
[Train] epoch 216 Batch 41 Loss 0.43594539165496826
[Train] epoch 216 Batch 42 Loss 0.10460302233695984
[Train] epoch 216 Batch 43 Loss 0.06666764616966248
[Train] epoch 216 Batch 44 Loss 0.13789711892604828
[Train] epoch 216 Batch 45 Loss 0.0719054788351059
[Train] epoch 216 Batch 46 Loss 0.16958409547805786
[Train] epoch 216 Batch 47 Loss 0.1741189956665039
[Train] epoch 217 Batch 0 Loss 0.17091423273086548
[Train] epoch 217 Batch 1 Loss 0.1350019872188568
[Train] epoch 217 Batch 2 Loss 0.17097987234592438
[Train] epoch 217 Batch 3 Loss 0.20511934161186218
[Train] epoch 217 Batch 4 Loss 0.23904244601726532
[Train] epoch 217 Batch 5 Loss 0.07015173137187958
[Train] epoch 217 Batch 6 Loss 0.10083650052547455
[Train] epoch 217 Batch 7 Loss 0.06840259581804276
[Train] epoch 217 Batch 8 Loss 0.1027284786105156
[Train] epoch 217 Batch 9 Loss 0.10630973428487778
[Train] epoch 217 Batch 10 Loss 0.20368291437625885
[Train] epoch 217 Batch 11 Loss 0.20179909467697144
[Train] epoch 217 Batch 12 Loss 0.1731961965560913
[Train] epoch 217 Batch 13 Loss 0.13892871141433716
[Train] epoch 217 Batch 14 Loss 0.0019366475753486156
[Train] epoch 217 Batch 15 Loss 0.1388477385044098
[Train] epoch 217 Batch 16 Loss 0.1376858353614807
[Train] epoch 217 Batch 17 Loss 0.17153578996658325
[Train] epoch 217 Batch 18 Loss 0.27237972617149353
[Train] epoch 217 Batch 19 Loss 0.1371050775051117
[Train] epoch 217 Batch 20 Loss 0.10670092701911926
[Train] epoch 217 Batch 21 Loss 0.23806121945381165
[Train] epoch 217 Batch 22 Loss 0.2056967318058014
[Train] epoch 217 Batch 23 Loss 0.17139437794685364
[Train] epoch 217 Batch 24 Loss 0.23807388544082642
[Train] epoch 217 Batch 25 Loss 0.37137967348098755
[Train] epoch 217 Batch 26 Loss 0.13708332180976868
[Train] epoch 217 Batch 27 Loss 0.20380738377571106
[Train] epoch 217 Batch 28 Loss 0.1371171623468399
[Train] epoch 217 Batch 29 Loss 0.10296057164669037
[Train] epoch 217 Batch 30 Loss 0.13708055019378662
[Train] epoch 217 Batch 31 Loss 0.3047151565551758
[Train] epoch 217 Batch 32 Loss 0.13706885278224945
[Train] epoch 217 Batch 33 Loss 0.0742093101143837
[Train] epoch 217 Batch 34 Loss 0.30279478430747986
[Train] epoch 217 Batch 35 Loss 0.10276526212692261
[Train] epoch 217 Batch 36 Loss 0.3104460537433624
[Train] epoch 217 Batch 37 Loss 0.13715198636054993
[Train] epoch 217 Batch 38 Loss 0.2726633846759796
[Train] epoch 217 Batch 39 Loss 0.3042827546596527
[Train] epoch 217 Batch 40 Loss 0.20990926027297974
[Train] epoch 217 Batch 41 Loss 0.26868924498558044
[Train] epoch 217 Batch 42 Loss 0.13714981079101562
[Train] epoch 217 Batch 43 Loss 0.03606318682432175
[Train] epoch 217 Batch 44 Loss 0.13733288645744324
[Train] epoch 217 Batch 45 Loss 0.2057952582836151
[Train] epoch 217 Batch 46 Loss 0.2704654335975647
[Train] epoch 217 Batch 47 Loss 0.3102259039878845
[Train] epoch 218 Batch 0 Loss 0.20554953813552856
[Train] epoch 218 Batch 1 Loss 0.23798763751983643
[Train] epoch 218 Batch 2 Loss 0.13511785864830017
[Train] epoch 218 Batch 3 Loss 0.10620851814746857
[Train] epoch 218 Batch 4 Loss 0.17336010932922363
[Train] epoch 218 Batch 5 Loss 0.2700939476490021
[Train] epoch 218 Batch 6 Loss 0.06857311725616455
[Train] epoch 218 Batch 7 Loss 0.13706308603286743
[Train] epoch 218 Batch 8 Loss 0.10502030700445175
[Train] epoch 218 Batch 9 Loss 0.16770589351654053
[Train] epoch 218 Batch 10 Loss 0.171100914478302
[Train] epoch 218 Batch 11 Loss 0.43618836998939514
[Train] epoch 218 Batch 12 Loss 0.20723101496696472
[Train] epoch 218 Batch 13 Loss 0.1712595373392105
[Train] epoch 218 Batch 14 Loss 0.17323559522628784
[Train] epoch 218 Batch 15 Loss 0.2684023976325989
[Train] epoch 218 Batch 16 Loss 0.20371437072753906
[Train] epoch 218 Batch 17 Loss 0.10108126699924469
[Train] epoch 218 Batch 18 Loss 0.20178169012069702
[Train] epoch 218 Batch 19 Loss 0.2037145346403122
[Train] epoch 218 Batch 20 Loss 0.13715001940727234
[Train] epoch 218 Batch 21 Loss 0.036069657653570175
[Train] epoch 218 Batch 22 Loss 0.06857368350028992
[Train] epoch 218 Batch 23 Loss 0.24565795063972473
[Train] epoch 218 Batch 24 Loss 0.27215200662612915
[Train] epoch 218 Batch 25 Loss 0.10848838090896606
[Train] epoch 218 Batch 26 Loss 0.17144490778446198
[Train] epoch 218 Batch 27 Loss 0.23999720811843872
[Train] epoch 218 Batch 28 Loss 0.27222204208374023
[Train] epoch 218 Batch 29 Loss 0.2000008225440979
[Train] epoch 218 Batch 30 Loss 0.13711296021938324
[Train] epoch 218 Batch 31 Loss 0.2684337794780731
[Train] epoch 218 Batch 32 Loss 0.3730049729347229
[Train] epoch 218 Batch 33 Loss 0.16947048902511597
[Train] epoch 218 Batch 34 Loss 0.1387287825345993
[Train] epoch 218 Batch 35 Loss 0.173081636428833
[Train] epoch 218 Batch 36 Loss 0.27583956718444824
[Train] epoch 218 Batch 37 Loss 0.00381405814550817
[Train] epoch 218 Batch 38 Loss 0.03793897107243538
[Train] epoch 218 Batch 39 Loss 0.3040570318698883
[Train] epoch 218 Batch 40 Loss 0.07426454871892929
[Train] epoch 218 Batch 41 Loss 0.10081115365028381
[Train] epoch 218 Batch 42 Loss 0.24147483706474304
[Train] epoch 218 Batch 43 Loss 0.1676522195339203
[Train] epoch 218 Batch 44 Loss 0.23593133687973022
[Train] epoch 218 Batch 45 Loss 1.0728851975727594e-06
[Train] epoch 218 Batch 46 Loss 0.20897433161735535
[Train] epoch 218 Batch 47 Loss 0.10596917569637299
[Train] epoch 219 Batch 0 Loss 0.14237359166145325
[Train] epoch 219 Batch 1 Loss 0.27558109164237976
[Train] epoch 219 Batch 2 Loss 0.06834541261196136
[Train] epoch 219 Batch 3 Loss 0.13680699467658997
[Train] epoch 219 Batch 4 Loss 0.23598219454288483
[Train] epoch 219 Batch 5 Loss 0.03762776404619217
[Train] epoch 219 Batch 6 Loss 0.134991854429245
[Train] epoch 219 Batch 7 Loss 0.20495843887329102
[Train] epoch 219 Batch 8 Loss 0.4016169011592865
[Train] epoch 219 Batch 9 Loss 0.20505580306053162
[Train] epoch 219 Batch 10 Loss 0.17084527015686035
[Train] epoch 219 Batch 11 Loss 0.1349496990442276
[Train] epoch 219 Batch 12 Loss 0.07007782906293869
[Train] epoch 219 Batch 13 Loss 0.23746256530284882
[Train] epoch 219 Batch 14 Loss 0.17073461413383484
[Train] epoch 219 Batch 15 Loss 0.13508927822113037
[Train] epoch 219 Batch 16 Loss 0.16915938258171082
[Train] epoch 219 Batch 17 Loss 0.26990047097206116
[Train] epoch 219 Batch 18 Loss 0.136557936668396
[Train] epoch 219 Batch 19 Loss 0.26988905668258667
[Train] epoch 219 Batch 20 Loss 0.17068558931350708
[Train] epoch 219 Batch 21 Loss 0.1367112547159195
[Train] epoch 219 Batch 22 Loss 0.3057137131690979
[Train] epoch 219 Batch 23 Loss 0.0730866938829422
[Train] epoch 219 Batch 24 Loss 0.20330549776554108
[Train] epoch 219 Batch 25 Loss 0.2000008225440979
[Train] epoch 219 Batch 26 Loss 0.06829199194908142
[Train] epoch 219 Batch 27 Loss 0.20638445019721985
[Train] epoch 219 Batch 28 Loss 0.2699452042579651
[Train] epoch 219 Batch 29 Loss 0.13657808303833008
[Train] epoch 219 Batch 30 Loss 0.06821303814649582
[Train] epoch 219 Batch 31 Loss 0.06824170053005219
[Train] epoch 219 Batch 32 Loss 0.06986507028341293
[Train] epoch 219 Batch 33 Loss 0.2356317639350891
[Train] epoch 219 Batch 34 Loss 0.13656124472618103
[Train] epoch 219 Batch 35 Loss 0.33802735805511475
[Train] epoch 219 Batch 36 Loss 0.10237519443035126
[Train] epoch 219 Batch 37 Loss 0.33649900555610657
[Train] epoch 219 Batch 38 Loss 0.06984052807092667
[Train] epoch 219 Batch 39 Loss 0.04021985083818436
[Train] epoch 219 Batch 40 Loss 0.305410772562027
[Train] epoch 219 Batch 41 Loss 0.17361216247081757
[Train] epoch 219 Batch 42 Loss 0.1380813717842102
[Train] epoch 219 Batch 43 Loss 0.3736947774887085
[Train] epoch 219 Batch 44 Loss 0.20607149600982666
[Train] epoch 219 Batch 45 Loss 0.17357632517814636
[Train] epoch 219 Batch 46 Loss 0.13640248775482178
[Train] epoch 219 Batch 47 Loss 0.13651356101036072
[Train] epoch 220 Batch 0 Loss 0.10225649178028107
[Train] epoch 220 Batch 1 Loss 0.2061481773853302
[Train] epoch 220 Batch 2 Loss 0.03707154095172882
[Train] epoch 220 Batch 3 Loss 0.07260048389434814
[Train] epoch 220 Batch 4 Loss 0.13792772591114044
[Train] epoch 220 Batch 5 Loss 0.20298823714256287
[Train] epoch 220 Batch 6 Loss 0.2698187232017517
[Train] epoch 220 Batch 7 Loss 0.1688411682844162
[Train] epoch 220 Batch 8 Loss 0.23992258310317993
[Train] epoch 220 Batch 9 Loss 0.2356327772140503
[Train] epoch 220 Batch 10 Loss 0.07101839780807495
[Train] epoch 220 Batch 11 Loss 0.23687562346458435
[Train] epoch 220 Batch 12 Loss 0.2682601511478424
[Train] epoch 220 Batch 13 Loss 0.10511018335819244
[Train] epoch 220 Batch 14 Loss 0.17037978768348694
[Train] epoch 220 Batch 15 Loss 0.2695329785346985
[Train] epoch 220 Batch 16 Loss 0.27252188324928284
[Train] epoch 220 Batch 17 Loss 0.10361412167549133
[Train] epoch 220 Batch 18 Loss 0.17199839651584625
[Train] epoch 220 Batch 19 Loss 0.30370551347732544
[Train] epoch 220 Batch 20 Loss 0.17674392461776733
[Train] epoch 220 Batch 21 Loss 0.269756942987442
[Train] epoch 220 Batch 22 Loss 0.13490433990955353
[Train] epoch 220 Batch 23 Loss 0.3722999393939972
[Train] epoch 220 Batch 24 Loss 0.13659293949604034
[Train] epoch 220 Batch 25 Loss 0.035767361521720886
[Train] epoch 220 Batch 26 Loss 0.07156752794981003
[Train] epoch 220 Batch 27 Loss 0.06990645825862885
[Train] epoch 220 Batch 28 Loss 0.133334219455719
[Train] epoch 220 Batch 29 Loss 0.13491186499595642
[Train] epoch 220 Batch 30 Loss 0.20477835834026337
[Train] epoch 220 Batch 31 Loss 0.10241668671369553
[Train] epoch 220 Batch 32 Loss 0.27327588200569153
[Train] epoch 220 Batch 33 Loss 0.2748444378376007
[Train] epoch 220 Batch 34 Loss 0.10591234266757965
[Train] epoch 220 Batch 35 Loss 0.2000008225440979
[Train] epoch 220 Batch 36 Loss 0.10409349203109741
[Train] epoch 220 Batch 37 Loss 0.30412954092025757
[Train] epoch 220 Batch 38 Loss 0.23739662766456604
[Train] epoch 220 Batch 39 Loss 0.23739488422870636
[Train] epoch 220 Batch 40 Loss 0.10594627261161804
[Train] epoch 220 Batch 41 Loss 0.20486709475517273
[Train] epoch 220 Batch 42 Loss 0.034144800156354904
[Train] epoch 220 Batch 43 Loss 0.20321616530418396
[Train] epoch 220 Batch 44 Loss 0.2698599696159363
[Train] epoch 220 Batch 45 Loss 0.10574094206094742
[Train] epoch 220 Batch 46 Loss 0.13492658734321594
[Train] epoch 220 Batch 47 Loss 0.20164981484413147
[Train] epoch 221 Batch 0 Loss 0.2015789896249771
[Train] epoch 221 Batch 1 Loss 0.46988892555236816
[Train] epoch 221 Batch 2 Loss 0.30402979254722595
[Train] epoch 221 Batch 3 Loss 0.20328551530838013
[Train] epoch 221 Batch 4 Loss 0.1739031821489334
[Train] epoch 221 Batch 5 Loss 0.24054667353630066
[Train] epoch 221 Batch 6 Loss 0.17060357332229614
[Train] epoch 221 Batch 7 Loss 0.1690789759159088
[Train] epoch 221 Batch 8 Loss 0.17064222693443298
[Train] epoch 221 Batch 9 Loss 0.2356785088777542
[Train] epoch 221 Batch 10 Loss 0.003214494092389941
[Train] epoch 221 Batch 11 Loss 0.17070986330509186
[Train] epoch 221 Batch 12 Loss 0.1380448341369629
[Train] epoch 221 Batch 13 Loss 0.1364593207836151
[Train] epoch 221 Batch 14 Loss 0.17064169049263
[Train] epoch 221 Batch 15 Loss 0.10236440598964691
[Train] epoch 221 Batch 16 Loss 0.0030908966436982155
[Train] epoch 221 Batch 17 Loss 0.1705627739429474
[Train] epoch 221 Batch 18 Loss 0.16901303827762604
[Train] epoch 221 Batch 19 Loss 0.1705808788537979
[Train] epoch 221 Batch 20 Loss 0.403133749961853
[Train] epoch 221 Batch 21 Loss 0.17048978805541992
[Train] epoch 221 Batch 22 Loss 0.27130797505378723
[Train] epoch 221 Batch 23 Loss 0.30227452516555786
[Train] epoch 221 Batch 24 Loss 0.10531657189130783
[Train] epoch 221 Batch 25 Loss 0.20294874906539917
[Train] epoch 221 Batch 26 Loss 0.1349056512117386
[Train] epoch 221 Batch 27 Loss 0.0711677074432373
[Train] epoch 221 Batch 28 Loss 0.13785342872142792
[Train] epoch 221 Batch 29 Loss 0.1689535677433014
[Train] epoch 221 Batch 30 Loss 0.17329822480678558
[Train] epoch 221 Batch 31 Loss 0.13633155822753906
[Train] epoch 221 Batch 32 Loss 0.1364750862121582
[Train] epoch 221 Batch 33 Loss 0.03559817001223564
[Train] epoch 221 Batch 34 Loss 0.10078593343496323
[Train] epoch 221 Batch 35 Loss 0.10517935454845428
[Train] epoch 221 Batch 36 Loss 0.06965823471546173
[Train] epoch 221 Batch 37 Loss 0.20304226875305176
[Train] epoch 221 Batch 38 Loss 0.13482457399368286
[Train] epoch 221 Batch 39 Loss 0.23854783177375793
[Train] epoch 221 Batch 40 Loss 0.2710886001586914
[Train] epoch 221 Batch 41 Loss 0.2044534981250763
[Train] epoch 221 Batch 42 Loss 0.17045649886131287
[Train] epoch 221 Batch 43 Loss 0.23716193437576294
[Train] epoch 221 Batch 44 Loss 0.2696644365787506
[Train] epoch 221 Batch 45 Loss 0.13472077250480652
[Train] epoch 221 Batch 46 Loss 0.24289551377296448
[Train] epoch 221 Batch 47 Loss 0.07084716856479645
[Train] epoch 222 Batch 0 Loss 0.23689541220664978
[Train] epoch 222 Batch 1 Loss 0.17022979259490967
[Train] epoch 222 Batch 2 Loss 0.06957803666591644
[Train] epoch 222 Batch 3 Loss 0.3392174541950226
[Train] epoch 222 Batch 4 Loss 0.10343389958143234
[Train] epoch 222 Batch 5 Loss 0.23835410177707672
[Train] epoch 222 Batch 6 Loss 0.17163501679897308
[Train] epoch 222 Batch 7 Loss 0.17024095356464386
[Train] epoch 222 Batch 8 Loss 0.3062872886657715
[Train] epoch 222 Batch 9 Loss 0.10070589184761047
[Train] epoch 222 Batch 10 Loss 0.23954153060913086
[Train] epoch 222 Batch 11 Loss 0.10214068740606308
[Train] epoch 222 Batch 12 Loss 0.20311473309993744
[Train] epoch 222 Batch 13 Loss 0.0696261003613472
[Train] epoch 222 Batch 14 Loss 0.33623313903808594
[Train] epoch 222 Batch 15 Loss 0.1362593024969101
[Train] epoch 222 Batch 16 Loss 0.26963576674461365
[Train] epoch 222 Batch 17 Loss 0.2385973036289215
[Train] epoch 222 Batch 18 Loss 0.20306797325611115
[Train] epoch 222 Batch 19 Loss 0.10379508137702942
[Train] epoch 222 Batch 20 Loss 0.4340971112251282
[Train] epoch 222 Batch 21 Loss 0.4031888544559479
[Train] epoch 222 Batch 22 Loss 0.2728250324726105
[Train] epoch 222 Batch 23 Loss 0.13651789724826813
[Train] epoch 222 Batch 24 Loss 0.23722052574157715
[Train] epoch 222 Batch 25 Loss 0.2387155443429947
[Train] epoch 222 Batch 26 Loss 0.06826120615005493
[Train] epoch 222 Batch 27 Loss 0.13485309481620789
[Train] epoch 222 Batch 28 Loss 0.03726046159863472
[Train] epoch 222 Batch 29 Loss 0.1365278661251068
[Train] epoch 222 Batch 30 Loss 0.1039639562368393
[Train] epoch 222 Batch 31 Loss 0.3038901388645172
[Train] epoch 222 Batch 32 Loss 0.20630164444446564
[Train] epoch 222 Batch 33 Loss 0.16909152269363403
[Train] epoch 222 Batch 34 Loss 0.1413191854953766
[Train] epoch 222 Batch 35 Loss 0.06991302222013474
[Train] epoch 222 Batch 36 Loss 0.10397318005561829
[Train] epoch 222 Batch 37 Loss 0.16900652647018433
[Train] epoch 222 Batch 38 Loss 0.07135114818811417
[Train] epoch 222 Batch 39 Loss 0.10389906167984009
[Train] epoch 222 Batch 40 Loss 0.16744814813137054
[Train] epoch 222 Batch 41 Loss 0.06982104480266571
[Train] epoch 222 Batch 42 Loss 0.10393539071083069
[Train] epoch 222 Batch 43 Loss 0.03410496935248375
[Train] epoch 222 Batch 44 Loss 0.17216449975967407
[Train] epoch 222 Batch 45 Loss 0.13643358647823334
[Train] epoch 222 Batch 46 Loss 0.37057754397392273
[Train] epoch 222 Batch 47 Loss 0.06983867287635803
[Train] epoch 223 Batch 0 Loss 0.06980480998754501
[Train] epoch 223 Batch 1 Loss 0.06666764616966248
[Train] epoch 223 Batch 2 Loss 0.13638216257095337
[Train] epoch 223 Batch 3 Loss 0.2372618019580841
[Train] epoch 223 Batch 4 Loss 0.0697193518280983
[Train] epoch 223 Batch 5 Loss 0.2015475630760193
[Train] epoch 223 Batch 6 Loss 0.0697420984506607
[Train] epoch 223 Batch 7 Loss 0.10384748876094818
[Train] epoch 223 Batch 8 Loss 0.17203816771507263
[Train] epoch 223 Batch 9 Loss 0.2015719711780548
[Train] epoch 223 Batch 10 Loss 0.1720331609249115
[Train] epoch 223 Batch 11 Loss 0.23569074273109436
[Train] epoch 223 Batch 12 Loss 0.10372435301542282
[Train] epoch 223 Batch 13 Loss 0.2711605429649353
[Train] epoch 223 Batch 14 Loss 0.23715060949325562
[Train] epoch 223 Batch 15 Loss 0.16895553469657898
[Train] epoch 223 Batch 16 Loss 0.2015111893415451
[Train] epoch 223 Batch 17 Loss 0.10383669286966324
[Train] epoch 223 Batch 18 Loss 0.20149116218090057
[Train] epoch 223 Batch 19 Loss 0.20305657386779785
[Train] epoch 223 Batch 20 Loss 0.10363630205392838
[Train] epoch 223 Batch 21 Loss 0.2370511144399643
[Train] epoch 223 Batch 22 Loss 0.06959399580955505
[Train] epoch 223 Batch 23 Loss 0.24002134799957275
[Train] epoch 223 Batch 24 Loss 0.2386450171470642
[Train] epoch 223 Batch 25 Loss 0.3363736569881439
[Train] epoch 223 Batch 26 Loss 0.13776667416095734
[Train] epoch 223 Batch 27 Loss 0.1051250696182251
[Train] epoch 223 Batch 28 Loss 0.20292851328849792
[Train] epoch 223 Batch 29 Loss 0.0014401145745068789
[Train] epoch 223 Batch 30 Loss 0.20439130067825317
[Train] epoch 223 Batch 31 Loss 0.17312920093536377
[Train] epoch 223 Batch 32 Loss 0.20433107018470764
[Train] epoch 223 Batch 33 Loss 0.272352397441864
[Train] epoch 223 Batch 34 Loss 0.2711713910102844
[Train] epoch 223 Batch 35 Loss 0.271106094121933
[Train] epoch 223 Batch 36 Loss 0.2709762454032898
[Train] epoch 223 Batch 37 Loss 0.20696821808815002
[Train] epoch 223 Batch 38 Loss 0.1362900733947754
[Train] epoch 223 Batch 39 Loss 0.10351495444774628
[Train] epoch 223 Batch 40 Loss 0.20294533669948578
[Train] epoch 223 Batch 41 Loss 0.2371300756931305
[Train] epoch 223 Batch 42 Loss 0.269717276096344
[Train] epoch 223 Batch 43 Loss 0.10496056079864502
[Train] epoch 223 Batch 44 Loss 0.133334219455719
[Train] epoch 223 Batch 45 Loss 0.16736575961112976
[Train] epoch 223 Batch 46 Loss 0.23834627866744995
[Train] epoch 223 Batch 47 Loss 0.10356859862804413
[Train] epoch 224 Batch 0 Loss 0.17026686668395996
[Train] epoch 224 Batch 1 Loss 0.20281323790550232
[Train] epoch 224 Batch 2 Loss 0.10202953219413757
[Train] epoch 224 Batch 3 Loss 0.17134535312652588
[Train] epoch 224 Batch 4 Loss 0.13881586492061615
[Train] epoch 224 Batch 5 Loss 0.1348913013935089
[Train] epoch 224 Batch 6 Loss 0.10220201313495636
[Train] epoch 224 Batch 7 Loss 0.3023349344730377
[Train] epoch 224 Batch 8 Loss 0.20301060378551483
[Train] epoch 224 Batch 9 Loss 0.17152899503707886
[Train] epoch 224 Batch 10 Loss 0.16872161626815796
[Train] epoch 224 Batch 11 Loss 0.20131060481071472
[Train] epoch 224 Batch 12 Loss 0.2038869708776474
[Train] epoch 224 Batch 13 Loss 0.10662773251533508
[Train] epoch 224 Batch 14 Loss 0.07219812273979187
[Train] epoch 224 Batch 15 Loss 0.13748347759246826
[Train] epoch 224 Batch 16 Loss 0.3035798966884613
[Train] epoch 224 Batch 17 Loss 0.23690058290958405
[Train] epoch 224 Batch 18 Loss 0.17036962509155273
[Train] epoch 224 Batch 19 Loss 0.03701647371053696
[Train] epoch 224 Batch 20 Loss 0.17036011815071106
[Train] epoch 224 Batch 21 Loss 0.23561464250087738
[Train] epoch 224 Batch 22 Loss 0.23717117309570312
[Train] epoch 224 Batch 23 Loss 0.23870837688446045
[Train] epoch 224 Batch 24 Loss 0.07136467099189758
[Train] epoch 224 Batch 25 Loss 0.17355240881443024
[Train] epoch 224 Batch 26 Loss 0.20463888347148895
[Train] epoch 224 Batch 27 Loss 0.2372363954782486
[Train] epoch 224 Batch 28 Loss 0.3364849090576172
[Train] epoch 224 Batch 29 Loss 0.13483233749866486
[Train] epoch 224 Batch 30 Loss 0.13483087718486786
[Train] epoch 224 Batch 31 Loss 0.1364147663116455
[Train] epoch 224 Batch 32 Loss 0.17219670116901398
[Train] epoch 224 Batch 33 Loss 0.10083504021167755
[Train] epoch 224 Batch 34 Loss 0.20454448461532593
[Train] epoch 224 Batch 35 Loss 0.1720787137746811
[Train] epoch 224 Batch 36 Loss 0.20313842594623566
[Train] epoch 224 Batch 37 Loss 0.2357463240623474
[Train] epoch 224 Batch 38 Loss 0.24345993995666504
[Train] epoch 224 Batch 39 Loss 0.2062244415283203
[Train] epoch 224 Batch 40 Loss 0.16889889538288116
[Train] epoch 224 Batch 41 Loss 0.20148789882659912
[Train] epoch 224 Batch 42 Loss 0.20300188660621643
[Train] epoch 224 Batch 43 Loss 0.20151382684707642
[Train] epoch 224 Batch 44 Loss 0.2046152651309967
[Train] epoch 224 Batch 45 Loss 0.13481812179088593
[Train] epoch 224 Batch 46 Loss 0.10074236989021301
[Train] epoch 224 Batch 47 Loss 0.0697549358010292
[Train] epoch 225 Batch 0 Loss 0.20155778527259827
[Train] epoch 225 Batch 1 Loss 0.26979881525039673
[Train] epoch 225 Batch 2 Loss 0.10229416936635971
[Train] epoch 225 Batch 3 Loss 0.13640397787094116
[Train] epoch 225 Batch 4 Loss 0.17049022018909454
[Train] epoch 225 Batch 5 Loss 0.17046596109867096
[Train] epoch 225 Batch 6 Loss 0.10692568123340607
[Train] epoch 225 Batch 7 Loss 0.2341366559267044
[Train] epoch 225 Batch 8 Loss 0.10526677221059799
[Train] epoch 225 Batch 9 Loss 0.10388810932636261
[Train] epoch 225 Batch 10 Loss 0.10232816636562347
[Train] epoch 225 Batch 11 Loss 0.13778682053089142
[Train] epoch 225 Batch 12 Loss 0.1037471741437912
[Train] epoch 225 Batch 13 Loss 0.20447713136672974
[Train] epoch 225 Batch 14 Loss 0.1688762605190277
[Train] epoch 225 Batch 15 Loss 0.3393417000770569
[Train] epoch 225 Batch 16 Loss 0.03707638010382652
[Train] epoch 225 Batch 17 Loss 0.1703469455242157
[Train] epoch 225 Batch 18 Loss 0.23556703329086304
[Train] epoch 225 Batch 19 Loss 0.46958696842193604
[Train] epoch 225 Batch 20 Loss 0.23407167196273804
[Train] epoch 225 Batch 21 Loss 0.20580372214317322
[Train] epoch 225 Batch 22 Loss 0.2725892961025238
[Train] epoch 225 Batch 23 Loss 0.17173397541046143
[Train] epoch 225 Batch 24 Loss 0.20296582579612732
[Train] epoch 225 Batch 25 Loss 0.1348390132188797
[Train] epoch 225 Batch 26 Loss 0.24127233028411865
[Train] epoch 225 Batch 27 Loss 0.06666764616966248
[Train] epoch 225 Batch 28 Loss 0.23552778363227844
[Train] epoch 225 Batch 29 Loss 0.3702402412891388
[Train] epoch 225 Batch 30 Loss 0.13901038467884064
[Train] epoch 225 Batch 31 Loss 0.1347276270389557
[Train] epoch 225 Batch 32 Loss 0.1744282841682434
[Train] epoch 225 Batch 33 Loss 0.10211879014968872
[Train] epoch 225 Batch 34 Loss 0.03827859088778496
[Train] epoch 225 Batch 35 Loss 0.17023582756519318
[Train] epoch 225 Batch 36 Loss 0.3064475357532501
[Train] epoch 225 Batch 37 Loss 0.03406912833452225
[Train] epoch 225 Batch 38 Loss 0.1361994445323944
[Train] epoch 225 Batch 39 Loss 0.038202494382858276
[Train] epoch 225 Batch 40 Loss 0.17015722393989563
[Train] epoch 225 Batch 41 Loss 0.17022667825222015
[Train] epoch 225 Batch 42 Loss 0.20291030406951904
[Train] epoch 225 Batch 43 Loss 0.1701076626777649
[Train] epoch 225 Batch 44 Loss 0.10073469579219818
[Train] epoch 225 Batch 45 Loss 0.13480132818222046
[Train] epoch 225 Batch 46 Loss 0.303451269865036
[Train] epoch 225 Batch 47 Loss 0.23692572116851807
[Train] epoch 226 Batch 0 Loss 0.20139183104038239
[Train] epoch 226 Batch 1 Loss 0.10219839960336685
[Train] epoch 226 Batch 2 Loss 0.17013534903526306
[Train] epoch 226 Batch 3 Loss 0.23679757118225098
[Train] epoch 226 Batch 4 Loss 0.23809778690338135
[Train] epoch 226 Batch 5 Loss 0.2750728130340576
[Train] epoch 226 Batch 6 Loss 0.23548173904418945
[Train] epoch 226 Batch 7 Loss 0.1361280232667923
[Train] epoch 226 Batch 8 Loss 0.16739746928215027
[Train] epoch 226 Batch 9 Loss 0.10202127695083618
[Train] epoch 226 Batch 10 Loss 0.17001043260097504
[Train] epoch 226 Batch 11 Loss 0.23817884922027588
[Train] epoch 226 Batch 12 Loss 0.2368379533290863
[Train] epoch 226 Batch 13 Loss 0.16879931092262268
[Train] epoch 226 Batch 14 Loss 0.10451120883226395
[Train] epoch 226 Batch 15 Loss 0.2367023229598999
[Train] epoch 226 Batch 16 Loss 0.10467129945755005
[Train] epoch 226 Batch 17 Loss 0.20551520586013794
[Train] epoch 226 Batch 18 Loss 0.1046297699213028
[Train] epoch 226 Batch 19 Loss 0.1033463180065155
[Train] epoch 226 Batch 20 Loss 0.13753080368041992
[Train] epoch 226 Batch 21 Loss 0.10191881656646729
[Train] epoch 226 Batch 22 Loss 0.1385800838470459
[Train] epoch 226 Batch 23 Loss 0.2365582287311554
[Train] epoch 226 Batch 24 Loss 0.16867074370384216
[Train] epoch 226 Batch 25 Loss 0.07056470215320587
[Train] epoch 226 Batch 26 Loss 0.20144900679588318
[Train] epoch 226 Batch 27 Loss 0.20504210889339447
[Train] epoch 226 Batch 28 Loss 0.23781904578208923
[Train] epoch 226 Batch 29 Loss 0.2365143597126007
[Train] epoch 226 Batch 30 Loss 0.2694501280784607
[Train] epoch 226 Batch 31 Loss 0.3700902462005615
[Train] epoch 226 Batch 32 Loss 0.03405740484595299
[Train] epoch 226 Batch 33 Loss 0.13715717196464539
[Train] epoch 226 Batch 34 Loss 0.20369970798492432
[Train] epoch 226 Batch 35 Loss 0.03638659045100212
[Train] epoch 226 Batch 36 Loss 0.2024727165699005
[Train] epoch 226 Batch 37 Loss 0.10315769910812378
[Train] epoch 226 Batch 38 Loss 0.2691246569156647
[Train] epoch 226 Batch 39 Loss 0.20245175063610077
[Train] epoch 226 Batch 40 Loss 0.10072311758995056
[Train] epoch 226 Batch 41 Loss 0.20131723582744598
[Train] epoch 226 Batch 42 Loss 0.1713346242904663
[Train] epoch 226 Batch 43 Loss 0.1006217747926712
[Train] epoch 226 Batch 44 Loss 0.20278607308864594
[Train] epoch 226 Batch 45 Loss 0.2050071656703949
[Train] epoch 226 Batch 46 Loss 0.23405560851097107
[Train] epoch 226 Batch 47 Loss 0.13718274235725403
[Train] epoch 227 Batch 0 Loss 0.2026425302028656
[Train] epoch 227 Batch 1 Loss 0.10308698564767838
[Train] epoch 227 Batch 2 Loss 0.1359705924987793
[Train] epoch 227 Batch 3 Loss 0.23638229072093964
[Train] epoch 227 Batch 4 Loss 0.1697673499584198
[Train] epoch 227 Batch 5 Loss 0.16987456381320953
[Train] epoch 227 Batch 6 Loss 0.13945668935775757
[Train] epoch 227 Batch 7 Loss 0.16727229952812195
[Train] epoch 227 Batch 8 Loss 0.16794103384017944
[Train] epoch 227 Batch 9 Loss 0.1381569504737854
[Train] epoch 227 Batch 10 Loss 0.16851806640625
[Train] epoch 227 Batch 11 Loss 0.17131727933883667
[Train] epoch 227 Batch 12 Loss 0.2379179745912552
[Train] epoch 227 Batch 13 Loss 0.26805615425109863
[Train] epoch 227 Batch 14 Loss 0.23811671137809753
[Train] epoch 227 Batch 15 Loss 0.13607290387153625
[Train] epoch 227 Batch 16 Loss 0.20275941491127014
[Train] epoch 227 Batch 17 Loss 0.16877055168151855
[Train] epoch 227 Batch 18 Loss 0.23959815502166748
[Train] epoch 227 Batch 19 Loss 0.17015431821346283
[Train] epoch 227 Batch 20 Loss 0.23543554544448853
[Train] epoch 227 Batch 21 Loss 0.20429627597332
[Train] epoch 227 Batch 22 Loss 0.13526183366775513
[Train] epoch 227 Batch 23 Loss 0.20427283644676208
[Train] epoch 227 Batch 24 Loss 0.1376599222421646
[Train] epoch 227 Batch 25 Loss 0.1347489207983017
[Train] epoch 227 Batch 26 Loss 0.30650007724761963
[Train] epoch 227 Batch 27 Loss 0.2000008225440979
[Train] epoch 227 Batch 28 Loss 0.3021225035190582
[Train] epoch 227 Batch 29 Loss 0.13614584505558014
[Train] epoch 227 Batch 30 Loss 0.13476848602294922
[Train] epoch 227 Batch 31 Loss 0.10212217271327972
[Train] epoch 227 Batch 32 Loss 0.337702214717865
[Train] epoch 227 Batch 33 Loss 0.17022919654846191
[Train] epoch 227 Batch 34 Loss 0.1717178225517273
[Train] epoch 227 Batch 35 Loss 0.10644318908452988
[Train] epoch 227 Batch 36 Loss 0.13620683550834656
[Train] epoch 227 Batch 37 Loss 0.16878142952919006
[Train] epoch 227 Batch 38 Loss 0.10215593874454498
[Train] epoch 227 Batch 39 Loss 0.07374930381774902
[Train] epoch 227 Batch 40 Loss 0.0695403590798378
[Train] epoch 227 Batch 41 Loss 0.20288193225860596
[Train] epoch 227 Batch 42 Loss 0.13753293454647064
[Train] epoch 227 Batch 43 Loss 0.1688462793827057
[Train] epoch 227 Batch 44 Loss 0.30503755807876587
[Train] epoch 227 Batch 45 Loss 0.10358017683029175
[Train] epoch 227 Batch 46 Loss 0.13750502467155457
[Train] epoch 227 Batch 47 Loss 0.2027602344751358
[Train] epoch 228 Batch 0 Loss 0.0681101530790329
[Train] epoch 228 Batch 1 Loss 0.16882246732711792
[Train] epoch 228 Batch 2 Loss 0.0027299472130835056
[Train] epoch 228 Batch 3 Loss 0.07216672599315643
[Train] epoch 228 Batch 4 Loss 0.10344143211841583
[Train] epoch 228 Batch 5 Loss 0.23674455285072327
[Train] epoch 228 Batch 6 Loss 0.20425167679786682
[Train] epoch 228 Batch 7 Loss 0.1673680543899536
[Train] epoch 228 Batch 8 Loss 0.136118084192276
[Train] epoch 228 Batch 9 Loss 0.10218232870101929
[Train] epoch 228 Batch 10 Loss 0.1359618753194809
[Train] epoch 228 Batch 11 Loss 0.17008715867996216
[Train] epoch 228 Batch 12 Loss 0.06801101565361023
[Train] epoch 228 Batch 13 Loss 0.1686227172613144
[Train] epoch 228 Batch 14 Loss 0.23669534921646118
[Train] epoch 228 Batch 15 Loss 0.16735181212425232
[Train] epoch 228 Batch 16 Loss 0.4708688259124756
[Train] epoch 228 Batch 17 Loss 0.3333339989185333
[Train] epoch 228 Batch 18 Loss 0.20533928275108337
[Train] epoch 228 Batch 19 Loss 0.33896511793136597
[Train] epoch 228 Batch 20 Loss 0.10469105839729309
[Train] epoch 228 Batch 21 Loss 0.2380511611700058
[Train] epoch 228 Batch 22 Loss 0.23797251284122467
[Train] epoch 228 Batch 23 Loss 0.13724789023399353
[Train] epoch 228 Batch 24 Loss 0.3712598383426666
[Train] epoch 228 Batch 25 Loss 0.1019892543554306
[Train] epoch 228 Batch 26 Loss 0.13472309708595276
[Train] epoch 228 Batch 27 Loss 0.2054806351661682
[Train] epoch 228 Batch 28 Loss 0.20128470659255981
[Train] epoch 228 Batch 29 Loss 0.2747975289821625
[Train] epoch 228 Batch 30 Loss 0.034059617668390274
[Train] epoch 228 Batch 31 Loss 0.23929668962955475
[Train] epoch 228 Batch 32 Loss 0.13584104180335999
[Train] epoch 228 Batch 33 Loss 0.13623227179050446
[Train] epoch 228 Batch 34 Loss 0.37144267559051514
[Train] epoch 228 Batch 35 Loss 0.1673133373260498
[Train] epoch 228 Batch 36 Loss 0.168567955493927
[Train] epoch 228 Batch 37 Loss 0.1713135540485382
[Train] epoch 228 Batch 38 Loss 0.06913821399211884
[Train] epoch 228 Batch 39 Loss 0.17152874171733856
[Train] epoch 228 Batch 40 Loss 0.20410418510437012
[Train] epoch 228 Batch 41 Loss 0.23771902918815613
[Train] epoch 228 Batch 42 Loss 0.16883237659931183
[Train] epoch 228 Batch 43 Loss 0.10548776388168335
[Train] epoch 228 Batch 44 Loss 0.2014426738023758
[Train] epoch 228 Batch 45 Loss 0.13621670007705688
[Train] epoch 228 Batch 46 Loss 0.10317596048116684
[Train] epoch 228 Batch 47 Loss 0.06905663758516312
[Train] epoch 229 Batch 0 Loss 0.03643784299492836
[Train] epoch 229 Batch 1 Loss 0.27041929960250854
[Train] epoch 229 Batch 2 Loss 0.2035903036594391
[Train] epoch 229 Batch 3 Loss 0.10314558446407318
[Train] epoch 229 Batch 4 Loss 0.003571365959942341
[Train] epoch 229 Batch 5 Loss 0.30469900369644165
[Train] epoch 229 Batch 6 Loss 0.10071930289268494
[Train] epoch 229 Batch 7 Loss 0.13700854778289795
[Train] epoch 229 Batch 8 Loss 0.06866215914487839
[Train] epoch 229 Batch 9 Loss 0.26943740248680115
[Train] epoch 229 Batch 10 Loss 0.20262843370437622
[Train] epoch 229 Batch 11 Loss 0.21780763566493988
[Train] epoch 229 Batch 12 Loss 0.14876872301101685
[Train] epoch 229 Batch 13 Loss 0.1686801016330719
[Train] epoch 229 Batch 14 Loss 0.26935872435569763
[Train] epoch 229 Batch 15 Loss 0.2367658019065857
[Train] epoch 229 Batch 16 Loss 0.10198280960321426
[Train] epoch 229 Batch 17 Loss 0.10203184187412262
[Train] epoch 229 Batch 18 Loss 0.20893128216266632
[Train] epoch 229 Batch 19 Loss 0.269450843334198
[Train] epoch 229 Batch 20 Loss 0.20455801486968994
[Train] epoch 229 Batch 21 Loss 0.10404321551322937
[Train] epoch 229 Batch 22 Loss 0.26666736602783203
[Train] epoch 229 Batch 23 Loss 0.10074722766876221
[Train] epoch 229 Batch 24 Loss 0.2030835747718811
[Train] epoch 229 Batch 25 Loss 0.16928422451019287
[Train] epoch 229 Batch 26 Loss 0.17099899053573608
[Train] epoch 229 Batch 27 Loss 0.20147587358951569
[Train] epoch 229 Batch 28 Loss 0.20520538091659546
[Train] epoch 229 Batch 29 Loss 0.23402321338653564
[Train] epoch 229 Batch 30 Loss 0.16920407116413116
[Train] epoch 229 Batch 31 Loss 0.16884878277778625
[Train] epoch 229 Batch 32 Loss 0.13471001386642456
[Train] epoch 229 Batch 33 Loss 0.23943287134170532
[Train] epoch 229 Batch 34 Loss 0.33785155415534973
[Train] epoch 229 Batch 35 Loss 0.07279261946678162
[Train] epoch 229 Batch 36 Loss 0.1728106439113617
[Train] epoch 229 Batch 37 Loss 0.17278282344341278
[Train] epoch 229 Batch 38 Loss 0.20734484493732452
[Train] epoch 229 Batch 39 Loss 0.3039538264274597
[Train] epoch 229 Batch 40 Loss 0.06992475688457489
[Train] epoch 229 Batch 41 Loss 0.1424676477909088
[Train] epoch 229 Batch 42 Loss 0.3085530400276184
[Train] epoch 229 Batch 43 Loss 0.20806103944778442
[Train] epoch 229 Batch 44 Loss 0.13619065284729004
[Train] epoch 229 Batch 45 Loss 0.07352620363235474
[Train] epoch 229 Batch 46 Loss 0.2071538269519806
[Train] epoch 229 Batch 47 Loss 0.10277924686670303
[Train] epoch 230 Batch 0 Loss 0.2174350768327713
[Train] epoch 230 Batch 1 Loss 0.17112496495246887
[Train] epoch 230 Batch 2 Loss 0.17465907335281372
[Train] epoch 230 Batch 3 Loss 0.26996299624443054
[Train] epoch 230 Batch 4 Loss 0.07183195650577545
[Train] epoch 230 Batch 5 Loss 0.10579454898834229
[Train] epoch 230 Batch 6 Loss 0.1347929686307907
[Train] epoch 230 Batch 7 Loss 0.13648086786270142
[Train] epoch 230 Batch 8 Loss 0.10228334367275238
[Train] epoch 230 Batch 9 Loss 0.1690019816160202
[Train] epoch 230 Batch 10 Loss 0.13500085473060608
[Train] epoch 230 Batch 11 Loss 0.3365299701690674
[Train] epoch 230 Batch 12 Loss 0.13802091777324677
[Train] epoch 230 Batch 13 Loss 0.20302888751029968
[Train] epoch 230 Batch 14 Loss 0.2388230264186859
[Train] epoch 230 Batch 15 Loss 0.13801686465740204
[Train] epoch 230 Batch 16 Loss 0.10616464167833328
[Train] epoch 230 Batch 17 Loss 0.20324084162712097
[Train] epoch 230 Batch 18 Loss 0.07181260734796524
[Train] epoch 230 Batch 19 Loss 0.06831373274326324
[Train] epoch 230 Batch 20 Loss 0.3038400113582611
[Train] epoch 230 Batch 21 Loss 0.036051131784915924
[Train] epoch 230 Batch 22 Loss 0.24133974313735962
[Train] epoch 230 Batch 23 Loss 0.10606682300567627
[Train] epoch 230 Batch 24 Loss 0.2341063916683197
[Train] epoch 230 Batch 25 Loss 0.34436047077178955
[Train] epoch 230 Batch 26 Loss 0.10679300129413605
[Train] epoch 230 Batch 27 Loss 0.23413151502609253
[Train] epoch 230 Batch 28 Loss 0.3729173541069031
[Train] epoch 230 Batch 29 Loss 0.13688704371452332
[Train] epoch 230 Batch 30 Loss 0.10077302157878876
[Train] epoch 230 Batch 31 Loss 0.15249022841453552
[Train] epoch 230 Batch 32 Loss 0.1738816201686859
[Train] epoch 230 Batch 33 Loss 0.14099203050136566
[Train] epoch 230 Batch 34 Loss 0.3352028727531433
[Train] epoch 230 Batch 35 Loss 0.07187741994857788
[Train] epoch 230 Batch 36 Loss 0.1745728850364685
[Train] epoch 230 Batch 37 Loss 0.18893367052078247
[Train] epoch 230 Batch 38 Loss 0.1351030468940735
[Train] epoch 230 Batch 39 Loss 0.13681089878082275
[Train] epoch 230 Batch 40 Loss 0.13506802916526794
[Train] epoch 230 Batch 41 Loss 0.2699732184410095
[Train] epoch 230 Batch 42 Loss 0.2084718942642212
[Train] epoch 230 Batch 43 Loss 0.13990864157676697
[Train] epoch 230 Batch 44 Loss 0.3070142865180969
[Train] epoch 230 Batch 45 Loss 0.13659241795539856
[Train] epoch 230 Batch 46 Loss 0.37380772829055786
[Train] epoch 230 Batch 47 Loss 0.13709424436092377
[Train] epoch 231 Batch 0 Loss 0.10436059534549713
[Train] epoch 231 Batch 1 Loss 0.13503888249397278
[Train] epoch 231 Batch 2 Loss 0.3711444139480591
[Train] epoch 231 Batch 3 Loss 0.10094325244426727
[Train] epoch 231 Batch 4 Loss 0.3691070079803467
[Train] epoch 231 Batch 5 Loss 0.21124368906021118
[Train] epoch 231 Batch 6 Loss 0.2011893093585968
[Train] epoch 231 Batch 7 Loss 0.10238668322563171
[Train] epoch 231 Batch 8 Loss 0.17242354154586792
[Train] epoch 231 Batch 9 Loss 0.2701890468597412
[Train] epoch 231 Batch 10 Loss 0.1365739107131958
[Train] epoch 231 Batch 11 Loss 0.23953770101070404
[Train] epoch 231 Batch 12 Loss 0.13675232231616974
[Train] epoch 231 Batch 13 Loss 0.3043956458568573
[Train] epoch 231 Batch 14 Loss 0.13861404359340668
[Train] epoch 231 Batch 15 Loss 0.13864362239837646
[Train] epoch 231 Batch 16 Loss 0.23953479528427124
[Train] epoch 231 Batch 17 Loss 0.06842972338199615
[Train] epoch 231 Batch 18 Loss 0.20335760712623596
[Train] epoch 231 Batch 19 Loss 0.13692359626293182
[Train] epoch 231 Batch 20 Loss 0.1728297472000122
[Train] epoch 231 Batch 21 Loss 0.27569305896759033
[Train] epoch 231 Batch 22 Loss 0.06857618689537048
[Train] epoch 231 Batch 23 Loss 0.2376536726951599
[Train] epoch 231 Batch 24 Loss 0.13863015174865723
[Train] epoch 231 Batch 25 Loss 0.16936928033828735
[Train] epoch 231 Batch 26 Loss 0.03757130727171898
[Train] epoch 231 Batch 27 Loss 0.1711319088935852
[Train] epoch 231 Batch 28 Loss 0.27216798067092896
[Train] epoch 231 Batch 29 Loss 0.16937747597694397
[Train] epoch 231 Batch 30 Loss 0.07024626433849335
[Train] epoch 231 Batch 31 Loss 0.2360195517539978
[Train] epoch 231 Batch 32 Loss 0.30441540479660034
[Train] epoch 231 Batch 33 Loss 0.07186158746480942
[Train] epoch 231 Batch 34 Loss 0.1746160089969635
[Train] epoch 231 Batch 35 Loss 0.07183962315320969
[Train] epoch 231 Batch 36 Loss 0.17114339768886566
[Train] epoch 231 Batch 37 Loss 0.4392377734184265
[Train] epoch 231 Batch 38 Loss 0.24102163314819336
[Train] epoch 231 Batch 39 Loss 0.00339035177603364
[Train] epoch 231 Batch 40 Loss 0.1350383460521698
[Train] epoch 231 Batch 41 Loss 0.27191680669784546
[Train] epoch 231 Batch 42 Loss 0.0685616284608841
[Train] epoch 231 Batch 43 Loss 0.1726302206516266
[Train] epoch 231 Batch 44 Loss 0.20491328835487366
[Train] epoch 231 Batch 45 Loss 0.2015637904405594
[Train] epoch 231 Batch 46 Loss 0.17084768414497375
[Train] epoch 231 Batch 47 Loss 0.0015489348443225026
[Train] epoch 232 Batch 0 Loss 0.07172238826751709
[Train] epoch 232 Batch 1 Loss 0.10401367396116257
[Train] epoch 232 Batch 2 Loss 0.13835756480693817
[Train] epoch 232 Batch 3 Loss 0.00160345365293324
[Train] epoch 232 Batch 4 Loss 0.3060833811759949
[Train] epoch 232 Batch 5 Loss 0.2701394259929657
[Train] epoch 232 Batch 6 Loss 0.2732132077217102
[Train] epoch 232 Batch 7 Loss 0.0685504823923111
[Train] epoch 232 Batch 8 Loss 0.13639232516288757
[Train] epoch 232 Batch 9 Loss 0.1693277657032013
[Train] epoch 232 Batch 10 Loss 0.13505011796951294
[Train] epoch 232 Batch 11 Loss 0.1382310539484024
[Train] epoch 232 Batch 12 Loss 0.13650980591773987
[Train] epoch 232 Batch 13 Loss 0.23719674348831177
[Train] epoch 232 Batch 14 Loss 0.13632377982139587
[Train] epoch 232 Batch 15 Loss 0.17414918541908264
[Train] epoch 232 Batch 16 Loss 0.20339065790176392
[Train] epoch 232 Batch 17 Loss 0.20633530616760254
[Train] epoch 232 Batch 18 Loss 0.30556267499923706
[Train] epoch 232 Batch 19 Loss 0.13831312954425812
[Train] epoch 232 Batch 20 Loss 0.13927876949310303
[Train] epoch 232 Batch 21 Loss 0.10692308843135834
[Train] epoch 232 Batch 22 Loss 0.16920210421085358
[Train] epoch 232 Batch 23 Loss 0.16759969294071198
[Train] epoch 232 Batch 24 Loss 0.26666736602783203
[Train] epoch 232 Batch 25 Loss 0.20332206785678864
[Train] epoch 232 Batch 26 Loss 0.13868892192840576
[Train] epoch 232 Batch 27 Loss 0.20528608560562134
[Train] epoch 232 Batch 28 Loss 0.2412787526845932
[Train] epoch 232 Batch 29 Loss 0.20603972673416138
[Train] epoch 232 Batch 30 Loss 0.35116297006607056
[Train] epoch 232 Batch 31 Loss 0.04010874778032303
[Train] epoch 232 Batch 32 Loss 0.14376263320446014
[Train] epoch 232 Batch 33 Loss 0.2851313352584839
[Train] epoch 232 Batch 34 Loss 0.13790851831436157
[Train] epoch 232 Batch 35 Loss 0.10715307295322418
[Train] epoch 232 Batch 36 Loss 0.06666764616966248
[Train] epoch 232 Batch 37 Loss 0.1372579038143158
[Train] epoch 232 Batch 38 Loss 0.318545937538147
[Train] epoch 232 Batch 39 Loss 0.20286992192268372
[Train] epoch 232 Batch 40 Loss 0.269983172416687
[Train] epoch 232 Batch 41 Loss 0.0685269758105278
[Train] epoch 232 Batch 42 Loss 0.13471511006355286
[Train] epoch 232 Batch 43 Loss 0.1061001718044281
[Train] epoch 232 Batch 44 Loss 0.302884042263031
[Train] epoch 232 Batch 45 Loss 0.20396257936954498
[Train] epoch 232 Batch 46 Loss 0.2684124708175659
[Train] epoch 232 Batch 47 Loss 0.2048184871673584
[Train] epoch 233 Batch 0 Loss 0.24082256853580475
[Train] epoch 233 Batch 1 Loss 0.10430480539798737
[Train] epoch 233 Batch 2 Loss 0.10456320643424988
[Train] epoch 233 Batch 3 Loss 0.20770448446273804
[Train] epoch 233 Batch 4 Loss 0.03642796725034714
[Train] epoch 233 Batch 5 Loss 0.27065348625183105
[Train] epoch 233 Batch 6 Loss 0.3395366668701172
[Train] epoch 233 Batch 7 Loss 0.3140806555747986
[Train] epoch 233 Batch 8 Loss 0.25215643644332886
[Train] epoch 233 Batch 9 Loss 0.23608222603797913
[Train] epoch 233 Batch 10 Loss 0.20196056365966797
[Train] epoch 233 Batch 11 Loss 0.2382267713546753
[Train] epoch 233 Batch 12 Loss 0.036096908152103424
[Train] epoch 233 Batch 13 Loss 0.308006227016449
[Train] epoch 233 Batch 14 Loss 0.1383744180202484
[Train] epoch 233 Batch 15 Loss 0.2392626851797104
[Train] epoch 233 Batch 16 Loss 0.2391291856765747
[Train] epoch 233 Batch 17 Loss 0.17264437675476074
[Train] epoch 233 Batch 18 Loss 0.03399607166647911
[Train] epoch 233 Batch 19 Loss 0.17076435685157776
[Train] epoch 233 Batch 20 Loss 0.1023934930562973
[Train] epoch 233 Batch 21 Loss 0.20251873135566711
[Train] epoch 233 Batch 22 Loss 0.41504499316215515
[Train] epoch 233 Batch 23 Loss 0.07158233970403671
[Train] epoch 233 Batch 24 Loss 0.2020435333251953
[Train] epoch 233 Batch 25 Loss 0.1027698814868927
[Train] epoch 233 Batch 26 Loss 0.3736177384853363
[Train] epoch 233 Batch 27 Loss 0.16762888431549072
[Train] epoch 233 Batch 28 Loss 0.07140932977199554
[Train] epoch 233 Batch 29 Loss 0.23879997432231903
[Train] epoch 233 Batch 30 Loss 0.10683219879865646
[Train] epoch 233 Batch 31 Loss 0.0347612164914608
[Train] epoch 233 Batch 32 Loss 0.2245757132768631
[Train] epoch 233 Batch 33 Loss 0.17938977479934692
[Train] epoch 233 Batch 34 Loss 0.1410348117351532
[Train] epoch 233 Batch 35 Loss 0.1405545026063919
[Train] epoch 233 Batch 36 Loss 0.17205193638801575
[Train] epoch 233 Batch 37 Loss 0.20247110724449158
[Train] epoch 233 Batch 38 Loss 0.17004936933517456
[Train] epoch 233 Batch 39 Loss 0.26869091391563416
[Train] epoch 233 Batch 40 Loss 0.10542158782482147
[Train] epoch 233 Batch 41 Loss 0.17392247915267944
[Train] epoch 233 Batch 42 Loss 0.14181223511695862
[Train] epoch 233 Batch 43 Loss 0.1374577283859253
[Train] epoch 233 Batch 44 Loss 0.23841777443885803
[Train] epoch 233 Batch 45 Loss 0.10105731338262558
[Train] epoch 233 Batch 46 Loss 0.13932037353515625
[Train] epoch 233 Batch 47 Loss 0.07069507986307144
[Train] epoch 234 Batch 0 Loss 0.17341119050979614
[Train] epoch 234 Batch 1 Loss 0.1393652856349945
[Train] epoch 234 Batch 2 Loss 0.07235409319400787
[Train] epoch 234 Batch 3 Loss 0.03817491605877876
[Train] epoch 234 Batch 4 Loss 0.10480649769306183
[Train] epoch 234 Batch 5 Loss 0.23626196384429932
[Train] epoch 234 Batch 6 Loss 0.2018277645111084
[Train] epoch 234 Batch 7 Loss 0.2708381414413452
[Train] epoch 234 Batch 8 Loss 0.1374378353357315
[Train] epoch 234 Batch 9 Loss 0.14074327051639557
[Train] epoch 234 Batch 10 Loss 0.20389437675476074
[Train] epoch 234 Batch 11 Loss 0.06885369122028351
[Train] epoch 234 Batch 12 Loss 0.1693865954875946
[Train] epoch 234 Batch 13 Loss 0.20548772811889648
[Train] epoch 234 Batch 14 Loss 0.17283841967582703
[Train] epoch 234 Batch 15 Loss 0.2053445428609848
[Train] epoch 234 Batch 16 Loss 0.27583304047584534
[Train] epoch 234 Batch 17 Loss 0.13692784309387207
[Train] epoch 234 Batch 18 Loss 0.10328192263841629
[Train] epoch 234 Batch 19 Loss 0.2019401490688324
[Train] epoch 234 Batch 20 Loss 0.2363635003566742
[Train] epoch 234 Batch 21 Loss 0.33656808733940125
[Train] epoch 234 Batch 22 Loss 0.10250524431467056
[Train] epoch 234 Batch 23 Loss 0.1393703669309616
[Train] epoch 234 Batch 24 Loss 0.20352023839950562
[Train] epoch 234 Batch 25 Loss 0.20351165533065796
[Train] epoch 234 Batch 26 Loss 0.16775843501091003
[Train] epoch 234 Batch 27 Loss 0.13862520456314087
[Train] epoch 234 Batch 28 Loss 0.0720619335770607
[Train] epoch 234 Batch 29 Loss 0.2717742919921875
[Train] epoch 234 Batch 30 Loss 0.17122739553451538
[Train] epoch 234 Batch 31 Loss 0.30427131056785583
[Train] epoch 234 Batch 32 Loss 0.2378748059272766
[Train] epoch 234 Batch 33 Loss 0.10264116525650024
[Train] epoch 234 Batch 34 Loss 0.23963654041290283
[Train] epoch 234 Batch 35 Loss 0.17238110303878784
[Train] epoch 234 Batch 36 Loss 0.13521592319011688
[Train] epoch 234 Batch 37 Loss 0.1386251598596573
[Train] epoch 234 Batch 38 Loss 0.13550515472888947
[Train] epoch 234 Batch 39 Loss 0.1383085995912552
[Train] epoch 234 Batch 40 Loss 0.3060459494590759
[Train] epoch 234 Batch 41 Loss 0.37107551097869873
[Train] epoch 234 Batch 42 Loss 0.10374587029218674
[Train] epoch 234 Batch 43 Loss 0.1732768416404724
[Train] epoch 234 Batch 44 Loss 0.20701780915260315
[Train] epoch 234 Batch 45 Loss 0.1354924887418747
[Train] epoch 234 Batch 46 Loss 0.20519380271434784
[Train] epoch 234 Batch 47 Loss 0.10261791944503784
[Train] epoch 235 Batch 0 Loss 0.27214688062667847
[Train] epoch 235 Batch 1 Loss 0.0015333129558712244
[Train] epoch 235 Batch 2 Loss 0.10218583047389984
[Train] epoch 235 Batch 3 Loss 0.13548021018505096
[Train] epoch 235 Batch 4 Loss 0.16988623142242432
[Train] epoch 235 Batch 5 Loss 0.23879855871200562
[Train] epoch 235 Batch 6 Loss 0.13693535327911377
[Train] epoch 235 Batch 7 Loss 0.1698746532201767
[Train] epoch 235 Batch 8 Loss 0.06994496285915375
[Train] epoch 235 Batch 9 Loss 0.10621116310358047
[Train] epoch 235 Batch 10 Loss 0.27024829387664795
[Train] epoch 235 Batch 11 Loss 0.17430679500102997
[Train] epoch 235 Batch 12 Loss 0.10250796377658844
[Train] epoch 235 Batch 13 Loss 0.23588943481445312
[Train] epoch 235 Batch 14 Loss 0.3737948536872864
[Train] epoch 235 Batch 15 Loss 0.30254608392715454
[Train] epoch 235 Batch 16 Loss 0.20471474528312683
[Train] epoch 235 Batch 17 Loss 0.07137175649404526
[Train] epoch 235 Batch 18 Loss 0.20348510146141052
[Train] epoch 235 Batch 19 Loss 0.13686418533325195
[Train] epoch 235 Batch 20 Loss 0.10431160032749176
[Train] epoch 235 Batch 21 Loss 0.27023929357528687
[Train] epoch 235 Batch 22 Loss 0.27164265513420105
[Train] epoch 235 Batch 23 Loss 0.10386437922716141
[Train] epoch 235 Batch 24 Loss 0.2687680721282959
[Train] epoch 235 Batch 25 Loss 0.3708912134170532
[Train] epoch 235 Batch 26 Loss 0.2407209277153015
[Train] epoch 235 Batch 27 Loss 0.10211726278066635
[Train] epoch 235 Batch 28 Loss 0.1733778417110443
[Train] epoch 235 Batch 29 Loss 0.03548984229564667
[Train] epoch 235 Batch 30 Loss 0.2375718206167221
[Train] epoch 235 Batch 31 Loss 0.2385149598121643
[Train] epoch 235 Batch 32 Loss 0.1038445457816124
[Train] epoch 235 Batch 33 Loss 0.10383572429418564
[Train] epoch 235 Batch 34 Loss 0.30241072177886963
[Train] epoch 235 Batch 35 Loss 0.13682997226715088
[Train] epoch 235 Batch 36 Loss 0.2392735630273819
[Train] epoch 235 Batch 37 Loss 0.07117205858230591
[Train] epoch 235 Batch 38 Loss 0.20169366896152496
[Train] epoch 235 Batch 39 Loss 0.06801652163267136
[Train] epoch 235 Batch 40 Loss 0.23745444416999817
[Train] epoch 235 Batch 41 Loss 0.20827648043632507
[Train] epoch 235 Batch 42 Loss 0.3048427999019623
[Train] epoch 235 Batch 43 Loss 0.17032980918884277
[Train] epoch 235 Batch 44 Loss 0.10365642607212067
[Train] epoch 235 Batch 45 Loss 0.035699181258678436
[Train] epoch 235 Batch 46 Loss 0.0693219006061554
[Train] epoch 235 Batch 47 Loss 0.2377561628818512
[Train] epoch 236 Batch 0 Loss 0.0713735818862915
[Train] epoch 236 Batch 1 Loss 0.1364121437072754
[Train] epoch 236 Batch 2 Loss 0.10507011413574219
[Train] epoch 236 Batch 3 Loss 0.334995836019516
[Train] epoch 236 Batch 4 Loss 0.2720910310745239
[Train] epoch 236 Batch 5 Loss 0.10543818771839142
[Train] epoch 236 Batch 6 Loss 0.1349898725748062
[Train] epoch 236 Batch 7 Loss 0.07002073526382446
[Train] epoch 236 Batch 8 Loss 0.1690359264612198
[Train] epoch 236 Batch 9 Loss 0.27175217866897583
[Train] epoch 236 Batch 10 Loss 0.13601303100585938
[Train] epoch 236 Batch 11 Loss 0.4707523584365845
[Train] epoch 236 Batch 12 Loss 0.03835707902908325
[Train] epoch 236 Batch 13 Loss 0.23568549752235413
[Train] epoch 236 Batch 14 Loss 0.1710076481103897
[Train] epoch 236 Batch 15 Loss 1.0728851975727594e-06
[Train] epoch 236 Batch 16 Loss 0.1689637303352356
[Train] epoch 236 Batch 17 Loss 0.0013240070547908545
[Train] epoch 236 Batch 18 Loss 0.33831244707107544
[Train] epoch 236 Batch 19 Loss 0.10101330280303955
[Train] epoch 236 Batch 20 Loss 0.1026841402053833
[Train] epoch 236 Batch 21 Loss 0.17061957716941833
[Train] epoch 236 Batch 22 Loss 0.13535398244857788
[Train] epoch 236 Batch 23 Loss 0.13697287440299988
[Train] epoch 236 Batch 24 Loss 0.10192439705133438
[Train] epoch 236 Batch 25 Loss 0.24111133813858032
[Train] epoch 236 Batch 26 Loss 0.17059585452079773
[Train] epoch 236 Batch 27 Loss 0.1362532675266266
[Train] epoch 236 Batch 28 Loss 0.2752898335456848
[Train] epoch 236 Batch 29 Loss 0.10773253440856934
[Train] epoch 236 Batch 30 Loss 0.17057396471500397
[Train] epoch 236 Batch 31 Loss 0.13988097012043
[Train] epoch 236 Batch 32 Loss 0.23393858969211578
[Train] epoch 236 Batch 33 Loss 0.30513644218444824
[Train] epoch 236 Batch 34 Loss 0.1672697514295578
[Train] epoch 236 Batch 35 Loss 0.06826356053352356
[Train] epoch 236 Batch 36 Loss 0.23805415630340576
[Train] epoch 236 Batch 37 Loss 0.37127798795700073
[Train] epoch 236 Batch 38 Loss 0.13748256862163544
[Train] epoch 236 Batch 39 Loss 0.23591011762619019
[Train] epoch 236 Batch 40 Loss 0.2695273160934448
[Train] epoch 236 Batch 41 Loss 0.13654208183288574
[Train] epoch 236 Batch 42 Loss 0.20281019806861877
[Train] epoch 236 Batch 43 Loss 0.10344153642654419
[Train] epoch 236 Batch 44 Loss 0.10339474678039551
[Train] epoch 236 Batch 45 Loss 0.17013920843601227
[Train] epoch 236 Batch 46 Loss 0.20496529340744019
[Train] epoch 236 Batch 47 Loss 0.30671775341033936
[Train] epoch 237 Batch 0 Loss 0.30294808745384216
[Train] epoch 237 Batch 1 Loss 0.0703420341014862
[Train] epoch 237 Batch 2 Loss 0.23592308163642883
[Train] epoch 237 Batch 3 Loss 0.170500248670578
[Train] epoch 237 Batch 4 Loss 0.17093676328659058
[Train] epoch 237 Batch 5 Loss 0.26822739839553833
[Train] epoch 237 Batch 6 Loss 0.13489224016666412
[Train] epoch 237 Batch 7 Loss 0.17167207598686218
[Train] epoch 237 Batch 8 Loss 0.07064519077539444
[Train] epoch 237 Batch 9 Loss 0.07313524186611176
[Train] epoch 237 Batch 10 Loss 0.10298366099596024
[Train] epoch 237 Batch 11 Loss 0.03671707585453987
[Train] epoch 237 Batch 12 Loss 0.4698023796081543
[Train] epoch 237 Batch 13 Loss 0.20309306681156158
[Train] epoch 237 Batch 14 Loss 0.13646087050437927
[Train] epoch 237 Batch 15 Loss 0.20349642634391785
[Train] epoch 237 Batch 16 Loss 0.0690034031867981
[Train] epoch 237 Batch 17 Loss 0.10180886834859848
[Train] epoch 237 Batch 18 Loss 0.10330242663621902
[Train] epoch 237 Batch 19 Loss 0.20551219582557678
[Train] epoch 237 Batch 20 Loss 0.17392757534980774
[Train] epoch 237 Batch 21 Loss 0.10370149463415146
[Train] epoch 237 Batch 22 Loss 0.133334219455719
[Train] epoch 237 Batch 23 Loss 0.034307725727558136
[Train] epoch 237 Batch 24 Loss 0.2011096179485321
[Train] epoch 237 Batch 25 Loss 0.10215739905834198
[Train] epoch 237 Batch 26 Loss 0.10680776834487915
[Train] epoch 237 Batch 27 Loss 0.17114059627056122
[Train] epoch 237 Batch 28 Loss 0.3040536642074585
[Train] epoch 237 Batch 29 Loss 0.2056954801082611
[Train] epoch 237 Batch 30 Loss 0.2080899029970169
[Train] epoch 237 Batch 31 Loss 0.10210181772708893
[Train] epoch 237 Batch 32 Loss 0.07089998573064804
[Train] epoch 237 Batch 33 Loss 0.20193496346473694
[Train] epoch 237 Batch 34 Loss 0.1676328182220459
[Train] epoch 237 Batch 35 Loss 0.2681780457496643
[Train] epoch 237 Batch 36 Loss 0.20421364903450012
[Train] epoch 237 Batch 37 Loss 0.13762354850769043
[Train] epoch 237 Batch 38 Loss 0.21065998077392578
[Train] epoch 237 Batch 39 Loss 0.1385652720928192
[Train] epoch 237 Batch 40 Loss 0.23680517077445984
[Train] epoch 237 Batch 41 Loss 0.20396864414215088
[Train] epoch 237 Batch 42 Loss 0.13617196679115295
[Train] epoch 237 Batch 43 Loss 0.27034425735473633
[Train] epoch 237 Batch 44 Loss 0.3042490780353546
[Train] epoch 237 Batch 45 Loss 0.23645111918449402
[Train] epoch 237 Batch 46 Loss 0.33829009532928467
[Train] epoch 237 Batch 47 Loss 0.20166343450546265
[Train] epoch 238 Batch 0 Loss 0.30303502082824707
[Train] epoch 238 Batch 1 Loss 0.2683197855949402
[Train] epoch 238 Batch 2 Loss 0.10266010463237762
[Train] epoch 238 Batch 3 Loss 0.0013399748131632805
[Train] epoch 238 Batch 4 Loss 0.13802358508110046
[Train] epoch 238 Batch 5 Loss 0.04078483581542969
[Train] epoch 238 Batch 6 Loss 0.06970588862895966
[Train] epoch 238 Batch 7 Loss 0.2013901174068451
[Train] epoch 238 Batch 8 Loss 0.13668721914291382
[Train] epoch 238 Batch 9 Loss 0.23601016402244568
[Train] epoch 238 Batch 10 Loss 0.06968805938959122
[Train] epoch 238 Batch 11 Loss 0.10073663294315338
[Train] epoch 238 Batch 12 Loss 0.06803588569164276
[Train] epoch 238 Batch 13 Loss 0.2019379436969757
[Train] epoch 238 Batch 14 Loss 0.1690051406621933
[Train] epoch 238 Batch 15 Loss 0.20171746611595154
[Train] epoch 238 Batch 16 Loss 0.004117154516279697
[Train] epoch 238 Batch 17 Loss 0.33718737959861755
[Train] epoch 238 Batch 18 Loss 0.07113181054592133
[Train] epoch 238 Batch 19 Loss 0.23910881578922272
[Train] epoch 238 Batch 20 Loss 0.06838902831077576
[Train] epoch 238 Batch 21 Loss 0.10268058627843857
[Train] epoch 238 Batch 22 Loss 0.17243483662605286
[Train] epoch 238 Batch 23 Loss 0.1718822568655014
[Train] epoch 238 Batch 24 Loss 0.30267560482025146
[Train] epoch 238 Batch 25 Loss 0.1690666675567627
[Train] epoch 238 Batch 26 Loss 0.10375925898551941
[Train] epoch 238 Batch 27 Loss 0.36906158924102783
[Train] epoch 238 Batch 28 Loss 0.13920089602470398
[Train] epoch 238 Batch 29 Loss 0.33639979362487793
[Train] epoch 238 Batch 30 Loss 0.135238379240036
[Train] epoch 238 Batch 31 Loss 0.2378137707710266
[Train] epoch 238 Batch 32 Loss 0.17344528436660767
[Train] epoch 238 Batch 33 Loss 0.40466946363449097
[Train] epoch 238 Batch 34 Loss 0.23724371194839478
[Train] epoch 238 Batch 35 Loss 0.20875099301338196
[Train] epoch 238 Batch 36 Loss 0.20795556902885437
[Train] epoch 238 Batch 37 Loss 0.3037697374820709
[Train] epoch 238 Batch 38 Loss 0.2387026697397232
[Train] epoch 238 Batch 39 Loss 0.1068403422832489
[Train] epoch 238 Batch 40 Loss 0.10366084426641464
[Train] epoch 238 Batch 41 Loss 0.20508930087089539
[Train] epoch 238 Batch 42 Loss 0.16892054677009583
[Train] epoch 238 Batch 43 Loss 0.13710245490074158
[Train] epoch 238 Batch 44 Loss 0.13622991740703583
[Train] epoch 238 Batch 45 Loss 0.17303788661956787
[Train] epoch 238 Batch 46 Loss 0.2045484185218811
[Train] epoch 238 Batch 47 Loss 0.20166178047657013
[Train] epoch 239 Batch 0 Loss 0.16738751530647278
[Train] epoch 239 Batch 1 Loss 0.06946347653865814
[Train] epoch 239 Batch 2 Loss 0.3383645713329315
[Train] epoch 239 Batch 3 Loss 0.10408871620893478
[Train] epoch 239 Batch 4 Loss 0.13783112168312073
[Train] epoch 239 Batch 5 Loss 0.302507221698761
[Train] epoch 239 Batch 6 Loss 0.10362067818641663
[Train] epoch 239 Batch 7 Loss 0.17043569684028625
[Train] epoch 239 Batch 8 Loss 0.034267112612724304
[Train] epoch 239 Batch 9 Loss 0.13519738614559174
[Train] epoch 239 Batch 10 Loss 0.27238231897354126
[Train] epoch 239 Batch 11 Loss 0.0711858868598938
[Train] epoch 239 Batch 12 Loss 0.16862116754055023
[Train] epoch 239 Batch 13 Loss 0.20450454950332642
[Train] epoch 239 Batch 14 Loss 0.10606841742992401
[Train] epoch 239 Batch 15 Loss 0.13937291502952576
[Train] epoch 239 Batch 16 Loss 0.16977685689926147
[Train] epoch 239 Batch 17 Loss 0.20533671975135803
[Train] epoch 239 Batch 18 Loss 0.17353196442127228
[Train] epoch 239 Batch 19 Loss 0.2701282203197479
[Train] epoch 239 Batch 20 Loss 0.30376172065734863
[Train] epoch 239 Batch 21 Loss 0.13487190008163452
[Train] epoch 239 Batch 22 Loss 0.20160196721553802
[Train] epoch 239 Batch 23 Loss 0.16894197463989258
[Train] epoch 239 Batch 24 Loss 0.26979565620422363
[Train] epoch 239 Batch 25 Loss 0.2058693766593933
[Train] epoch 239 Batch 26 Loss 0.13804616034030914
[Train] epoch 239 Batch 27 Loss 0.16879817843437195
[Train] epoch 239 Batch 28 Loss 0.13879786431789398
[Train] epoch 239 Batch 29 Loss 0.10193541646003723
[Train] epoch 239 Batch 30 Loss 0.2686268389225006
[Train] epoch 239 Batch 31 Loss 0.33762627840042114
[Train] epoch 239 Batch 32 Loss 0.1032857596874237
[Train] epoch 239 Batch 33 Loss 0.10328057408332825
[Train] epoch 239 Batch 34 Loss 0.2684749364852905
[Train] epoch 239 Batch 35 Loss 0.17029547691345215
[Train] epoch 239 Batch 36 Loss 0.23722560703754425
[Train] epoch 239 Batch 37 Loss 0.07248562574386597
[Train] epoch 239 Batch 38 Loss 0.17184999585151672
[Train] epoch 239 Batch 39 Loss 0.20302727818489075
[Train] epoch 239 Batch 40 Loss 0.1674516797065735
[Train] epoch 239 Batch 41 Loss 0.20635825395584106
[Train] epoch 239 Batch 42 Loss 0.17101439833641052
[Train] epoch 239 Batch 43 Loss 0.03564237803220749
[Train] epoch 239 Batch 44 Loss 0.16932369768619537
[Train] epoch 239 Batch 45 Loss 0.3056092858314514
[Train] epoch 239 Batch 46 Loss 0.26988711953163147
[Train] epoch 239 Batch 47 Loss 0.0357477143406868
[Train] epoch 240 Batch 0 Loss 0.20176327228546143
[Train] epoch 240 Batch 1 Loss 0.27003079652786255
[Train] epoch 240 Batch 2 Loss 0.16902396082878113
[Train] epoch 240 Batch 3 Loss 0.17208236455917358
[Train] epoch 240 Batch 4 Loss 0.16908815503120422
[Train] epoch 240 Batch 5 Loss 0.16893696784973145
[Train] epoch 240 Batch 6 Loss 0.20299579203128815
[Train] epoch 240 Batch 7 Loss 0.10256791859865189
[Train] epoch 240 Batch 8 Loss 0.23595958948135376
[Train] epoch 240 Batch 9 Loss 0.10226532071828842
[Train] epoch 240 Batch 10 Loss 0.2682935893535614
[Train] epoch 240 Batch 11 Loss 0.20488131046295166
[Train] epoch 240 Batch 12 Loss 0.2077709287405014
[Train] epoch 240 Batch 13 Loss 0.20778359472751617
[Train] epoch 240 Batch 14 Loss 0.2375636100769043
[Train] epoch 240 Batch 15 Loss 0.10535718500614166
[Train] epoch 240 Batch 16 Loss 0.13666541874408722
[Train] epoch 240 Batch 17 Loss 0.23699557781219482
[Train] epoch 240 Batch 18 Loss 0.1035694032907486
[Train] epoch 240 Batch 19 Loss 0.17220550775527954
[Train] epoch 240 Batch 20 Loss 0.37069445848464966
[Train] epoch 240 Batch 21 Loss 0.341135174036026
[Train] epoch 240 Batch 22 Loss 0.1379684954881668
[Train] epoch 240 Batch 23 Loss 0.16902023553848267
[Train] epoch 240 Batch 24 Loss 0.23584894835948944
[Train] epoch 240 Batch 25 Loss 0.10530738532543182
[Train] epoch 240 Batch 26 Loss 0.10260145366191864
[Train] epoch 240 Batch 27 Loss 0.2062244415283203
[Train] epoch 240 Batch 28 Loss 0.10232732445001602
[Train] epoch 240 Batch 29 Loss 0.16908922791481018
[Train] epoch 240 Batch 30 Loss 0.23702853918075562
[Train] epoch 240 Batch 31 Loss 0.20599836111068726
[Train] epoch 240 Batch 32 Loss 0.16753143072128296
[Train] epoch 240 Batch 33 Loss 0.17044448852539062
[Train] epoch 240 Batch 34 Loss 0.10211680829524994
[Train] epoch 240 Batch 35 Loss 0.20462793111801147
[Train] epoch 240 Batch 36 Loss 0.06666764616966248
[Train] epoch 240 Batch 37 Loss 0.06809018552303314
[Train] epoch 240 Batch 38 Loss 0.10074511170387268
[Train] epoch 240 Batch 39 Loss 0.10209022462368011
[Train] epoch 240 Batch 40 Loss 0.1376233994960785
[Train] epoch 240 Batch 41 Loss 0.23751649260520935
[Train] epoch 240 Batch 42 Loss 0.06934307515621185
[Train] epoch 240 Batch 43 Loss 0.17179155349731445
[Train] epoch 240 Batch 44 Loss 0.3396952748298645
[Train] epoch 240 Batch 45 Loss 0.06958560645580292
[Train] epoch 240 Batch 46 Loss 0.2398209422826767
[Train] epoch 240 Batch 47 Loss 0.172016441822052
[Train] epoch 241 Batch 0 Loss 0.23675748705863953
[Train] epoch 241 Batch 1 Loss 0.3702801465988159
[Train] epoch 241 Batch 2 Loss 0.10257375240325928
[Train] epoch 241 Batch 3 Loss 0.23741449415683746
[Train] epoch 241 Batch 4 Loss 0.17080673575401306
[Train] epoch 241 Batch 5 Loss 0.20416924357414246
[Train] epoch 241 Batch 6 Loss 0.23554840683937073
[Train] epoch 241 Batch 7 Loss 0.23990380764007568
[Train] epoch 241 Batch 8 Loss 0.2712875008583069
[Train] epoch 241 Batch 9 Loss 0.07086019217967987
[Train] epoch 241 Batch 10 Loss 0.17164340615272522
[Train] epoch 241 Batch 11 Loss 0.06928810477256775
[Train] epoch 241 Batch 12 Loss 0.17174002528190613
[Train] epoch 241 Batch 13 Loss 0.2369062304496765
[Train] epoch 241 Batch 14 Loss 0.20281432569026947
[Train] epoch 241 Batch 15 Loss 0.06963472068309784
[Train] epoch 241 Batch 16 Loss 0.1021699607372284
[Train] epoch 241 Batch 17 Loss 0.1033695787191391
[Train] epoch 241 Batch 18 Loss 0.0012573536951094866
[Train] epoch 241 Batch 19 Loss 0.20403769612312317
[Train] epoch 241 Batch 20 Loss 0.13611215353012085
[Train] epoch 241 Batch 21 Loss 0.1059437096118927
[Train] epoch 241 Batch 22 Loss 0.10310851782560349
[Train] epoch 241 Batch 23 Loss 0.23418261110782623
[Train] epoch 241 Batch 24 Loss 0.13503026962280273
[Train] epoch 241 Batch 25 Loss 0.1020815446972847
[Train] epoch 241 Batch 26 Loss 0.26987767219543457
[Train] epoch 241 Batch 27 Loss 0.27191489934921265
[Train] epoch 241 Batch 28 Loss 0.23564061522483826
[Train] epoch 241 Batch 29 Loss 0.23805201053619385
[Train] epoch 241 Batch 30 Loss 0.17272737622261047
[Train] epoch 241 Batch 31 Loss 0.30187466740608215
[Train] epoch 241 Batch 32 Loss 0.036604683846235275
[Train] epoch 241 Batch 33 Loss 0.33942511677742004
[Train] epoch 241 Batch 34 Loss 0.07159093767404556
[Train] epoch 241 Batch 35 Loss 0.1720946580171585
[Train] epoch 241 Batch 36 Loss 0.26984938979148865
[Train] epoch 241 Batch 37 Loss 0.1350218504667282
[Train] epoch 241 Batch 38 Loss 0.17039185762405396
[Train] epoch 241 Batch 39 Loss 0.035368725657463074
[Train] epoch 241 Batch 40 Loss 0.2678564786911011
[Train] epoch 241 Batch 41 Loss 0.13456885516643524
[Train] epoch 241 Batch 42 Loss 0.03520631790161133
[Train] epoch 241 Batch 43 Loss 0.13772526383399963
[Train] epoch 241 Batch 44 Loss 0.202705517411232
[Train] epoch 241 Batch 45 Loss 0.10467227548360825
[Train] epoch 241 Batch 46 Loss 0.3381195068359375
[Train] epoch 241 Batch 47 Loss 0.23396682739257812
[Train] epoch 242 Batch 0 Loss 0.23522862792015076
[Train] epoch 242 Batch 1 Loss 0.2716894745826721
[Train] epoch 242 Batch 2 Loss 0.37302666902542114
[Train] epoch 242 Batch 3 Loss 0.13570815324783325
[Train] epoch 242 Batch 4 Loss 0.1687106490135193
[Train] epoch 242 Batch 5 Loss 0.1686634123325348
[Train] epoch 242 Batch 6 Loss 0.30418238043785095
[Train] epoch 242 Batch 7 Loss 0.30443260073661804
[Train] epoch 242 Batch 8 Loss 0.2030831277370453
[Train] epoch 242 Batch 9 Loss 0.23766392469406128
[Train] epoch 242 Batch 10 Loss 0.133334219455719
[Train] epoch 242 Batch 11 Loss 0.27088844776153564
[Train] epoch 242 Batch 12 Loss 0.03623761236667633
[Train] epoch 242 Batch 13 Loss 0.23842112720012665
[Train] epoch 242 Batch 14 Loss 0.23789063096046448
[Train] epoch 242 Batch 15 Loss 0.10310854762792587
[Train] epoch 242 Batch 16 Loss 0.1672765016555786
[Train] epoch 242 Batch 17 Loss 0.10222962498664856
[Train] epoch 242 Batch 18 Loss 0.133334219455719
[Train] epoch 242 Batch 19 Loss 0.2378585934638977
[Train] epoch 242 Batch 20 Loss 0.2355979084968567
[Train] epoch 242 Batch 21 Loss 0.1345408856868744
[Train] epoch 242 Batch 22 Loss 0.13499215245246887
[Train] epoch 242 Batch 23 Loss 0.4049583077430725
[Train] epoch 242 Batch 24 Loss 0.13731063902378082
[Train] epoch 242 Batch 25 Loss 0.20393311977386475
[Train] epoch 242 Batch 26 Loss 0.20369774103164673
[Train] epoch 242 Batch 27 Loss 0.0683213546872139
[Train] epoch 242 Batch 28 Loss 0.13836321234703064
[Train] epoch 242 Batch 29 Loss 0.10285347700119019
[Train] epoch 242 Batch 30 Loss 0.10193450003862381
[Train] epoch 242 Batch 31 Loss 0.06942465156316757
[Train] epoch 242 Batch 32 Loss 0.20393428206443787
[Train] epoch 242 Batch 33 Loss 0.2044016420841217
[Train] epoch 242 Batch 34 Loss 0.13584527373313904
[Train] epoch 242 Batch 35 Loss 0.13697689771652222
[Train] epoch 242 Batch 36 Loss 0.13583797216415405
[Train] epoch 242 Batch 37 Loss 0.10304770618677139
[Train] epoch 242 Batch 38 Loss 0.06912808120250702
[Train] epoch 242 Batch 39 Loss 0.06940138339996338
[Train] epoch 242 Batch 40 Loss 0.1374320089817047
[Train] epoch 242 Batch 41 Loss 0.3044656813144684
[Train] epoch 242 Batch 42 Loss 0.20552371442317963
[Train] epoch 242 Batch 43 Loss 0.10190311074256897
[Train] epoch 242 Batch 44 Loss 0.16996213793754578
[Train] epoch 242 Batch 45 Loss 0.1716219037771225
[Train] epoch 242 Batch 46 Loss 0.2016395926475525
[Train] epoch 242 Batch 47 Loss 0.10245713591575623
[Train] epoch 243 Batch 0 Loss 0.13582828640937805
[Train] epoch 243 Batch 1 Loss 0.13443833589553833
[Train] epoch 243 Batch 2 Loss 0.036287467926740646
[Train] epoch 243 Batch 3 Loss 0.33965134620666504
[Train] epoch 243 Batch 4 Loss 0.20379537343978882
[Train] epoch 243 Batch 5 Loss 0.1392812430858612
[Train] epoch 243 Batch 6 Loss 0.13471311330795288
[Train] epoch 243 Batch 7 Loss 0.1731698215007782
[Train] epoch 243 Batch 8 Loss 0.2726348638534546
[Train] epoch 243 Batch 9 Loss 0.13705699145793915
[Train] epoch 243 Batch 10 Loss 0.16877025365829468
[Train] epoch 243 Batch 11 Loss 0.13754358887672424
[Train] epoch 243 Batch 12 Loss 0.06811662763357162
[Train] epoch 243 Batch 13 Loss 0.2029908150434494
[Train] epoch 243 Batch 14 Loss 0.1022852286696434
[Train] epoch 243 Batch 15 Loss 0.10080035030841827
[Train] epoch 243 Batch 16 Loss 0.14070412516593933
[Train] epoch 243 Batch 17 Loss 0.20312583446502686
[Train] epoch 243 Batch 18 Loss 0.20308077335357666
[Train] epoch 243 Batch 19 Loss 0.03721267357468605
[Train] epoch 243 Batch 20 Loss 0.10079821944236755
[Train] epoch 243 Batch 21 Loss 0.16743871569633484
[Train] epoch 243 Batch 22 Loss 0.23728220164775848
[Train] epoch 243 Batch 23 Loss 0.10244773328304291
[Train] epoch 243 Batch 24 Loss 0.20666144788265228
[Train] epoch 243 Batch 25 Loss 0.33986684679985046
[Train] epoch 243 Batch 26 Loss 0.1365286409854889
[Train] epoch 243 Batch 27 Loss 0.3398374915122986
[Train] epoch 243 Batch 28 Loss 0.20158907771110535
[Train] epoch 243 Batch 29 Loss 0.10410132259130478
[Train] epoch 243 Batch 30 Loss 0.1707550585269928
[Train] epoch 243 Batch 31 Loss 0.20160816609859467
[Train] epoch 243 Batch 32 Loss 0.13826271891593933
[Train] epoch 243 Batch 33 Loss 0.3723309636116028
[Train] epoch 243 Batch 34 Loss 0.3057459592819214
[Train] epoch 243 Batch 35 Loss 0.23752623796463013
[Train] epoch 243 Batch 36 Loss 0.17238105833530426
[Train] epoch 243 Batch 37 Loss 0.17233958840370178
[Train] epoch 243 Batch 38 Loss 0.17086686193943024
[Train] epoch 243 Batch 39 Loss 0.1399564892053604
[Train] epoch 243 Batch 40 Loss 0.13510850071907043
[Train] epoch 243 Batch 41 Loss 0.204787015914917
[Train] epoch 243 Batch 42 Loss 0.1367664337158203
[Train] epoch 243 Batch 43 Loss 0.2000008225440979
[Train] epoch 243 Batch 44 Loss 0.13492226600646973
[Train] epoch 243 Batch 45 Loss 0.1365133374929428
[Train] epoch 243 Batch 46 Loss 0.30260753631591797
[Train] epoch 243 Batch 47 Loss 0.13989146053791046
[Train] epoch 244 Batch 0 Loss 0.17068606615066528
[Train] epoch 244 Batch 1 Loss 0.04048606753349304
[Train] epoch 244 Batch 2 Loss 0.06831121444702148
[Train] epoch 244 Batch 3 Loss 0.3364933133125305
[Train] epoch 244 Batch 4 Loss 0.2356908917427063
[Train] epoch 244 Batch 5 Loss 0.3381108045578003
[Train] epoch 244 Batch 6 Loss 0.30246981978416443
[Train] epoch 244 Batch 7 Loss 0.10239654779434204
[Train] epoch 244 Batch 8 Loss 0.201603502035141
[Train] epoch 244 Batch 9 Loss 0.10558243095874786
[Train] epoch 244 Batch 10 Loss 0.27297860383987427
[Train] epoch 244 Batch 11 Loss 0.2356712818145752
[Train] epoch 244 Batch 12 Loss 0.17064063251018524
[Train] epoch 244 Batch 13 Loss 0.33490943908691406
[Train] epoch 244 Batch 14 Loss 0.14257095754146576
[Train] epoch 244 Batch 15 Loss 0.30541765689849854
[Train] epoch 244 Batch 16 Loss 0.002995892893522978
[Train] epoch 244 Batch 17 Loss 0.13482517004013062
[Train] epoch 244 Batch 18 Loss 0.17204385995864868
[Train] epoch 244 Batch 19 Loss 0.23412075638771057
[Train] epoch 244 Batch 20 Loss 0.20306530594825745
[Train] epoch 244 Batch 21 Loss 0.17354126274585724
[Train] epoch 244 Batch 22 Loss 0.06813360005617142
[Train] epoch 244 Batch 23 Loss 0.10381747782230377
[Train] epoch 244 Batch 24 Loss 0.3023541569709778
[Train] epoch 244 Batch 25 Loss 0.13490507006645203
[Train] epoch 244 Batch 26 Loss 0.13478070497512817
[Train] epoch 244 Batch 27 Loss 0.13933968544006348
[Train] epoch 244 Batch 28 Loss 0.10222438722848892
[Train] epoch 244 Batch 29 Loss 0.06815479695796967
[Train] epoch 244 Batch 30 Loss 0.10523129999637604
[Train] epoch 244 Batch 31 Loss 0.1703041046857834
[Train] epoch 244 Batch 32 Loss 0.17039506137371063
[Train] epoch 244 Batch 33 Loss 0.23852044343948364
[Train] epoch 244 Batch 34 Loss 0.10373763740062714
[Train] epoch 244 Batch 35 Loss 0.2031351625919342
[Train] epoch 244 Batch 36 Loss 0.2058776319026947
[Train] epoch 244 Batch 37 Loss 0.07099934667348862
[Train] epoch 244 Batch 38 Loss 0.23568227887153625
[Train] epoch 244 Batch 39 Loss 0.27106282114982605
[Train] epoch 244 Batch 40 Loss 0.2043868601322174
[Train] epoch 244 Batch 41 Loss 0.20442360639572144
[Train] epoch 244 Batch 42 Loss 0.1702520251274109
[Train] epoch 244 Batch 43 Loss 0.3022960424423218
[Train] epoch 244 Batch 44 Loss 0.13480016589164734
[Train] epoch 244 Batch 45 Loss 0.10506998002529144
[Train] epoch 244 Batch 46 Loss 0.10499456524848938
[Train] epoch 244 Batch 47 Loss 0.13619649410247803
[Train] epoch 245 Batch 0 Loss 0.1701565384864807
[Train] epoch 245 Batch 1 Loss 0.2043030709028244
[Train] epoch 245 Batch 2 Loss 0.1377122849225998
[Train] epoch 245 Batch 3 Loss 0.23984688520431519
[Train] epoch 245 Batch 4 Loss 0.13482335209846497
[Train] epoch 245 Batch 5 Loss 0.1347799152135849
[Train] epoch 245 Batch 6 Loss 0.1348908543586731
[Train] epoch 245 Batch 7 Loss 0.20409990847110748
[Train] epoch 245 Batch 8 Loss 0.23691442608833313
[Train] epoch 245 Batch 9 Loss 0.2681049704551697
[Train] epoch 245 Batch 10 Loss 0.06802242994308472
[Train] epoch 245 Batch 11 Loss 0.3360753059387207
[Train] epoch 245 Batch 12 Loss 0.1689140796661377
[Train] epoch 245 Batch 13 Loss 0.23676294088363647
[Train] epoch 245 Batch 14 Loss 0.1375325322151184
[Train] epoch 245 Batch 15 Loss 0.2041914463043213
[Train] epoch 245 Batch 16 Loss 0.3020743727684021
[Train] epoch 245 Batch 17 Loss 0.06954838335514069
[Train] epoch 245 Batch 18 Loss 0.10210352391004562
[Train] epoch 245 Batch 19 Loss 0.16876664757728577
[Train] epoch 245 Batch 20 Loss 0.1729203760623932
[Train] epoch 245 Batch 21 Loss 0.16872432827949524
[Train] epoch 245 Batch 22 Loss 0.13619741797447205
[Train] epoch 245 Batch 23 Loss 0.13736680150032043
[Train] epoch 245 Batch 24 Loss 0.20426689088344574
[Train] epoch 245 Batch 25 Loss 0.23537811636924744
[Train] epoch 245 Batch 26 Loss 0.2040107399225235
[Train] epoch 245 Batch 27 Loss 0.2040765881538391
[Train] epoch 245 Batch 28 Loss 0.10192660987377167
[Train] epoch 245 Batch 29 Loss 0.23554077744483948
[Train] epoch 245 Batch 30 Loss 0.17152929306030273
[Train] epoch 245 Batch 31 Loss 0.2370486855506897
[Train] epoch 245 Batch 32 Loss 0.27324363589286804
[Train] epoch 245 Batch 33 Loss 0.1374334692955017
[Train] epoch 245 Batch 34 Loss 0.13849161565303802
[Train] epoch 245 Batch 35 Loss 0.20423421263694763
[Train] epoch 245 Batch 36 Loss 0.10333685576915741
[Train] epoch 245 Batch 37 Loss 0.1032998114824295
[Train] epoch 245 Batch 38 Loss 0.13739363849163055
[Train] epoch 245 Batch 39 Loss 0.06927911937236786
[Train] epoch 245 Batch 40 Loss 0.1714523434638977
[Train] epoch 245 Batch 41 Loss 0.13702699542045593
[Train] epoch 245 Batch 42 Loss 0.10336501896381378
[Train] epoch 245 Batch 43 Loss 0.2711147367954254
[Train] epoch 245 Batch 44 Loss 0.1687026023864746
[Train] epoch 245 Batch 45 Loss 0.23396611213684082
[Train] epoch 245 Batch 46 Loss 0.16847699880599976
[Train] epoch 245 Batch 47 Loss 0.17017143964767456
[Train] epoch 246 Batch 0 Loss 0.1019684299826622
[Train] epoch 246 Batch 1 Loss 0.2054869532585144
[Train] epoch 246 Batch 2 Loss 0.07042412459850311
[Train] epoch 246 Batch 3 Loss 0.20655307173728943
[Train] epoch 246 Batch 4 Loss 0.3374674320220947
[Train] epoch 246 Batch 5 Loss 0.20652970671653748
[Train] epoch 246 Batch 6 Loss 0.10214737057685852
[Train] epoch 246 Batch 7 Loss 0.20271021127700806
[Train] epoch 246 Batch 8 Loss 0.1034693717956543
[Train] epoch 246 Batch 9 Loss 0.23662501573562622
[Train] epoch 246 Batch 10 Loss 0.20389866828918457
[Train] epoch 246 Batch 11 Loss 0.37030017375946045
[Train] epoch 246 Batch 12 Loss 0.23681238293647766
[Train] epoch 246 Batch 13 Loss 0.20121780037879944
[Train] epoch 246 Batch 14 Loss 0.20286403596401215
[Train] epoch 246 Batch 15 Loss 0.03409397602081299
[Train] epoch 246 Batch 16 Loss 0.13719987869262695
[Train] epoch 246 Batch 17 Loss 0.10212218761444092
[Train] epoch 246 Batch 18 Loss 0.30309849977493286
[Train] epoch 246 Batch 19 Loss 0.07254413515329361
[Train] epoch 246 Batch 20 Loss 0.03524572402238846
[Train] epoch 246 Batch 21 Loss 0.20373141765594482
[Train] epoch 246 Batch 22 Loss 0.10307967662811279
[Train] epoch 246 Batch 23 Loss 0.13484668731689453
[Train] epoch 246 Batch 24 Loss 0.23658597469329834
[Train] epoch 246 Batch 25 Loss 0.23543868958950043
[Train] epoch 246 Batch 26 Loss 0.20265153050422668
[Train] epoch 246 Batch 27 Loss 0.1687690168619156
[Train] epoch 246 Batch 28 Loss 0.0693349838256836
[Train] epoch 246 Batch 29 Loss 0.1674216389656067
[Train] epoch 246 Batch 30 Loss 0.30302193760871887
[Train] epoch 246 Batch 31 Loss 0.10301743447780609
[Train] epoch 246 Batch 32 Loss 0.0034137461334466934
[Train] epoch 246 Batch 33 Loss 0.1712031066417694
[Train] epoch 246 Batch 34 Loss 0.1689247488975525
[Train] epoch 246 Batch 35 Loss 0.20360428094863892
[Train] epoch 246 Batch 36 Loss 0.30191704630851746
[Train] epoch 246 Batch 37 Loss 0.06931187957525253
[Train] epoch 246 Batch 38 Loss 0.338083416223526
[Train] epoch 246 Batch 39 Loss 0.07157979160547256
[Train] epoch 246 Batch 40 Loss 0.23519885540008545
[Train] epoch 246 Batch 41 Loss 0.0352168083190918
[Train] epoch 246 Batch 42 Loss 0.1683313548564911
[Train] epoch 246 Batch 43 Loss 0.2710975706577301
[Train] epoch 246 Batch 44 Loss 0.16836369037628174
[Train] epoch 246 Batch 45 Loss 0.17076526582241058
[Train] epoch 246 Batch 46 Loss 0.23520329594612122
[Train] epoch 246 Batch 47 Loss 0.23518094420433044
[Train] epoch 247 Batch 0 Loss 0.10405731946229935
[Train] epoch 247 Batch 1 Loss 0.13687342405319214
[Train] epoch 247 Batch 2 Loss 0.0022013455163687468
[Train] epoch 247 Batch 3 Loss 0.2014978528022766
[Train] epoch 247 Batch 4 Loss 0.36852025985717773
[Train] epoch 247 Batch 5 Loss 0.16978976130485535
[Train] epoch 247 Batch 6 Loss 0.3031386137008667
[Train] epoch 247 Batch 7 Loss 0.20520704984664917
[Train] epoch 247 Batch 8 Loss 0.30224353075027466
[Train] epoch 247 Batch 9 Loss 0.13661761581897736
[Train] epoch 247 Batch 10 Loss 0.2701534330844879
[Train] epoch 247 Batch 11 Loss 0.27011144161224365
[Train] epoch 247 Batch 12 Loss 0.03836003690958023
[Train] epoch 247 Batch 13 Loss 0.06880360841751099
[Train] epoch 247 Batch 14 Loss 0.2377202808856964
[Train] epoch 247 Batch 15 Loss 0.2362389862537384
[Train] epoch 247 Batch 16 Loss 0.13678140938282013
[Train] epoch 247 Batch 17 Loss 0.20127546787261963
[Train] epoch 247 Batch 18 Loss 0.13695356249809265
[Train] epoch 247 Batch 19 Loss 0.067939393222332
[Train] epoch 247 Batch 20 Loss 0.16720977425575256
[Train] epoch 247 Batch 21 Loss 0.3360927700996399
[Train] epoch 247 Batch 22 Loss 0.1712488830089569
[Train] epoch 247 Batch 23 Loss 0.27237069606781006
[Train] epoch 247 Batch 24 Loss 0.06899394094944
[Train] epoch 247 Batch 25 Loss 0.06921278685331345
[Train] epoch 247 Batch 26 Loss 0.2000008225440979
[Train] epoch 247 Batch 27 Loss 0.10200603306293488
[Train] epoch 247 Batch 28 Loss 0.1007433533668518
[Train] epoch 247 Batch 29 Loss 0.1688937544822693
[Train] epoch 247 Batch 30 Loss 0.133334219455719
[Train] epoch 247 Batch 31 Loss 0.2693084478378296
[Train] epoch 247 Batch 32 Loss 0.10296130925416946
[Train] epoch 247 Batch 33 Loss 0.10447224229574203
[Train] epoch 247 Batch 34 Loss 0.3353499174118042
[Train] epoch 247 Batch 35 Loss 0.21049436926841736
[Train] epoch 247 Batch 36 Loss 0.16925325989723206
[Train] epoch 247 Batch 37 Loss 0.06666764616966248
[Train] epoch 247 Batch 38 Loss 0.1701325923204422
[Train] epoch 247 Batch 39 Loss 0.10347640514373779
[Train] epoch 247 Batch 40 Loss 0.07085046172142029
[Train] epoch 247 Batch 41 Loss 0.13767239451408386
[Train] epoch 247 Batch 42 Loss 0.30664587020874023
[Train] epoch 247 Batch 43 Loss 0.20446816086769104
[Train] epoch 247 Batch 44 Loss 0.2711414098739624
[Train] epoch 247 Batch 45 Loss 0.17187829315662384
[Train] epoch 247 Batch 46 Loss 0.3022875487804413
[Train] epoch 247 Batch 47 Loss 0.07407141476869583
[Train] epoch 248 Batch 0 Loss 0.20301218330860138
[Train] epoch 248 Batch 1 Loss 0.23866909742355347
[Train] epoch 248 Batch 2 Loss 0.10225532948970795
[Train] epoch 248 Batch 3 Loss 0.2386569082736969
[Train] epoch 248 Batch 4 Loss 0.13637422025203705
[Train] epoch 248 Batch 5 Loss 0.20757992565631866
[Train] epoch 248 Batch 6 Loss 0.20307111740112305
[Train] epoch 248 Batch 7 Loss 0.1364094316959381
[Train] epoch 248 Batch 8 Loss 0.10382513701915741
[Train] epoch 248 Batch 9 Loss 0.10379227250814438
[Train] epoch 248 Batch 10 Loss 0.23563280701637268
[Train] epoch 248 Batch 11 Loss 0.16896504163742065
[Train] epoch 248 Batch 12 Loss 0.13789549469947815
[Train] epoch 248 Batch 13 Loss 0.23874083161354065
[Train] epoch 248 Batch 14 Loss 0.272705078125
[Train] epoch 248 Batch 15 Loss 0.23559296131134033
[Train] epoch 248 Batch 16 Loss 0.1023349016904831
[Train] epoch 248 Batch 17 Loss 0.07265263795852661
[Train] epoch 248 Batch 18 Loss 0.10374967753887177
[Train] epoch 248 Batch 19 Loss 0.26973456144332886
[Train] epoch 248 Batch 20 Loss 0.20305311679840088
[Train] epoch 248 Batch 21 Loss 0.33689969778060913
[Train] epoch 248 Batch 22 Loss 0.10228186845779419
[Train] epoch 248 Batch 23 Loss 0.30381035804748535
[Train] epoch 248 Batch 24 Loss 0.10532569885253906
[Train] epoch 248 Batch 25 Loss 0.035613398998975754
[Train] epoch 248 Batch 26 Loss 0.27274784445762634
[Train] epoch 248 Batch 27 Loss 0.2697063684463501
[Train] epoch 248 Batch 28 Loss 0.20151987671852112
[Train] epoch 248 Batch 29 Loss 0.13637033104896545
[Train] epoch 248 Batch 30 Loss 0.1067962497472763
[Train] epoch 248 Batch 31 Loss 0.1689147651195526
[Train] epoch 248 Batch 32 Loss 0.136337548494339
[Train] epoch 248 Batch 33 Loss 0.1022491306066513
[Train] epoch 248 Batch 34 Loss 0.2386137843132019
[Train] epoch 248 Batch 35 Loss 0.07263711839914322
[Train] epoch 248 Batch 36 Loss 0.1363283395767212
[Train] epoch 248 Batch 37 Loss 0.17333200573921204
[Train] epoch 248 Batch 38 Loss 0.26963865756988525
[Train] epoch 248 Batch 39 Loss 0.40448129177093506
[Train] epoch 248 Batch 40 Loss 0.10228747874498367
[Train] epoch 248 Batch 41 Loss 0.034049563109874725
[Train] epoch 248 Batch 42 Loss 0.13782478868961334
[Train] epoch 248 Batch 43 Loss 0.20147305727005005
[Train] epoch 248 Batch 44 Loss 0.26810261607170105
[Train] epoch 248 Batch 45 Loss 0.2384263575077057
[Train] epoch 248 Batch 46 Loss 0.13626500964164734
[Train] epoch 248 Batch 47 Loss 0.06807240098714828
[Train] epoch 249 Batch 0 Loss 0.2384331226348877
[Train] epoch 249 Batch 1 Loss 0.20143617689609528
[Train] epoch 249 Batch 2 Loss 0.20295225083827972
[Train] epoch 249 Batch 3 Loss 0.1703086942434311
[Train] epoch 249 Batch 4 Loss 0.2680920362472534
[Train] epoch 249 Batch 5 Loss 0.13625332713127136
[Train] epoch 249 Batch 6 Loss 0.17022038996219635
[Train] epoch 249 Batch 7 Loss 0.13771137595176697
[Train] epoch 249 Batch 8 Loss 0.10211657732725143
[Train] epoch 249 Batch 9 Loss 0.1020689457654953
[Train] epoch 249 Batch 10 Loss 0.13765732944011688
[Train] epoch 249 Batch 11 Loss 0.23549164831638336
[Train] epoch 249 Batch 12 Loss 0.2382965385913849
[Train] epoch 249 Batch 13 Loss 0.2368544489145279
[Train] epoch 249 Batch 14 Loss 0.1062254011631012
[Train] epoch 249 Batch 15 Loss 0.10348202288150787
[Train] epoch 249 Batch 16 Loss 0.03409162908792496
[Train] epoch 249 Batch 17 Loss 0.27081719040870667
[Train] epoch 249 Batch 18 Loss 0.2709718346595764
[Train] epoch 249 Batch 19 Loss 0.0707419365644455
[Train] epoch 249 Batch 20 Loss 0.1373738944530487
[Train] epoch 249 Batch 21 Loss 0.2371181845664978
[Train] epoch 249 Batch 22 Loss 0.3064451813697815
[Train] epoch 249 Batch 23 Loss 0.1729361116886139
[Train] epoch 249 Batch 24 Loss 0.10075697302818298
[Train] epoch 249 Batch 25 Loss 0.26960325241088867
[Train] epoch 249 Batch 26 Loss 0.10338492691516876
[Train] epoch 249 Batch 27 Loss 0.1373760998249054
[Train] epoch 249 Batch 28 Loss 0.269503653049469
[Train] epoch 249 Batch 29 Loss 0.1701006293296814
[Train] epoch 249 Batch 30 Loss 0.06938160955905914
[Train] epoch 249 Batch 31 Loss 0.1701495200395584
[Train] epoch 249 Batch 32 Loss 0.13601592183113098
[Train] epoch 249 Batch 33 Loss 0.27220040559768677
[Train] epoch 249 Batch 34 Loss 0.10320408642292023
[Train] epoch 249 Batch 35 Loss 0.10343889892101288
[Train] epoch 249 Batch 36 Loss 0.30225643515586853
[Train] epoch 249 Batch 37 Loss 0.13724178075790405
[Train] epoch 249 Batch 38 Loss 0.10204429924488068
[Train] epoch 249 Batch 39 Loss 0.2708326578140259
[Train] epoch 249 Batch 40 Loss 0.1359926462173462
[Train] epoch 249 Batch 41 Loss 0.10340467840433121
[Train] epoch 249 Batch 42 Loss 0.2680569887161255
[Train] epoch 249 Batch 43 Loss 0.1686726212501526
[Train] epoch 249 Batch 44 Loss 0.23810932040214539
[Train] epoch 249 Batch 45 Loss 0.2354673445224762
[Train] epoch 249 Batch 46 Loss 0.10211068391799927
[Train] epoch 249 Batch 47 Loss 0.20398661494255066
[Train] epoch 250 Batch 0 Loss 0.1363249272108078
[Train] epoch 250 Batch 1 Loss 0.40533190965652466
[Train] epoch 250 Batch 2 Loss 0.23529662191867828
[Train] epoch 250 Batch 3 Loss 0.1358257532119751
[Train] epoch 250 Batch 4 Loss 0.13582059741020203
[Train] epoch 250 Batch 5 Loss 0.13607671856880188
[Train] epoch 250 Batch 6 Loss 0.139875128865242
[Train] epoch 250 Batch 7 Loss 0.10458390414714813
[Train] epoch 250 Batch 8 Loss 0.20148965716362
[Train] epoch 250 Batch 9 Loss 0.16876456141471863
[Train] epoch 250 Batch 10 Loss 0.16865047812461853
[Train] epoch 250 Batch 11 Loss 0.1687598079442978
[Train] epoch 250 Batch 12 Loss 0.16886895895004272
[Train] epoch 250 Batch 13 Loss 0.2053368091583252
[Train] epoch 250 Batch 14 Loss 0.2365582287311554
[Train] epoch 250 Batch 15 Loss 0.23806218802928925
[Train] epoch 250 Batch 16 Loss 0.20256073772907257
[Train] epoch 250 Batch 17 Loss 0.10197074711322784
[Train] epoch 250 Batch 18 Loss 0.10325729846954346
[Train] epoch 250 Batch 19 Loss 0.23678407073020935
[Train] epoch 250 Batch 20 Loss 0.5035001039505005
[Train] epoch 250 Batch 21 Loss 0.203919917345047
[Train] epoch 250 Batch 22 Loss 0.1699821650981903
[Train] epoch 250 Batch 23 Loss 0.33742383122444153
[Train] epoch 250 Batch 24 Loss 0.20517316460609436
[Train] epoch 250 Batch 25 Loss 0.1724170744419098
[Train] epoch 250 Batch 26 Loss 0.26919981837272644
[Train] epoch 250 Batch 27 Loss 0.06789714097976685
[Train] epoch 250 Batch 28 Loss 0.23902219533920288
[Train] epoch 250 Batch 29 Loss 0.20141902565956116
[Train] epoch 250 Batch 30 Loss 0.2366282045841217
[Train] epoch 250 Batch 31 Loss 0.16990961134433746
[Train] epoch 250 Batch 32 Loss 0.10199674218893051
[Train] epoch 250 Batch 33 Loss 0.03661299869418144
[Train] epoch 250 Batch 34 Loss 0.10450989007949829
[Train] epoch 250 Batch 35 Loss 0.033937033265829086
[Train] epoch 250 Batch 36 Loss 0.03404033184051514
[Train] epoch 250 Batch 37 Loss 0.035316016525030136
[Train] epoch 250 Batch 38 Loss 0.17223504185676575
[Train] epoch 250 Batch 39 Loss 0.13463595509529114
[Train] epoch 250 Batch 40 Loss 0.23668347299098969
[Train] epoch 250 Batch 41 Loss 0.20256347954273224
[Train] epoch 250 Batch 42 Loss 0.0704880952835083
[Train] epoch 250 Batch 43 Loss 0.0693340003490448
[Train] epoch 250 Batch 44 Loss 0.23544526100158691
[Train] epoch 250 Batch 45 Loss 0.3032877743244171
[Train] epoch 250 Batch 46 Loss 0.10332050919532776
[Train] epoch 250 Batch 47 Loss 0.17115390300750732
[Train] epoch 251 Batch 0 Loss 0.26935914158821106
[Train] epoch 251 Batch 1 Loss 0.2013615518808365
[Train] epoch 251 Batch 2 Loss 0.30070239305496216
[Train] epoch 251 Batch 3 Loss 0.06899262219667435
[Train] epoch 251 Batch 4 Loss 0.3358500003814697
[Train] epoch 251 Batch 5 Loss 0.10316595435142517
[Train] epoch 251 Batch 6 Loss 0.3711796700954437
[Train] epoch 251 Batch 7 Loss 0.10185392200946808
[Train] epoch 251 Batch 8 Loss 0.10415259003639221
[Train] epoch 251 Batch 9 Loss 0.20621256530284882
[Train] epoch 251 Batch 10 Loss 0.0679398626089096
[Train] epoch 251 Batch 11 Loss 0.13729026913642883
[Train] epoch 251 Batch 12 Loss 0.13588495552539825
[Train] epoch 251 Batch 13 Loss 0.20500892400741577
[Train] epoch 251 Batch 14 Loss 0.16990604996681213
[Train] epoch 251 Batch 15 Loss 0.16856738924980164
[Train] epoch 251 Batch 16 Loss 0.3370564579963684
[Train] epoch 251 Batch 17 Loss 0.10301858186721802
[Train] epoch 251 Batch 18 Loss 0.23542702198028564
[Train] epoch 251 Batch 19 Loss 0.10188627243041992
[Train] epoch 251 Batch 20 Loss 0.1066288873553276
[Train] epoch 251 Batch 21 Loss 0.2377222776412964
[Train] epoch 251 Batch 22 Loss 0.10326898097991943
[Train] epoch 251 Batch 23 Loss 0.03403054177761078
[Train] epoch 251 Batch 24 Loss 0.06798295676708221
[Train] epoch 251 Batch 25 Loss 0.1371435821056366
[Train] epoch 251 Batch 26 Loss 0.13582667708396912
[Train] epoch 251 Batch 27 Loss 0.10289657115936279
[Train] epoch 251 Batch 28 Loss 0.2715599536895752
[Train] epoch 251 Batch 29 Loss 0.1347225457429886
[Train] epoch 251 Batch 30 Loss 0.16982391476631165
[Train] epoch 251 Batch 31 Loss 0.23887884616851807
[Train] epoch 251 Batch 32 Loss 0.2034793645143509
[Train] epoch 251 Batch 33 Loss 0.20242533087730408
[Train] epoch 251 Batch 34 Loss 0.2702217102050781
[Train] epoch 251 Batch 35 Loss 0.20360985398292542
[Train] epoch 251 Batch 36 Loss 0.16735941171646118
[Train] epoch 251 Batch 37 Loss 0.20113912224769592
[Train] epoch 251 Batch 38 Loss 0.10207495838403702
[Train] epoch 251 Batch 39 Loss 0.16977858543395996
[Train] epoch 251 Batch 40 Loss 0.10160739719867706
[Train] epoch 251 Batch 41 Loss 0.2350928634405136
[Train] epoch 251 Batch 42 Loss 0.2362755686044693
[Train] epoch 251 Batch 43 Loss 0.1684819459915161
[Train] epoch 251 Batch 44 Loss 0.3040369153022766
[Train] epoch 251 Batch 45 Loss 0.10164985060691833
[Train] epoch 251 Batch 46 Loss 0.13800394535064697
[Train] epoch 251 Batch 47 Loss 0.17196232080459595
[Train] epoch 252 Batch 0 Loss 0.2704293131828308
[Train] epoch 252 Batch 1 Loss 0.16978438198566437
[Train] epoch 252 Batch 2 Loss 0.16951146721839905
[Train] epoch 252 Batch 3 Loss 0.30173665285110474
[Train] epoch 252 Batch 4 Loss 0.20137609541416168
[Train] epoch 252 Batch 5 Loss 0.10381854325532913
[Train] epoch 252 Batch 6 Loss 0.033910155296325684
[Train] epoch 252 Batch 7 Loss 0.16965436935424805
[Train] epoch 252 Batch 8 Loss 0.3029836118221283
[Train] epoch 252 Batch 9 Loss 0.10367916524410248
[Train] epoch 252 Batch 10 Loss 0.2677554488182068
[Train] epoch 252 Batch 11 Loss 0.20137271285057068
[Train] epoch 252 Batch 12 Loss 0.20137226581573486
[Train] epoch 252 Batch 13 Loss 0.20558804273605347
[Train] epoch 252 Batch 14 Loss 0.0700213611125946
[Train] epoch 252 Batch 15 Loss 0.13685721158981323
[Train] epoch 252 Batch 16 Loss 0.23646163940429688
[Train] epoch 252 Batch 17 Loss 0.13481339812278748
[Train] epoch 252 Batch 18 Loss 0.20582976937294006
[Train] epoch 252 Batch 19 Loss 0.20468997955322266
[Train] epoch 252 Batch 20 Loss 0.13565203547477722
[Train] epoch 252 Batch 21 Loss 0.06666764616966248
[Train] epoch 252 Batch 22 Loss 0.30187463760375977
[Train] epoch 252 Batch 23 Loss 0.3383364677429199
[Train] epoch 252 Batch 24 Loss 0.10430784523487091
[Train] epoch 252 Batch 25 Loss 0.23535051941871643
[Train] epoch 252 Batch 26 Loss 0.13601869344711304
[Train] epoch 252 Batch 27 Loss 0.06666764616966248
[Train] epoch 252 Batch 28 Loss 0.13838234543800354
[Train] epoch 252 Batch 29 Loss 0.13846583664417267
[Train] epoch 252 Batch 30 Loss 0.13469289243221283
[Train] epoch 252 Batch 31 Loss 0.4053422212600708
[Train] epoch 252 Batch 32 Loss 0.20268341898918152
[Train] epoch 252 Batch 33 Loss 0.13462170958518982
[Train] epoch 252 Batch 34 Loss 0.16994914412498474
[Train] epoch 252 Batch 35 Loss 0.17128199338912964
[Train] epoch 252 Batch 36 Loss 0.23529565334320068
[Train] epoch 252 Batch 37 Loss 0.13862554728984833
[Train] epoch 252 Batch 38 Loss 0.23789715766906738
[Train] epoch 252 Batch 39 Loss 0.1699126958847046
[Train] epoch 252 Batch 40 Loss 0.20258325338363647
[Train] epoch 252 Batch 41 Loss 0.10200086236000061
[Train] epoch 252 Batch 42 Loss 0.10454873740673065
[Train] epoch 252 Batch 43 Loss 0.10207830369472504
[Train] epoch 252 Batch 44 Loss 0.10062931478023529
[Train] epoch 252 Batch 45 Loss 0.17246206104755402
[Train] epoch 252 Batch 46 Loss 0.20392045378684998
[Train] epoch 252 Batch 47 Loss 0.10191278159618378
[Train] epoch 253 Batch 0 Loss 0.1371963620185852
[Train] epoch 253 Batch 1 Loss 0.36986345052719116
[Train] epoch 253 Batch 2 Loss 0.171134352684021
[Train] epoch 253 Batch 3 Loss 0.20519721508026123
[Train] epoch 253 Batch 4 Loss 0.0037932018749415874
[Train] epoch 253 Batch 5 Loss 0.17002980411052704
[Train] epoch 253 Batch 6 Loss 0.16867545247077942
[Train] epoch 253 Batch 7 Loss 0.2353089153766632
[Train] epoch 253 Batch 8 Loss 0.13587623834609985
[Train] epoch 253 Batch 9 Loss 0.10065874457359314
[Train] epoch 253 Batch 10 Loss 0.4352594017982483
[Train] epoch 253 Batch 11 Loss 0.2025589942932129
[Train] epoch 253 Batch 12 Loss 0.17109528183937073
[Train] epoch 253 Batch 13 Loss 0.10449370741844177
[Train] epoch 253 Batch 14 Loss 0.07040294259786606
[Train] epoch 253 Batch 15 Loss 0.30193671584129333
[Train] epoch 253 Batch 16 Loss 0.20388323068618774
[Train] epoch 253 Batch 17 Loss 0.1019296795129776
[Train] epoch 253 Batch 18 Loss 0.23658505082130432
[Train] epoch 253 Batch 19 Loss 0.20264770090579987
[Train] epoch 253 Batch 20 Loss 0.2353108823299408
[Train] epoch 253 Batch 21 Loss 0.10436645150184631
[Train] epoch 253 Batch 22 Loss 0.2679775357246399
[Train] epoch 253 Batch 23 Loss 0.13701540231704712
[Train] epoch 253 Batch 24 Loss 0.23392575979232788
[Train] epoch 253 Batch 25 Loss 0.20373517274856567
[Train] epoch 253 Batch 26 Loss 0.27288615703582764
[Train] epoch 253 Batch 27 Loss 0.3032708466053009
[Train] epoch 253 Batch 28 Loss 0.10306477546691895
[Train] epoch 253 Batch 29 Loss 0.13704133033752441
[Train] epoch 253 Batch 30 Loss 0.27401238679885864
[Train] epoch 253 Batch 31 Loss 0.10065392404794693
[Train] epoch 253 Batch 32 Loss 0.07150928676128387
[Train] epoch 253 Batch 33 Loss 0.30194711685180664
[Train] epoch 253 Batch 34 Loss 0.13463878631591797
[Train] epoch 253 Batch 35 Loss 0.10185252130031586
[Train] epoch 253 Batch 36 Loss 0.1005755364894867
[Train] epoch 253 Batch 37 Loss 0.06666764616966248
[Train] epoch 253 Batch 38 Loss 0.2678910493850708
[Train] epoch 253 Batch 39 Loss 0.2025863081216812
[Train] epoch 253 Batch 40 Loss 0.10417279601097107
[Train] epoch 253 Batch 41 Loss 0.0035347265657037497
[Train] epoch 253 Batch 42 Loss 0.13568833470344543
[Train] epoch 253 Batch 43 Loss 0.10306034982204437
[Train] epoch 253 Batch 44 Loss 0.07023391872644424
[Train] epoch 253 Batch 45 Loss 0.16861891746520996
[Train] epoch 253 Batch 46 Loss 0.2704513669013977
[Train] epoch 253 Batch 47 Loss 0.2398582398891449
[Train] epoch 254 Batch 0 Loss 0.20474034547805786
[Train] epoch 254 Batch 1 Loss 0.07142963260412216
[Train] epoch 254 Batch 2 Loss 0.30194950103759766
[Train] epoch 254 Batch 3 Loss 0.16848286986351013
[Train] epoch 254 Batch 4 Loss 0.16981831192970276
[Train] epoch 254 Batch 5 Loss 0.16838014125823975
[Train] epoch 254 Batch 6 Loss 0.10180632025003433
[Train] epoch 254 Batch 7 Loss 0.13798630237579346
[Train] epoch 254 Batch 8 Loss 0.16731581091880798
[Train] epoch 254 Batch 9 Loss 0.17076042294502258
[Train] epoch 254 Batch 10 Loss 0.2700481414794922
[Train] epoch 254 Batch 11 Loss 0.16975319385528564
[Train] epoch 254 Batch 12 Loss 0.13690823316574097
[Train] epoch 254 Batch 13 Loss 0.3707267940044403
[Train] epoch 254 Batch 14 Loss 0.20475496351718903
[Train] epoch 254 Batch 15 Loss 0.16838881373405457
[Train] epoch 254 Batch 16 Loss 0.23527395725250244
[Train] epoch 254 Batch 17 Loss 0.13671860098838806
[Train] epoch 254 Batch 18 Loss 0.23724833130836487
[Train] epoch 254 Batch 19 Loss 0.30187687277793884
[Train] epoch 254 Batch 20 Loss 0.20224842429161072
[Train] epoch 254 Batch 21 Loss 0.20463448762893677
[Train] epoch 254 Batch 22 Loss 0.301871120929718
[Train] epoch 254 Batch 23 Loss 0.20235158503055573
[Train] epoch 254 Batch 24 Loss 0.20239657163619995
[Train] epoch 254 Batch 25 Loss 0.23641908168792725
[Train] epoch 254 Batch 26 Loss 0.10291819274425507
[Train] epoch 254 Batch 27 Loss 0.10169720649719238
[Train] epoch 254 Batch 28 Loss 0.23495632410049438
[Train] epoch 254 Batch 29 Loss 0.06904982030391693
[Train] epoch 254 Batch 30 Loss 0.10273760557174683
[Train] epoch 254 Batch 31 Loss 0.3027329742908478
[Train] epoch 254 Batch 32 Loss 0.07217016071081161
[Train] epoch 254 Batch 33 Loss 0.13575080037117004
[Train] epoch 254 Batch 34 Loss 0.10172677040100098
[Train] epoch 254 Batch 35 Loss 0.2691120207309723
[Train] epoch 254 Batch 36 Loss 0.3016415238380432
[Train] epoch 254 Batch 37 Loss 0.20331227779388428
[Train] epoch 254 Batch 38 Loss 0.07095950841903687
[Train] epoch 254 Batch 39 Loss 0.16850832104682922
[Train] epoch 254 Batch 40 Loss 0.1355140209197998
[Train] epoch 254 Batch 41 Loss 0.13563989102840424
[Train] epoch 254 Batch 42 Loss 0.16943922638893127
[Train] epoch 254 Batch 43 Loss 0.10174794495105743
[Train] epoch 254 Batch 44 Loss 0.10267738997936249
[Train] epoch 254 Batch 45 Loss 0.10174237936735153
[Train] epoch 254 Batch 46 Loss 0.06900456547737122
[Train] epoch 254 Batch 47 Loss 0.13685669004917145
[Train] epoch 255 Batch 0 Loss 0.10169300436973572
[Train] epoch 255 Batch 1 Loss 0.10155563056468964
[Train] epoch 255 Batch 2 Loss 0.17174234986305237
[Train] epoch 255 Batch 3 Loss 0.20328935980796814
[Train] epoch 255 Batch 4 Loss 0.16848811507225037
[Train] epoch 255 Batch 5 Loss 0.0710306465625763
[Train] epoch 255 Batch 6 Loss 0.2359139621257782
[Train] epoch 255 Batch 7 Loss 0.10365357249975204
[Train] epoch 255 Batch 8 Loss 0.2711098790168762
[Train] epoch 255 Batch 9 Loss 0.23510636389255524
[Train] epoch 255 Batch 10 Loss 0.06872832030057907
[Train] epoch 255 Batch 11 Loss 0.46999865770339966
[Train] epoch 255 Batch 12 Loss 0.06864134967327118
[Train] epoch 255 Batch 13 Loss 0.16949665546417236
[Train] epoch 255 Batch 14 Loss 0.1683255434036255
[Train] epoch 255 Batch 15 Loss 0.13889943063259125
[Train] epoch 255 Batch 16 Loss 0.23622241616249084
[Train] epoch 255 Batch 17 Loss 0.2021397352218628
[Train] epoch 255 Batch 18 Loss 0.20243394374847412
[Train] epoch 255 Batch 19 Loss 0.20325613021850586
[Train] epoch 255 Batch 20 Loss 0.13658484816551208
[Train] epoch 255 Batch 21 Loss 0.10190702974796295
[Train] epoch 255 Batch 22 Loss 0.1362743228673935
[Train] epoch 255 Batch 23 Loss 0.30275529623031616
[Train] epoch 255 Batch 24 Loss 0.23635438084602356
[Train] epoch 255 Batch 25 Loss 0.1375262439250946
[Train] epoch 255 Batch 26 Loss 0.10163138806819916
[Train] epoch 255 Batch 27 Loss 0.27064651250839233
[Train] epoch 255 Batch 28 Loss 0.2689266502857208
[Train] epoch 255 Batch 29 Loss 0.27003514766693115
[Train] epoch 255 Batch 30 Loss 0.10158755630254745
[Train] epoch 255 Batch 31 Loss 0.16927364468574524
[Train] epoch 255 Batch 32 Loss 0.10351826250553131
[Train] epoch 255 Batch 33 Loss 0.168247789144516
[Train] epoch 255 Batch 34 Loss 0.1006329208612442
[Train] epoch 255 Batch 35 Loss 0.23832614719867706
[Train] epoch 255 Batch 36 Loss 0.23506879806518555
[Train] epoch 255 Batch 37 Loss 0.23616929352283478
[Train] epoch 255 Batch 38 Loss 0.10241933166980743
[Train] epoch 255 Batch 39 Loss 0.035714082419872284
[Train] epoch 255 Batch 40 Loss 1.0728851975727594e-06
[Train] epoch 255 Batch 41 Loss 0.13446564972400665
[Train] epoch 255 Batch 42 Loss 0.06792788207530975
[Train] epoch 255 Batch 43 Loss 0.4033552408218384
[Train] epoch 255 Batch 44 Loss 0.1355251669883728
[Train] epoch 255 Batch 45 Loss 0.13542474806308746
[Train] epoch 255 Batch 46 Loss 0.3353569209575653
[Train] epoch 255 Batch 47 Loss 0.16825690865516663
[Train] epoch 256 Batch 0 Loss 0.06861744076013565
[Train] epoch 256 Batch 1 Loss 0.26779067516326904
[Train] epoch 256 Batch 2 Loss 0.20251436531543732
[Train] epoch 256 Batch 3 Loss 0.1362699568271637
[Train] epoch 256 Batch 4 Loss 0.20279833674430847
[Train] epoch 256 Batch 5 Loss 0.16821575164794922
[Train] epoch 256 Batch 6 Loss 0.13618609309196472
[Train] epoch 256 Batch 7 Loss 0.23477360606193542
[Train] epoch 256 Batch 8 Loss 0.1043558344244957
[Train] epoch 256 Batch 9 Loss 0.1344497799873352
[Train] epoch 256 Batch 10 Loss 0.10157161951065063
[Train] epoch 256 Batch 11 Loss 0.13752427697181702
[Train] epoch 256 Batch 12 Loss 0.2368929386138916
[Train] epoch 256 Batch 13 Loss 0.16911064088344574
[Train] epoch 256 Batch 14 Loss 0.06882745772600174
[Train] epoch 256 Batch 15 Loss 0.20233240723609924
[Train] epoch 256 Batch 16 Loss 0.13627931475639343
[Train] epoch 256 Batch 17 Loss 0.27303051948547363
[Train] epoch 256 Batch 18 Loss 0.20345446467399597
[Train] epoch 256 Batch 19 Loss 0.4018976092338562
[Train] epoch 256 Batch 20 Loss 0.1695682853460312
[Train] epoch 256 Batch 21 Loss 0.13645946979522705
[Train] epoch 256 Batch 22 Loss 0.1684434711933136
[Train] epoch 256 Batch 23 Loss 0.1377742737531662
[Train] epoch 256 Batch 24 Loss 0.002110371133312583
[Train] epoch 256 Batch 25 Loss 0.1378365010023117
[Train] epoch 256 Batch 26 Loss 0.1344347596168518
[Train] epoch 256 Batch 27 Loss 0.2035278081893921
[Train] epoch 256 Batch 28 Loss 0.2677885591983795
[Train] epoch 256 Batch 29 Loss 0.06897514313459396
[Train] epoch 256 Batch 30 Loss 0.27125537395477295
[Train] epoch 256 Batch 31 Loss 0.30419421195983887
[Train] epoch 256 Batch 32 Loss 0.135690838098526
[Train] epoch 256 Batch 33 Loss 0.06903965771198273
[Train] epoch 256 Batch 34 Loss 0.30297863483428955
[Train] epoch 256 Batch 35 Loss 0.2338915318250656
[Train] epoch 256 Batch 36 Loss 0.20349884033203125
[Train] epoch 256 Batch 37 Loss 0.23515519499778748
[Train] epoch 256 Batch 38 Loss 0.3028971254825592
[Train] epoch 256 Batch 39 Loss 0.20242485404014587
[Train] epoch 256 Batch 40 Loss 0.135765939950943
[Train] epoch 256 Batch 41 Loss 0.23506563901901245
[Train] epoch 256 Batch 42 Loss 0.10060569643974304
[Train] epoch 256 Batch 43 Loss 0.033938758075237274
[Train] epoch 256 Batch 44 Loss 0.3042129874229431
[Train] epoch 256 Batch 45 Loss 0.13564009964466095
[Train] epoch 256 Batch 46 Loss 0.10526324808597565
[Train] epoch 256 Batch 47 Loss 0.10177157819271088
[Train] epoch 257 Batch 0 Loss 0.10411998629570007
[Train] epoch 257 Batch 1 Loss 0.203499436378479
[Train] epoch 257 Batch 2 Loss 0.30302608013153076
[Train] epoch 257 Batch 3 Loss 0.23393622040748596
[Train] epoch 257 Batch 4 Loss 0.23623411357402802
[Train] epoch 257 Batch 5 Loss 0.23630663752555847
[Train] epoch 257 Batch 6 Loss 0.1706790328025818
[Train] epoch 257 Batch 7 Loss 0.06783120334148407
[Train] epoch 257 Batch 8 Loss 0.06666764616966248
[Train] epoch 257 Batch 9 Loss 0.17083236575126648
[Train] epoch 257 Batch 10 Loss 0.1356491595506668
[Train] epoch 257 Batch 11 Loss 0.2035142183303833
[Train] epoch 257 Batch 12 Loss 0.1345328688621521
[Train] epoch 257 Batch 13 Loss 0.10405542701482773
[Train] epoch 257 Batch 14 Loss 0.2361469268798828
[Train] epoch 257 Batch 15 Loss 0.06896189600229263
[Train] epoch 257 Batch 16 Loss 0.27236077189445496
[Train] epoch 257 Batch 17 Loss 0.03616708517074585
[Train] epoch 257 Batch 18 Loss 0.20570307970046997
[Train] epoch 257 Batch 19 Loss 0.16955924034118652
[Train] epoch 257 Batch 20 Loss 0.16839832067489624
[Train] epoch 257 Batch 21 Loss 0.17066590487957
[Train] epoch 257 Batch 22 Loss 0.10059978067874908
[Train] epoch 257 Batch 23 Loss 0.2361380159854889
[Train] epoch 257 Batch 24 Loss 0.1718016415834427
[Train] epoch 257 Batch 25 Loss 0.03714439645409584
[Train] epoch 257 Batch 26 Loss 0.1672045886516571
[Train] epoch 257 Batch 27 Loss 0.20224504172801971
[Train] epoch 257 Batch 28 Loss 0.33551013469696045
[Train] epoch 257 Batch 29 Loss 0.2011045217514038
[Train] epoch 257 Batch 30 Loss 0.13665717840194702
[Train] epoch 257 Batch 31 Loss 0.20448492467403412
[Train] epoch 257 Batch 32 Loss 0.27011704444885254
[Train] epoch 257 Batch 33 Loss 0.03393208235502243
[Train] epoch 257 Batch 34 Loss 0.13547839224338531
[Train] epoch 257 Batch 35 Loss 0.135617196559906
[Train] epoch 257 Batch 36 Loss 0.20119543373584747
[Train] epoch 257 Batch 37 Loss 0.16834822297096252
[Train] epoch 257 Batch 38 Loss 0.20436599850654602
[Train] epoch 257 Batch 39 Loss 0.17050506174564362
[Train] epoch 257 Batch 40 Loss 0.13672159612178802
[Train] epoch 257 Batch 41 Loss 0.1695314198732376
[Train] epoch 257 Batch 42 Loss 0.16833576560020447
[Train] epoch 257 Batch 43 Loss 0.3028589189052582
[Train] epoch 257 Batch 44 Loss 0.06781497597694397
[Train] epoch 257 Batch 45 Loss 0.13559138774871826
[Train] epoch 257 Batch 46 Loss 0.26895666122436523
[Train] epoch 257 Batch 47 Loss 0.37054261565208435
[Train] epoch 258 Batch 0 Loss 0.20119071006774902
[Train] epoch 258 Batch 1 Loss 0.13672283291816711
[Train] epoch 258 Batch 2 Loss 0.20221242308616638
[Train] epoch 258 Batch 3 Loss 0.23392824828624725
[Train] epoch 258 Batch 4 Loss 0.16828098893165588
[Train] epoch 258 Batch 5 Loss 0.23392774164676666
[Train] epoch 258 Batch 6 Loss 0.0687018632888794
[Train] epoch 258 Batch 7 Loss 0.17039401829242706
[Train] epoch 258 Batch 8 Loss 0.1016940176486969
[Train] epoch 258 Batch 9 Loss 0.1365785002708435
[Train] epoch 258 Batch 10 Loss 0.27100634574890137
[Train] epoch 258 Batch 11 Loss 0.30278730392456055
[Train] epoch 258 Batch 12 Loss 0.10059303790330887
[Train] epoch 258 Batch 13 Loss 0.1693611741065979
[Train] epoch 258 Batch 14 Loss 0.03493114933371544
[Train] epoch 258 Batch 15 Loss 0.26891905069351196
[Train] epoch 258 Batch 16 Loss 0.13445885479450226
[Train] epoch 258 Batch 17 Loss 0.2370830923318863
[Train] epoch 258 Batch 18 Loss 0.06888074427843094
[Train] epoch 258 Batch 19 Loss 0.1693180501461029
[Train] epoch 258 Batch 20 Loss 0.13653969764709473
[Train] epoch 258 Batch 21 Loss 0.10376374423503876
[Train] epoch 258 Batch 22 Loss 0.035848651081323624
[Train] epoch 258 Batch 23 Loss 0.2390674501657486
[Train] epoch 258 Batch 24 Loss 0.36920180916786194
[Train] epoch 258 Batch 25 Loss 0.16938826441764832
[Train] epoch 258 Batch 26 Loss 0.13634857535362244
[Train] epoch 258 Batch 27 Loss 0.10271322727203369
[Train] epoch 258 Batch 28 Loss 0.23500211536884308
[Train] epoch 258 Batch 29 Loss 0.16843432188034058
[Train] epoch 258 Batch 30 Loss 0.13451172411441803
[Train] epoch 258 Batch 31 Loss 0.16836118698120117
[Train] epoch 258 Batch 32 Loss 0.23787127435207367
[Train] epoch 258 Batch 33 Loss 0.13543671369552612
[Train] epoch 258 Batch 34 Loss 0.20411279797554016
[Train] epoch 258 Batch 35 Loss 0.16843101382255554
[Train] epoch 258 Batch 36 Loss 0.23690307140350342
[Train] epoch 258 Batch 37 Loss 0.2359822541475296
[Train] epoch 258 Batch 38 Loss 0.3036351799964905
[Train] epoch 258 Batch 39 Loss 0.1713632047176361
[Train] epoch 258 Batch 40 Loss 0.23392096161842346
[Train] epoch 258 Batch 41 Loss 0.10244479775428772
[Train] epoch 258 Batch 42 Loss 0.30453914403915405
[Train] epoch 258 Batch 43 Loss 0.23705050349235535
[Train] epoch 258 Batch 44 Loss 0.1690950095653534
[Train] epoch 258 Batch 45 Loss 0.034867919981479645
[Train] epoch 258 Batch 46 Loss 0.13536465167999268
[Train] epoch 258 Batch 47 Loss 0.10164406150579453
[Train] epoch 259 Batch 0 Loss 0.36927682161331177
[Train] epoch 259 Batch 1 Loss 0.0028468002565205097
[Train] epoch 259 Batch 2 Loss 0.26882708072662354
[Train] epoch 259 Batch 3 Loss 0.06666764616966248
[Train] epoch 259 Batch 4 Loss 0.10166346281766891
[Train] epoch 259 Batch 5 Loss 0.2048351764678955
[Train] epoch 259 Batch 6 Loss 0.1681833267211914
[Train] epoch 259 Batch 7 Loss 0.20286381244659424
[Train] epoch 259 Batch 8 Loss 0.13835930824279785
[Train] epoch 259 Batch 9 Loss 0.13545314967632294
[Train] epoch 259 Batch 10 Loss 0.0009246927802450955
[Train] epoch 259 Batch 11 Loss 0.2031603455543518
[Train] epoch 259 Batch 12 Loss 0.16904041171073914
[Train] epoch 259 Batch 13 Loss 0.17027977108955383
[Train] epoch 259 Batch 14 Loss 0.3024413585662842
[Train] epoch 259 Batch 15 Loss 0.17019252479076385
[Train] epoch 259 Batch 16 Loss 0.3025839030742645
[Train] epoch 259 Batch 17 Loss 0.2028852105140686
[Train] epoch 259 Batch 18 Loss 0.06783384084701538
[Train] epoch 259 Batch 19 Loss 0.10058388113975525
[Train] epoch 259 Batch 20 Loss 0.06850265711545944
[Train] epoch 259 Batch 21 Loss 0.10254575312137604
[Train] epoch 259 Batch 22 Loss 0.13645878434181213
[Train] epoch 259 Batch 23 Loss 0.30163854360580444
[Train] epoch 259 Batch 24 Loss 0.06783187389373779
[Train] epoch 259 Batch 25 Loss 0.2040162980556488
[Train] epoch 259 Batch 26 Loss 0.13815467059612274
[Train] epoch 259 Batch 27 Loss 0.2023266851902008
[Train] epoch 259 Batch 28 Loss 0.13541316986083984
[Train] epoch 259 Batch 29 Loss 0.23558950424194336
[Train] epoch 259 Batch 30 Loss 0.23496326804161072
[Train] epoch 259 Batch 31 Loss 0.10240595042705536
[Train] epoch 259 Batch 32 Loss 0.23678246140480042
[Train] epoch 259 Batch 33 Loss 0.2686219811439514
[Train] epoch 259 Batch 34 Loss 0.2685982882976532
[Train] epoch 259 Batch 35 Loss 0.16929176449775696
[Train] epoch 259 Batch 36 Loss 0.13526025414466858
[Train] epoch 259 Batch 37 Loss 0.2028072476387024
[Train] epoch 259 Batch 38 Loss 0.0011030163150280714
[Train] epoch 259 Batch 39 Loss 0.17121835052967072
[Train] epoch 259 Batch 40 Loss 0.17008361220359802
[Train] epoch 259 Batch 41 Loss 0.31363850831985474
[Train] epoch 259 Batch 42 Loss 0.3692253828048706
[Train] epoch 259 Batch 43 Loss 0.256733238697052
[Train] epoch 259 Batch 44 Loss 0.1742919385433197
[Train] epoch 259 Batch 45 Loss 0.23596134781837463
[Train] epoch 259 Batch 46 Loss 0.17314687371253967
[Train] epoch 259 Batch 47 Loss 0.10177326202392578
[Train] epoch 260 Batch 0 Loss 0.10179901868104935
[Train] epoch 260 Batch 1 Loss 0.1090780720114708
[Train] epoch 260 Batch 2 Loss 0.23528781533241272
[Train] epoch 260 Batch 3 Loss 0.26942679286003113
[Train] epoch 260 Batch 4 Loss 0.1792360246181488
[Train] epoch 260 Batch 5 Loss 0.2038746327161789
[Train] epoch 260 Batch 6 Loss 0.13148468732833862
[Train] epoch 260 Batch 7 Loss 0.3376755118370056
[Train] epoch 260 Batch 8 Loss 0.3984646201133728
[Train] epoch 260 Batch 9 Loss 0.14406320452690125
[Train] epoch 260 Batch 10 Loss 0.20518988370895386
[Train] epoch 260 Batch 11 Loss 0.10838016122579575
[Train] epoch 260 Batch 12 Loss 0.10583925247192383
[Train] epoch 260 Batch 13 Loss 0.2373667061328888
[Train] epoch 260 Batch 14 Loss 0.06976969540119171
[Train] epoch 260 Batch 15 Loss 0.03835563361644745
[Train] epoch 260 Batch 16 Loss 0.13928762078285217
[Train] epoch 260 Batch 17 Loss 0.10498075187206268
[Train] epoch 260 Batch 18 Loss 0.16955673694610596
[Train] epoch 260 Batch 19 Loss 0.16939769685268402
[Train] epoch 260 Batch 20 Loss 0.10281568765640259
[Train] epoch 260 Batch 21 Loss 0.1695641130208969
[Train] epoch 260 Batch 22 Loss 0.2725781798362732
[Train] epoch 260 Batch 23 Loss 0.20524169504642487
[Train] epoch 260 Batch 24 Loss 0.3051225543022156
[Train] epoch 260 Batch 25 Loss 0.10730329900979996
[Train] epoch 260 Batch 26 Loss 0.40189677476882935
[Train] epoch 260 Batch 27 Loss 0.11042904108762741
[Train] epoch 260 Batch 28 Loss 0.03978875279426575
[Train] epoch 260 Batch 29 Loss 0.143741637468338
[Train] epoch 260 Batch 30 Loss 0.23785054683685303
[Train] epoch 260 Batch 31 Loss 0.2143121212720871
[Train] epoch 260 Batch 32 Loss 0.2368447184562683
[Train] epoch 260 Batch 33 Loss 0.16952428221702576
[Train] epoch 260 Batch 34 Loss 0.2686700224876404
[Train] epoch 260 Batch 35 Loss 0.1354912966489792
[Train] epoch 260 Batch 36 Loss 0.2057822048664093
[Train] epoch 260 Batch 37 Loss 0.17319339513778687
[Train] epoch 260 Batch 38 Loss 0.17368726432323456
[Train] epoch 260 Batch 39 Loss 0.23790523409843445
[Train] epoch 260 Batch 40 Loss 0.17208510637283325
[Train] epoch 260 Batch 41 Loss 0.2382887899875641
[Train] epoch 260 Batch 42 Loss 0.19204331934452057
[Train] epoch 260 Batch 43 Loss 0.2342076301574707
[Train] epoch 260 Batch 44 Loss 0.1352754384279251
[Train] epoch 260 Batch 45 Loss 0.24063120782375336
[Train] epoch 260 Batch 46 Loss 0.17204532027244568
[Train] epoch 260 Batch 47 Loss 0.1718035340309143
[Train] epoch 261 Batch 0 Loss 0.30500859022140503
[Train] epoch 261 Batch 1 Loss 0.17417624592781067
[Train] epoch 261 Batch 2 Loss 0.20484545826911926
[Train] epoch 261 Batch 3 Loss 0.1736014485359192
[Train] epoch 261 Batch 4 Loss 0.2073398381471634
[Train] epoch 261 Batch 5 Loss 0.17900517582893372
[Train] epoch 261 Batch 6 Loss 0.20685207843780518
[Train] epoch 261 Batch 7 Loss 0.13536754250526428
[Train] epoch 261 Batch 8 Loss 0.20516236126422882
[Train] epoch 261 Batch 9 Loss 0.17141535878181458
[Train] epoch 261 Batch 10 Loss 0.20333966612815857
[Train] epoch 261 Batch 11 Loss 0.10245189070701599
[Train] epoch 261 Batch 12 Loss 0.10429087281227112
[Train] epoch 261 Batch 13 Loss 0.2033940553665161
[Train] epoch 261 Batch 14 Loss 0.10425201058387756
[Train] epoch 261 Batch 15 Loss 0.23590868711471558
[Train] epoch 261 Batch 16 Loss 0.10253050923347473
[Train] epoch 261 Batch 17 Loss 0.16899211704730988
[Train] epoch 261 Batch 18 Loss 0.17065896093845367
[Train] epoch 261 Batch 19 Loss 0.2045726776123047
[Train] epoch 261 Batch 20 Loss 0.1691078245639801
[Train] epoch 261 Batch 21 Loss 0.23735277354717255
[Train] epoch 261 Batch 22 Loss 0.10382083058357239
[Train] epoch 261 Batch 23 Loss 0.1687476485967636
[Train] epoch 261 Batch 24 Loss 0.303663432598114
[Train] epoch 261 Batch 25 Loss 0.13755463063716888
[Train] epoch 261 Batch 26 Loss 0.20455443859100342
[Train] epoch 261 Batch 27 Loss 0.17138974368572235
[Train] epoch 261 Batch 28 Loss 0.03536766394972801
[Train] epoch 261 Batch 29 Loss 0.204422727227211
[Train] epoch 261 Batch 30 Loss 0.1363280713558197
[Train] epoch 261 Batch 31 Loss 0.17156022787094116
[Train] epoch 261 Batch 32 Loss 0.03517751768231392
[Train] epoch 261 Batch 33 Loss 0.16877779364585876
[Train] epoch 261 Batch 34 Loss 0.20121780037879944
[Train] epoch 261 Batch 35 Loss 0.3020440936088562
[Train] epoch 261 Batch 36 Loss 0.13620468974113464
[Train] epoch 261 Batch 37 Loss 0.23817825317382812
[Train] epoch 261 Batch 38 Loss 0.038992222398519516
[Train] epoch 261 Batch 39 Loss 0.17154811322689056
[Train] epoch 261 Batch 40 Loss 0.3378738760948181
[Train] epoch 261 Batch 41 Loss 0.17122182250022888
[Train] epoch 261 Batch 42 Loss 0.2417961061000824
[Train] epoch 261 Batch 43 Loss 0.06792785972356796
[Train] epoch 261 Batch 44 Loss 0.23582924902439117
[Train] epoch 261 Batch 45 Loss 0.03822508081793785
[Train] epoch 261 Batch 46 Loss 0.3364042043685913
[Train] epoch 261 Batch 47 Loss 0.16909143328666687
[Train] epoch 262 Batch 0 Loss 0.1382640302181244
[Train] epoch 262 Batch 1 Loss 0.1726219654083252
[Train] epoch 262 Batch 2 Loss 0.23959234356880188
[Train] epoch 262 Batch 3 Loss 0.10269168019294739
[Train] epoch 262 Batch 4 Loss 0.17140169441699982
[Train] epoch 262 Batch 5 Loss 0.10302253067493439
[Train] epoch 262 Batch 6 Loss 0.3045061528682709
[Train] epoch 262 Batch 7 Loss 0.14168475568294525
[Train] epoch 262 Batch 8 Loss 0.2702005207538605
[Train] epoch 262 Batch 9 Loss 0.2097509354352951
[Train] epoch 262 Batch 10 Loss 0.27257129549980164
[Train] epoch 262 Batch 11 Loss 0.23591676354408264
[Train] epoch 262 Batch 12 Loss 0.13496291637420654
[Train] epoch 262 Batch 13 Loss 0.20558205246925354
[Train] epoch 262 Batch 14 Loss 0.10719317197799683
[Train] epoch 262 Batch 15 Loss 0.10265668481588364
[Train] epoch 262 Batch 16 Loss 0.1008136123418808
[Train] epoch 262 Batch 17 Loss 0.23607994616031647
[Train] epoch 262 Batch 18 Loss 0.20181667804718018
[Train] epoch 262 Batch 19 Loss 0.13495750725269318
[Train] epoch 262 Batch 20 Loss 0.10638731718063354
[Train] epoch 262 Batch 21 Loss 0.07040758430957794
[Train] epoch 262 Batch 22 Loss 0.13511183857917786
[Train] epoch 262 Batch 23 Loss 0.2682882249355316
[Train] epoch 262 Batch 24 Loss 0.17635992169380188
[Train] epoch 262 Batch 25 Loss 0.305970162153244
[Train] epoch 262 Batch 26 Loss 0.30597221851348877
[Train] epoch 262 Batch 27 Loss 1.0728851975727594e-06
[Train] epoch 262 Batch 28 Loss 0.2357800304889679
[Train] epoch 262 Batch 29 Loss 0.20164044201374054
[Train] epoch 262 Batch 30 Loss 0.1350981593132019
[Train] epoch 262 Batch 31 Loss 0.13656526803970337
[Train] epoch 262 Batch 32 Loss 0.16913729906082153
[Train] epoch 262 Batch 33 Loss 0.10911586880683899
[Train] epoch 262 Batch 34 Loss 0.20663315057754517
[Train] epoch 262 Batch 35 Loss 0.133334219455719
[Train] epoch 262 Batch 36 Loss 0.1040092185139656
[Train] epoch 262 Batch 37 Loss 0.33982592821121216
[Train] epoch 262 Batch 38 Loss 0.16896949708461761
[Train] epoch 262 Batch 39 Loss 0.0682651475071907
[Train] epoch 262 Batch 40 Loss 0.2046111822128296
[Train] epoch 262 Batch 41 Loss 0.2388186752796173
[Train] epoch 262 Batch 42 Loss 0.13485580682754517
[Train] epoch 262 Batch 43 Loss 0.13929679989814758
[Train] epoch 262 Batch 44 Loss 0.37194544076919556
[Train] epoch 262 Batch 45 Loss 0.0712176263332367
[Train] epoch 262 Batch 46 Loss 0.13790395855903625
[Train] epoch 262 Batch 47 Loss 0.23708616197109222
[Train] epoch 263 Batch 0 Loss 0.20305612683296204
[Train] epoch 263 Batch 1 Loss 0.2013867050409317
[Train] epoch 263 Batch 2 Loss 0.13612882792949677
[Train] epoch 263 Batch 3 Loss 0.06953292340040207
[Train] epoch 263 Batch 4 Loss 0.20299804210662842
[Train] epoch 263 Batch 5 Loss 0.20581457018852234
[Train] epoch 263 Batch 6 Loss 0.17155668139457703
[Train] epoch 263 Batch 7 Loss 0.06814658641815186
[Train] epoch 263 Batch 8 Loss 0.26969560980796814
[Train] epoch 263 Batch 9 Loss 0.16875867545604706
[Train] epoch 263 Batch 10 Loss 0.23559507727622986
[Train] epoch 263 Batch 11 Loss 0.13912034034729004
[Train] epoch 263 Batch 12 Loss 0.16746574640274048
[Train] epoch 263 Batch 13 Loss 0.23520085215568542
[Train] epoch 263 Batch 14 Loss 0.17125636339187622
[Train] epoch 263 Batch 15 Loss 0.16855160892009735
[Train] epoch 263 Batch 16 Loss 0.1034649908542633
[Train] epoch 263 Batch 17 Loss 0.17546939849853516
[Train] epoch 263 Batch 18 Loss 0.13576731085777283
[Train] epoch 263 Batch 19 Loss 0.13617315888404846
[Train] epoch 263 Batch 20 Loss 0.3688772916793823
[Train] epoch 263 Batch 21 Loss 0.27324074506759644
[Train] epoch 263 Batch 22 Loss 0.10175749659538269
[Train] epoch 263 Batch 23 Loss 0.06943073123693466
[Train] epoch 263 Batch 24 Loss 0.10238225013017654
[Train] epoch 263 Batch 25 Loss 0.30292198061943054
[Train] epoch 263 Batch 26 Loss 0.1005961075425148
[Train] epoch 263 Batch 27 Loss 0.2039530873298645
[Train] epoch 263 Batch 28 Loss 0.23550733923912048
[Train] epoch 263 Batch 29 Loss 0.23708710074424744
[Train] epoch 263 Batch 30 Loss 0.035011954605579376
[Train] epoch 263 Batch 31 Loss 0.3023737668991089
[Train] epoch 263 Batch 32 Loss 0.13557349145412445
[Train] epoch 263 Batch 33 Loss 0.23548826575279236
[Train] epoch 263 Batch 34 Loss 0.17110440135002136
[Train] epoch 263 Batch 35 Loss 0.2691306471824646
[Train] epoch 263 Batch 36 Loss 0.10305637121200562
[Train] epoch 263 Batch 37 Loss 0.17099696397781372
[Train] epoch 263 Batch 38 Loss 0.17319412529468536
[Train] epoch 263 Batch 39 Loss 0.16853821277618408
[Train] epoch 263 Batch 40 Loss 0.10186688601970673
[Train] epoch 263 Batch 41 Loss 0.20699769258499146
[Train] epoch 263 Batch 42 Loss 0.04537573084235191
[Train] epoch 263 Batch 43 Loss 0.23548030853271484
[Train] epoch 263 Batch 44 Loss 0.23567239940166473
[Train] epoch 263 Batch 45 Loss 0.13638952374458313
[Train] epoch 263 Batch 46 Loss 0.1707828938961029
[Train] epoch 263 Batch 47 Loss 0.20504307746887207
[Train] epoch 264 Batch 0 Loss 0.3366033434867859
[Train] epoch 264 Batch 1 Loss 0.11022832989692688
[Train] epoch 264 Batch 2 Loss 0.20189841091632843
[Train] epoch 264 Batch 3 Loss 0.2069110870361328
[Train] epoch 264 Batch 4 Loss 0.37189871072769165
[Train] epoch 264 Batch 5 Loss 0.27491846680641174
[Train] epoch 264 Batch 6 Loss 0.3068299889564514
[Train] epoch 264 Batch 7 Loss 0.37151601910591125
[Train] epoch 264 Batch 8 Loss 0.16909316182136536
[Train] epoch 264 Batch 9 Loss 0.07139341533184052
[Train] epoch 264 Batch 10 Loss 0.20419849455356598
[Train] epoch 264 Batch 11 Loss 0.2382652908563614
[Train] epoch 264 Batch 12 Loss 0.17154458165168762
[Train] epoch 264 Batch 13 Loss 0.21217438578605652
[Train] epoch 264 Batch 14 Loss 0.2014213502407074
[Train] epoch 264 Batch 15 Loss 0.2046859860420227
[Train] epoch 264 Batch 16 Loss 0.16735824942588806
[Train] epoch 264 Batch 17 Loss 0.06831292808055878
[Train] epoch 264 Batch 18 Loss 0.1363556683063507
[Train] epoch 264 Batch 19 Loss 0.13963446021080017
[Train] epoch 264 Batch 20 Loss 0.10245248675346375
[Train] epoch 264 Batch 21 Loss 0.2390935868024826
[Train] epoch 264 Batch 22 Loss 0.07184211909770966
[Train] epoch 264 Batch 23 Loss 0.1026020273566246
[Train] epoch 264 Batch 24 Loss 0.10591742396354675
[Train] epoch 264 Batch 25 Loss 0.1385396420955658
[Train] epoch 264 Batch 26 Loss 0.07192005217075348
[Train] epoch 264 Batch 27 Loss 0.10823309421539307
[Train] epoch 264 Batch 28 Loss 0.21023130416870117
[Train] epoch 264 Batch 29 Loss 0.06815710663795471
[Train] epoch 264 Batch 30 Loss 0.1026519238948822
[Train] epoch 264 Batch 31 Loss 0.17293715476989746
[Train] epoch 264 Batch 32 Loss 0.27201882004737854
[Train] epoch 264 Batch 33 Loss 0.2034347951412201
[Train] epoch 264 Batch 34 Loss 0.16944605112075806
[Train] epoch 264 Batch 35 Loss 0.10437311977148056
[Train] epoch 264 Batch 36 Loss 0.26983001828193665
[Train] epoch 264 Batch 37 Loss 0.06856295466423035
[Train] epoch 264 Batch 38 Loss 0.20487648248672485
[Train] epoch 264 Batch 39 Loss 0.16760659217834473
[Train] epoch 264 Batch 40 Loss 0.37067127227783203
[Train] epoch 264 Batch 41 Loss 0.23585255444049835
[Train] epoch 264 Batch 42 Loss 0.2372400462627411
[Train] epoch 264 Batch 43 Loss 0.13676998019218445
[Train] epoch 264 Batch 44 Loss 0.16750875115394592
[Train] epoch 264 Batch 45 Loss 0.10405346751213074
[Train] epoch 264 Batch 46 Loss 0.06814296543598175
[Train] epoch 264 Batch 47 Loss 0.07013916969299316
[Train] epoch 265 Batch 0 Loss 0.2409171164035797
[Train] epoch 265 Batch 1 Loss 0.13982832431793213
[Train] epoch 265 Batch 2 Loss 0.16928377747535706
[Train] epoch 265 Batch 3 Loss 0.20310840010643005
[Train] epoch 265 Batch 4 Loss 0.13666638731956482
[Train] epoch 265 Batch 5 Loss 0.26998305320739746
[Train] epoch 265 Batch 6 Loss 0.10074055194854736
[Train] epoch 265 Batch 7 Loss 0.1707548350095749
[Train] epoch 265 Batch 8 Loss 0.2015371322631836
[Train] epoch 265 Batch 9 Loss 0.1380787193775177
[Train] epoch 265 Batch 10 Loss 0.10246729105710983
[Train] epoch 265 Batch 11 Loss 0.1348167359828949
[Train] epoch 265 Batch 12 Loss 0.10078359395265579
[Train] epoch 265 Batch 13 Loss 0.1691124588251114
[Train] epoch 265 Batch 14 Loss 0.1722763329744339
[Train] epoch 265 Batch 15 Loss 0.30545544624328613
[Train] epoch 265 Batch 16 Loss 0.27311429381370544
[Train] epoch 265 Batch 17 Loss 0.10384738445281982
[Train] epoch 265 Batch 18 Loss 0.06817121803760529
[Train] epoch 265 Batch 19 Loss 0.27446886897087097
[Train] epoch 265 Batch 20 Loss 0.10553164780139923
[Train] epoch 265 Batch 21 Loss 0.26985853910446167
[Train] epoch 265 Batch 22 Loss 0.2078341245651245
[Train] epoch 265 Batch 23 Loss 0.13797886669635773
[Train] epoch 265 Batch 24 Loss 0.03720904886722565
[Train] epoch 265 Batch 25 Loss 0.37208008766174316
[Train] epoch 265 Batch 26 Loss 0.17045652866363525
[Train] epoch 265 Batch 27 Loss 0.06813293695449829
[Train] epoch 265 Batch 28 Loss 0.20922887325286865
[Train] epoch 265 Batch 29 Loss 0.16743850708007812
[Train] epoch 265 Batch 30 Loss 0.10220082104206085
[Train] epoch 265 Batch 31 Loss 0.30662500858306885
[Train] epoch 265 Batch 32 Loss 0.30374446511268616
[Train] epoch 265 Batch 33 Loss 0.10525096952915192
[Train] epoch 265 Batch 34 Loss 0.10516880452632904
[Train] epoch 265 Batch 35 Loss 0.20148389041423798
[Train] epoch 265 Batch 36 Loss 0.06815406680107117
[Train] epoch 265 Batch 37 Loss 0.10216179490089417
[Train] epoch 265 Batch 38 Loss 0.2680901885032654
[Train] epoch 265 Batch 39 Loss 0.2043704092502594
[Train] epoch 265 Batch 40 Loss 0.2043609619140625
[Train] epoch 265 Batch 41 Loss 0.13471873104572296
[Train] epoch 265 Batch 42 Loss 0.16891387104988098
[Train] epoch 265 Batch 43 Loss 0.30224642157554626
[Train] epoch 265 Batch 44 Loss 0.07219862937927246
[Train] epoch 265 Batch 45 Loss 0.2043187916278839
[Train] epoch 265 Batch 46 Loss 0.26807722449302673
[Train] epoch 265 Batch 47 Loss 0.1347842812538147
[Train] epoch 266 Batch 0 Loss 0.2383750081062317
[Train] epoch 266 Batch 1 Loss 0.2355767786502838
[Train] epoch 266 Batch 2 Loss 0.1387481838464737
[Train] epoch 266 Batch 3 Loss 0.3021867871284485
[Train] epoch 266 Batch 4 Loss 0.13610079884529114
[Train] epoch 266 Batch 5 Loss 0.3034578859806061
[Train] epoch 266 Batch 6 Loss 0.23815491795539856
[Train] epoch 266 Batch 7 Loss 0.07214666903018951
[Train] epoch 266 Batch 8 Loss 0.10212317109107971
[Train] epoch 266 Batch 9 Loss 0.1373230367898941
[Train] epoch 266 Batch 10 Loss 0.16876178979873657
[Train] epoch 266 Batch 11 Loss 0.13612064719200134
[Train] epoch 266 Batch 12 Loss 0.30203714966773987
[Train] epoch 266 Batch 13 Loss 0.10208113491535187
[Train] epoch 266 Batch 14 Loss 0.1674117147922516
[Train] epoch 266 Batch 15 Loss 0.2012343406677246
[Train] epoch 266 Batch 16 Loss 0.23922571539878845
[Train] epoch 266 Batch 17 Loss 0.16864383220672607
[Train] epoch 266 Batch 18 Loss 0.10472440719604492
[Train] epoch 266 Batch 19 Loss 0.13468751311302185
[Train] epoch 266 Batch 20 Loss 0.2355666160583496
[Train] epoch 266 Batch 21 Loss 0.1047401949763298
[Train] epoch 266 Batch 22 Loss 0.17120572924613953
[Train] epoch 266 Batch 23 Loss 0.30189019441604614
[Train] epoch 266 Batch 24 Loss 0.17246368527412415
[Train] epoch 266 Batch 25 Loss 0.23407800495624542
[Train] epoch 266 Batch 26 Loss 0.3044838309288025
[Train] epoch 266 Batch 27 Loss 0.30350178480148315
[Train] epoch 266 Batch 28 Loss 0.1361546516418457
[Train] epoch 266 Batch 29 Loss 0.2013324350118637
[Train] epoch 266 Batch 30 Loss 0.10310190171003342
[Train] epoch 266 Batch 31 Loss 0.03533010184764862
[Train] epoch 266 Batch 32 Loss 0.1713939607143402
[Train] epoch 266 Batch 33 Loss 0.1345783770084381
[Train] epoch 266 Batch 34 Loss 0.1348191350698471
[Train] epoch 266 Batch 35 Loss 0.20396080613136292
[Train] epoch 266 Batch 36 Loss 0.10559618473052979
[Train] epoch 266 Batch 37 Loss 0.20547577738761902
[Train] epoch 266 Batch 38 Loss 0.16977886855602264
[Train] epoch 266 Batch 39 Loss 0.16876204311847687
[Train] epoch 266 Batch 40 Loss 0.13694515824317932
[Train] epoch 266 Batch 41 Loss 0.0035608718171715736
[Train] epoch 266 Batch 42 Loss 0.13598749041557312
[Train] epoch 266 Batch 43 Loss 0.2718236744403839
[Train] epoch 266 Batch 44 Loss 0.2027856409549713
[Train] epoch 266 Batch 45 Loss 0.13481533527374268
[Train] epoch 266 Batch 46 Loss 0.23895035684108734
[Train] epoch 266 Batch 47 Loss 0.10222163051366806
[Train] epoch 267 Batch 0 Loss 0.10440485179424286
[Train] epoch 267 Batch 1 Loss 0.1359572559595108
[Train] epoch 267 Batch 2 Loss 0.10074007511138916
[Train] epoch 267 Batch 3 Loss 0.16972094774246216
[Train] epoch 267 Batch 4 Loss 0.20264872908592224
[Train] epoch 267 Batch 5 Loss 0.07123563438653946
[Train] epoch 267 Batch 6 Loss 0.068890281021595
[Train] epoch 267 Batch 7 Loss 0.3372538089752197
[Train] epoch 267 Batch 8 Loss 0.16984379291534424
[Train] epoch 267 Batch 9 Loss 0.36868351697921753
[Train] epoch 267 Batch 10 Loss 1.0728851975727594e-06
[Train] epoch 267 Batch 11 Loss 0.1685177981853485
[Train] epoch 267 Batch 12 Loss 0.002258198568597436
[Train] epoch 267 Batch 13 Loss 0.10426121205091476
[Train] epoch 267 Batch 14 Loss 0.10053662955760956
[Train] epoch 267 Batch 15 Loss 0.06927625089883804
[Train] epoch 267 Batch 16 Loss 0.33703988790512085
[Train] epoch 267 Batch 17 Loss 0.23536992073059082
[Train] epoch 267 Batch 18 Loss 0.3698316812515259
[Train] epoch 267 Batch 19 Loss 0.17109155654907227
[Train] epoch 267 Batch 20 Loss 0.33677732944488525
[Train] epoch 267 Batch 21 Loss 0.23624342679977417
[Train] epoch 267 Batch 22 Loss 0.3362676203250885
[Train] epoch 267 Batch 23 Loss 0.06666764616966248
[Train] epoch 267 Batch 24 Loss 0.20108093321323395
[Train] epoch 267 Batch 25 Loss 0.2378654181957245
[Train] epoch 267 Batch 26 Loss 0.1710163652896881
[Train] epoch 267 Batch 27 Loss 0.10416571795940399
[Train] epoch 267 Batch 28 Loss 0.0692342147231102
[Train] epoch 267 Batch 29 Loss 0.16996170580387115
[Train] epoch 267 Batch 30 Loss 0.2034490704536438
[Train] epoch 267 Batch 31 Loss 0.23640696704387665
[Train] epoch 267 Batch 32 Loss 0.26918846368789673
[Train] epoch 267 Batch 33 Loss 0.20218659937381744
[Train] epoch 267 Batch 34 Loss 0.03621082380414009
[Train] epoch 267 Batch 35 Loss 0.03406256064772606
[Train] epoch 267 Batch 36 Loss 0.3055935502052307
[Train] epoch 267 Batch 37 Loss 0.06880098581314087
[Train] epoch 267 Batch 38 Loss 0.16844289004802704
[Train] epoch 267 Batch 39 Loss 0.20231273770332336
[Train] epoch 267 Batch 40 Loss 0.17394006252288818
[Train] epoch 267 Batch 41 Loss 0.17079992592334747
[Train] epoch 267 Batch 42 Loss 0.17098164558410645
[Train] epoch 267 Batch 43 Loss 0.27038174867630005
[Train] epoch 267 Batch 44 Loss 0.13581645488739014
[Train] epoch 267 Batch 45 Loss 0.23650723695755005
[Train] epoch 267 Batch 46 Loss 0.16927996277809143
[Train] epoch 267 Batch 47 Loss 0.16943973302841187
[Train] epoch 268 Batch 0 Loss 0.2712084650993347
[Train] epoch 268 Batch 1 Loss 0.06788496673107147
[Train] epoch 268 Batch 2 Loss 0.16928166151046753
[Train] epoch 268 Batch 3 Loss 0.06872239708900452
[Train] epoch 268 Batch 4 Loss 0.16842953860759735
[Train] epoch 268 Batch 5 Loss 0.20446939766407013
[Train] epoch 268 Batch 6 Loss 0.17149436473846436
[Train] epoch 268 Batch 7 Loss 0.16839154064655304
[Train] epoch 268 Batch 8 Loss 0.17065048217773438
[Train] epoch 268 Batch 9 Loss 0.20144447684288025
[Train] epoch 268 Batch 10 Loss 0.1694042682647705
[Train] epoch 268 Batch 11 Loss 0.03579593077301979
[Train] epoch 268 Batch 12 Loss 0.168590247631073
[Train] epoch 268 Batch 13 Loss 0.13477671146392822
[Train] epoch 268 Batch 14 Loss 0.1027151346206665
[Train] epoch 268 Batch 15 Loss 0.20144236087799072
[Train] epoch 268 Batch 16 Loss 0.3045817017555237
[Train] epoch 268 Batch 17 Loss 0.16860967874526978
[Train] epoch 268 Batch 18 Loss 0.2352474331855774
[Train] epoch 268 Batch 19 Loss 0.13769307732582092
[Train] epoch 268 Batch 20 Loss 0.13530570268630981
[Train] epoch 268 Batch 21 Loss 0.16959889233112335
[Train] epoch 268 Batch 22 Loss 0.2712554335594177
[Train] epoch 268 Batch 23 Loss 0.20532821118831635
[Train] epoch 268 Batch 24 Loss 0.2678799629211426
[Train] epoch 268 Batch 25 Loss 0.07007774710655212
[Train] epoch 268 Batch 26 Loss 0.1695786416530609
[Train] epoch 268 Batch 27 Loss 0.10265840590000153
[Train] epoch 268 Batch 28 Loss 0.13748568296432495
[Train] epoch 268 Batch 29 Loss 0.20286068320274353
[Train] epoch 268 Batch 30 Loss 0.10234110057353973
[Train] epoch 268 Batch 31 Loss 0.20237867534160614
[Train] epoch 268 Batch 32 Loss 0.23684293031692505
[Train] epoch 268 Batch 33 Loss 0.17154622077941895
[Train] epoch 268 Batch 34 Loss 0.16957621276378632
[Train] epoch 268 Batch 35 Loss 0.30210500955581665
[Train] epoch 268 Batch 36 Loss 0.3006984293460846
[Train] epoch 268 Batch 37 Loss 0.30416983366012573
[Train] epoch 268 Batch 38 Loss 0.06983774900436401
[Train] epoch 268 Batch 39 Loss 0.10175963491201401
[Train] epoch 268 Batch 40 Loss 0.06666764616966248
[Train] epoch 268 Batch 41 Loss 0.2048700749874115
[Train] epoch 268 Batch 42 Loss 0.23618397116661072
[Train] epoch 268 Batch 43 Loss 0.10182668268680573
[Train] epoch 268 Batch 44 Loss 0.3359525799751282
[Train] epoch 268 Batch 45 Loss 0.13557645678520203
[Train] epoch 268 Batch 46 Loss 0.1030663251876831
[Train] epoch 268 Batch 47 Loss 0.23510584235191345
[Train] epoch 269 Batch 0 Loss 0.20122624933719635
[Train] epoch 269 Batch 1 Loss 0.06784244626760483
[Train] epoch 269 Batch 2 Loss 0.27367520332336426
[Train] epoch 269 Batch 3 Loss 0.20257577300071716
[Train] epoch 269 Batch 4 Loss 0.23865607380867004
[Train] epoch 269 Batch 5 Loss 1.0728851975727594e-06
[Train] epoch 269 Batch 6 Loss 0.30532267689704895
[Train] epoch 269 Batch 7 Loss 0.23514854907989502
[Train] epoch 269 Batch 8 Loss 0.270175576210022
[Train] epoch 269 Batch 9 Loss 0.06910618394613266
[Train] epoch 269 Batch 10 Loss 0.10282935947179794
[Train] epoch 269 Batch 11 Loss 0.10184559226036072
[Train] epoch 269 Batch 12 Loss 0.2023925632238388
[Train] epoch 269 Batch 13 Loss 0.20369412004947662
[Train] epoch 269 Batch 14 Loss 0.16855522990226746
[Train] epoch 269 Batch 15 Loss 0.1685543656349182
[Train] epoch 269 Batch 16 Loss 0.16850049793720245
[Train] epoch 269 Batch 17 Loss 0.1698026955127716
[Train] epoch 269 Batch 18 Loss 0.17086872458457947
[Train] epoch 269 Batch 19 Loss 0.2024976909160614
[Train] epoch 269 Batch 20 Loss 0.23646023869514465
[Train] epoch 269 Batch 21 Loss 0.3029378056526184
[Train] epoch 269 Batch 22 Loss 0.2364530861377716
[Train] epoch 269 Batch 23 Loss 0.13821016252040863
[Train] epoch 269 Batch 24 Loss 0.034002069383859634
[Train] epoch 269 Batch 25 Loss 0.1707277148962021
[Train] epoch 269 Batch 26 Loss 0.2364760786294937
[Train] epoch 269 Batch 27 Loss 0.2692020535469055
[Train] epoch 269 Batch 28 Loss 0.237604022026062
[Train] epoch 269 Batch 29 Loss 0.23605966567993164
[Train] epoch 269 Batch 30 Loss 0.2385847270488739
[Train] epoch 269 Batch 31 Loss 0.17078068852424622
[Train] epoch 269 Batch 32 Loss 0.10284306108951569
[Train] epoch 269 Batch 33 Loss 0.16999384760856628
[Train] epoch 269 Batch 34 Loss 0.2024129033088684
[Train] epoch 269 Batch 35 Loss 0.2689342498779297
[Train] epoch 269 Batch 36 Loss 0.10174156725406647
[Train] epoch 269 Batch 37 Loss 0.2037305384874344
[Train] epoch 269 Batch 38 Loss 0.2712419629096985
[Train] epoch 269 Batch 39 Loss 0.16950178146362305
[Train] epoch 269 Batch 40 Loss 0.1686551570892334
[Train] epoch 269 Batch 41 Loss 0.20235595107078552
[Train] epoch 269 Batch 42 Loss 0.13681308925151825
[Train] epoch 269 Batch 43 Loss 0.06908156722784042
[Train] epoch 269 Batch 44 Loss 0.06881385296583176
[Train] epoch 269 Batch 45 Loss 0.03493214398622513
[Train] epoch 269 Batch 46 Loss 0.13441815972328186
[Train] epoch 269 Batch 47 Loss 0.10159089416265488
[Train] epoch 270 Batch 0 Loss 0.2373521775007248
[Train] epoch 270 Batch 1 Loss 0.0687558501958847
[Train] epoch 270 Batch 2 Loss 0.17060637474060059
[Train] epoch 270 Batch 3 Loss 0.269025981426239
[Train] epoch 270 Batch 4 Loss 0.30066049098968506
[Train] epoch 270 Batch 5 Loss 0.10197994112968445
[Train] epoch 270 Batch 6 Loss 0.13436546921730042
[Train] epoch 270 Batch 7 Loss 0.40237897634506226
[Train] epoch 270 Batch 8 Loss 0.20224624872207642
[Train] epoch 270 Batch 9 Loss 0.2688791751861572
[Train] epoch 270 Batch 10 Loss 0.16953426599502563
[Train] epoch 270 Batch 11 Loss 0.20349085330963135
[Train] epoch 270 Batch 12 Loss 0.1380329728126526
[Train] epoch 270 Batch 13 Loss 0.13580037653446198
[Train] epoch 270 Batch 14 Loss 0.2362155020236969
[Train] epoch 270 Batch 15 Loss 0.07088401913642883
[Train] epoch 270 Batch 16 Loss 0.07205174118280411
[Train] epoch 270 Batch 17 Loss 0.03502766042947769
[Train] epoch 270 Batch 18 Loss 0.27015751600265503
[Train] epoch 270 Batch 19 Loss 0.23730528354644775
[Train] epoch 270 Batch 20 Loss 0.0020014652982354164
[Train] epoch 270 Batch 21 Loss 0.10296338051557541
[Train] epoch 270 Batch 22 Loss 0.16732236742973328
[Train] epoch 270 Batch 23 Loss 0.10363379865884781
[Train] epoch 270 Batch 24 Loss 0.20212599635124207
[Train] epoch 270 Batch 25 Loss 0.1356593370437622
[Train] epoch 270 Batch 26 Loss 0.1693212240934372
[Train] epoch 270 Batch 27 Loss 0.13866043090820312
[Train] epoch 270 Batch 28 Loss 0.03398769721388817
[Train] epoch 270 Batch 29 Loss 0.1354689747095108
[Train] epoch 270 Batch 30 Loss 0.26892101764678955
[Train] epoch 270 Batch 31 Loss 0.13561302423477173
[Train] epoch 270 Batch 32 Loss 0.2019999772310257
[Train] epoch 270 Batch 33 Loss 0.2011517882347107
[Train] epoch 270 Batch 34 Loss 0.16931012272834778
[Train] epoch 270 Batch 35 Loss 0.23591682314872742
[Train] epoch 270 Batch 36 Loss 0.23693111538887024
[Train] epoch 270 Batch 37 Loss 0.235289067029953
[Train] epoch 270 Batch 38 Loss 0.13543736934661865
[Train] epoch 270 Batch 39 Loss 0.20095783472061157
[Train] epoch 270 Batch 40 Loss 0.20456835627555847
[Train] epoch 270 Batch 41 Loss 0.06876087933778763
[Train] epoch 270 Batch 42 Loss 0.33767539262771606
[Train] epoch 270 Batch 43 Loss 0.20130105316638947
[Train] epoch 270 Batch 44 Loss 0.1342809647321701
[Train] epoch 270 Batch 45 Loss 0.1361696869134903
[Train] epoch 270 Batch 46 Loss 0.3038352429866791
[Train] epoch 270 Batch 47 Loss 0.10369051992893219
[Train] epoch 271 Batch 0 Loss 0.3046240508556366
[Train] epoch 271 Batch 1 Loss 0.10161234438419342
[Train] epoch 271 Batch 2 Loss 0.001869437051936984
[Train] epoch 271 Batch 3 Loss 0.03491456061601639
[Train] epoch 271 Batch 4 Loss 0.16711978614330292
[Train] epoch 271 Batch 5 Loss 0.0037872958928346634
[Train] epoch 271 Batch 6 Loss 0.2714817523956299
[Train] epoch 271 Batch 7 Loss 0.13759920001029968
[Train] epoch 271 Batch 8 Loss 0.16955643892288208
[Train] epoch 271 Batch 9 Loss 0.13557244837284088
[Train] epoch 271 Batch 10 Loss 0.13742852210998535
[Train] epoch 271 Batch 11 Loss 0.20367878675460815
[Train] epoch 271 Batch 12 Loss 0.13442444801330566
[Train] epoch 271 Batch 13 Loss 0.3026953935623169
[Train] epoch 271 Batch 14 Loss 0.17026843130588531
[Train] epoch 271 Batch 15 Loss 0.1697135865688324
[Train] epoch 271 Batch 16 Loss 0.23619705438613892
[Train] epoch 271 Batch 17 Loss 0.1353464126586914
[Train] epoch 271 Batch 18 Loss 0.03768590837717056
[Train] epoch 271 Batch 19 Loss 0.16949790716171265
[Train] epoch 271 Batch 20 Loss 0.30064332485198975
[Train] epoch 271 Batch 21 Loss 0.23597678542137146
[Train] epoch 271 Batch 22 Loss 0.16925980150699615
[Train] epoch 271 Batch 23 Loss 0.3044259548187256
[Train] epoch 271 Batch 24 Loss 0.20183326303958893
[Train] epoch 271 Batch 25 Loss 0.16730807721614838
[Train] epoch 271 Batch 26 Loss 0.0693817213177681
[Train] epoch 271 Batch 27 Loss 0.10043342411518097
[Train] epoch 271 Batch 28 Loss 0.1370628923177719
[Train] epoch 271 Batch 29 Loss 0.0686216801404953
[Train] epoch 271 Batch 30 Loss 0.23571482300758362
[Train] epoch 271 Batch 31 Loss 0.23514169454574585
[Train] epoch 271 Batch 32 Loss 0.23469872772693634
[Train] epoch 271 Batch 33 Loss 0.23786190152168274
[Train] epoch 271 Batch 34 Loss 0.10352885723114014
[Train] epoch 271 Batch 35 Loss 0.2349432110786438
[Train] epoch 271 Batch 36 Loss 0.1366734802722931
[Train] epoch 271 Batch 37 Loss 0.1718621551990509
[Train] epoch 271 Batch 38 Loss 0.23598745465278625
[Train] epoch 271 Batch 39 Loss 0.13543444871902466
[Train] epoch 271 Batch 40 Loss 0.13660632073879242
[Train] epoch 271 Batch 41 Loss 0.2000008225440979
[Train] epoch 271 Batch 42 Loss 0.301861435174942
[Train] epoch 271 Batch 43 Loss 0.16832531988620758
[Train] epoch 271 Batch 44 Loss 0.2025531828403473
[Train] epoch 271 Batch 45 Loss 0.2686086893081665
[Train] epoch 271 Batch 46 Loss 0.1004725769162178
[Train] epoch 271 Batch 47 Loss 0.30352556705474854
[Train] epoch 272 Batch 0 Loss 0.06766811013221741
[Train] epoch 272 Batch 1 Loss 0.07003237307071686
[Train] epoch 272 Batch 2 Loss 0.26906317472457886
[Train] epoch 272 Batch 3 Loss 0.1695396453142166
[Train] epoch 272 Batch 4 Loss 0.16917508840560913
[Train] epoch 272 Batch 5 Loss 0.17030653357505798
[Train] epoch 272 Batch 6 Loss 0.4021908640861511
[Train] epoch 272 Batch 7 Loss 0.03681479021906853
[Train] epoch 272 Batch 8 Loss 0.2374529391527176
[Train] epoch 272 Batch 9 Loss 0.16954290866851807
[Train] epoch 272 Batch 10 Loss 0.10193099081516266
[Train] epoch 272 Batch 11 Loss 0.36954009532928467
[Train] epoch 272 Batch 12 Loss 0.035019226372241974
[Train] epoch 272 Batch 13 Loss 0.30265313386917114
[Train] epoch 272 Batch 14 Loss 0.3028411865234375
[Train] epoch 272 Batch 15 Loss 0.10243067145347595
[Train] epoch 272 Batch 16 Loss 0.2050110399723053
[Train] epoch 272 Batch 17 Loss 0.17076809704303741
[Train] epoch 272 Batch 18 Loss 0.1698027402162552
[Train] epoch 272 Batch 19 Loss 0.2023911476135254
[Train] epoch 272 Batch 20 Loss 0.06666764616966248
[Train] epoch 272 Batch 21 Loss 0.4012073874473572
[Train] epoch 272 Batch 22 Loss 0.40241265296936035
[Train] epoch 272 Batch 23 Loss 0.10366585105657578
[Train] epoch 272 Batch 24 Loss 0.10262323915958405
[Train] epoch 272 Batch 25 Loss 0.10286957025527954
[Train] epoch 272 Batch 26 Loss 0.10362257063388824
[Train] epoch 272 Batch 27 Loss 0.10311464220285416
[Train] epoch 272 Batch 28 Loss 0.301408976316452
[Train] epoch 272 Batch 29 Loss 0.2397857904434204
[Train] epoch 272 Batch 30 Loss 0.136447012424469
[Train] epoch 272 Batch 31 Loss 0.2047833949327469
[Train] epoch 272 Batch 32 Loss 0.26826831698417664
[Train] epoch 272 Batch 33 Loss 0.10191074013710022
[Train] epoch 272 Batch 34 Loss 0.10290192067623138
[Train] epoch 272 Batch 35 Loss 0.03808659687638283
[Train] epoch 272 Batch 36 Loss 0.17070282995700836
[Train] epoch 272 Batch 37 Loss 0.13453663885593414
[Train] epoch 272 Batch 38 Loss 0.2013964205980301
[Train] epoch 272 Batch 39 Loss 0.13594037294387817
[Train] epoch 272 Batch 40 Loss 0.20389533042907715
[Train] epoch 272 Batch 41 Loss 0.13676932454109192
[Train] epoch 272 Batch 42 Loss 0.10276493430137634
[Train] epoch 272 Batch 43 Loss 0.10069334506988525
[Train] epoch 272 Batch 44 Loss 0.2000008225440979
[Train] epoch 272 Batch 45 Loss 0.23525753617286682
[Train] epoch 272 Batch 46 Loss 0.0034577487967908382
[Train] epoch 272 Batch 47 Loss 0.3028111457824707
[Train] epoch 273 Batch 0 Loss 0.10176119208335876
[Train] epoch 273 Batch 1 Loss 0.33726567029953003
[Train] epoch 273 Batch 2 Loss 0.1358899474143982
[Train] epoch 273 Batch 3 Loss 0.13571646809577942
[Train] epoch 273 Batch 4 Loss 0.2351270467042923
[Train] epoch 273 Batch 5 Loss 0.2352999746799469
[Train] epoch 273 Batch 6 Loss 0.10320766270160675
[Train] epoch 273 Batch 7 Loss 0.20735794305801392
[Train] epoch 273 Batch 8 Loss 0.002295607700943947
[Train] epoch 273 Batch 9 Loss 0.10059396922588348
[Train] epoch 273 Batch 10 Loss 0.202291801571846
[Train] epoch 273 Batch 11 Loss 0.10424970835447311
[Train] epoch 273 Batch 12 Loss 0.06908495724201202
[Train] epoch 273 Batch 13 Loss 0.03515826165676117
[Train] epoch 273 Batch 14 Loss 0.1356489062309265
[Train] epoch 273 Batch 15 Loss 0.10191673040390015
[Train] epoch 273 Batch 16 Loss 0.06920791417360306
[Train] epoch 273 Batch 17 Loss 0.20123058557510376
[Train] epoch 273 Batch 18 Loss 0.33573076128959656
[Train] epoch 273 Batch 19 Loss 0.16871564090251923
[Train] epoch 273 Batch 20 Loss 0.06899555027484894
[Train] epoch 273 Batch 21 Loss 0.13445889949798584
[Train] epoch 273 Batch 22 Loss 0.2024865299463272
[Train] epoch 273 Batch 23 Loss 0.06792823225259781
[Train] epoch 273 Batch 24 Loss 0.20717018842697144
[Train] epoch 273 Batch 25 Loss 0.40237388014793396
[Train] epoch 273 Batch 26 Loss 0.06892941147089005
[Train] epoch 273 Batch 27 Loss 0.23508737981319427
[Train] epoch 273 Batch 28 Loss 0.13594891130924225
[Train] epoch 273 Batch 29 Loss 0.370697021484375
[Train] epoch 273 Batch 30 Loss 0.0011024773120880127
[Train] epoch 273 Batch 31 Loss 0.5031392574310303
[Train] epoch 273 Batch 32 Loss 0.13556091487407684
[Train] epoch 273 Batch 33 Loss 0.16979962587356567
[Train] epoch 273 Batch 34 Loss 0.10413868725299835
[Train] epoch 273 Batch 35 Loss 0.1706438511610031
[Train] epoch 273 Batch 36 Loss 0.2072438895702362
[Train] epoch 273 Batch 37 Loss 0.1695937216281891
[Train] epoch 273 Batch 38 Loss 0.2353702187538147
[Train] epoch 273 Batch 39 Loss 0.3054860532283783
[Train] epoch 273 Batch 40 Loss 0.13683098554611206
[Train] epoch 273 Batch 41 Loss 0.3019068241119385
[Train] epoch 273 Batch 42 Loss 0.23630210757255554
[Train] epoch 273 Batch 43 Loss 0.13604184985160828
[Train] epoch 273 Batch 44 Loss 0.27103424072265625
[Train] epoch 273 Batch 45 Loss 0.2372455894947052
[Train] epoch 273 Batch 46 Loss 0.06788691878318787
[Train] epoch 273 Batch 47 Loss 0.13773444294929504
[Train] epoch 274 Batch 0 Loss 0.10276930034160614
[Train] epoch 274 Batch 1 Loss 0.10279601812362671
[Train] epoch 274 Batch 2 Loss 0.20117886364459991
[Train] epoch 274 Batch 3 Loss 0.10171210020780563
[Train] epoch 274 Batch 4 Loss 0.1048765778541565
[Train] epoch 274 Batch 5 Loss 0.3042263984680176
[Train] epoch 274 Batch 6 Loss 0.20237571001052856
[Train] epoch 274 Batch 7 Loss 0.30304551124572754
[Train] epoch 274 Batch 8 Loss 0.16734060645103455
[Train] epoch 274 Batch 9 Loss 0.16719305515289307
[Train] epoch 274 Batch 10 Loss 0.10252733528614044
[Train] epoch 274 Batch 11 Loss 0.10067331790924072
[Train] epoch 274 Batch 12 Loss 0.13685350120067596
[Train] epoch 274 Batch 13 Loss 0.20339596271514893
[Train] epoch 274 Batch 14 Loss 0.13675522804260254
[Train] epoch 274 Batch 15 Loss 0.10201478004455566
[Train] epoch 274 Batch 16 Loss 0.10368375480175018
[Train] epoch 274 Batch 17 Loss 0.13658474385738373
[Train] epoch 274 Batch 18 Loss 0.10269978642463684
[Train] epoch 274 Batch 19 Loss 0.10253731161355972
[Train] epoch 274 Batch 20 Loss 0.10201092064380646
[Train] epoch 274 Batch 21 Loss 0.20517663657665253
[Train] epoch 274 Batch 22 Loss 0.102837935090065
[Train] epoch 274 Batch 23 Loss 0.20369337499141693
[Train] epoch 274 Batch 24 Loss 0.20235121250152588
[Train] epoch 274 Batch 25 Loss 0.23534011840820312
[Train] epoch 274 Batch 26 Loss 0.17277882993221283
[Train] epoch 274 Batch 27 Loss 0.202927827835083
[Train] epoch 274 Batch 28 Loss 0.3343077003955841
[Train] epoch 274 Batch 29 Loss 0.20227700471878052
[Train] epoch 274 Batch 30 Loss 0.1026344895362854
[Train] epoch 274 Batch 31 Loss 0.1704309731721878
[Train] epoch 274 Batch 32 Loss 0.23612672090530396
[Train] epoch 274 Batch 33 Loss 0.30179929733276367
[Train] epoch 274 Batch 34 Loss 0.10357252508401871
[Train] epoch 274 Batch 35 Loss 0.1354486644268036
[Train] epoch 274 Batch 36 Loss 0.033825866878032684
[Train] epoch 274 Batch 37 Loss 0.1356448084115982
[Train] epoch 274 Batch 38 Loss 0.20444074273109436
[Train] epoch 274 Batch 39 Loss 0.2357168197631836
[Train] epoch 274 Batch 40 Loss 0.36981236934661865
[Train] epoch 274 Batch 41 Loss 0.2676388621330261
[Train] epoch 274 Batch 42 Loss 0.10481774806976318
[Train] epoch 274 Batch 43 Loss 0.06857363134622574
[Train] epoch 274 Batch 44 Loss 0.268777072429657
[Train] epoch 274 Batch 45 Loss 0.23399749398231506
[Train] epoch 274 Batch 46 Loss 0.2712402939796448
[Train] epoch 274 Batch 47 Loss 0.23492789268493652
[Train] epoch 275 Batch 0 Loss 0.2684980630874634
[Train] epoch 275 Batch 1 Loss 0.20320585370063782
[Train] epoch 275 Batch 2 Loss 0.0675930380821228
[Train] epoch 275 Batch 3 Loss 0.2685132622718811
[Train] epoch 275 Batch 4 Loss 0.17028066515922546
[Train] epoch 275 Batch 5 Loss 0.23494140803813934
[Train] epoch 275 Batch 6 Loss 0.16824616491794586
[Train] epoch 275 Batch 7 Loss 0.13767112791538239
[Train] epoch 275 Batch 8 Loss 0.20242834091186523
[Train] epoch 275 Batch 9 Loss 0.035600077360868454
[Train] epoch 275 Batch 10 Loss 0.23603269457817078
[Train] epoch 275 Batch 11 Loss 0.1673281341791153
[Train] epoch 275 Batch 12 Loss 0.20203286409378052
[Train] epoch 275 Batch 13 Loss 0.2706279754638672
[Train] epoch 275 Batch 14 Loss 0.2040807604789734
[Train] epoch 275 Batch 15 Loss 0.10336427390575409
[Train] epoch 275 Batch 16 Loss 0.1682264655828476
[Train] epoch 275 Batch 17 Loss 0.1702679544687271
[Train] epoch 275 Batch 18 Loss 0.20308473706245422
[Train] epoch 275 Batch 19 Loss 0.2040250152349472
[Train] epoch 275 Batch 20 Loss 0.16712604463100433
[Train] epoch 275 Batch 21 Loss 0.13645513355731964
[Train] epoch 275 Batch 22 Loss 0.13424795866012573
[Train] epoch 275 Batch 23 Loss 0.035589106380939484
[Train] epoch 275 Batch 24 Loss 0.1351281702518463
[Train] epoch 275 Batch 25 Loss 0.10376206040382385
[Train] epoch 275 Batch 26 Loss 0.1017429381608963
[Train] epoch 275 Batch 27 Loss 0.36910632252693176
[Train] epoch 275 Batch 28 Loss 0.13910725712776184
[Train] epoch 275 Batch 29 Loss 0.27150410413742065
[Train] epoch 275 Batch 30 Loss 0.06866998225450516
[Train] epoch 275 Batch 31 Loss 0.13533249497413635
[Train] epoch 275 Batch 32 Loss 0.13441261649131775
[Train] epoch 275 Batch 33 Loss 0.30351608991622925
[Train] epoch 275 Batch 34 Loss 0.2699427604675293
[Train] epoch 275 Batch 35 Loss 0.07145664095878601
[Train] epoch 275 Batch 36 Loss 0.23571345210075378
[Train] epoch 275 Batch 37 Loss 0.270143061876297
[Train] epoch 275 Batch 38 Loss 0.10370185971260071
[Train] epoch 275 Batch 39 Loss 0.23641058802604675
[Train] epoch 275 Batch 40 Loss 0.0675690621137619
[Train] epoch 275 Batch 41 Loss 0.33444422483444214
[Train] epoch 275 Batch 42 Loss 0.10158960521221161
[Train] epoch 275 Batch 43 Loss 0.1344597190618515
[Train] epoch 275 Batch 44 Loss 0.16712641716003418
[Train] epoch 275 Batch 45 Loss 0.16860154271125793
[Train] epoch 275 Batch 46 Loss 0.10064473748207092
[Train] epoch 275 Batch 47 Loss 0.2371244728565216
[Train] epoch 276 Batch 0 Loss 0.26881611347198486
[Train] epoch 276 Batch 1 Loss 0.16947031021118164
[Train] epoch 276 Batch 2 Loss 0.10156489908695221
[Train] epoch 276 Batch 3 Loss 0.17461395263671875
[Train] epoch 276 Batch 4 Loss 0.13643689453601837
[Train] epoch 276 Batch 5 Loss 0.23514299094676971
[Train] epoch 276 Batch 6 Loss 0.37071242928504944
[Train] epoch 276 Batch 7 Loss 0.337060809135437
[Train] epoch 276 Batch 8 Loss 0.2699474096298218
[Train] epoch 276 Batch 9 Loss 0.20348875224590302
[Train] epoch 276 Batch 10 Loss 0.0021157856099307537
[Train] epoch 276 Batch 11 Loss 0.30500227212905884
[Train] epoch 276 Batch 12 Loss 0.03491499647498131
[Train] epoch 276 Batch 13 Loss 0.16730360686779022
[Train] epoch 276 Batch 14 Loss 0.2031272053718567
[Train] epoch 276 Batch 15 Loss 0.10063642263412476
[Train] epoch 276 Batch 16 Loss 0.2022787481546402
[Train] epoch 276 Batch 17 Loss 0.10388912260532379
[Train] epoch 276 Batch 18 Loss 0.03383764997124672
[Train] epoch 276 Batch 19 Loss 0.36964333057403564
[Train] epoch 276 Batch 20 Loss 0.1016736626625061
[Train] epoch 276 Batch 21 Loss 0.10284087061882019
[Train] epoch 276 Batch 22 Loss 0.10190193355083466
[Train] epoch 276 Batch 23 Loss 0.07003677636384964
[Train] epoch 276 Batch 24 Loss 0.03606724739074707
[Train] epoch 276 Batch 25 Loss 0.2700643539428711
[Train] epoch 276 Batch 26 Loss 0.13689424097537994
[Train] epoch 276 Batch 27 Loss 0.17072315514087677
[Train] epoch 276 Batch 28 Loss 0.16842789947986603
[Train] epoch 276 Batch 29 Loss 0.16719648241996765
[Train] epoch 276 Batch 30 Loss 0.133334219455719
[Train] epoch 276 Batch 31 Loss 0.20112624764442444
[Train] epoch 276 Batch 32 Loss 0.1726379096508026
[Train] epoch 276 Batch 33 Loss 0.2688100337982178
[Train] epoch 276 Batch 34 Loss 0.23718515038490295
[Train] epoch 276 Batch 35 Loss 0.2690810263156891
[Train] epoch 276 Batch 36 Loss 0.3356059789657593
[Train] epoch 276 Batch 37 Loss 0.13845068216323853
[Train] epoch 276 Batch 38 Loss 0.10163785517215729
[Train] epoch 276 Batch 39 Loss 0.0020431922748684883
[Train] epoch 276 Batch 40 Loss 0.20211762189865112
[Train] epoch 276 Batch 41 Loss 0.23499438166618347
[Train] epoch 276 Batch 42 Loss 0.06880833208560944
[Train] epoch 276 Batch 43 Loss 0.236246258020401
[Train] epoch 276 Batch 44 Loss 0.16916555166244507
[Train] epoch 276 Batch 45 Loss 0.23521818220615387
[Train] epoch 276 Batch 46 Loss 0.13686512410640717
[Train] epoch 276 Batch 47 Loss 0.1692984402179718
[Train] epoch 277 Batch 0 Loss 0.03381098434329033
[Train] epoch 277 Batch 1 Loss 0.2036425918340683
[Train] epoch 277 Batch 2 Loss 0.16809217631816864
[Train] epoch 277 Batch 3 Loss 0.16854725778102875
[Train] epoch 277 Batch 4 Loss 0.06865096092224121
[Train] epoch 277 Batch 5 Loss 0.16854578256607056
[Train] epoch 277 Batch 6 Loss 0.1354045569896698
[Train] epoch 277 Batch 7 Loss 0.27017074823379517
[Train] epoch 277 Batch 8 Loss 0.13530409336090088
[Train] epoch 277 Batch 9 Loss 0.16713649034500122
[Train] epoch 277 Batch 10 Loss 0.2698494791984558
[Train] epoch 277 Batch 11 Loss 0.10547740012407303
[Train] epoch 277 Batch 12 Loss 0.30286502838134766
[Train] epoch 277 Batch 13 Loss 0.2710837125778198
[Train] epoch 277 Batch 14 Loss 0.13556897640228271
[Train] epoch 277 Batch 15 Loss 0.13665273785591125
[Train] epoch 277 Batch 16 Loss 0.20429755747318268
[Train] epoch 277 Batch 17 Loss 0.20426252484321594
[Train] epoch 277 Batch 18 Loss 0.06889044493436813
[Train] epoch 277 Batch 19 Loss 0.13441568613052368
[Train] epoch 277 Batch 20 Loss 0.17123177647590637
[Train] epoch 277 Batch 21 Loss 0.23714089393615723
[Train] epoch 277 Batch 22 Loss 0.4021833539009094
[Train] epoch 277 Batch 23 Loss 0.168197900056839
[Train] epoch 277 Batch 24 Loss 0.30238115787506104
[Train] epoch 277 Batch 25 Loss 0.3344072997570038
[Train] epoch 277 Batch 26 Loss 0.10262437164783478
[Train] epoch 277 Batch 27 Loss 0.20394232869148254
[Train] epoch 277 Batch 28 Loss 0.2029239684343338
[Train] epoch 277 Batch 29 Loss 0.1342589259147644
[Train] epoch 277 Batch 30 Loss 0.23599764704704285
[Train] epoch 277 Batch 31 Loss 0.17012904584407806
[Train] epoch 277 Batch 32 Loss 0.06867669522762299
[Train] epoch 277 Batch 33 Loss 0.23519083857536316
[Train] epoch 277 Batch 34 Loss 0.17114216089248657
[Train] epoch 277 Batch 35 Loss 0.03565215319395065
[Train] epoch 277 Batch 36 Loss 0.2021462768316269
[Train] epoch 277 Batch 37 Loss 0.1683436632156372
[Train] epoch 277 Batch 38 Loss 0.36728525161743164
[Train] epoch 277 Batch 39 Loss 0.06759636104106903
[Train] epoch 277 Batch 40 Loss 0.13639678061008453
[Train] epoch 277 Batch 41 Loss 0.06864627450704575
[Train] epoch 277 Batch 42 Loss 0.20318490266799927
[Train] epoch 277 Batch 43 Loss 0.03579387813806534
[Train] epoch 277 Batch 44 Loss 0.06866328418254852
[Train] epoch 277 Batch 45 Loss 0.06881807744503021
[Train] epoch 277 Batch 46 Loss 0.23557165265083313
[Train] epoch 277 Batch 47 Loss 0.2695421576499939
[Train] epoch 278 Batch 0 Loss 0.1352921575307846
[Train] epoch 278 Batch 1 Loss 0.20193088054656982
[Train] epoch 278 Batch 2 Loss 0.20107033848762512
[Train] epoch 278 Batch 3 Loss 0.16906890273094177
[Train] epoch 278 Batch 4 Loss 0.13620883226394653
[Train] epoch 278 Batch 5 Loss 0.20279616117477417
[Train] epoch 278 Batch 6 Loss 0.10132531821727753
[Train] epoch 278 Batch 7 Loss 0.20246151089668274
[Train] epoch 278 Batch 8 Loss 0.16921654343605042
[Train] epoch 278 Batch 9 Loss 0.10150948166847229
[Train] epoch 278 Batch 10 Loss 0.06859640777111053
[Train] epoch 278 Batch 11 Loss 0.33525991439819336
[Train] epoch 278 Batch 12 Loss 0.27157220244407654
[Train] epoch 278 Batch 13 Loss 0.2038649320602417
[Train] epoch 278 Batch 14 Loss 0.1014995127916336
[Train] epoch 278 Batch 15 Loss 0.06772275269031525
[Train] epoch 278 Batch 16 Loss 0.06923940777778625
[Train] epoch 278 Batch 17 Loss 0.06754625588655472
[Train] epoch 278 Batch 18 Loss 0.13646596670150757
[Train] epoch 278 Batch 19 Loss 0.20225472748279572
[Train] epoch 278 Batch 20 Loss 0.06839119642972946
[Train] epoch 278 Batch 21 Loss 0.2697671353816986
[Train] epoch 278 Batch 22 Loss 0.36810433864593506
[Train] epoch 278 Batch 23 Loss 0.13707324862480164
[Train] epoch 278 Batch 24 Loss 0.336067259311676
[Train] epoch 278 Batch 25 Loss 0.2706424295902252
[Train] epoch 278 Batch 26 Loss 0.3024958372116089
[Train] epoch 278 Batch 27 Loss 0.16850194334983826
[Train] epoch 278 Batch 28 Loss 0.2678898870944977
[Train] epoch 278 Batch 29 Loss 0.033945344388484955
[Train] epoch 278 Batch 30 Loss 0.23706205189228058
[Train] epoch 278 Batch 31 Loss 0.13559305667877197
[Train] epoch 278 Batch 32 Loss 0.20357784628868103
[Train] epoch 278 Batch 33 Loss 0.10125760734081268
[Train] epoch 278 Batch 34 Loss 0.07021239399909973
[Train] epoch 278 Batch 35 Loss 0.3362080156803131
[Train] epoch 278 Batch 36 Loss 0.06854815781116486
[Train] epoch 278 Batch 37 Loss 0.13638658821582794
[Train] epoch 278 Batch 38 Loss 0.1341569721698761
[Train] epoch 278 Batch 39 Loss 0.0695490837097168
[Train] epoch 278 Batch 40 Loss 0.335348904132843
[Train] epoch 278 Batch 41 Loss 0.168955460190773
[Train] epoch 278 Batch 42 Loss 0.13538801670074463
[Train] epoch 278 Batch 43 Loss 0.2020314335823059
[Train] epoch 278 Batch 44 Loss 0.26970016956329346
[Train] epoch 278 Batch 45 Loss 0.16975492238998413
[Train] epoch 278 Batch 46 Loss 0.1711547076702118
[Train] epoch 278 Batch 47 Loss 0.10039545595645905
[Train] epoch 279 Batch 0 Loss 0.07011350989341736
[Train] epoch 279 Batch 1 Loss 0.16969409584999084
[Train] epoch 279 Batch 2 Loss 0.20221105217933655
[Train] epoch 279 Batch 3 Loss 0.17113032937049866
[Train] epoch 279 Batch 4 Loss 0.2697179615497589
[Train] epoch 279 Batch 5 Loss 0.13454464077949524
[Train] epoch 279 Batch 6 Loss 0.23475861549377441
[Train] epoch 279 Batch 7 Loss 0.16856375336647034
[Train] epoch 279 Batch 8 Loss 0.10060366988182068
[Train] epoch 279 Batch 9 Loss 0.06767648458480835
[Train] epoch 279 Batch 10 Loss 0.13538913428783417
[Train] epoch 279 Batch 11 Loss 0.33627307415008545
[Train] epoch 279 Batch 12 Loss 0.13613221049308777
[Train] epoch 279 Batch 13 Loss 0.13529178500175476
[Train] epoch 279 Batch 14 Loss 0.2706698179244995
[Train] epoch 279 Batch 15 Loss 0.10255903005599976
[Train] epoch 279 Batch 16 Loss 0.1692381203174591
[Train] epoch 279 Batch 17 Loss 0.2677452564239502
[Train] epoch 279 Batch 18 Loss 0.16931653022766113
[Train] epoch 279 Batch 19 Loss 0.16715815663337708
[Train] epoch 279 Batch 20 Loss 0.23610109090805054
[Train] epoch 279 Batch 21 Loss 0.269874632358551
[Train] epoch 279 Batch 22 Loss 0.1357027143239975
[Train] epoch 279 Batch 23 Loss 0.10156391561031342
[Train] epoch 279 Batch 24 Loss 0.1364089697599411
[Train] epoch 279 Batch 25 Loss 0.16936267912387848
[Train] epoch 279 Batch 26 Loss 0.06980860233306885
[Train] epoch 279 Batch 27 Loss 0.23588767647743225
[Train] epoch 279 Batch 28 Loss 0.10145975649356842
[Train] epoch 279 Batch 29 Loss 0.30270320177078247
[Train] epoch 279 Batch 30 Loss 0.26973405480384827
[Train] epoch 279 Batch 31 Loss 0.4020824432373047
[Train] epoch 279 Batch 32 Loss 0.17133980989456177
[Train] epoch 279 Batch 33 Loss 0.10157335549592972
[Train] epoch 279 Batch 34 Loss 0.17023828625679016
[Train] epoch 279 Batch 35 Loss 0.13756930828094482
[Train] epoch 279 Batch 36 Loss 0.23392170667648315
[Train] epoch 279 Batch 37 Loss 0.33658120036125183
[Train] epoch 279 Batch 38 Loss 0.16818244755268097
[Train] epoch 279 Batch 39 Loss 0.17236725986003876
[Train] epoch 279 Batch 40 Loss 0.10256892442703247
[Train] epoch 279 Batch 41 Loss 0.27179545164108276
[Train] epoch 279 Batch 42 Loss 0.06775464117527008
[Train] epoch 279 Batch 43 Loss 0.10155533254146576
[Train] epoch 279 Batch 44 Loss 0.13532809913158417
[Train] epoch 279 Batch 45 Loss 0.10254484415054321
[Train] epoch 279 Batch 46 Loss 0.2020440399646759
[Train] epoch 279 Batch 47 Loss 0.033919986337423325
[Train] epoch 280 Batch 0 Loss 0.0368218831717968
[Train] epoch 280 Batch 1 Loss 0.20212672650814056
[Train] epoch 280 Batch 2 Loss 0.06783808767795563
[Train] epoch 280 Batch 3 Loss 0.20193183422088623
[Train] epoch 280 Batch 4 Loss 0.2029428780078888
[Train] epoch 280 Batch 5 Loss 0.23815186321735382
[Train] epoch 280 Batch 6 Loss 0.13427871465682983
[Train] epoch 280 Batch 7 Loss 0.23391860723495483
[Train] epoch 280 Batch 8 Loss 0.1353439837694168
[Train] epoch 280 Batch 9 Loss 0.20200777053833008
[Train] epoch 280 Batch 10 Loss 0.1354677826166153
[Train] epoch 280 Batch 11 Loss 0.13642846047878265
[Train] epoch 280 Batch 12 Loss 0.2041265219449997
[Train] epoch 280 Batch 13 Loss 0.10340472310781479
[Train] epoch 280 Batch 14 Loss 0.23574592173099518
[Train] epoch 280 Batch 15 Loss 0.10246467590332031
[Train] epoch 280 Batch 16 Loss 0.13722074031829834
[Train] epoch 280 Batch 17 Loss 0.0705718845129013
[Train] epoch 280 Batch 18 Loss 0.2019755244255066
[Train] epoch 280 Batch 19 Loss 0.1353042721748352
[Train] epoch 280 Batch 20 Loss 0.10241031646728516
[Train] epoch 280 Batch 21 Loss 0.33449897170066833
[Train] epoch 280 Batch 22 Loss 0.2694462239742279
[Train] epoch 280 Batch 23 Loss 0.1354312300682068
[Train] epoch 280 Batch 24 Loss 0.10267743468284607
[Train] epoch 280 Batch 25 Loss 0.20477135479450226
[Train] epoch 280 Batch 26 Loss 0.10058280825614929
[Train] epoch 280 Batch 27 Loss 0.16841262578964233
[Train] epoch 280 Batch 28 Loss 0.10227736830711365
[Train] epoch 280 Batch 29 Loss 0.1023939847946167
[Train] epoch 280 Batch 30 Loss 0.06857235729694366
[Train] epoch 280 Batch 31 Loss 0.1013215035200119
[Train] epoch 280 Batch 32 Loss 0.06874144822359085
[Train] epoch 280 Batch 33 Loss 0.3681080937385559
[Train] epoch 280 Batch 34 Loss 0.1004549115896225
[Train] epoch 280 Batch 35 Loss 0.06964142620563507
[Train] epoch 280 Batch 36 Loss 0.3024684190750122
[Train] epoch 280 Batch 37 Loss 0.20219293236732483
[Train] epoch 280 Batch 38 Loss 0.2010066956281662
[Train] epoch 280 Batch 39 Loss 0.3037751615047455
[Train] epoch 280 Batch 40 Loss 0.20089873671531677
[Train] epoch 280 Batch 41 Loss 0.3375762701034546
[Train] epoch 280 Batch 42 Loss 0.23594240844249725
[Train] epoch 280 Batch 43 Loss 0.23678505420684814
[Train] epoch 280 Batch 44 Loss 0.17176535725593567
[Train] epoch 280 Batch 45 Loss 0.3353566527366638
[Train] epoch 280 Batch 46 Loss 0.16899773478507996
[Train] epoch 280 Batch 47 Loss 0.20115655660629272
[Train] epoch 281 Batch 0 Loss 0.20201674103736877
[Train] epoch 281 Batch 1 Loss 0.10261639952659607
[Train] epoch 281 Batch 2 Loss 0.10231725871562958
[Train] epoch 281 Batch 3 Loss 0.13636115193367004
[Train] epoch 281 Batch 4 Loss 0.16900058090686798
[Train] epoch 281 Batch 5 Loss 0.13418765366077423
[Train] epoch 281 Batch 6 Loss 0.20370768010616302
[Train] epoch 281 Batch 7 Loss 0.16839507222175598
[Train] epoch 281 Batch 8 Loss 0.1031450480222702
[Train] epoch 281 Batch 9 Loss 0.1694040447473526
[Train] epoch 281 Batch 10 Loss 0.2020193636417389
[Train] epoch 281 Batch 11 Loss 0.10228633135557175
[Train] epoch 281 Batch 12 Loss 0.06837485730648041
[Train] epoch 281 Batch 13 Loss 0.06767383217811584
[Train] epoch 281 Batch 14 Loss 0.20368993282318115
[Train] epoch 281 Batch 15 Loss 0.16824573278427124
[Train] epoch 281 Batch 16 Loss 0.201839879155159
[Train] epoch 281 Batch 17 Loss 0.06852702796459198
[Train] epoch 281 Batch 18 Loss 0.16905280947685242
[Train] epoch 281 Batch 19 Loss 0.2049790918827057
[Train] epoch 281 Batch 20 Loss 0.13533219695091248
[Train] epoch 281 Batch 21 Loss 0.33615827560424805
[Train] epoch 281 Batch 22 Loss 0.23651355504989624
[Train] epoch 281 Batch 23 Loss 0.16808709502220154
[Train] epoch 281 Batch 24 Loss 0.2008247673511505
[Train] epoch 281 Batch 25 Loss 0.1364433765411377
[Train] epoch 281 Batch 26 Loss 0.2008434385061264
[Train] epoch 281 Batch 27 Loss 0.1696973443031311
[Train] epoch 281 Batch 28 Loss 0.2382107377052307
[Train] epoch 281 Batch 29 Loss 0.30041950941085815
[Train] epoch 281 Batch 30 Loss 0.16820555925369263
[Train] epoch 281 Batch 31 Loss 0.23737365007400513
[Train] epoch 281 Batch 32 Loss 0.1698468178510666
[Train] epoch 281 Batch 33 Loss 0.1678922176361084
[Train] epoch 281 Batch 34 Loss 0.2691115438938141
[Train] epoch 281 Batch 35 Loss 0.10122017562389374
[Train] epoch 281 Batch 36 Loss 0.469771146774292
[Train] epoch 281 Batch 37 Loss 0.10155174881219864
[Train] epoch 281 Batch 38 Loss 0.06780650466680527
[Train] epoch 281 Batch 39 Loss 0.16961514949798584
[Train] epoch 281 Batch 40 Loss 0.2337433397769928
[Train] epoch 281 Batch 41 Loss 0.036173369735479355
[Train] epoch 281 Batch 42 Loss 0.1699843853712082
[Train] epoch 281 Batch 43 Loss 0.13508296012878418
[Train] epoch 281 Batch 44 Loss 0.2346743941307068
[Train] epoch 281 Batch 45 Loss 0.2011374980211258
[Train] epoch 281 Batch 46 Loss 0.20192617177963257
[Train] epoch 281 Batch 47 Loss 0.2028767168521881
[Train] epoch 282 Batch 0 Loss 0.06824082881212234
[Train] epoch 282 Batch 1 Loss 0.2709239721298218
[Train] epoch 282 Batch 2 Loss 0.16997705399990082
[Train] epoch 282 Batch 3 Loss 0.10056822001934052
[Train] epoch 282 Batch 4 Loss 0.30170199275016785
[Train] epoch 282 Batch 5 Loss 0.16836819052696228
[Train] epoch 282 Batch 6 Loss 0.20191262662410736
[Train] epoch 282 Batch 7 Loss 0.06998471915721893
[Train] epoch 282 Batch 8 Loss 0.30151131749153137
[Train] epoch 282 Batch 9 Loss 0.2034577578306198
[Train] epoch 282 Batch 10 Loss 0.06840377300977707
[Train] epoch 282 Batch 11 Loss 0.16802522540092468
[Train] epoch 282 Batch 12 Loss 0.2015630304813385
[Train] epoch 282 Batch 13 Loss 0.20288050174713135
[Train] epoch 282 Batch 14 Loss 0.20226071774959564
[Train] epoch 282 Batch 15 Loss 0.10135271400213242
[Train] epoch 282 Batch 16 Loss 0.2674533426761627
[Train] epoch 282 Batch 17 Loss 0.1355181336402893
[Train] epoch 282 Batch 18 Loss 0.03374840319156647
[Train] epoch 282 Batch 19 Loss 0.13530048727989197
[Train] epoch 282 Batch 20 Loss 0.20301440358161926
[Train] epoch 282 Batch 21 Loss 0.10434727370738983
[Train] epoch 282 Batch 22 Loss 0.17033208906650543
[Train] epoch 282 Batch 23 Loss 0.2030629813671112
[Train] epoch 282 Batch 24 Loss 0.17032082378864288
[Train] epoch 282 Batch 25 Loss 0.1030162125825882
[Train] epoch 282 Batch 26 Loss 0.2720451354980469
[Train] epoch 282 Batch 27 Loss 0.1682925820350647
[Train] epoch 282 Batch 28 Loss 0.13777592778205872
[Train] epoch 282 Batch 29 Loss 0.20110997557640076
[Train] epoch 282 Batch 30 Loss 0.16841232776641846
[Train] epoch 282 Batch 31 Loss 0.13447795808315277
[Train] epoch 282 Batch 32 Loss 0.03503440320491791
[Train] epoch 282 Batch 33 Loss 0.13675321638584137
[Train] epoch 282 Batch 34 Loss 0.2701008915901184
[Train] epoch 282 Batch 35 Loss 0.20586997270584106
[Train] epoch 282 Batch 36 Loss 0.2701767086982727
[Train] epoch 282 Batch 37 Loss 0.23629820346832275
[Train] epoch 282 Batch 38 Loss 0.23618510365486145
[Train] epoch 282 Batch 39 Loss 0.20474398136138916
[Train] epoch 282 Batch 40 Loss 0.10287682712078094
[Train] epoch 282 Batch 41 Loss 0.20229971408843994
[Train] epoch 282 Batch 42 Loss 0.133334219455719
[Train] epoch 282 Batch 43 Loss 0.07026912271976471
[Train] epoch 282 Batch 44 Loss 0.30291634798049927
[Train] epoch 282 Batch 45 Loss 0.10055867582559586
[Train] epoch 282 Batch 46 Loss 0.13579200208187103
[Train] epoch 282 Batch 47 Loss 0.36841708421707153
[Train] epoch 283 Batch 0 Loss 0.2700871527194977
[Train] epoch 283 Batch 1 Loss 0.30168232321739197
[Train] epoch 283 Batch 2 Loss 0.06901310384273529
[Train] epoch 283 Batch 3 Loss 0.133334219455719
[Train] epoch 283 Batch 4 Loss 0.17182227969169617
[Train] epoch 283 Batch 5 Loss 0.16727644205093384
[Train] epoch 283 Batch 6 Loss 0.03389238193631172
[Train] epoch 283 Batch 7 Loss 0.1707231104373932
[Train] epoch 283 Batch 8 Loss 0.202327162027359
[Train] epoch 283 Batch 9 Loss 0.23621535301208496
[Train] epoch 283 Batch 10 Loss 0.2374163120985031
[Train] epoch 283 Batch 11 Loss 0.23972347378730774
[Train] epoch 283 Batch 12 Loss 0.2701776623725891
[Train] epoch 283 Batch 13 Loss 0.1694817841053009
[Train] epoch 283 Batch 14 Loss 0.270072340965271
[Train] epoch 283 Batch 15 Loss 0.23389160633087158
[Train] epoch 283 Batch 16 Loss 0.13558629155158997
[Train] epoch 283 Batch 17 Loss 0.169473335146904
[Train] epoch 283 Batch 18 Loss 0.1367102563381195
[Train] epoch 283 Batch 19 Loss 0.10397186875343323
[Train] epoch 283 Batch 20 Loss 0.10391787439584732
[Train] epoch 283 Batch 21 Loss 0.13563770055770874
[Train] epoch 283 Batch 22 Loss 0.2022547423839569
[Train] epoch 283 Batch 23 Loss 0.1367187649011612
[Train] epoch 283 Batch 24 Loss 0.2688899636268616
[Train] epoch 283 Batch 25 Loss 0.2688441276550293
[Train] epoch 283 Batch 26 Loss 0.10170245915651321
[Train] epoch 283 Batch 27 Loss 0.20111271739006042
[Train] epoch 283 Batch 28 Loss 0.13780803978443146
[Train] epoch 283 Batch 29 Loss 0.06881608068943024
[Train] epoch 283 Batch 30 Loss 0.1695023775100708
[Train] epoch 283 Batch 31 Loss 0.1027744859457016
[Train] epoch 283 Batch 32 Loss 0.3050130307674408
[Train] epoch 283 Batch 33 Loss 0.20336061716079712
[Train] epoch 283 Batch 34 Loss 0.10275113582611084
[Train] epoch 283 Batch 35 Loss 0.16829688847064972
[Train] epoch 283 Batch 36 Loss 0.13658374547958374
[Train] epoch 283 Batch 37 Loss 0.1682908535003662
[Train] epoch 283 Batch 38 Loss 0.10709376633167267
[Train] epoch 283 Batch 39 Loss 0.1354961097240448
[Train] epoch 283 Batch 40 Loss 0.10164050757884979
[Train] epoch 283 Batch 41 Loss 0.20221999287605286
[Train] epoch 283 Batch 42 Loss 0.1682817041873932
[Train] epoch 283 Batch 43 Loss 0.30270883440971375
[Train] epoch 283 Batch 44 Loss 0.23388834297657013
[Train] epoch 283 Batch 45 Loss 0.26878347992897034
[Train] epoch 283 Batch 46 Loss 0.06885048002004623
[Train] epoch 283 Batch 47 Loss 0.13551312685012817
[Train] epoch 284 Batch 0 Loss 0.03705652058124542
[Train] epoch 284 Batch 1 Loss 0.4021947383880615
[Train] epoch 284 Batch 2 Loss 0.06982993334531784
[Train] epoch 284 Batch 3 Loss 0.16932913661003113
[Train] epoch 284 Batch 4 Loss 0.16820643842220306
[Train] epoch 284 Batch 5 Loss 0.33764684200286865
[Train] epoch 284 Batch 6 Loss 0.2000008225440979
[Train] epoch 284 Batch 7 Loss 0.06981666386127472
[Train] epoch 284 Batch 8 Loss 0.1355157494544983
[Train] epoch 284 Batch 9 Loss 0.1692695915699005
[Train] epoch 284 Batch 10 Loss 0.27089419960975647
[Train] epoch 284 Batch 11 Loss 0.17033714056015015
[Train] epoch 284 Batch 12 Loss 0.2349565625190735
[Train] epoch 284 Batch 13 Loss 0.26666736602783203
[Train] epoch 284 Batch 14 Loss 0.1682526171207428
[Train] epoch 284 Batch 15 Loss 0.2020997405052185
[Train] epoch 284 Batch 16 Loss 0.30271875858306885
[Train] epoch 284 Batch 17 Loss 0.23494845628738403
[Train] epoch 284 Batch 18 Loss 0.10348545014858246
[Train] epoch 284 Batch 19 Loss 0.3025932013988495
[Train] epoch 284 Batch 20 Loss 0.102670818567276
[Train] epoch 284 Batch 21 Loss 0.10266786813735962
[Train] epoch 284 Batch 22 Loss 0.2020416557788849
[Train] epoch 284 Batch 23 Loss 0.2347886562347412
[Train] epoch 284 Batch 24 Loss 0.10149720311164856
[Train] epoch 284 Batch 25 Loss 0.20105427503585815
[Train] epoch 284 Batch 26 Loss 0.06971544772386551
[Train] epoch 284 Batch 27 Loss 0.13438580930233002
[Train] epoch 284 Batch 28 Loss 0.20199154317378998
[Train] epoch 284 Batch 29 Loss 0.1383858472108841
[Train] epoch 284 Batch 30 Loss 0.13539865612983704
[Train] epoch 284 Batch 31 Loss 0.036726489663124084
[Train] epoch 284 Batch 32 Loss 0.10146088898181915
[Train] epoch 284 Batch 33 Loss 0.13627496361732483
[Train] epoch 284 Batch 34 Loss 0.13724994659423828
[Train] epoch 284 Batch 35 Loss 0.20300713181495667
[Train] epoch 284 Batch 36 Loss 0.201097309589386
[Train] epoch 284 Batch 37 Loss 0.10345752537250519
[Train] epoch 284 Batch 38 Loss 0.17115363478660583
[Train] epoch 284 Batch 39 Loss 0.20204156637191772
[Train] epoch 284 Batch 40 Loss 0.0685817152261734
[Train] epoch 284 Batch 41 Loss 0.20197218656539917
[Train] epoch 284 Batch 42 Loss 0.20290657877922058
[Train] epoch 284 Batch 43 Loss 0.26869678497314453
[Train] epoch 284 Batch 44 Loss 0.2686944305896759
[Train] epoch 284 Batch 45 Loss 0.20212219655513763
[Train] epoch 284 Batch 46 Loss 0.06862214207649231
[Train] epoch 284 Batch 47 Loss 0.20406901836395264
[Train] epoch 285 Batch 0 Loss 0.33637532591819763
[Train] epoch 285 Batch 1 Loss 0.20290932059288025
[Train] epoch 285 Batch 2 Loss 0.2337796688079834
[Train] epoch 285 Batch 3 Loss 0.2376539558172226
[Train] epoch 285 Batch 4 Loss 0.10146261751651764
[Train] epoch 285 Batch 5 Loss 0.16830548644065857
[Train] epoch 285 Batch 6 Loss 0.10250389575958252
[Train] epoch 285 Batch 7 Loss 0.03380397707223892
[Train] epoch 285 Batch 8 Loss 0.0685616284608841
[Train] epoch 285 Batch 9 Loss 0.10046885907649994
[Train] epoch 285 Batch 10 Loss 0.10321119427680969
[Train] epoch 285 Batch 11 Loss 0.06954111158847809
[Train] epoch 285 Batch 12 Loss 0.07038157433271408
[Train] epoch 285 Batch 13 Loss 0.16822101175785065
[Train] epoch 285 Batch 14 Loss 0.07039579749107361
[Train] epoch 285 Batch 15 Loss 0.2359464168548584
[Train] epoch 285 Batch 16 Loss 0.23485606908798218
[Train] epoch 285 Batch 17 Loss 0.3016335964202881
[Train] epoch 285 Batch 18 Loss 0.20186671614646912
[Train] epoch 285 Batch 19 Loss 0.23465310037136078
[Train] epoch 285 Batch 20 Loss 0.033878158777952194
[Train] epoch 285 Batch 21 Loss 0.13524729013442993
[Train] epoch 285 Batch 22 Loss 0.20100009441375732
[Train] epoch 285 Batch 23 Loss 0.06857554614543915
[Train] epoch 285 Batch 24 Loss 0.2696322202682495
[Train] epoch 285 Batch 25 Loss 0.16829679906368256
[Train] epoch 285 Batch 26 Loss 0.13518179953098297
[Train] epoch 285 Batch 27 Loss 0.20178291201591492
[Train] epoch 285 Batch 28 Loss 0.3374653160572052
[Train] epoch 285 Batch 29 Loss 0.17007169127464294
[Train] epoch 285 Batch 30 Loss 0.13619187474250793
[Train] epoch 285 Batch 31 Loss 0.23873811960220337
[Train] epoch 285 Batch 32 Loss 0.23465237021446228
[Train] epoch 285 Batch 33 Loss 0.1672089546918869
[Train] epoch 285 Batch 34 Loss 0.102328822016716
[Train] epoch 285 Batch 35 Loss 0.20277123153209686
[Train] epoch 285 Batch 36 Loss 0.20172934234142303
[Train] epoch 285 Batch 37 Loss 0.30315476655960083
[Train] epoch 285 Batch 38 Loss 0.10149969160556793
[Train] epoch 285 Batch 39 Loss 0.2713344395160675
[Train] epoch 285 Batch 40 Loss 0.1688976287841797
[Train] epoch 285 Batch 41 Loss 0.0017378595657646656
[Train] epoch 285 Batch 42 Loss 0.23475252091884613
[Train] epoch 285 Batch 43 Loss 0.27120429277420044
[Train] epoch 285 Batch 44 Loss 0.2010800987482071
[Train] epoch 285 Batch 45 Loss 0.20203113555908203
[Train] epoch 285 Batch 46 Loss 0.13684996962547302
[Train] epoch 285 Batch 47 Loss 0.23666608333587646
[Train] epoch 286 Batch 0 Loss 0.20215678215026855
[Train] epoch 286 Batch 1 Loss 0.1032421812415123
[Train] epoch 286 Batch 2 Loss 0.10137926042079926
[Train] epoch 286 Batch 3 Loss 0.13514211773872375
[Train] epoch 286 Batch 4 Loss 0.3015071749687195
[Train] epoch 286 Batch 5 Loss 0.20193561911582947
[Train] epoch 286 Batch 6 Loss 0.03545466810464859
[Train] epoch 286 Batch 7 Loss 0.2355664074420929
[Train] epoch 286 Batch 8 Loss 0.16827106475830078
[Train] epoch 286 Batch 9 Loss 0.13523562252521515
[Train] epoch 286 Batch 10 Loss 0.3043566644191742
[Train] epoch 286 Batch 11 Loss 0.10148638486862183
[Train] epoch 286 Batch 12 Loss 0.036448799073696136
[Train] epoch 286 Batch 13 Loss 0.13695503771305084
[Train] epoch 286 Batch 14 Loss 0.26763468980789185
[Train] epoch 286 Batch 15 Loss 0.30234742164611816
[Train] epoch 286 Batch 16 Loss 0.23565708100795746
[Train] epoch 286 Batch 17 Loss 0.16849061846733093
[Train] epoch 286 Batch 18 Loss 0.23470507562160492
[Train] epoch 286 Batch 19 Loss 0.03473762050271034
[Train] epoch 286 Batch 20 Loss 0.06934152543544769
[Train] epoch 286 Batch 21 Loss 0.33729463815689087
[Train] epoch 286 Batch 22 Loss 0.10140390694141388
[Train] epoch 286 Batch 23 Loss 0.2711796462535858
[Train] epoch 286 Batch 24 Loss 0.06832783669233322
[Train] epoch 286 Batch 25 Loss 0.13609230518341064
[Train] epoch 286 Batch 26 Loss 0.2695850729942322
[Train] epoch 286 Batch 27 Loss 0.23661676049232483
[Train] epoch 286 Batch 28 Loss 0.23559708893299103
[Train] epoch 286 Batch 29 Loss 0.20177432894706726
[Train] epoch 286 Batch 30 Loss 0.13602906465530396
[Train] epoch 286 Batch 31 Loss 0.06773506104946136
[Train] epoch 286 Batch 32 Loss 0.2676546275615692
[Train] epoch 286 Batch 33 Loss 0.2036713808774948
[Train] epoch 286 Batch 34 Loss 0.20277926325798035
[Train] epoch 286 Batch 35 Loss 0.20255857706069946
[Train] epoch 286 Batch 36 Loss 0.1705441176891327
[Train] epoch 286 Batch 37 Loss 0.06760285794734955
[Train] epoch 286 Batch 38 Loss 0.20178180932998657
[Train] epoch 286 Batch 39 Loss 0.1360958069562912
[Train] epoch 286 Batch 40 Loss 0.17215606570243835
[Train] epoch 286 Batch 41 Loss 0.20098185539245605
[Train] epoch 286 Batch 42 Loss 0.23386985063552856
[Train] epoch 286 Batch 43 Loss 0.06745554506778717
[Train] epoch 286 Batch 44 Loss 0.23386991024017334
[Train] epoch 286 Batch 45 Loss 0.1353835165500641
[Train] epoch 286 Batch 46 Loss 0.133334219455719
[Train] epoch 286 Batch 47 Loss 0.20332477986812592
[Train] epoch 287 Batch 0 Loss 0.16705793142318726
[Train] epoch 287 Batch 1 Loss 0.16720324754714966
[Train] epoch 287 Batch 2 Loss 0.26929545402526855
[Train] epoch 287 Batch 3 Loss 0.13547684252262115
[Train] epoch 287 Batch 4 Loss 0.23761320114135742
[Train] epoch 287 Batch 5 Loss 0.2036927342414856
[Train] epoch 287 Batch 6 Loss 0.1678778976202011
[Train] epoch 287 Batch 7 Loss 0.13497765362262726
[Train] epoch 287 Batch 8 Loss 0.2010706067085266
[Train] epoch 287 Batch 9 Loss 0.2346394956111908
[Train] epoch 287 Batch 10 Loss 0.17149583995342255
[Train] epoch 287 Batch 11 Loss 0.16710039973258972
[Train] epoch 287 Batch 12 Loss 0.2009185403585434
[Train] epoch 287 Batch 13 Loss 0.03463495522737503
[Train] epoch 287 Batch 14 Loss 0.06743241101503372
[Train] epoch 287 Batch 15 Loss 0.16816580295562744
[Train] epoch 287 Batch 16 Loss 0.20172734558582306
[Train] epoch 287 Batch 17 Loss 0.10149721801280975
[Train] epoch 287 Batch 18 Loss 0.20091503858566284
[Train] epoch 287 Batch 19 Loss 0.10219833254814148
[Train] epoch 287 Batch 20 Loss 0.2039986252784729
[Train] epoch 287 Batch 21 Loss 0.20202693343162537
[Train] epoch 287 Batch 22 Loss 0.16886934638023376
[Train] epoch 287 Batch 23 Loss 0.16880762577056885
[Train] epoch 287 Batch 24 Loss 0.10224581509828568
[Train] epoch 287 Batch 25 Loss 0.23755095899105072
[Train] epoch 287 Batch 26 Loss 0.16961339116096497
[Train] epoch 287 Batch 27 Loss 0.1381622850894928
[Train] epoch 287 Batch 28 Loss 0.10120302438735962
[Train] epoch 287 Batch 29 Loss 0.06926097720861435
[Train] epoch 287 Batch 30 Loss 0.16804850101470947
[Train] epoch 287 Batch 31 Loss 0.06765732169151306
[Train] epoch 287 Batch 32 Loss 0.1689002364873886
[Train] epoch 287 Batch 33 Loss 0.16893155872821808
[Train] epoch 287 Batch 34 Loss 0.16809827089309692
[Train] epoch 287 Batch 35 Loss 0.20105165243148804
[Train] epoch 287 Batch 36 Loss 0.16897889971733093
[Train] epoch 287 Batch 37 Loss 0.20300453901290894
[Train] epoch 287 Batch 38 Loss 0.13427400588989258
[Train] epoch 287 Batch 39 Loss 0.2037736177444458
[Train] epoch 287 Batch 40 Loss 0.20382127165794373
[Train] epoch 287 Batch 41 Loss 0.30155718326568604
[Train] epoch 287 Batch 42 Loss 0.3691093921661377
[Train] epoch 287 Batch 43 Loss 0.20387372374534607
[Train] epoch 287 Batch 44 Loss 0.10244961082935333
[Train] epoch 287 Batch 45 Loss 0.169127956032753
[Train] epoch 287 Batch 46 Loss 0.33638858795166016
[Train] epoch 287 Batch 47 Loss 0.17100659012794495
[Train] epoch 288 Batch 0 Loss 0.2020132839679718
[Train] epoch 288 Batch 1 Loss 0.30336862802505493
[Train] epoch 288 Batch 2 Loss 0.13527874648571014
[Train] epoch 288 Batch 3 Loss 0.1042046919465065
[Train] epoch 288 Batch 4 Loss 0.36906176805496216
[Train] epoch 288 Batch 5 Loss 0.20194286108016968
[Train] epoch 288 Batch 6 Loss 0.10335852205753326
[Train] epoch 288 Batch 7 Loss 0.2020755559206009
[Train] epoch 288 Batch 8 Loss 0.06860482692718506
[Train] epoch 288 Batch 9 Loss 0.07046666741371155
[Train] epoch 288 Batch 10 Loss 0.27053186297416687
[Train] epoch 288 Batch 11 Loss 0.10244645178318024
[Train] epoch 288 Batch 12 Loss 0.2348116934299469
[Train] epoch 288 Batch 13 Loss 0.23488852381706238
[Train] epoch 288 Batch 14 Loss 0.1680763065814972
[Train] epoch 288 Batch 15 Loss 0.3353172540664673
[Train] epoch 288 Batch 16 Loss 0.0685730129480362
[Train] epoch 288 Batch 17 Loss 0.1023658961057663
[Train] epoch 288 Batch 18 Loss 0.13517875969409943
[Train] epoch 288 Batch 19 Loss 0.10426674038171768
[Train] epoch 288 Batch 20 Loss 0.2018277943134308
[Train] epoch 288 Batch 21 Loss 0.2028595209121704
[Train] epoch 288 Batch 22 Loss 0.1351677030324936
[Train] epoch 288 Batch 23 Loss 0.10335017740726471
[Train] epoch 288 Batch 24 Loss 0.13427135348320007
[Train] epoch 288 Batch 25 Loss 0.2694898843765259
[Train] epoch 288 Batch 26 Loss 0.2029172033071518
[Train] epoch 288 Batch 27 Loss 0.13535913825035095
[Train] epoch 288 Batch 28 Loss 0.16819533705711365
[Train] epoch 288 Batch 29 Loss 0.0675320252776146
[Train] epoch 288 Batch 30 Loss 0.16813042759895325
[Train] epoch 288 Batch 31 Loss 0.10316160321235657
[Train] epoch 288 Batch 32 Loss 0.4357510507106781
[Train] epoch 288 Batch 33 Loss 0.33436474204063416
[Train] epoch 288 Batch 34 Loss 0.0685281828045845
[Train] epoch 288 Batch 35 Loss 0.168212890625
[Train] epoch 288 Batch 36 Loss 0.30148887634277344
[Train] epoch 288 Batch 37 Loss 0.20382356643676758
[Train] epoch 288 Batch 38 Loss 0.37088340520858765
[Train] epoch 288 Batch 39 Loss 0.1015138328075409
[Train] epoch 288 Batch 40 Loss 0.0356026366353035
[Train] epoch 288 Batch 41 Loss 0.0009051620727404952
[Train] epoch 288 Batch 42 Loss 0.23484236001968384
[Train] epoch 288 Batch 43 Loss 0.1352626383304596
[Train] epoch 288 Batch 44 Loss 0.035553958266973495
[Train] epoch 288 Batch 45 Loss 0.23779086768627167
[Train] epoch 288 Batch 46 Loss 0.16897234320640564
[Train] epoch 288 Batch 47 Loss 0.1679229587316513
[Train] epoch 289 Batch 0 Loss 0.03468278422951698
[Train] epoch 289 Batch 1 Loss 0.1352500319480896
[Train] epoch 289 Batch 2 Loss 0.1698867678642273
[Train] epoch 289 Batch 3 Loss 0.10051348805427551
[Train] epoch 289 Batch 4 Loss 0.20192378759384155
[Train] epoch 289 Batch 5 Loss 0.20543013513088226
[Train] epoch 289 Batch 6 Loss 0.10212311893701553
[Train] epoch 289 Batch 7 Loss 0.4702743887901306
[Train] epoch 289 Batch 8 Loss 0.13596586883068085
[Train] epoch 289 Batch 9 Loss 0.10133446753025055
[Train] epoch 289 Batch 10 Loss 0.06748655438423157
[Train] epoch 289 Batch 11 Loss 0.33696842193603516
[Train] epoch 289 Batch 12 Loss 0.13680817186832428
[Train] epoch 289 Batch 13 Loss 0.16880643367767334
[Train] epoch 289 Batch 14 Loss 0.20285767316818237
[Train] epoch 289 Batch 15 Loss 0.20199131965637207
[Train] epoch 289 Batch 16 Loss 0.16798582673072815
[Train] epoch 289 Batch 17 Loss 0.30233973264694214
[Train] epoch 289 Batch 18 Loss 0.0684933140873909
[Train] epoch 289 Batch 19 Loss 0.07093971222639084
[Train] epoch 289 Batch 20 Loss 0.16905024647712708
[Train] epoch 289 Batch 21 Loss 0.10210910439491272
[Train] epoch 289 Batch 22 Loss 0.133334219455719
[Train] epoch 289 Batch 23 Loss 0.3352494537830353
[Train] epoch 289 Batch 24 Loss 0.03452518582344055
[Train] epoch 289 Batch 25 Loss 0.30153071880340576
[Train] epoch 289 Batch 26 Loss 0.3359863758087158
[Train] epoch 289 Batch 27 Loss 0.10297812521457672
[Train] epoch 289 Batch 28 Loss 0.16801390051841736
[Train] epoch 289 Batch 29 Loss 0.13743335008621216
[Train] epoch 289 Batch 30 Loss 0.16896018385887146
[Train] epoch 289 Batch 31 Loss 0.13518409430980682
[Train] epoch 289 Batch 32 Loss 0.2676151990890503
[Train] epoch 289 Batch 33 Loss 0.10126729309558868
[Train] epoch 289 Batch 34 Loss 0.23544913530349731
[Train] epoch 289 Batch 35 Loss 0.1681937575340271
[Train] epoch 289 Batch 36 Loss 0.1353687047958374
[Train] epoch 289 Batch 37 Loss 0.17037175595760345
[Train] epoch 289 Batch 38 Loss 0.26935315132141113
[Train] epoch 289 Batch 39 Loss 0.30234453082084656
[Train] epoch 289 Batch 40 Loss 0.0338423028588295
[Train] epoch 289 Batch 41 Loss 0.03615320846438408
[Train] epoch 289 Batch 42 Loss 0.2703591287136078
[Train] epoch 289 Batch 43 Loss 0.1681118905544281
[Train] epoch 289 Batch 44 Loss 0.10038448870182037
[Train] epoch 289 Batch 45 Loss 0.13508163392543793
[Train] epoch 289 Batch 46 Loss 0.167984277009964
[Train] epoch 289 Batch 47 Loss 0.3353605568408966
[Train] epoch 290 Batch 0 Loss 0.20245783030986786
[Train] epoch 290 Batch 1 Loss 0.1351078897714615
[Train] epoch 290 Batch 2 Loss 0.16882920265197754
[Train] epoch 290 Batch 3 Loss 0.23459947109222412
[Train] epoch 290 Batch 4 Loss 0.06835523992776871
[Train] epoch 290 Batch 5 Loss 0.0007579574594274163
[Train] epoch 290 Batch 6 Loss 0.1681838035583496
[Train] epoch 290 Batch 7 Loss 0.0338396281003952
[Train] epoch 290 Batch 8 Loss 0.2691865861415863
[Train] epoch 290 Batch 9 Loss 0.1348857581615448
[Train] epoch 290 Batch 10 Loss 0.23635616898536682
[Train] epoch 290 Batch 11 Loss 0.03693133592605591
[Train] epoch 290 Batch 12 Loss 0.033753011375665665
[Train] epoch 290 Batch 13 Loss 0.2682952880859375
[Train] epoch 290 Batch 14 Loss 0.3023049533367157
[Train] epoch 290 Batch 15 Loss 0.1349135786294937
[Train] epoch 290 Batch 16 Loss 0.26907846331596375
[Train] epoch 290 Batch 17 Loss 0.16787023842334747
[Train] epoch 290 Batch 18 Loss 0.26951178908348083
[Train] epoch 290 Batch 19 Loss 0.06911210715770721
[Train] epoch 290 Batch 20 Loss 0.16891874372959137
[Train] epoch 290 Batch 21 Loss 0.13521429896354675
[Train] epoch 290 Batch 22 Loss 0.2373274266719818
[Train] epoch 290 Batch 23 Loss 0.13662676513195038
[Train] epoch 290 Batch 24 Loss 0.10357258468866348
[Train] epoch 290 Batch 25 Loss 0.26767298579216003
[Train] epoch 290 Batch 26 Loss 0.10191664099693298
[Train] epoch 290 Batch 27 Loss 0.13534408807754517
[Train] epoch 290 Batch 28 Loss 0.16780464351177216
[Train] epoch 290 Batch 29 Loss 0.06767190247774124
[Train] epoch 290 Batch 30 Loss 0.3023725748062134
[Train] epoch 290 Batch 31 Loss 0.20191015303134918
[Train] epoch 290 Batch 32 Loss 0.23532843589782715
[Train] epoch 290 Batch 33 Loss 0.20191499590873718
[Train] epoch 290 Batch 34 Loss 0.10364691913127899
[Train] epoch 290 Batch 35 Loss 0.1366245150566101
[Train] epoch 290 Batch 36 Loss 0.23542779684066772
[Train] epoch 290 Batch 37 Loss 0.2000008225440979
[Train] epoch 290 Batch 38 Loss 0.168763667345047
[Train] epoch 290 Batch 39 Loss 0.06829078495502472
[Train] epoch 290 Batch 40 Loss 0.3351645767688751
[Train] epoch 290 Batch 41 Loss 0.13432376086711884
[Train] epoch 290 Batch 42 Loss 0.16902174055576324
[Train] epoch 290 Batch 43 Loss 0.3023272454738617
[Train] epoch 290 Batch 44 Loss 0.20190660655498505
[Train] epoch 290 Batch 45 Loss 0.20196595788002014
[Train] epoch 290 Batch 46 Loss 0.2375139445066452
[Train] epoch 290 Batch 47 Loss 0.23741358518600464
[Train] epoch 291 Batch 0 Loss 0.43481481075286865
[Train] epoch 291 Batch 1 Loss 0.13617882132530212
[Train] epoch 291 Batch 2 Loss 0.16996687650680542
[Train] epoch 291 Batch 3 Loss 0.20093077421188354
[Train] epoch 291 Batch 4 Loss 0.06759817898273468
[Train] epoch 291 Batch 5 Loss 0.13618743419647217
[Train] epoch 291 Batch 6 Loss 0.13620063662528992
[Train] epoch 291 Batch 7 Loss 0.2356877326965332
[Train] epoch 291 Batch 8 Loss 0.2038743942975998
[Train] epoch 291 Batch 9 Loss 0.06941615790128708
[Train] epoch 291 Batch 10 Loss 0.16715653240680695
[Train] epoch 291 Batch 11 Loss 0.26947444677352905
[Train] epoch 291 Batch 12 Loss 0.06860265880823135
[Train] epoch 291 Batch 13 Loss 0.20274552702903748
[Train] epoch 291 Batch 14 Loss 0.20464926958084106
[Train] epoch 291 Batch 15 Loss 0.1681315302848816
[Train] epoch 291 Batch 16 Loss 0.1368594765663147
[Train] epoch 291 Batch 17 Loss 0.13509413599967957
[Train] epoch 291 Batch 18 Loss 0.16814091801643372
[Train] epoch 291 Batch 19 Loss 0.17165067791938782
[Train] epoch 291 Batch 20 Loss 0.13616876304149628
[Train] epoch 291 Batch 21 Loss 0.13524988293647766
[Train] epoch 291 Batch 22 Loss 0.23562385141849518
[Train] epoch 291 Batch 23 Loss 0.16802452504634857
[Train] epoch 291 Batch 24 Loss 0.2693844735622406
[Train] epoch 291 Batch 25 Loss 0.20184645056724548
[Train] epoch 291 Batch 26 Loss 0.20189251005649567
[Train] epoch 291 Batch 27 Loss 0.23566323518753052
[Train] epoch 291 Batch 28 Loss 0.20383621752262115
[Train] epoch 291 Batch 29 Loss 0.13614466786384583
[Train] epoch 291 Batch 30 Loss 0.27032870054244995
[Train] epoch 291 Batch 31 Loss 0.033819954842329025
[Train] epoch 291 Batch 32 Loss 0.2366134375333786
[Train] epoch 291 Batch 33 Loss 0.1699405014514923
[Train] epoch 291 Batch 34 Loss 0.1361209750175476
[Train] epoch 291 Batch 35 Loss 0.13520316779613495
[Train] epoch 291 Batch 36 Loss 0.16890186071395874
[Train] epoch 291 Batch 37 Loss 0.03556343913078308
[Train] epoch 291 Batch 38 Loss 0.0008984834421426058
[Train] epoch 291 Batch 39 Loss 0.034650325775146484
[Train] epoch 291 Batch 40 Loss 0.1350676417350769
[Train] epoch 291 Batch 41 Loss 0.3350635766983032
[Train] epoch 291 Batch 42 Loss 0.1351788491010666
[Train] epoch 291 Batch 43 Loss 0.23471930623054504
[Train] epoch 291 Batch 44 Loss 0.03558967635035515
[Train] epoch 291 Batch 45 Loss 0.23381806910037994
[Train] epoch 291 Batch 46 Loss 0.40089893341064453
[Train] epoch 291 Batch 47 Loss 0.2676350176334381
[Train] epoch 292 Batch 0 Loss 0.33510902523994446
[Train] epoch 292 Batch 1 Loss 0.13498471677303314
[Train] epoch 292 Batch 2 Loss 0.1688709557056427
[Train] epoch 292 Batch 3 Loss 0.13512393832206726
[Train] epoch 292 Batch 4 Loss 0.13763493299484253
[Train] epoch 292 Batch 5 Loss 0.16804364323616028
[Train] epoch 292 Batch 6 Loss 0.23657171428203583
[Train] epoch 292 Batch 7 Loss 0.20096692442893982
[Train] epoch 292 Batch 8 Loss 0.2685737609863281
[Train] epoch 292 Batch 9 Loss 0.23473043739795685
[Train] epoch 292 Batch 10 Loss 0.10131894797086716
[Train] epoch 292 Batch 11 Loss 0.20167329907417297
[Train] epoch 292 Batch 12 Loss 0.13677793741226196
[Train] epoch 292 Batch 13 Loss 0.2026812732219696
[Train] epoch 292 Batch 14 Loss 0.10295258462429047
[Train] epoch 292 Batch 15 Loss 0.16893687844276428
[Train] epoch 292 Batch 16 Loss 0.1351020485162735
[Train] epoch 292 Batch 17 Loss 0.033816251903772354
[Train] epoch 292 Batch 18 Loss 0.20354369282722473
[Train] epoch 292 Batch 19 Loss 0.20177680253982544
[Train] epoch 292 Batch 20 Loss 0.10306480526924133
[Train] epoch 292 Batch 21 Loss 0.036202460527420044
[Train] epoch 292 Batch 22 Loss 0.2357407808303833
[Train] epoch 292 Batch 23 Loss 0.10132123529911041
[Train] epoch 292 Batch 24 Loss 0.3022812008857727
[Train] epoch 292 Batch 25 Loss 0.16789795458316803
[Train] epoch 292 Batch 26 Loss 0.267628937959671
[Train] epoch 292 Batch 27 Loss 0.3021879196166992
[Train] epoch 292 Batch 28 Loss 0.2018807828426361
[Train] epoch 292 Batch 29 Loss 0.335124671459198
[Train] epoch 292 Batch 30 Loss 0.03542615845799446
[Train] epoch 292 Batch 31 Loss 0.0682770162820816
[Train] epoch 292 Batch 32 Loss 0.168799489736557
[Train] epoch 292 Batch 33 Loss 0.13525323569774628
[Train] epoch 292 Batch 34 Loss 0.3004343509674072
[Train] epoch 292 Batch 35 Loss 0.168836772441864
[Train] epoch 292 Batch 36 Loss 0.10372032970190048
[Train] epoch 292 Batch 37 Loss 0.2692631185054779
[Train] epoch 292 Batch 38 Loss 0.06825900077819824
[Train] epoch 292 Batch 39 Loss 0.2017311453819275
[Train] epoch 292 Batch 40 Loss 0.23626238107681274
[Train] epoch 292 Batch 41 Loss 0.035394832491874695
[Train] epoch 292 Batch 42 Loss 0.1349135935306549
[Train] epoch 292 Batch 43 Loss 0.23471716046333313
[Train] epoch 292 Batch 44 Loss 0.16952654719352722
[Train] epoch 292 Batch 45 Loss 0.16967171430587769
[Train] epoch 292 Batch 46 Loss 0.16861549019813538
[Train] epoch 292 Batch 47 Loss 0.16890500485897064
[Train] epoch 293 Batch 0 Loss 0.3040344715118408
[Train] epoch 293 Batch 1 Loss 0.23546811938285828
[Train] epoch 293 Batch 2 Loss 0.10143379867076874
[Train] epoch 293 Batch 3 Loss 0.20336171984672546
[Train] epoch 293 Batch 4 Loss 0.06917083263397217
[Train] epoch 293 Batch 5 Loss 0.2675618529319763
[Train] epoch 293 Batch 6 Loss 0.2033310830593109
[Train] epoch 293 Batch 7 Loss 0.2023310661315918
[Train] epoch 293 Batch 8 Loss 0.23619742691516876
[Train] epoch 293 Batch 9 Loss 0.035343773663043976
[Train] epoch 293 Batch 10 Loss 0.23538053035736084
[Train] epoch 293 Batch 11 Loss 0.16867077350616455
[Train] epoch 293 Batch 12 Loss 0.13428643345832825
[Train] epoch 293 Batch 13 Loss 1.0728851975727594e-06
[Train] epoch 293 Batch 14 Loss 0.20162469148635864
[Train] epoch 293 Batch 15 Loss 0.06976598501205444
[Train] epoch 293 Batch 16 Loss 0.1686948537826538
[Train] epoch 293 Batch 17 Loss 0.1004074364900589
[Train] epoch 293 Batch 18 Loss 0.16871972382068634
[Train] epoch 293 Batch 19 Loss 0.3687554597854614
[Train] epoch 293 Batch 20 Loss 0.1680222749710083
[Train] epoch 293 Batch 21 Loss 0.16875210404396057
[Train] epoch 293 Batch 22 Loss 0.07206899672746658
[Train] epoch 293 Batch 23 Loss 0.10280755907297134
[Train] epoch 293 Batch 24 Loss 0.2347586750984192
[Train] epoch 293 Batch 25 Loss 0.13580848276615143
[Train] epoch 293 Batch 26 Loss 0.47023805975914
[Train] epoch 293 Batch 27 Loss 0.23453043401241302
[Train] epoch 293 Batch 28 Loss 0.16941630840301514
[Train] epoch 293 Batch 29 Loss 0.20306745171546936
[Train] epoch 293 Batch 30 Loss 0.23524415493011475
[Train] epoch 293 Batch 31 Loss 0.2346399575471878
[Train] epoch 293 Batch 32 Loss 0.16876131296157837
[Train] epoch 293 Batch 33 Loss 0.06899899989366531
[Train] epoch 293 Batch 34 Loss 0.10197222232818604
[Train] epoch 293 Batch 35 Loss 0.2022523730993271
[Train] epoch 293 Batch 36 Loss 0.134043887257576
[Train] epoch 293 Batch 37 Loss 0.06666764616966248
[Train] epoch 293 Batch 38 Loss 0.0007441708585247397
[Train] epoch 293 Batch 39 Loss 0.10117977857589722
[Train] epoch 293 Batch 40 Loss 0.2017223984003067
[Train] epoch 293 Batch 41 Loss 0.3021581172943115
[Train] epoch 293 Batch 42 Loss 0.33403730392456055
[Train] epoch 293 Batch 43 Loss 0.23545417189598083
[Train] epoch 293 Batch 44 Loss 0.06761253625154495
[Train] epoch 293 Batch 45 Loss 0.2361515611410141
[Train] epoch 293 Batch 46 Loss 0.0675242692232132
[Train] epoch 293 Batch 47 Loss 0.20167794823646545
[Train] epoch 294 Batch 0 Loss 0.16865819692611694
[Train] epoch 294 Batch 1 Loss 0.033806104212999344
[Train] epoch 294 Batch 2 Loss 0.06812875717878342
[Train] epoch 294 Batch 3 Loss 0.13491740822792053
[Train] epoch 294 Batch 4 Loss 0.23531830310821533
[Train] epoch 294 Batch 5 Loss 0.33402806520462036
[Train] epoch 294 Batch 6 Loss 0.06821277737617493
[Train] epoch 294 Batch 7 Loss 0.13487748801708221
[Train] epoch 294 Batch 8 Loss 0.3358517289161682
[Train] epoch 294 Batch 9 Loss 0.0007253327057696879
[Train] epoch 294 Batch 10 Loss 0.2353779822587967
[Train] epoch 294 Batch 11 Loss 0.2353421151638031
[Train] epoch 294 Batch 12 Loss 0.16961456835269928
[Train] epoch 294 Batch 13 Loss 0.1357155293226242
[Train] epoch 294 Batch 14 Loss 0.1685428023338318
[Train] epoch 294 Batch 15 Loss 0.06901104748249054
[Train] epoch 294 Batch 16 Loss 0.16798244416713715
[Train] epoch 294 Batch 17 Loss 0.16794875264167786
[Train] epoch 294 Batch 18 Loss 0.23617321252822876
[Train] epoch 294 Batch 19 Loss 0.23532867431640625
[Train] epoch 294 Batch 20 Loss 0.10329075157642365
[Train] epoch 294 Batch 21 Loss 0.13563284277915955
[Train] epoch 294 Batch 22 Loss 0.2359035164117813
[Train] epoch 294 Batch 23 Loss 0.10130976140499115
[Train] epoch 294 Batch 24 Loss 0.20286834239959717
[Train] epoch 294 Batch 25 Loss 0.16878008842468262
[Train] epoch 294 Batch 26 Loss 0.10117492824792862
[Train] epoch 294 Batch 27 Loss 0.135748952627182
[Train] epoch 294 Batch 28 Loss 0.16944736242294312
[Train] epoch 294 Batch 29 Loss 0.1679701954126358
[Train] epoch 294 Batch 30 Loss 0.1354760229587555
[Train] epoch 294 Batch 31 Loss 0.06803594529628754
[Train] epoch 294 Batch 32 Loss 0.13483411073684692
[Train] epoch 294 Batch 33 Loss 0.20093561708927155
[Train] epoch 294 Batch 34 Loss 0.336223840713501
[Train] epoch 294 Batch 35 Loss 0.13675984740257263
[Train] epoch 294 Batch 36 Loss 0.10209600627422333
[Train] epoch 294 Batch 37 Loss 0.23456740379333496
[Train] epoch 294 Batch 38 Loss 0.1004628837108612
[Train] epoch 294 Batch 39 Loss 0.16882282495498657
[Train] epoch 294 Batch 40 Loss 0.3689134120941162
[Train] epoch 294 Batch 41 Loss 0.3359941840171814
[Train] epoch 294 Batch 42 Loss 0.13424846529960632
[Train] epoch 294 Batch 43 Loss 0.43648797273635864
[Train] epoch 294 Batch 44 Loss 0.43573468923568726
[Train] epoch 294 Batch 45 Loss 0.035651642829179764
[Train] epoch 294 Batch 46 Loss 0.10235073417425156
[Train] epoch 294 Batch 47 Loss 0.06856468319892883
[Train] epoch 295 Batch 0 Loss 0.07053687423467636
[Train] epoch 295 Batch 1 Loss 0.20302383601665497
[Train] epoch 295 Batch 2 Loss 0.17379659414291382
[Train] epoch 295 Batch 3 Loss 0.40281614661216736
[Train] epoch 295 Batch 4 Loss 0.10225530713796616
[Train] epoch 295 Batch 5 Loss 0.10213307291269302
[Train] epoch 295 Batch 6 Loss 0.13507337868213654
[Train] epoch 295 Batch 7 Loss 0.3603895306587219
[Train] epoch 295 Batch 8 Loss 0.22201699018478394
[Train] epoch 295 Batch 9 Loss 0.1680830717086792
[Train] epoch 295 Batch 10 Loss 0.17434273660182953
[Train] epoch 295 Batch 11 Loss 0.14197048544883728
[Train] epoch 295 Batch 12 Loss 0.2693374752998352
[Train] epoch 295 Batch 13 Loss 0.2334175705909729
[Train] epoch 295 Batch 14 Loss 0.10152791440486908
[Train] epoch 295 Batch 15 Loss 0.05685818940401077
[Train] epoch 295 Batch 16 Loss 0.28530073165893555
[Train] epoch 295 Batch 17 Loss 0.24425581097602844
[Train] epoch 295 Batch 18 Loss 0.1015506461262703
[Train] epoch 295 Batch 19 Loss 0.13561418652534485
[Train] epoch 295 Batch 20 Loss 0.16838008165359497
[Train] epoch 295 Batch 21 Loss 0.13540665805339813
[Train] epoch 295 Batch 22 Loss 0.16831044852733612
[Train] epoch 295 Batch 23 Loss 0.27012693881988525
[Train] epoch 295 Batch 24 Loss 0.07013864070177078
[Train] epoch 295 Batch 25 Loss 0.13690254092216492
[Train] epoch 295 Batch 26 Loss 0.13694404065608978
[Train] epoch 295 Batch 27 Loss 0.33795344829559326
[Train] epoch 295 Batch 28 Loss 0.10296586900949478
[Train] epoch 295 Batch 29 Loss 0.23514512181282043
[Train] epoch 295 Batch 30 Loss 0.20362061262130737
[Train] epoch 295 Batch 31 Loss 0.10675443708896637
[Train] epoch 295 Batch 32 Loss 0.20467033982276917
[Train] epoch 295 Batch 33 Loss 0.2338816225528717
[Train] epoch 295 Batch 34 Loss 0.10448817163705826
[Train] epoch 295 Batch 35 Loss 0.2385832816362381
[Train] epoch 295 Batch 36 Loss 0.169920414686203
[Train] epoch 295 Batch 37 Loss 0.17002590000629425
[Train] epoch 295 Batch 38 Loss 0.20380310714244843
[Train] epoch 295 Batch 39 Loss 0.33803391456604004
[Train] epoch 295 Batch 40 Loss 0.1686144471168518
[Train] epoch 295 Batch 41 Loss 0.20133203268051147
[Train] epoch 295 Batch 42 Loss 0.10194852203130722
[Train] epoch 295 Batch 43 Loss 0.13870221376419067
[Train] epoch 295 Batch 44 Loss 0.1033121645450592
[Train] epoch 295 Batch 45 Loss 0.23534879088401794
[Train] epoch 295 Batch 46 Loss 0.034016262739896774
[Train] epoch 295 Batch 47 Loss 0.13471508026123047
[Train] epoch 296 Batch 0 Loss 0.10201144218444824
[Train] epoch 296 Batch 1 Loss 0.06942589581012726
[Train] epoch 296 Batch 2 Loss 0.13763223588466644
[Train] epoch 296 Batch 3 Loss 0.30351799726486206
[Train] epoch 296 Batch 4 Loss 0.23811212182044983
[Train] epoch 296 Batch 5 Loss 0.07084260880947113
[Train] epoch 296 Batch 6 Loss 0.1701008677482605
[Train] epoch 296 Batch 7 Loss 0.06807075440883636
[Train] epoch 296 Batch 8 Loss 0.17290054261684418
[Train] epoch 296 Batch 9 Loss 0.23805582523345947
[Train] epoch 296 Batch 10 Loss 0.16997405886650085
[Train] epoch 296 Batch 11 Loss 0.17002204060554504
[Train] epoch 296 Batch 12 Loss 0.2000008225440979
[Train] epoch 296 Batch 13 Loss 0.13722246885299683
[Train] epoch 296 Batch 14 Loss 0.133334219455719
[Train] epoch 296 Batch 15 Loss 0.2366136610507965
[Train] epoch 296 Batch 16 Loss 0.10205186903476715
[Train] epoch 296 Batch 17 Loss 0.06666764616966248
[Train] epoch 296 Batch 18 Loss 0.1345628798007965
[Train] epoch 296 Batch 19 Loss 0.1346738338470459
[Train] epoch 296 Batch 20 Loss 0.33958613872528076
[Train] epoch 296 Batch 21 Loss 0.23400476574897766
[Train] epoch 296 Batch 22 Loss 0.13710062205791473
[Train] epoch 296 Batch 23 Loss 0.20249392092227936
[Train] epoch 296 Batch 24 Loss 0.06915049254894257
[Train] epoch 296 Batch 25 Loss 0.07159897685050964
[Train] epoch 296 Batch 26 Loss 0.13693442940711975
[Train] epoch 296 Batch 27 Loss 0.20493140816688538
[Train] epoch 296 Batch 28 Loss 0.20262368023395538
[Train] epoch 296 Batch 29 Loss 0.16863369941711426
[Train] epoch 296 Batch 30 Loss 0.23643650114536285
[Train] epoch 296 Batch 31 Loss 0.20480337738990784
[Train] epoch 296 Batch 32 Loss 0.07022314518690109
[Train] epoch 296 Batch 33 Loss 0.10185978561639786
[Train] epoch 296 Batch 34 Loss 0.23983079195022583
[Train] epoch 296 Batch 35 Loss 0.40237319469451904
[Train] epoch 296 Batch 36 Loss 0.16956055164337158
[Train] epoch 296 Batch 37 Loss 0.16954700648784637
[Train] epoch 296 Batch 38 Loss 0.20350071787834167
[Train] epoch 296 Batch 39 Loss 0.13572575151920319
[Train] epoch 296 Batch 40 Loss 0.06783175468444824
[Train] epoch 296 Batch 41 Loss 0.3698328137397766
[Train] epoch 296 Batch 42 Loss 0.368526816368103
[Train] epoch 296 Batch 43 Loss 0.13454017043113708
[Train] epoch 296 Batch 44 Loss 0.16922803223133087
[Train] epoch 296 Batch 45 Loss 0.17161086201667786
[Train] epoch 296 Batch 46 Loss 0.16960321366786957
[Train] epoch 296 Batch 47 Loss 0.23683524131774902
[Train] epoch 297 Batch 0 Loss 0.13554970920085907
[Train] epoch 297 Batch 1 Loss 0.10285159200429916
[Train] epoch 297 Batch 2 Loss 0.16832974553108215
[Train] epoch 297 Batch 3 Loss 0.3028314709663391
[Train] epoch 297 Batch 4 Loss 0.0367761105298996
[Train] epoch 297 Batch 5 Loss 0.13657404482364655
[Train] epoch 297 Batch 6 Loss 0.2025817632675171
[Train] epoch 297 Batch 7 Loss 0.20201461017131805
[Train] epoch 297 Batch 8 Loss 0.06973768770694733
[Train] epoch 297 Batch 9 Loss 0.16828472912311554
[Train] epoch 297 Batch 10 Loss 0.03494580462574959
[Train] epoch 297 Batch 11 Loss 0.43733370304107666
[Train] epoch 297 Batch 12 Loss 0.3702459931373596
[Train] epoch 297 Batch 13 Loss 0.20128902792930603
[Train] epoch 297 Batch 14 Loss 0.268862783908844
[Train] epoch 297 Batch 15 Loss 0.2020801454782486
[Train] epoch 297 Batch 16 Loss 0.17129714787006378
[Train] epoch 297 Batch 17 Loss 0.23576948046684265
[Train] epoch 297 Batch 18 Loss 0.1689760982990265
[Train] epoch 297 Batch 19 Loss 0.06852123141288757
[Train] epoch 297 Batch 20 Loss 0.3357028663158417
[Train] epoch 297 Batch 21 Loss 0.10047897696495056
[Train] epoch 297 Batch 22 Loss 0.13461750745773315
[Train] epoch 297 Batch 23 Loss 0.06882496178150177
[Train] epoch 297 Batch 24 Loss 0.06794962286949158
[Train] epoch 297 Batch 25 Loss 0.17002516984939575
[Train] epoch 297 Batch 26 Loss 0.16907647252082825
[Train] epoch 297 Batch 27 Loss 0.1354774832725525
[Train] epoch 297 Batch 28 Loss 0.10150043666362762
[Train] epoch 297 Batch 29 Loss 0.23700344562530518
[Train] epoch 297 Batch 30 Loss 0.13635694980621338
[Train] epoch 297 Batch 31 Loss 0.10241352021694183
[Train] epoch 297 Batch 32 Loss 0.03467811644077301
[Train] epoch 297 Batch 33 Loss 0.2688246965408325
[Train] epoch 297 Batch 34 Loss 0.2021889090538025
[Train] epoch 297 Batch 35 Loss 0.07028186321258545
[Train] epoch 297 Batch 36 Loss 0.2017102837562561
[Train] epoch 297 Batch 37 Loss 0.2042166292667389
[Train] epoch 297 Batch 38 Loss 0.37154507637023926
[Train] epoch 297 Batch 39 Loss 0.16918280720710754
[Train] epoch 297 Batch 40 Loss 0.100413978099823
[Train] epoch 297 Batch 41 Loss 0.13751812279224396
[Train] epoch 297 Batch 42 Loss 0.16793058812618256
[Train] epoch 297 Batch 43 Loss 0.27074146270751953
[Train] epoch 297 Batch 44 Loss 0.303561806678772
[Train] epoch 297 Batch 45 Loss 0.16940976679325104
[Train] epoch 297 Batch 46 Loss 0.034775495529174805
[Train] epoch 297 Batch 47 Loss 0.26793143153190613
[Train] epoch 298 Batch 0 Loss 0.1681017279624939
[Train] epoch 298 Batch 1 Loss 0.17225679755210876
[Train] epoch 298 Batch 2 Loss 0.06773397326469421
[Train] epoch 298 Batch 3 Loss 0.30367910861968994
[Train] epoch 298 Batch 4 Loss 0.16946792602539062
[Train] epoch 298 Batch 5 Loss 0.17092576622962952
[Train] epoch 298 Batch 6 Loss 0.1044410690665245
[Train] epoch 298 Batch 7 Loss 0.13608518242835999
[Train] epoch 298 Batch 8 Loss 0.06787523627281189
[Train] epoch 298 Batch 9 Loss 0.13804464042186737
[Train] epoch 298 Batch 10 Loss 0.20283757150173187
[Train] epoch 298 Batch 11 Loss 0.20700308680534363
[Train] epoch 298 Batch 12 Loss 0.13816453516483307
[Train] epoch 298 Batch 13 Loss 0.33809828758239746
[Train] epoch 298 Batch 14 Loss 0.27237629890441895
[Train] epoch 298 Batch 15 Loss 0.17159529030323029
[Train] epoch 298 Batch 16 Loss 0.0036307242698967457
[Train] epoch 298 Batch 17 Loss 0.3685199022293091
[Train] epoch 298 Batch 18 Loss 0.23618100583553314
[Train] epoch 298 Batch 19 Loss 0.3333339989185333
[Train] epoch 298 Batch 20 Loss 0.13479363918304443
[Train] epoch 298 Batch 21 Loss 0.06865274906158447
[Train] epoch 298 Batch 22 Loss 0.20466750860214233
[Train] epoch 298 Batch 23 Loss 0.1493750363588333
[Train] epoch 298 Batch 24 Loss 0.16885147988796234
[Train] epoch 298 Batch 25 Loss 0.13730813562870026
[Train] epoch 298 Batch 26 Loss 0.23518669605255127
[Train] epoch 298 Batch 27 Loss 0.20560969412326813
[Train] epoch 298 Batch 28 Loss 0.03498616814613342
[Train] epoch 298 Batch 29 Loss 0.16854293644428253
[Train] epoch 298 Batch 30 Loss 0.06911704689264297
[Train] epoch 298 Batch 31 Loss 0.274015873670578
[Train] epoch 298 Batch 32 Loss 0.20363017916679382
[Train] epoch 298 Batch 33 Loss 0.16845297813415527
[Train] epoch 298 Batch 34 Loss 0.16965316236019135
[Train] epoch 298 Batch 35 Loss 0.23507916927337646
[Train] epoch 298 Batch 36 Loss 0.13579700887203217
[Train] epoch 298 Batch 37 Loss 0.17111031711101532
[Train] epoch 298 Batch 38 Loss 0.23778799176216125
[Train] epoch 298 Batch 39 Loss 0.1372629702091217
[Train] epoch 298 Batch 40 Loss 0.17125748097896576
[Train] epoch 298 Batch 41 Loss 0.17006829380989075
[Train] epoch 298 Batch 42 Loss 0.2000008225440979
[Train] epoch 298 Batch 43 Loss 0.1338045448064804
[Train] epoch 298 Batch 44 Loss 0.13478241860866547
[Train] epoch 298 Batch 45 Loss 0.23408569395542145
[Train] epoch 298 Batch 46 Loss 0.17135417461395264
[Train] epoch 298 Batch 47 Loss 0.16999973356723785
[Train] epoch 299 Batch 0 Loss 0.10178796947002411
[Train] epoch 299 Batch 1 Loss 0.1345401257276535
[Train] epoch 299 Batch 2 Loss 0.301857054233551
[Train] epoch 299 Batch 3 Loss 0.13703037798404694
[Train] epoch 299 Batch 4 Loss 0.23787444829940796
[Train] epoch 299 Batch 5 Loss 0.06789736449718475
[Train] epoch 299 Batch 6 Loss 0.23396410048007965
[Train] epoch 299 Batch 7 Loss 0.03396838158369064
[Train] epoch 299 Batch 8 Loss 0.13823479413986206
[Train] epoch 299 Batch 9 Loss 0.23643136024475098
[Train] epoch 299 Batch 10 Loss 0.36989033222198486
[Train] epoch 299 Batch 11 Loss 0.3032364249229431
[Train] epoch 299 Batch 12 Loss 0.06909535825252533
[Train] epoch 299 Batch 13 Loss 0.10065174847841263
[Train] epoch 299 Batch 14 Loss 0.17214277386665344
[Train] epoch 299 Batch 15 Loss 0.20252761244773865
[Train] epoch 299 Batch 16 Loss 0.16966430842876434
[Train] epoch 299 Batch 17 Loss 0.03622892498970032
[Train] epoch 299 Batch 18 Loss 0.23530615866184235
[Train] epoch 299 Batch 19 Loss 0.23737074434757233
[Train] epoch 299 Batch 20 Loss 0.20472878217697144
[Train] epoch 299 Batch 21 Loss 0.14012332260608673
[Train] epoch 299 Batch 22 Loss 0.2703363001346588
[Train] epoch 299 Batch 23 Loss 0.2352001965045929
[Train] epoch 299 Batch 24 Loss 0.07019728422164917
[Train] epoch 299 Batch 25 Loss 0.13458135724067688
[Train] epoch 299 Batch 26 Loss 0.13582316040992737
[Train] epoch 299 Batch 27 Loss 0.13794058561325073
[Train] epoch 299 Batch 28 Loss 0.30291545391082764
[Train] epoch 299 Batch 29 Loss 0.2360520362854004
[Train] epoch 299 Batch 30 Loss 0.20371036231517792
[Train] epoch 299 Batch 31 Loss 0.3358529508113861
[Train] epoch 299 Batch 32 Loss 0.16826650500297546
[Train] epoch 299 Batch 33 Loss 0.23815599083900452
[Train] epoch 299 Batch 34 Loss 0.13908328115940094
[Train] epoch 299 Batch 35 Loss 0.1706005334854126
[Train] epoch 299 Batch 36 Loss 0.13455161452293396
[Train] epoch 299 Batch 37 Loss 0.03606845438480377
[Train] epoch 299 Batch 38 Loss 0.26989662647247314
[Train] epoch 299 Batch 39 Loss 0.36841899156570435
[Train] epoch 299 Batch 40 Loss 0.10154037177562714
[Train] epoch 299 Batch 41 Loss 0.1686699092388153
[Train] epoch 299 Batch 42 Loss 0.13573911786079407
[Train] epoch 299 Batch 43 Loss 0.10169495642185211
[Train] epoch 299 Batch 44 Loss 0.20116034150123596
[Train] epoch 299 Batch 45 Loss 0.07059531658887863
[Train] epoch 299 Batch 46 Loss 0.13656017184257507
[Train] epoch 299 Batch 47 Loss 0.06782182306051254
[Train] epoch 300 Batch 0 Loss 0.16852426528930664
[Train] epoch 300 Batch 1 Loss 0.43717747926712036
[Train] epoch 300 Batch 2 Loss 0.06882768869400024
[Train] epoch 300 Batch 3 Loss 0.17062921822071075
[Train] epoch 300 Batch 4 Loss 0.20337718725204468
[Train] epoch 300 Batch 5 Loss 0.20316633582115173
[Train] epoch 300 Batch 6 Loss 0.16961023211479187
[Train] epoch 300 Batch 7 Loss 0.10163877159357071
[Train] epoch 300 Batch 8 Loss 0.03597934916615486
[Train] epoch 300 Batch 9 Loss 0.3367847204208374
[Train] epoch 300 Batch 10 Loss 0.001013933215290308
[Train] epoch 300 Batch 11 Loss 0.06666764616966248
[Train] epoch 300 Batch 12 Loss 0.20216874778270721
[Train] epoch 300 Batch 13 Loss 0.20101678371429443
[Train] epoch 300 Batch 14 Loss 0.13654133677482605
[Train] epoch 300 Batch 15 Loss 0.20122581720352173
[Train] epoch 300 Batch 16 Loss 0.20335817337036133
[Train] epoch 300 Batch 17 Loss 0.13642948865890503
[Train] epoch 300 Batch 18 Loss 0.10182642936706543
[Train] epoch 300 Batch 19 Loss 0.20308785140514374
[Train] epoch 300 Batch 20 Loss 0.03489862382411957
[Train] epoch 300 Batch 21 Loss 0.10383753478527069
[Train] epoch 300 Batch 22 Loss 0.30264317989349365
[Train] epoch 300 Batch 23 Loss 0.13436132669448853
[Train] epoch 300 Batch 24 Loss 0.17024275660514832
[Train] epoch 300 Batch 25 Loss 0.16937322914600372
[Train] epoch 300 Batch 26 Loss 0.1355365514755249
[Train] epoch 300 Batch 27 Loss 0.20323500037193298
[Train] epoch 300 Batch 28 Loss 0.1672700047492981
[Train] epoch 300 Batch 29 Loss 0.27067846059799194
[Train] epoch 300 Batch 30 Loss 0.0349404476583004
[Train] epoch 300 Batch 31 Loss 0.2012045979499817
[Train] epoch 300 Batch 32 Loss 0.23602333664894104
[Train] epoch 300 Batch 33 Loss 0.26997286081314087
[Train] epoch 300 Batch 34 Loss 0.26992812752723694
[Train] epoch 300 Batch 35 Loss 0.102442666888237
[Train] epoch 300 Batch 36 Loss 0.20230408012866974
[Train] epoch 300 Batch 37 Loss 0.0019462979398667812
[Train] epoch 300 Batch 38 Loss 0.30471792817115784
[Train] epoch 300 Batch 39 Loss 0.33573204278945923
[Train] epoch 300 Batch 40 Loss 0.2699328660964966
[Train] epoch 300 Batch 41 Loss 0.13428547978401184
[Train] epoch 300 Batch 42 Loss 0.23933061957359314
[Train] epoch 300 Batch 43 Loss 0.1691572368144989
[Train] epoch 300 Batch 44 Loss 0.17012935876846313
[Train] epoch 300 Batch 45 Loss 0.17022806406021118
[Train] epoch 300 Batch 46 Loss 0.13549822568893433
[Train] epoch 300 Batch 47 Loss 0.13547657430171967
[Train] epoch 301 Batch 0 Loss 0.23608529567718506
[Train] epoch 301 Batch 1 Loss 0.10434133559465408
[Train] epoch 301 Batch 2 Loss 0.20105765759944916
[Train] epoch 301 Batch 3 Loss 0.16844987869262695
[Train] epoch 301 Batch 4 Loss 0.3357084393501282
[Train] epoch 301 Batch 5 Loss 0.1671259105205536
[Train] epoch 301 Batch 6 Loss 0.1701885461807251
[Train] epoch 301 Batch 7 Loss 0.03470301628112793
[Train] epoch 301 Batch 8 Loss 0.13438069820404053
[Train] epoch 301 Batch 9 Loss 0.17015168070793152
[Train] epoch 301 Batch 10 Loss 0.20236334204673767
[Train] epoch 301 Batch 11 Loss 0.2369590699672699
[Train] epoch 301 Batch 12 Loss 0.10317182540893555
[Train] epoch 301 Batch 13 Loss 0.20183002948760986
[Train] epoch 301 Batch 14 Loss 0.03573057800531387
[Train] epoch 301 Batch 15 Loss 0.10419349372386932
[Train] epoch 301 Batch 16 Loss 0.20297294855117798
[Train] epoch 301 Batch 17 Loss 0.17020627856254578
[Train] epoch 301 Batch 18 Loss 0.2360118180513382
[Train] epoch 301 Batch 19 Loss 0.07049985229969025
[Train] epoch 301 Batch 20 Loss 0.16990210115909576
[Train] epoch 301 Batch 21 Loss 0.16799329221248627
[Train] epoch 301 Batch 22 Loss 0.13435694575309753
[Train] epoch 301 Batch 23 Loss 0.16813704371452332
[Train] epoch 301 Batch 24 Loss 0.13523295521736145
[Train] epoch 301 Batch 25 Loss 0.46901392936706543
[Train] epoch 301 Batch 26 Loss 0.13695886731147766
[Train] epoch 301 Batch 27 Loss 0.10131513327360153
[Train] epoch 301 Batch 28 Loss 0.3045228123664856
[Train] epoch 301 Batch 29 Loss 0.267692893743515
[Train] epoch 301 Batch 30 Loss 0.10144945979118347
[Train] epoch 301 Batch 31 Loss 0.16842280328273773
[Train] epoch 301 Batch 32 Loss 0.23680506646633148
[Train] epoch 301 Batch 33 Loss 0.13603952527046204
[Train] epoch 301 Batch 34 Loss 0.23930364847183228
[Train] epoch 301 Batch 35 Loss 0.03545599430799484
[Train] epoch 301 Batch 36 Loss 0.1014196127653122
[Train] epoch 301 Batch 37 Loss 0.36994028091430664
[Train] epoch 301 Batch 38 Loss 0.06766524910926819
[Train] epoch 301 Batch 39 Loss 0.13433045148849487
[Train] epoch 301 Batch 40 Loss 0.13614867627620697
[Train] epoch 301 Batch 41 Loss 0.23391613364219666
[Train] epoch 301 Batch 42 Loss 0.16924560070037842
[Train] epoch 301 Batch 43 Loss 0.3023911416530609
[Train] epoch 301 Batch 44 Loss 0.13433587551116943
[Train] epoch 301 Batch 45 Loss 0.23475438356399536
[Train] epoch 301 Batch 46 Loss 0.16889864206314087
[Train] epoch 301 Batch 47 Loss 0.10140419006347656
[Train] epoch 302 Batch 0 Loss 0.13612443208694458
[Train] epoch 302 Batch 1 Loss 0.13596925139427185
[Train] epoch 302 Batch 2 Loss 0.2027817964553833
[Train] epoch 302 Batch 3 Loss 0.0008169361390173435
[Train] epoch 302 Batch 4 Loss 0.20213645696640015
[Train] epoch 302 Batch 5 Loss 0.3043240010738373
[Train] epoch 302 Batch 6 Loss 0.10057838261127472
[Train] epoch 302 Batch 7 Loss 0.23634785413742065
[Train] epoch 302 Batch 8 Loss 0.3015628755092621
[Train] epoch 302 Batch 9 Loss 0.20273947715759277
[Train] epoch 302 Batch 10 Loss 0.1344856321811676
[Train] epoch 302 Batch 11 Loss 0.10392747819423676
[Train] epoch 302 Batch 12 Loss 0.23390883207321167
[Train] epoch 302 Batch 13 Loss 0.10217054188251495
[Train] epoch 302 Batch 14 Loss 0.1360740065574646
[Train] epoch 302 Batch 15 Loss 0.07017501443624496
[Train] epoch 302 Batch 16 Loss 0.2025374323129654
[Train] epoch 302 Batch 17 Loss 0.10119123756885529
[Train] epoch 302 Batch 18 Loss 0.13490986824035645
[Train] epoch 302 Batch 19 Loss 0.16995589435100555
[Train] epoch 302 Batch 20 Loss 0.23486462235450745
[Train] epoch 302 Batch 21 Loss 0.13429149985313416
[Train] epoch 302 Batch 22 Loss 0.23448783159255981
[Train] epoch 302 Batch 23 Loss 0.30421459674835205
[Train] epoch 302 Batch 24 Loss 0.268995463848114
[Train] epoch 302 Batch 25 Loss 0.06914685666561127
[Train] epoch 302 Batch 26 Loss 0.20232608914375305
[Train] epoch 302 Batch 27 Loss 0.16801735758781433
[Train] epoch 302 Batch 28 Loss 0.10246838629245758
[Train] epoch 302 Batch 29 Loss 0.10228326916694641
[Train] epoch 302 Batch 30 Loss 0.30284935235977173
[Train] epoch 302 Batch 31 Loss 0.16876910626888275
[Train] epoch 302 Batch 32 Loss 0.20360076427459717
[Train] epoch 302 Batch 33 Loss 0.1672358214855194
[Train] epoch 302 Batch 34 Loss 0.16704075038433075
[Train] epoch 302 Batch 35 Loss 0.10206793248653412
[Train] epoch 302 Batch 36 Loss 0.33670759201049805
[Train] epoch 302 Batch 37 Loss 0.0676051527261734
[Train] epoch 302 Batch 38 Loss 0.13446666300296783
[Train] epoch 302 Batch 39 Loss 0.10130557417869568
[Train] epoch 302 Batch 40 Loss 0.10036969184875488
[Train] epoch 302 Batch 41 Loss 0.20262187719345093
[Train] epoch 302 Batch 42 Loss 0.2709522545337677
[Train] epoch 302 Batch 43 Loss 0.10223878175020218
[Train] epoch 302 Batch 44 Loss 0.20240356028079987
[Train] epoch 302 Batch 45 Loss 0.2009294331073761
[Train] epoch 302 Batch 46 Loss 0.40298163890838623
[Train] epoch 302 Batch 47 Loss 0.13592344522476196
[Train] epoch 303 Batch 0 Loss 0.2020498514175415
[Train] epoch 303 Batch 1 Loss 0.33612358570098877
[Train] epoch 303 Batch 2 Loss 0.1371779441833496
[Train] epoch 303 Batch 3 Loss 0.2687181234359741
[Train] epoch 303 Batch 4 Loss 0.27015647292137146
[Train] epoch 303 Batch 5 Loss 0.10240594297647476
[Train] epoch 303 Batch 6 Loss 0.13571274280548096
[Train] epoch 303 Batch 7 Loss 0.16702546179294586
[Train] epoch 303 Batch 8 Loss 1.0728851975727594e-06
[Train] epoch 303 Batch 9 Loss 0.1672242283821106
[Train] epoch 303 Batch 10 Loss 0.23512303829193115
[Train] epoch 303 Batch 11 Loss 0.20254281163215637
[Train] epoch 303 Batch 12 Loss 0.13607345521450043
[Train] epoch 303 Batch 13 Loss 0.0344051793217659
[Train] epoch 303 Batch 14 Loss 0.06666764616966248
[Train] epoch 303 Batch 15 Loss 0.33515673875808716
[Train] epoch 303 Batch 16 Loss 0.10267682373523712
[Train] epoch 303 Batch 17 Loss 0.23550452291965485
[Train] epoch 303 Batch 18 Loss 0.17086338996887207
[Train] epoch 303 Batch 19 Loss 0.36935535073280334
[Train] epoch 303 Batch 20 Loss 0.10239965468645096
[Train] epoch 303 Batch 21 Loss 0.16989272832870483
[Train] epoch 303 Batch 22 Loss 0.1691179871559143
[Train] epoch 303 Batch 23 Loss 0.30444082617759705
[Train] epoch 303 Batch 24 Loss 0.3025261461734772
[Train] epoch 303 Batch 25 Loss 0.2369987517595291
[Train] epoch 303 Batch 26 Loss 0.3678601086139679
[Train] epoch 303 Batch 27 Loss 0.136586993932724
[Train] epoch 303 Batch 28 Loss 0.16822245717048645
[Train] epoch 303 Batch 29 Loss 0.13441205024719238
[Train] epoch 303 Batch 30 Loss 0.033958256244659424
[Train] epoch 303 Batch 31 Loss 0.2349490523338318
[Train] epoch 303 Batch 32 Loss 0.13816671073436737
[Train] epoch 303 Batch 33 Loss 0.2387332171201706
[Train] epoch 303 Batch 34 Loss 0.133334219455719
[Train] epoch 303 Batch 35 Loss 0.16814351081848145
[Train] epoch 303 Batch 36 Loss 0.10420069098472595
[Train] epoch 303 Batch 37 Loss 0.1720794439315796
[Train] epoch 303 Batch 38 Loss 0.20203539729118347
[Train] epoch 303 Batch 39 Loss 0.1393652856349945
[Train] epoch 303 Batch 40 Loss 0.304135262966156
[Train] epoch 303 Batch 41 Loss 0.035123154520988464
[Train] epoch 303 Batch 42 Loss 0.0689871609210968
[Train] epoch 303 Batch 43 Loss 0.2022843360900879
[Train] epoch 303 Batch 44 Loss 0.06896267831325531
[Train] epoch 303 Batch 45 Loss 0.2034621238708496
[Train] epoch 303 Batch 46 Loss 0.10286189615726471
[Train] epoch 303 Batch 47 Loss 0.10172626376152039
[Train] epoch 304 Batch 0 Loss 0.2701316773891449
[Train] epoch 304 Batch 1 Loss 0.16954083740711212
[Train] epoch 304 Batch 2 Loss 0.20336779952049255
[Train] epoch 304 Batch 3 Loss 0.06782904267311096
[Train] epoch 304 Batch 4 Loss 0.23513230681419373
[Train] epoch 304 Batch 5 Loss 0.20111989974975586
[Train] epoch 304 Batch 6 Loss 0.1716768443584442
[Train] epoch 304 Batch 7 Loss 0.20120954513549805
[Train] epoch 304 Batch 8 Loss 0.30602505803108215
[Train] epoch 304 Batch 9 Loss 0.13561215996742249
[Train] epoch 304 Batch 10 Loss 0.16941481828689575
[Train] epoch 304 Batch 11 Loss 0.10394088178873062
[Train] epoch 304 Batch 12 Loss 0.06885651499032974
[Train] epoch 304 Batch 13 Loss 0.13555380702018738
[Train] epoch 304 Batch 14 Loss 0.16843022406101227
[Train] epoch 304 Batch 15 Loss 0.2033986896276474
[Train] epoch 304 Batch 16 Loss 0.2687447667121887
[Train] epoch 304 Batch 17 Loss 0.2372416853904724
[Train] epoch 304 Batch 18 Loss 0.1344010829925537
[Train] epoch 304 Batch 19 Loss 0.1354902684688568
[Train] epoch 304 Batch 20 Loss 0.23490700125694275
[Train] epoch 304 Batch 21 Loss 0.13558346033096313
[Train] epoch 304 Batch 22 Loss 0.30277401208877563
[Train] epoch 304 Batch 23 Loss 0.10359174758195877
[Train] epoch 304 Batch 24 Loss 0.2032889425754547
[Train] epoch 304 Batch 25 Loss 0.1684085577726364
[Train] epoch 304 Batch 26 Loss 0.16945676505565643
[Train] epoch 304 Batch 27 Loss 0.102901890873909
[Train] epoch 304 Batch 28 Loss 0.1016736626625061
[Train] epoch 304 Batch 29 Loss 0.10286707431077957
[Train] epoch 304 Batch 30 Loss 0.20374947786331177
[Train] epoch 304 Batch 31 Loss 0.1398124396800995
[Train] epoch 304 Batch 32 Loss 0.10319183021783829
[Train] epoch 304 Batch 33 Loss 0.1360228806734085
[Train] epoch 304 Batch 34 Loss 0.13584154844284058
[Train] epoch 304 Batch 35 Loss 0.2694268226623535
[Train] epoch 304 Batch 36 Loss 0.20408576726913452
[Train] epoch 304 Batch 37 Loss 0.06897082924842834
[Train] epoch 304 Batch 38 Loss 0.1376456618309021
[Train] epoch 304 Batch 39 Loss 0.2371048927307129
[Train] epoch 304 Batch 40 Loss 0.10304675251245499
[Train] epoch 304 Batch 41 Loss 0.13564033806324005
[Train] epoch 304 Batch 42 Loss 0.23586204648017883
[Train] epoch 304 Batch 43 Loss 0.33563849329948425
[Train] epoch 304 Batch 44 Loss 0.2349381148815155
[Train] epoch 304 Batch 45 Loss 0.23704758286476135
[Train] epoch 304 Batch 46 Loss 0.06871974468231201
[Train] epoch 304 Batch 47 Loss 0.2337951362133026
[Train] epoch 305 Batch 0 Loss 0.10052147507667542
[Train] epoch 305 Batch 1 Loss 0.17112545669078827
[Train] epoch 305 Batch 2 Loss 0.1024969220161438
[Train] epoch 305 Batch 3 Loss 0.06771782040596008
[Train] epoch 305 Batch 4 Loss 0.06759625673294067
[Train] epoch 305 Batch 5 Loss 0.23671163618564606
[Train] epoch 305 Batch 6 Loss 0.1680487096309662
[Train] epoch 305 Batch 7 Loss 0.20201176404953003
[Train] epoch 305 Batch 8 Loss 0.33717650175094604
[Train] epoch 305 Batch 9 Loss 0.2687256932258606
[Train] epoch 305 Batch 10 Loss 0.2377219796180725
[Train] epoch 305 Batch 11 Loss 0.16985422372817993
[Train] epoch 305 Batch 12 Loss 0.2684396207332611
[Train] epoch 305 Batch 13 Loss 0.16903896629810333
[Train] epoch 305 Batch 14 Loss 0.06760348379611969
[Train] epoch 305 Batch 15 Loss 0.03813830018043518
[Train] epoch 305 Batch 16 Loss 0.23581606149673462
[Train] epoch 305 Batch 17 Loss 0.06763900816440582
[Train] epoch 305 Batch 18 Loss 0.13527189195156097
[Train] epoch 305 Batch 19 Loss 0.2038261592388153
[Train] epoch 305 Batch 20 Loss 0.16816499829292297
[Train] epoch 305 Batch 21 Loss 0.1690201461315155
[Train] epoch 305 Batch 22 Loss 0.16986629366874695
[Train] epoch 305 Batch 23 Loss 0.167972132563591
[Train] epoch 305 Batch 24 Loss 0.20161385834217072
[Train] epoch 305 Batch 25 Loss 0.10298125445842743
[Train] epoch 305 Batch 26 Loss 0.13531479239463806
[Train] epoch 305 Batch 27 Loss 0.1680334508419037
[Train] epoch 305 Batch 28 Loss 0.16882319748401642
[Train] epoch 305 Batch 29 Loss 0.3672001361846924
[Train] epoch 305 Batch 30 Loss 0.20197470486164093
[Train] epoch 305 Batch 31 Loss 0.13581103086471558
[Train] epoch 305 Batch 32 Loss 0.06920959055423737
[Train] epoch 305 Batch 33 Loss 0.1679440438747406
[Train] epoch 305 Batch 34 Loss 0.13773885369300842
[Train] epoch 305 Batch 35 Loss 0.0677318274974823
[Train] epoch 305 Batch 36 Loss 0.13584744930267334
[Train] epoch 305 Batch 37 Loss 0.3025290369987488
[Train] epoch 305 Batch 38 Loss 0.16973325610160828
[Train] epoch 305 Batch 39 Loss 0.23649093508720398
[Train] epoch 305 Batch 40 Loss 0.2689867913722992
[Train] epoch 305 Batch 41 Loss 0.2007267028093338
[Train] epoch 305 Batch 42 Loss 0.20178532600402832
[Train] epoch 305 Batch 43 Loss 0.16795232892036438
[Train] epoch 305 Batch 44 Loss 0.4363238513469696
[Train] epoch 305 Batch 45 Loss 0.034475743770599365
[Train] epoch 305 Batch 46 Loss 0.1671973466873169
[Train] epoch 305 Batch 47 Loss 0.16900232434272766
[Train] epoch 306 Batch 0 Loss 0.2021186649799347
[Train] epoch 306 Batch 1 Loss 0.16948695480823517
[Train] epoch 306 Batch 2 Loss 0.20074081420898438
[Train] epoch 306 Batch 3 Loss 0.13498584926128387
[Train] epoch 306 Batch 4 Loss 0.3023226857185364
[Train] epoch 306 Batch 5 Loss 0.2016150951385498
[Train] epoch 306 Batch 6 Loss 0.23474067449569702
[Train] epoch 306 Batch 7 Loss 0.16898229718208313
[Train] epoch 306 Batch 8 Loss 0.16868534684181213
[Train] epoch 306 Batch 9 Loss 0.16976727545261383
[Train] epoch 306 Batch 10 Loss 0.13423992693424225
[Train] epoch 306 Batch 11 Loss 0.13514266908168793
[Train] epoch 306 Batch 12 Loss 0.16791701316833496
[Train] epoch 306 Batch 13 Loss 0.1349271535873413
[Train] epoch 306 Batch 14 Loss 0.20297586917877197
[Train] epoch 306 Batch 15 Loss 0.0344272181391716
[Train] epoch 306 Batch 16 Loss 0.23536497354507446
[Train] epoch 306 Batch 17 Loss 0.16794079542160034
[Train] epoch 306 Batch 18 Loss 0.2357187271118164
[Train] epoch 306 Batch 19 Loss 0.20166067779064178
[Train] epoch 306 Batch 20 Loss 0.13501007854938507
[Train] epoch 306 Batch 21 Loss 0.3353002667427063
[Train] epoch 306 Batch 22 Loss 0.23582208156585693
[Train] epoch 306 Batch 23 Loss 0.13515210151672363
[Train] epoch 306 Batch 24 Loss 0.10433662682771683
[Train] epoch 306 Batch 25 Loss 0.23586449027061462
[Train] epoch 306 Batch 26 Loss 0.1035696268081665
[Train] epoch 306 Batch 27 Loss 0.06764430552721024
[Train] epoch 306 Batch 28 Loss 0.2030637562274933
[Train] epoch 306 Batch 29 Loss 0.10251283645629883
[Train] epoch 306 Batch 30 Loss 0.16824986040592194
[Train] epoch 306 Batch 31 Loss 0.10251974314451218
[Train] epoch 306 Batch 32 Loss 0.20310188829898834
[Train] epoch 306 Batch 33 Loss 0.10465742647647858
[Train] epoch 306 Batch 34 Loss 0.1692710965871811
[Train] epoch 306 Batch 35 Loss 0.13761857151985168
[Train] epoch 306 Batch 36 Loss 0.46766406297683716
[Train] epoch 306 Batch 37 Loss 0.20102086663246155
[Train] epoch 306 Batch 38 Loss 0.2338438183069229
[Train] epoch 306 Batch 39 Loss 0.10264162719249725
[Train] epoch 306 Batch 40 Loss 0.2381482571363449
[Train] epoch 306 Batch 41 Loss 0.06773054599761963
[Train] epoch 306 Batch 42 Loss 0.17036625742912292
[Train] epoch 306 Batch 43 Loss 0.20322701334953308
[Train] epoch 306 Batch 44 Loss 0.17043906450271606
[Train] epoch 306 Batch 45 Loss 0.16825056076049805
[Train] epoch 306 Batch 46 Loss 0.17128267884254456
[Train] epoch 306 Batch 47 Loss 0.06973685324192047
[Train] epoch 307 Batch 0 Loss 0.16823306679725647
[Train] epoch 307 Batch 1 Loss 0.10047869384288788
[Train] epoch 307 Batch 2 Loss 0.2061823010444641
[Train] epoch 307 Batch 3 Loss 0.06761540472507477
[Train] epoch 307 Batch 4 Loss 0.23586159944534302
[Train] epoch 307 Batch 5 Loss 0.20195500552654266
[Train] epoch 307 Batch 6 Loss 0.23384125530719757
[Train] epoch 307 Batch 7 Loss 0.30253416299819946
[Train] epoch 307 Batch 8 Loss 0.10152161121368408
[Train] epoch 307 Batch 9 Loss 0.10149353742599487
[Train] epoch 307 Batch 10 Loss 0.0676807314157486
[Train] epoch 307 Batch 11 Loss 0.06971238553524017
[Train] epoch 307 Batch 12 Loss 0.06763216853141785
[Train] epoch 307 Batch 13 Loss 0.2020249366760254
[Train] epoch 307 Batch 14 Loss 0.20404043793678284
[Train] epoch 307 Batch 15 Loss 0.23583896458148956
[Train] epoch 307 Batch 16 Loss 0.23689362406730652
[Train] epoch 307 Batch 17 Loss 0.2686378061771393
[Train] epoch 307 Batch 18 Loss 0.13434559106826782
[Train] epoch 307 Batch 19 Loss 0.3681250512599945
[Train] epoch 307 Batch 20 Loss 0.1690731942653656
[Train] epoch 307 Batch 21 Loss 0.3033444881439209
[Train] epoch 307 Batch 22 Loss 0.16818059980869293
[Train] epoch 307 Batch 23 Loss 0.2348334640264511
[Train] epoch 307 Batch 24 Loss 0.20100873708724976
[Train] epoch 307 Batch 25 Loss 0.17010162770748138
[Train] epoch 307 Batch 26 Loss 0.07045595347881317
[Train] epoch 307 Batch 27 Loss 0.23675362765789032
[Train] epoch 307 Batch 28 Loss 0.1690179705619812
[Train] epoch 307 Batch 29 Loss 0.16817644238471985
[Train] epoch 307 Batch 30 Loss 0.23671145737171173
[Train] epoch 307 Batch 31 Loss 0.23475036025047302
[Train] epoch 307 Batch 32 Loss 0.07142917811870575
[Train] epoch 307 Batch 33 Loss 0.10223999619483948
[Train] epoch 307 Batch 34 Loss 0.2365938127040863
[Train] epoch 307 Batch 35 Loss 0.138159841299057
[Train] epoch 307 Batch 36 Loss 0.20200829207897186
[Train] epoch 307 Batch 37 Loss 0.06758862733840942
[Train] epoch 307 Batch 38 Loss 0.23658829927444458
[Train] epoch 307 Batch 39 Loss 0.16804957389831543
[Train] epoch 307 Batch 40 Loss 0.36904793977737427
[Train] epoch 307 Batch 41 Loss 0.0346684567630291
[Train] epoch 307 Batch 42 Loss 0.16890780627727509
[Train] epoch 307 Batch 43 Loss 0.2694486379623413
[Train] epoch 307 Batch 44 Loss 0.10308855772018433
[Train] epoch 307 Batch 45 Loss 0.06852628290653229
[Train] epoch 307 Batch 46 Loss 0.1708240509033203
[Train] epoch 307 Batch 47 Loss 0.0675705224275589
[Train] epoch 308 Batch 0 Loss 0.10228821635246277
[Train] epoch 308 Batch 1 Loss 0.23483432829380035
[Train] epoch 308 Batch 2 Loss 0.10234161466360092
[Train] epoch 308 Batch 3 Loss 0.10050068795681
[Train] epoch 308 Batch 4 Loss 0.16894139349460602
[Train] epoch 308 Batch 5 Loss 0.2692527174949646
[Train] epoch 308 Batch 6 Loss 0.10143611580133438
[Train] epoch 308 Batch 7 Loss 0.20362995564937592
[Train] epoch 308 Batch 8 Loss 0.13695548474788666
[Train] epoch 308 Batch 9 Loss 0.13433167338371277
[Train] epoch 308 Batch 10 Loss 0.23482967913150787
[Train] epoch 308 Batch 11 Loss 0.1688401699066162
[Train] epoch 308 Batch 12 Loss 0.20273621380329132
[Train] epoch 308 Batch 13 Loss 0.3011547029018402
[Train] epoch 308 Batch 14 Loss 0.10219913721084595
[Train] epoch 308 Batch 15 Loss 0.20180203020572662
[Train] epoch 308 Batch 16 Loss 0.2025279700756073
[Train] epoch 308 Batch 17 Loss 0.20087821781635284
[Train] epoch 308 Batch 18 Loss 0.16804048418998718
[Train] epoch 308 Batch 19 Loss 0.06830128282308578
[Train] epoch 308 Batch 20 Loss 0.2398306280374527
[Train] epoch 308 Batch 21 Loss 0.13599132001399994
[Train] epoch 308 Batch 22 Loss 0.2675383687019348
[Train] epoch 308 Batch 23 Loss 0.23564794659614563
[Train] epoch 308 Batch 24 Loss 0.2008245438337326
[Train] epoch 308 Batch 25 Loss 0.0337056927382946
[Train] epoch 308 Batch 26 Loss 0.13609579205513
[Train] epoch 308 Batch 27 Loss 0.3028682768344879
[Train] epoch 308 Batch 28 Loss 0.20171740651130676
[Train] epoch 308 Batch 29 Loss 0.23563037812709808
[Train] epoch 308 Batch 30 Loss 0.16995012760162354
[Train] epoch 308 Batch 31 Loss 0.23626592755317688
[Train] epoch 308 Batch 32 Loss 0.06820272654294968
[Train] epoch 308 Batch 33 Loss 0.23616129159927368
[Train] epoch 308 Batch 34 Loss 0.17028707265853882
[Train] epoch 308 Batch 35 Loss 0.3013862371444702
[Train] epoch 308 Batch 36 Loss 0.4023101031780243
[Train] epoch 308 Batch 37 Loss 0.20160767436027527
[Train] epoch 308 Batch 38 Loss 0.2360846996307373
[Train] epoch 308 Batch 39 Loss 0.034577030688524246
[Train] epoch 308 Batch 40 Loss 0.06843604147434235
[Train] epoch 308 Batch 41 Loss 0.1341812014579773
[Train] epoch 308 Batch 42 Loss 0.13577225804328918
[Train] epoch 308 Batch 43 Loss 0.13488657772541046
[Train] epoch 308 Batch 44 Loss 0.1704290807247162
[Train] epoch 308 Batch 45 Loss 0.13403472304344177
[Train] epoch 308 Batch 46 Loss 0.03382618725299835
[Train] epoch 308 Batch 47 Loss 0.13563701510429382
[Train] epoch 309 Batch 0 Loss 0.2026212215423584
[Train] epoch 309 Batch 1 Loss 0.26826679706573486
[Train] epoch 309 Batch 2 Loss 0.10147494077682495
[Train] epoch 309 Batch 3 Loss 0.3340229392051697
[Train] epoch 309 Batch 4 Loss 0.167766273021698
[Train] epoch 309 Batch 5 Loss 0.0352647602558136
[Train] epoch 309 Batch 6 Loss 0.2032511979341507
[Train] epoch 309 Batch 7 Loss 0.2016979157924652
[Train] epoch 309 Batch 8 Loss 0.06896038353443146
[Train] epoch 309 Batch 9 Loss 0.1349097341299057
[Train] epoch 309 Batch 10 Loss 0.06752945482730865
[Train] epoch 309 Batch 11 Loss 0.30362996459007263
[Train] epoch 309 Batch 12 Loss 0.23453083634376526
[Train] epoch 309 Batch 13 Loss 0.06958536803722382
[Train] epoch 309 Batch 14 Loss 0.06978797912597656
[Train] epoch 309 Batch 15 Loss 0.23452436923980713
[Train] epoch 309 Batch 16 Loss 0.13860149681568146
[Train] epoch 309 Batch 17 Loss 0.10146865993738174
[Train] epoch 309 Batch 18 Loss 0.1341862678527832
[Train] epoch 309 Batch 19 Loss 0.20223547518253326
[Train] epoch 309 Batch 20 Loss 0.13431181013584137
[Train] epoch 309 Batch 21 Loss 0.23523014783859253
[Train] epoch 309 Batch 22 Loss 0.2683303952217102
[Train] epoch 309 Batch 23 Loss 0.2676440477371216
[Train] epoch 309 Batch 24 Loss 0.1685514748096466
[Train] epoch 309 Batch 25 Loss 0.06731776893138885
[Train] epoch 309 Batch 26 Loss 0.20168671011924744
[Train] epoch 309 Batch 27 Loss 0.16834671795368195
[Train] epoch 309 Batch 28 Loss 0.10048846900463104
[Train] epoch 309 Batch 29 Loss 0.20417019724845886
[Train] epoch 309 Batch 30 Loss 0.3363587558269501
[Train] epoch 309 Batch 31 Loss 0.3012954294681549
[Train] epoch 309 Batch 32 Loss 0.1683579385280609
[Train] epoch 309 Batch 33 Loss 0.23685938119888306
[Train] epoch 309 Batch 34 Loss 0.20264293253421783
[Train] epoch 309 Batch 35 Loss 0.13413825631141663
[Train] epoch 309 Batch 36 Loss 0.2024984061717987
[Train] epoch 309 Batch 37 Loss 0.03451135382056236
[Train] epoch 309 Batch 38 Loss 0.3020888864994049
[Train] epoch 309 Batch 39 Loss 0.10197537392377853
[Train] epoch 309 Batch 40 Loss 0.13413362205028534
[Train] epoch 309 Batch 41 Loss 0.16780897974967957
[Train] epoch 309 Batch 42 Loss 0.10102769732475281
[Train] epoch 309 Batch 43 Loss 0.06883089244365692
[Train] epoch 309 Batch 44 Loss 0.2016218900680542
[Train] epoch 309 Batch 45 Loss 0.2019370198249817
[Train] epoch 309 Batch 46 Loss 0.2029770314693451
[Train] epoch 309 Batch 47 Loss 0.20200471580028534
[Train] epoch 310 Batch 0 Loss 0.2689858078956604
[Train] epoch 310 Batch 1 Loss 0.16945618391036987
[Train] epoch 310 Batch 2 Loss 0.10251910984516144
[Train] epoch 310 Batch 3 Loss 0.16783292591571808
[Train] epoch 310 Batch 4 Loss 0.13515499234199524
[Train] epoch 310 Batch 5 Loss 0.06847819685935974
[Train] epoch 310 Batch 6 Loss 0.2028389573097229
[Train] epoch 310 Batch 7 Loss 0.17023351788520813
[Train] epoch 310 Batch 8 Loss 0.16903123259544373
[Train] epoch 310 Batch 9 Loss 0.33521097898483276
[Train] epoch 310 Batch 10 Loss 0.20220717787742615
[Train] epoch 310 Batch 11 Loss 0.10163860768079758
[Train] epoch 310 Batch 12 Loss 0.1356654167175293
[Train] epoch 310 Batch 13 Loss 0.1419413685798645
[Train] epoch 310 Batch 14 Loss 0.20346692204475403
[Train] epoch 310 Batch 15 Loss 0.10326214134693146
[Train] epoch 310 Batch 16 Loss 0.17331916093826294
[Train] epoch 310 Batch 17 Loss 0.10159219801425934
[Train] epoch 310 Batch 18 Loss 0.27077770233154297
[Train] epoch 310 Batch 19 Loss 0.3679371178150177
[Train] epoch 310 Batch 20 Loss 0.16801610589027405
[Train] epoch 310 Batch 21 Loss 0.2706149220466614
[Train] epoch 310 Batch 22 Loss 0.23392042517662048
[Train] epoch 310 Batch 23 Loss 0.20200231671333313
[Train] epoch 310 Batch 24 Loss 0.14868706464767456
[Train] epoch 310 Batch 25 Loss 0.10317812114953995
[Train] epoch 310 Batch 26 Loss 0.23389078676700592
[Train] epoch 310 Batch 27 Loss 0.10210039466619492
[Train] epoch 310 Batch 28 Loss 0.1361633688211441
[Train] epoch 310 Batch 29 Loss 0.2019561231136322
[Train] epoch 310 Batch 30 Loss 0.2679731845855713
[Train] epoch 310 Batch 31 Loss 0.21599605679512024
[Train] epoch 310 Batch 32 Loss 0.03594816476106644
[Train] epoch 310 Batch 33 Loss 0.1374378204345703
[Train] epoch 310 Batch 34 Loss 0.1682145893573761
[Train] epoch 310 Batch 35 Loss 0.23696550726890564
[Train] epoch 310 Batch 36 Loss 0.03479313105344772
[Train] epoch 310 Batch 37 Loss 0.2362082600593567
[Train] epoch 310 Batch 38 Loss 0.3357313871383667
[Train] epoch 310 Batch 39 Loss 0.1017877534031868
[Train] epoch 310 Batch 40 Loss 0.10285497456789017
[Train] epoch 310 Batch 41 Loss 0.13783304393291473
[Train] epoch 310 Batch 42 Loss 0.20339207351207733
[Train] epoch 310 Batch 43 Loss 0.27145737409591675
[Train] epoch 310 Batch 44 Loss 0.1344863921403885
[Train] epoch 310 Batch 45 Loss 0.2038438469171524
[Train] epoch 310 Batch 46 Loss 0.10307563096284866
[Train] epoch 310 Batch 47 Loss 0.17108282446861267
[Train] epoch 311 Batch 0 Loss 0.1364276111125946
[Train] epoch 311 Batch 1 Loss 0.13596302270889282
[Train] epoch 311 Batch 2 Loss 0.13867416977882385
[Train] epoch 311 Batch 3 Loss 0.1714487075805664
[Train] epoch 311 Batch 4 Loss 0.2353745698928833
[Train] epoch 311 Batch 5 Loss 0.20278096199035645
[Train] epoch 311 Batch 6 Loss 0.036890286952257156
[Train] epoch 311 Batch 7 Loss 0.20412516593933105
[Train] epoch 311 Batch 8 Loss 0.2710619866847992
[Train] epoch 311 Batch 9 Loss 0.17011986672878265
[Train] epoch 311 Batch 10 Loss 0.17465966939926147
[Train] epoch 311 Batch 11 Loss 0.10209367424249649
[Train] epoch 311 Batch 12 Loss 0.13904953002929688
[Train] epoch 311 Batch 13 Loss 0.17011985182762146
[Train] epoch 311 Batch 14 Loss 0.20424990355968475
[Train] epoch 311 Batch 15 Loss 0.06935890763998032
[Train] epoch 311 Batch 16 Loss 0.23988689482212067
[Train] epoch 311 Batch 17 Loss 0.033986084163188934
[Train] epoch 311 Batch 18 Loss 0.2040756642818451
[Train] epoch 311 Batch 19 Loss 0.1374271810054779
[Train] epoch 311 Batch 20 Loss 0.20273929834365845
[Train] epoch 311 Batch 21 Loss 0.06796051561832428
[Train] epoch 311 Batch 22 Loss 0.17394396662712097
[Train] epoch 311 Batch 23 Loss 0.16856864094734192
[Train] epoch 311 Batch 24 Loss 0.3712018132209778
[Train] epoch 311 Batch 25 Loss 0.2704452872276306
[Train] epoch 311 Batch 26 Loss 1.0728851975727594e-06
[Train] epoch 311 Batch 27 Loss 0.23533615469932556
[Train] epoch 311 Batch 28 Loss 0.1044376790523529
[Train] epoch 311 Batch 29 Loss 0.17098863422870636
[Train] epoch 311 Batch 30 Loss 0.13589605689048767
[Train] epoch 311 Batch 31 Loss 0.3006489872932434
[Train] epoch 311 Batch 32 Loss 0.3698198199272156
[Train] epoch 311 Batch 33 Loss 0.06795990467071533
[Train] epoch 311 Batch 34 Loss 0.13677939772605896
[Train] epoch 311 Batch 35 Loss 0.2012757956981659
[Train] epoch 311 Batch 36 Loss 0.10306786000728607
[Train] epoch 311 Batch 37 Loss 0.23764067888259888
[Train] epoch 311 Batch 38 Loss 0.2024221420288086
[Train] epoch 311 Batch 39 Loss 0.3357911705970764
[Train] epoch 311 Batch 40 Loss 0.13564804196357727
[Train] epoch 311 Batch 41 Loss 0.10166105628013611
[Train] epoch 311 Batch 42 Loss 0.20446859300136566
[Train] epoch 311 Batch 43 Loss 0.10049998760223389
[Train] epoch 311 Batch 44 Loss 0.10179053246974945
[Train] epoch 311 Batch 45 Loss 0.16821932792663574
[Train] epoch 311 Batch 46 Loss 0.20332035422325134
[Train] epoch 311 Batch 47 Loss 0.40129056572914124
[Train] epoch 312 Batch 0 Loss 0.2359786331653595
[Train] epoch 312 Batch 1 Loss 0.20128971338272095
[Train] epoch 312 Batch 2 Loss 0.1691906899213791
[Train] epoch 312 Batch 3 Loss 0.27019041776657104
[Train] epoch 312 Batch 4 Loss 0.16953949630260468
[Train] epoch 312 Batch 5 Loss 0.30459344387054443
[Train] epoch 312 Batch 6 Loss 0.06988321244716644
[Train] epoch 312 Batch 7 Loss 0.035892825573682785
[Train] epoch 312 Batch 8 Loss 0.13521388173103333
[Train] epoch 312 Batch 9 Loss 0.20318952202796936
[Train] epoch 312 Batch 10 Loss 0.2689225673675537
[Train] epoch 312 Batch 11 Loss 0.23627108335494995
[Train] epoch 312 Batch 12 Loss 0.06984986364841461
[Train] epoch 312 Batch 13 Loss 0.2032879889011383
[Train] epoch 312 Batch 14 Loss 0.335419237613678
[Train] epoch 312 Batch 15 Loss 0.03489368036389351
[Train] epoch 312 Batch 16 Loss 0.2361195981502533
[Train] epoch 312 Batch 17 Loss 0.23479843139648438
[Train] epoch 312 Batch 18 Loss 0.13563598692417145
[Train] epoch 312 Batch 19 Loss 0.10258518159389496
[Train] epoch 312 Batch 20 Loss 0.2678797245025635
[Train] epoch 312 Batch 21 Loss 0.10158997774124146
[Train] epoch 312 Batch 22 Loss 0.06787388771772385
[Train] epoch 312 Batch 23 Loss 0.26858797669410706
[Train] epoch 312 Batch 24 Loss 0.3375614285469055
[Train] epoch 312 Batch 25 Loss 0.1693480908870697
[Train] epoch 312 Batch 26 Loss 0.1005992591381073
[Train] epoch 312 Batch 27 Loss 0.27108973264694214
[Train] epoch 312 Batch 28 Loss 0.2700190246105194
[Train] epoch 312 Batch 29 Loss 0.06763050705194473
[Train] epoch 312 Batch 30 Loss 0.10340774059295654
[Train] epoch 312 Batch 31 Loss 0.13630318641662598
[Train] epoch 312 Batch 32 Loss 0.16715990006923676
[Train] epoch 312 Batch 33 Loss 0.2359257936477661
[Train] epoch 312 Batch 34 Loss 0.2047656774520874
[Train] epoch 312 Batch 35 Loss 0.1372000277042389
[Train] epoch 312 Batch 36 Loss 0.20197740197181702
[Train] epoch 312 Batch 37 Loss 0.13631261885166168
[Train] epoch 312 Batch 38 Loss 0.23571288585662842
[Train] epoch 312 Batch 39 Loss 0.1693548560142517
[Train] epoch 312 Batch 40 Loss 0.10147586464881897
[Train] epoch 312 Batch 41 Loss 0.06772501766681671
[Train] epoch 312 Batch 42 Loss 0.26757243275642395
[Train] epoch 312 Batch 43 Loss 0.03747309371829033
[Train] epoch 312 Batch 44 Loss 0.06858658790588379
[Train] epoch 312 Batch 45 Loss 0.16916733980178833
[Train] epoch 312 Batch 46 Loss 0.13537004590034485
[Train] epoch 312 Batch 47 Loss 0.26979315280914307
[Train] epoch 313 Batch 0 Loss 0.033921122550964355
[Train] epoch 313 Batch 1 Loss 0.03479670360684395
[Train] epoch 313 Batch 2 Loss 0.2694466710090637
[Train] epoch 313 Batch 3 Loss 0.20187708735466003
[Train] epoch 313 Batch 4 Loss 0.23461896181106567
[Train] epoch 313 Batch 5 Loss 0.2703975737094879
[Train] epoch 313 Batch 6 Loss 0.1355304718017578
[Train] epoch 313 Batch 7 Loss 0.1345040500164032
[Train] epoch 313 Batch 8 Loss 0.17027001082897186
[Train] epoch 313 Batch 9 Loss 0.13632351160049438
[Train] epoch 313 Batch 10 Loss 0.2685064673423767
[Train] epoch 313 Batch 11 Loss 0.10122941434383392
[Train] epoch 313 Batch 12 Loss 0.10226117074489594
[Train] epoch 313 Batch 13 Loss 0.23556530475616455
[Train] epoch 313 Batch 14 Loss 0.2365688979625702
[Train] epoch 313 Batch 15 Loss 0.13449837267398834
[Train] epoch 313 Batch 16 Loss 0.0676162838935852
[Train] epoch 313 Batch 17 Loss 0.16840165853500366
[Train] epoch 313 Batch 18 Loss 0.20299425721168518
[Train] epoch 313 Batch 19 Loss 0.10152167081832886
[Train] epoch 313 Batch 20 Loss 0.26969054341316223
[Train] epoch 313 Batch 21 Loss 0.1682252585887909
[Train] epoch 313 Batch 22 Loss 0.10467581450939178
[Train] epoch 313 Batch 23 Loss 0.23603585362434387
[Train] epoch 313 Batch 24 Loss 0.13445371389389038
[Train] epoch 313 Batch 25 Loss 0.16834157705307007
[Train] epoch 313 Batch 26 Loss 0.13449543714523315
[Train] epoch 313 Batch 27 Loss 0.1379958689212799
[Train] epoch 313 Batch 28 Loss 0.4688814878463745
[Train] epoch 313 Batch 29 Loss 0.20238013565540314
[Train] epoch 313 Batch 30 Loss 0.10188914090394974
[Train] epoch 313 Batch 31 Loss 0.06902291625738144
[Train] epoch 313 Batch 32 Loss 0.2712401747703552
[Train] epoch 313 Batch 33 Loss 0.3017567992210388
[Train] epoch 313 Batch 34 Loss 0.1382199376821518
[Train] epoch 313 Batch 35 Loss 0.16721424460411072
[Train] epoch 313 Batch 36 Loss 0.30564579367637634
[Train] epoch 313 Batch 37 Loss 0.07030801475048065
[Train] epoch 313 Batch 38 Loss 0.237533301115036
[Train] epoch 313 Batch 39 Loss 0.20243588089942932
[Train] epoch 313 Batch 40 Loss 0.17223790287971497
[Train] epoch 313 Batch 41 Loss 0.06907767057418823
[Train] epoch 313 Batch 42 Loss 0.23627004027366638
[Train] epoch 313 Batch 43 Loss 0.23621493577957153
[Train] epoch 313 Batch 44 Loss 0.1718970537185669
[Train] epoch 313 Batch 45 Loss 0.23504967987537384
[Train] epoch 313 Batch 46 Loss 0.03972567245364189
[Train] epoch 313 Batch 47 Loss 0.13452467322349548
[Train] epoch 314 Batch 0 Loss 0.134424090385437
[Train] epoch 314 Batch 1 Loss 0.30054569244384766
[Train] epoch 314 Batch 2 Loss 0.13551434874534607
[Train] epoch 314 Batch 3 Loss 0.2361651062965393
[Train] epoch 314 Batch 4 Loss 0.33556246757507324
[Train] epoch 314 Batch 5 Loss 0.3344266414642334
[Train] epoch 314 Batch 6 Loss 0.1694236546754837
[Train] epoch 314 Batch 7 Loss 0.23715630173683167
[Train] epoch 314 Batch 8 Loss 0.06990095973014832
[Train] epoch 314 Batch 9 Loss 0.10271961987018585
[Train] epoch 314 Batch 10 Loss 0.06986923515796661
[Train] epoch 314 Batch 11 Loss 0.16826003789901733
[Train] epoch 314 Batch 12 Loss 0.2370605766773224
[Train] epoch 314 Batch 13 Loss 0.2021794319152832
[Train] epoch 314 Batch 14 Loss 0.1365288645029068
[Train] epoch 314 Batch 15 Loss 0.139657661318779
[Train] epoch 314 Batch 16 Loss 0.20316460728645325
[Train] epoch 314 Batch 17 Loss 0.068722203373909
[Train] epoch 314 Batch 18 Loss 0.3026031255722046
[Train] epoch 314 Batch 19 Loss 0.1701551377773285
[Train] epoch 314 Batch 20 Loss 0.20306609570980072
[Train] epoch 314 Batch 21 Loss 0.10147646814584732
[Train] epoch 314 Batch 22 Loss 0.133334219455719
[Train] epoch 314 Batch 23 Loss 0.27066314220428467
[Train] epoch 314 Batch 24 Loss 0.16808374226093292
[Train] epoch 314 Batch 25 Loss 0.20200404524803162
[Train] epoch 314 Batch 26 Loss 0.2019938826560974
[Train] epoch 314 Batch 27 Loss 0.10250495374202728
[Train] epoch 314 Batch 28 Loss 0.1351739466190338
[Train] epoch 314 Batch 29 Loss 0.13534004986286163
[Train] epoch 314 Batch 30 Loss 0.06762345880270004
[Train] epoch 314 Batch 31 Loss 0.06849817931652069
[Train] epoch 314 Batch 32 Loss 0.20400328934192657
[Train] epoch 314 Batch 33 Loss 0.20302483439445496
[Train] epoch 314 Batch 34 Loss 0.2366701364517212
[Train] epoch 314 Batch 35 Loss 0.16910752654075623
[Train] epoch 314 Batch 36 Loss 0.1352415680885315
[Train] epoch 314 Batch 37 Loss 0.20198844373226166
[Train] epoch 314 Batch 38 Loss 0.1361870914697647
[Train] epoch 314 Batch 39 Loss 0.30263659358024597
[Train] epoch 314 Batch 40 Loss 0.06839138269424438
[Train] epoch 314 Batch 41 Loss 0.16830289363861084
[Train] epoch 314 Batch 42 Loss 0.2677571773529053
[Train] epoch 314 Batch 43 Loss 0.13806985318660736
[Train] epoch 314 Batch 44 Loss 0.13418281078338623
[Train] epoch 314 Batch 45 Loss 0.10402831435203552
[Train] epoch 314 Batch 46 Loss 0.1681959629058838
[Train] epoch 314 Batch 47 Loss 0.2358233630657196
[Train] epoch 315 Batch 0 Loss 0.10139863193035126
[Train] epoch 315 Batch 1 Loss 0.03460172563791275
[Train] epoch 315 Batch 2 Loss 0.2046094685792923
[Train] epoch 315 Batch 3 Loss 0.23593592643737793
[Train] epoch 315 Batch 4 Loss 0.2685752809047699
[Train] epoch 315 Batch 5 Loss 0.16900086402893066
[Train] epoch 315 Batch 6 Loss 0.10318309813737869
[Train] epoch 315 Batch 7 Loss 0.16802412271499634
[Train] epoch 315 Batch 8 Loss 0.3016239106655121
[Train] epoch 315 Batch 9 Loss 0.13753443956375122
[Train] epoch 315 Batch 10 Loss 0.06937979906797409
[Train] epoch 315 Batch 11 Loss 0.10366886854171753
[Train] epoch 315 Batch 12 Loss 0.2017745077610016
[Train] epoch 315 Batch 13 Loss 0.3369624614715576
[Train] epoch 315 Batch 14 Loss 0.13522356748580933
[Train] epoch 315 Batch 15 Loss 0.13584953546524048
[Train] epoch 315 Batch 16 Loss 0.0008041099063120782
[Train] epoch 315 Batch 17 Loss 0.2355881929397583
[Train] epoch 315 Batch 18 Loss 0.0007824279018677771
[Train] epoch 315 Batch 19 Loss 0.16892856359481812
[Train] epoch 315 Batch 20 Loss 0.30040425062179565
[Train] epoch 315 Batch 21 Loss 0.10208596289157867
[Train] epoch 315 Batch 22 Loss 0.2685304880142212
[Train] epoch 315 Batch 23 Loss 0.30161523818969727
[Train] epoch 315 Batch 24 Loss 0.20262441039085388
[Train] epoch 315 Batch 25 Loss 0.10286131501197815
[Train] epoch 315 Batch 26 Loss 0.1687738299369812
[Train] epoch 315 Batch 27 Loss 0.16813738644123077
[Train] epoch 315 Batch 28 Loss 0.2360435128211975
[Train] epoch 315 Batch 29 Loss 0.20262812077999115
[Train] epoch 315 Batch 30 Loss 0.20184147357940674
[Train] epoch 315 Batch 31 Loss 0.16888025403022766
[Train] epoch 315 Batch 32 Loss 0.20092520117759705
[Train] epoch 315 Batch 33 Loss 0.0684865266084671
[Train] epoch 315 Batch 34 Loss 0.168540358543396
[Train] epoch 315 Batch 35 Loss 0.1351480484008789
[Train] epoch 315 Batch 36 Loss 0.26907938718795776
[Train] epoch 315 Batch 37 Loss 0.20180970430374146
[Train] epoch 315 Batch 38 Loss 0.1027560830116272
[Train] epoch 315 Batch 39 Loss 0.16810524463653564
[Train] epoch 315 Batch 40 Loss 0.3023373484611511
[Train] epoch 315 Batch 41 Loss 0.10144834220409393
[Train] epoch 315 Batch 42 Loss 0.23624932765960693
[Train] epoch 315 Batch 43 Loss 0.16822361946105957
[Train] epoch 315 Batch 44 Loss 0.06757626682519913
[Train] epoch 315 Batch 45 Loss 0.2687733769416809
[Train] epoch 315 Batch 46 Loss 0.20364788174629211
[Train] epoch 315 Batch 47 Loss 0.20178988575935364
[Train] epoch 316 Batch 0 Loss 0.1022815853357315
[Train] epoch 316 Batch 1 Loss 0.13429757952690125
[Train] epoch 316 Batch 2 Loss 0.20102599263191223
[Train] epoch 316 Batch 3 Loss 0.26969054341316223
[Train] epoch 316 Batch 4 Loss 0.06768456101417542
[Train] epoch 316 Batch 5 Loss 0.10050756484270096
[Train] epoch 316 Batch 6 Loss 0.16818200051784515
[Train] epoch 316 Batch 7 Loss 0.10256302356719971
[Train] epoch 316 Batch 8 Loss 0.13856741786003113
[Train] epoch 316 Batch 9 Loss 0.10150261968374252
[Train] epoch 316 Batch 10 Loss 0.23704589903354645
[Train] epoch 316 Batch 11 Loss 0.10267385095357895
[Train] epoch 316 Batch 12 Loss 0.2349635511636734
[Train] epoch 316 Batch 13 Loss 0.2042156159877777
[Train] epoch 316 Batch 14 Loss 0.20313167572021484
[Train] epoch 316 Batch 15 Loss 0.2021431028842926
[Train] epoch 316 Batch 16 Loss 0.10155880451202393
[Train] epoch 316 Batch 17 Loss 0.20205362141132355
[Train] epoch 316 Batch 18 Loss 0.16927793622016907
[Train] epoch 316 Batch 19 Loss 0.06883608549833298
[Train] epoch 316 Batch 20 Loss 0.10378685593605042
[Train] epoch 316 Batch 21 Loss 0.17044562101364136
[Train] epoch 316 Batch 22 Loss 0.06772401928901672
[Train] epoch 316 Batch 23 Loss 0.30364102125167847
[Train] epoch 316 Batch 24 Loss 0.16716063022613525
[Train] epoch 316 Batch 25 Loss 0.2021181583404541
[Train] epoch 316 Batch 26 Loss 0.10370850563049316
[Train] epoch 316 Batch 27 Loss 0.16916336119174957
[Train] epoch 316 Batch 28 Loss 0.23914925754070282
[Train] epoch 316 Batch 29 Loss 0.06770241260528564
[Train] epoch 316 Batch 30 Loss 0.30367761850357056
[Train] epoch 316 Batch 31 Loss 0.17127516865730286
[Train] epoch 316 Batch 32 Loss 0.169175386428833
[Train] epoch 316 Batch 33 Loss 0.30149874091148376
[Train] epoch 316 Batch 34 Loss 0.10253538191318512
[Train] epoch 316 Batch 35 Loss 0.1681743860244751
[Train] epoch 316 Batch 36 Loss 0.3034925162792206
[Train] epoch 316 Batch 37 Loss 0.10149438679218292
[Train] epoch 316 Batch 38 Loss 0.2696174383163452
[Train] epoch 316 Batch 39 Loss 0.16914579272270203
[Train] epoch 316 Batch 40 Loss 0.20294827222824097
[Train] epoch 316 Batch 41 Loss 0.23765307664871216
[Train] epoch 316 Batch 42 Loss 0.06666764616966248
[Train] epoch 316 Batch 43 Loss 0.30142784118652344
[Train] epoch 316 Batch 44 Loss 0.16909633576869965
[Train] epoch 316 Batch 45 Loss 0.23475807905197144
[Train] epoch 316 Batch 46 Loss 0.06764388084411621
[Train] epoch 316 Batch 47 Loss 0.37105947732925415
[Train] epoch 317 Batch 0 Loss 0.1690693348646164
[Train] epoch 317 Batch 1 Loss 0.03475775569677353
[Train] epoch 317 Batch 2 Loss 0.2686253786087036
[Train] epoch 317 Batch 3 Loss 0.2357238233089447
[Train] epoch 317 Batch 4 Loss 0.16812554001808167
[Train] epoch 317 Batch 5 Loss 0.16992712020874023
[Train] epoch 317 Batch 6 Loss 0.3014870882034302
[Train] epoch 317 Batch 7 Loss 0.30326199531555176
[Train] epoch 317 Batch 8 Loss 0.10318370163440704
[Train] epoch 317 Batch 9 Loss 0.1342860460281372
[Train] epoch 317 Batch 10 Loss 0.23660634458065033
[Train] epoch 317 Batch 11 Loss 0.10136857628822327
[Train] epoch 317 Batch 12 Loss 0.3031662702560425
[Train] epoch 317 Batch 13 Loss 0.1022450402379036
[Train] epoch 317 Batch 14 Loss 0.2036130130290985
[Train] epoch 317 Batch 15 Loss 0.1688637137413025
[Train] epoch 317 Batch 16 Loss 0.2675894796848297
[Train] epoch 317 Batch 17 Loss 0.13418570160865784
[Train] epoch 317 Batch 18 Loss 0.10312487930059433
[Train] epoch 317 Batch 19 Loss 0.06751339137554169
[Train] epoch 317 Batch 20 Loss 0.06666764616966248
[Train] epoch 317 Batch 21 Loss 0.10212656855583191
[Train] epoch 317 Batch 22 Loss 0.16808727383613586
[Train] epoch 317 Batch 23 Loss 0.16800832748413086
[Train] epoch 317 Batch 24 Loss 0.102089062333107
[Train] epoch 317 Batch 25 Loss 0.2701774537563324
[Train] epoch 317 Batch 26 Loss 0.03548802062869072
[Train] epoch 317 Batch 27 Loss 0.13416820764541626
[Train] epoch 317 Batch 28 Loss 0.13606896996498108
[Train] epoch 317 Batch 29 Loss 0.13677720725536346
[Train] epoch 317 Batch 30 Loss 0.17068269848823547
[Train] epoch 317 Batch 31 Loss 0.3698667883872986
[Train] epoch 317 Batch 32 Loss 0.3023126721382141
[Train] epoch 317 Batch 33 Loss 0.10308323800563812
[Train] epoch 317 Batch 34 Loss 0.20098784565925598
[Train] epoch 317 Batch 35 Loss 0.20079675316810608
[Train] epoch 317 Batch 36 Loss 0.10287466645240784
[Train] epoch 317 Batch 37 Loss 0.06907574087381363
[Train] epoch 317 Batch 38 Loss 0.10120685398578644
[Train] epoch 317 Batch 39 Loss 0.16894268989562988
[Train] epoch 317 Batch 40 Loss 0.10208237171173096
[Train] epoch 317 Batch 41 Loss 0.26754942536354065
[Train] epoch 317 Batch 42 Loss 0.16716012358665466
[Train] epoch 317 Batch 43 Loss 0.20157355070114136
[Train] epoch 317 Batch 44 Loss 0.23658043146133423
[Train] epoch 317 Batch 45 Loss 0.1718275249004364
[Train] epoch 317 Batch 46 Loss 0.1350967288017273
[Train] epoch 317 Batch 47 Loss 0.4346999526023865
[Train] epoch 318 Batch 0 Loss 0.13520243763923645
[Train] epoch 318 Batch 1 Loss 0.1679307520389557
[Train] epoch 318 Batch 2 Loss 0.10190753638744354
[Train] epoch 318 Batch 3 Loss 0.1694367229938507
[Train] epoch 318 Batch 4 Loss 0.3014748692512512
[Train] epoch 318 Batch 5 Loss 0.1364665925502777
[Train] epoch 318 Batch 6 Loss 0.1350754201412201
[Train] epoch 318 Batch 7 Loss 0.1368015557527542
[Train] epoch 318 Batch 8 Loss 0.03520597144961357
[Train] epoch 318 Batch 9 Loss 0.16877225041389465
[Train] epoch 318 Batch 10 Loss 0.13505496084690094
[Train] epoch 318 Batch 11 Loss 0.3348303437232971
[Train] epoch 318 Batch 12 Loss 0.23468244075775146
[Train] epoch 318 Batch 13 Loss 0.10209135711193085
[Train] epoch 318 Batch 14 Loss 0.26827436685562134
[Train] epoch 318 Batch 15 Loss 0.1670425832271576
[Train] epoch 318 Batch 16 Loss 0.1687391847372055
[Train] epoch 318 Batch 17 Loss 0.16860973834991455
[Train] epoch 318 Batch 18 Loss 0.30233052372932434
[Train] epoch 318 Batch 19 Loss 0.23566225171089172
[Train] epoch 318 Batch 20 Loss 0.13478702306747437
[Train] epoch 318 Batch 21 Loss 0.201578289270401
[Train] epoch 318 Batch 22 Loss 0.16958850622177124
[Train] epoch 318 Batch 23 Loss 0.13503704965114594
[Train] epoch 318 Batch 24 Loss 0.16897715628147125
[Train] epoch 318 Batch 25 Loss 0.20168906450271606
[Train] epoch 318 Batch 26 Loss 0.2692160904407501
[Train] epoch 318 Batch 27 Loss 0.13417690992355347
[Train] epoch 318 Batch 28 Loss 0.03596952185034752
[Train] epoch 318 Batch 29 Loss 0.23538845777511597
[Train] epoch 318 Batch 30 Loss 0.13404130935668945
[Train] epoch 318 Batch 31 Loss 0.10119258612394333
[Train] epoch 318 Batch 32 Loss 0.23608434200286865
[Train] epoch 318 Batch 33 Loss 0.27047663927078247
[Train] epoch 318 Batch 34 Loss 0.26834800839424133
[Train] epoch 318 Batch 35 Loss 0.13643833994865417
[Train] epoch 318 Batch 36 Loss 0.16701611876487732
[Train] epoch 318 Batch 37 Loss 0.035786546766757965
[Train] epoch 318 Batch 38 Loss 0.20153476297855377
[Train] epoch 318 Batch 39 Loss 0.10035569965839386
[Train] epoch 318 Batch 40 Loss 0.1025734394788742
[Train] epoch 318 Batch 41 Loss 0.06970196217298508
[Train] epoch 318 Batch 42 Loss 0.20220965147018433
[Train] epoch 318 Batch 43 Loss 0.20180407166481018
[Train] epoch 318 Batch 44 Loss 0.33513617515563965
[Train] epoch 318 Batch 45 Loss 0.03543545678257942
[Train] epoch 318 Batch 46 Loss 0.30197805166244507
[Train] epoch 318 Batch 47 Loss 0.20173940062522888
[Train] epoch 319 Batch 0 Loss 0.10043516755104065
[Train] epoch 319 Batch 1 Loss 0.1389642208814621
[Train] epoch 319 Batch 2 Loss 0.1353043019771576
[Train] epoch 319 Batch 3 Loss 0.2675560712814331
[Train] epoch 319 Batch 4 Loss 0.17027908563613892
[Train] epoch 319 Batch 5 Loss 0.23729592561721802
[Train] epoch 319 Batch 6 Loss 0.14050038158893585
[Train] epoch 319 Batch 7 Loss 0.3023945093154907
[Train] epoch 319 Batch 8 Loss 0.06847500801086426
[Train] epoch 319 Batch 9 Loss 0.13629016280174255
[Train] epoch 319 Batch 10 Loss 0.03489181399345398
[Train] epoch 319 Batch 11 Loss 0.2684023678302765
[Train] epoch 319 Batch 12 Loss 0.668586015701294
[Train] epoch 319 Batch 13 Loss 0.13590803742408752
[Train] epoch 319 Batch 14 Loss 0.136002779006958
[Train] epoch 319 Batch 15 Loss 0.23785893619060516
[Train] epoch 319 Batch 16 Loss 0.3342810571193695
[Train] epoch 319 Batch 17 Loss 0.24633988738059998
[Train] epoch 319 Batch 18 Loss 0.1665618121623993
[Train] epoch 319 Batch 19 Loss 0.353308767080307
[Train] epoch 319 Batch 20 Loss 0.16623526811599731
[Train] epoch 319 Batch 21 Loss 0.30047571659088135
[Train] epoch 319 Batch 22 Loss 0.1025470569729805
[Train] epoch 319 Batch 23 Loss 0.23583094775676727
[Train] epoch 319 Batch 24 Loss 0.20114487409591675
[Train] epoch 319 Batch 25 Loss 0.20292307436466217
[Train] epoch 319 Batch 26 Loss 0.2602538466453552
[Train] epoch 319 Batch 27 Loss 0.10156252980232239
[Train] epoch 319 Batch 28 Loss 0.10231228172779083
[Train] epoch 319 Batch 29 Loss 0.23517456650733948
[Train] epoch 319 Batch 30 Loss 0.13483752310276031
[Train] epoch 319 Batch 31 Loss 0.2016138732433319
[Train] epoch 319 Batch 32 Loss 0.146916463971138
[Train] epoch 319 Batch 33 Loss 0.16835233569145203
[Train] epoch 319 Batch 34 Loss 0.23474334180355072
[Train] epoch 319 Batch 35 Loss 0.137422114610672
[Train] epoch 319 Batch 36 Loss 0.20288917422294617
[Train] epoch 319 Batch 37 Loss 0.16725870966911316
[Train] epoch 319 Batch 38 Loss 0.27055153250694275
[Train] epoch 319 Batch 39 Loss 0.03661486506462097
[Train] epoch 319 Batch 40 Loss 0.17309051752090454
[Train] epoch 319 Batch 41 Loss 0.10216173529624939
[Train] epoch 319 Batch 42 Loss 0.23847854137420654
[Train] epoch 319 Batch 43 Loss 0.2696111798286438
[Train] epoch 319 Batch 44 Loss 0.10389372706413269
[Train] epoch 319 Batch 45 Loss 0.2680814564228058
[Train] epoch 319 Batch 46 Loss 0.20464834570884705
[Train] epoch 319 Batch 47 Loss 0.1673661172389984
[Train] epoch 320 Batch 0 Loss 0.30592504143714905
[Train] epoch 320 Batch 1 Loss 0.16919326782226562
[Train] epoch 320 Batch 2 Loss 0.16913971304893494
[Train] epoch 320 Batch 3 Loss 0.23589208722114563
[Train] epoch 320 Batch 4 Loss 0.06821922957897186
[Train] epoch 320 Batch 5 Loss 0.10223942995071411
[Train] epoch 320 Batch 6 Loss 0.07175476104021072
[Train] epoch 320 Batch 7 Loss 0.17080095410346985
[Train] epoch 320 Batch 8 Loss 0.2695811986923218
[Train] epoch 320 Batch 9 Loss 0.26802873611450195
[Train] epoch 320 Batch 10 Loss 0.13849137723445892
[Train] epoch 320 Batch 11 Loss 0.4045941233634949
[Train] epoch 320 Batch 12 Loss 0.23749183118343353
[Train] epoch 320 Batch 13 Loss 0.13880698382854462
[Train] epoch 320 Batch 14 Loss 0.2051711082458496
[Train] epoch 320 Batch 15 Loss 0.1364971399307251
[Train] epoch 320 Batch 16 Loss 0.20518100261688232
[Train] epoch 320 Batch 17 Loss 0.06989286839962006
[Train] epoch 320 Batch 18 Loss 0.2713855504989624
[Train] epoch 320 Batch 19 Loss 0.10398596525192261
[Train] epoch 320 Batch 20 Loss 0.17016088962554932
[Train] epoch 320 Batch 21 Loss 0.20136813819408417
[Train] epoch 320 Batch 22 Loss 0.16735154390335083
[Train] epoch 320 Batch 23 Loss 0.137643501162529
[Train] epoch 320 Batch 24 Loss 0.20296943187713623
[Train] epoch 320 Batch 25 Loss 0.0681232437491417
[Train] epoch 320 Batch 26 Loss 0.23836137354373932
[Train] epoch 320 Batch 27 Loss 0.07258453220129013
[Train] epoch 320 Batch 28 Loss 0.10211728513240814
[Train] epoch 320 Batch 29 Loss 0.270912230014801
[Train] epoch 320 Batch 30 Loss 0.20565560460090637
[Train] epoch 320 Batch 31 Loss 0.2054676115512848
[Train] epoch 320 Batch 32 Loss 0.168694406747818
[Train] epoch 320 Batch 33 Loss 0.27071475982666016
[Train] epoch 320 Batch 34 Loss 0.10063852369785309
[Train] epoch 320 Batch 35 Loss 0.20537444949150085
[Train] epoch 320 Batch 36 Loss 0.03668281063437462
[Train] epoch 320 Batch 37 Loss 0.205338716506958
[Train] epoch 320 Batch 38 Loss 0.17120611667633057
[Train] epoch 320 Batch 39 Loss 0.2365449070930481
[Train] epoch 320 Batch 40 Loss 0.23515522480010986
[Train] epoch 320 Batch 41 Loss 0.3019644021987915
[Train] epoch 320 Batch 42 Loss 0.10199716687202454
[Train] epoch 320 Batch 43 Loss 0.13459858298301697
[Train] epoch 320 Batch 44 Loss 0.2048984169960022
[Train] epoch 320 Batch 45 Loss 0.06912378966808319
[Train] epoch 320 Batch 46 Loss 0.17104566097259521
[Train] epoch 320 Batch 47 Loss 0.07013243436813354
[Train] epoch 321 Batch 0 Loss 0.2716524600982666
[Train] epoch 321 Batch 1 Loss 0.06897863745689392
[Train] epoch 321 Batch 2 Loss 0.2365128993988037
[Train] epoch 321 Batch 3 Loss 0.13569113612174988
[Train] epoch 321 Batch 4 Loss 0.07026151567697525
[Train] epoch 321 Batch 5 Loss 0.10410070419311523
[Train] epoch 321 Batch 6 Loss 0.10283544659614563
[Train] epoch 321 Batch 7 Loss 0.03620774298906326
[Train] epoch 321 Batch 8 Loss 0.06789809465408325
[Train] epoch 321 Batch 9 Loss 0.13545361161231995
[Train] epoch 321 Batch 10 Loss 0.1671723872423172
[Train] epoch 321 Batch 11 Loss 0.13815425336360931
[Train] epoch 321 Batch 12 Loss 0.10171303153038025
[Train] epoch 321 Batch 13 Loss 0.2678777277469635
[Train] epoch 321 Batch 14 Loss 0.23641058802604675
[Train] epoch 321 Batch 15 Loss 0.2362556904554367
[Train] epoch 321 Batch 16 Loss 0.13573366403579712
[Train] epoch 321 Batch 17 Loss 0.13555017113685608
[Train] epoch 321 Batch 18 Loss 0.16935673356056213
[Train] epoch 321 Batch 19 Loss 0.43619421124458313
[Train] epoch 321 Batch 20 Loss 0.1050424575805664
[Train] epoch 321 Batch 21 Loss 0.23612704873085022
[Train] epoch 321 Batch 22 Loss 0.1347019225358963
[Train] epoch 321 Batch 23 Loss 0.17061933875083923
[Train] epoch 321 Batch 24 Loss 0.23614761233329773
[Train] epoch 321 Batch 25 Loss 0.06955333054065704
[Train] epoch 321 Batch 26 Loss 0.3039398193359375
[Train] epoch 321 Batch 27 Loss 0.2714700698852539
[Train] epoch 321 Batch 28 Loss 0.06782734394073486
[Train] epoch 321 Batch 29 Loss 0.13714569807052612
[Train] epoch 321 Batch 30 Loss 0.33541834354400635
[Train] epoch 321 Batch 31 Loss 0.33446115255355835
[Train] epoch 321 Batch 32 Loss 0.10161752998828888
[Train] epoch 321 Batch 33 Loss 0.23469778895378113
[Train] epoch 321 Batch 34 Loss 0.1355932205915451
[Train] epoch 321 Batch 35 Loss 0.20297753810882568
[Train] epoch 321 Batch 36 Loss 0.2691250443458557
[Train] epoch 321 Batch 37 Loss 0.2013433575630188
[Train] epoch 321 Batch 38 Loss 0.20292413234710693
[Train] epoch 321 Batch 39 Loss 0.17029216885566711
[Train] epoch 321 Batch 40 Loss 0.30287668108940125
[Train] epoch 321 Batch 41 Loss 0.23715165257453918
[Train] epoch 321 Batch 42 Loss 0.30264878273010254
[Train] epoch 321 Batch 43 Loss 0.0008801904041320086
[Train] epoch 321 Batch 44 Loss 0.0008768156985752285
[Train] epoch 321 Batch 45 Loss 0.07063297927379608
[Train] epoch 321 Batch 46 Loss 0.20284587144851685
[Train] epoch 321 Batch 47 Loss 0.13530446588993073
[Train] epoch 322 Batch 0 Loss 0.13640061020851135
[Train] epoch 322 Batch 1 Loss 0.2364180088043213
[Train] epoch 322 Batch 2 Loss 0.20193253457546234
[Train] epoch 322 Batch 3 Loss 0.10151111334562302
[Train] epoch 322 Batch 4 Loss 0.1697160005569458
[Train] epoch 322 Batch 5 Loss 0.06971204280853271
[Train] epoch 322 Batch 6 Loss 0.20239995419979095
[Train] epoch 322 Batch 7 Loss 0.2359124720096588
[Train] epoch 322 Batch 8 Loss 0.23529550433158875
[Train] epoch 322 Batch 9 Loss 0.26967892050743103
[Train] epoch 322 Batch 10 Loss 0.10042664408683777
[Train] epoch 322 Batch 11 Loss 0.13627660274505615
[Train] epoch 322 Batch 12 Loss 0.2688113749027252
[Train] epoch 322 Batch 13 Loss 0.13414165377616882
[Train] epoch 322 Batch 14 Loss 0.3033590018749237
[Train] epoch 322 Batch 15 Loss 0.13605603575706482
[Train] epoch 322 Batch 16 Loss 0.06877399235963821
[Train] epoch 322 Batch 17 Loss 0.1014767661690712
[Train] epoch 322 Batch 18 Loss 0.101438969373703
[Train] epoch 322 Batch 19 Loss 0.237477645277977
[Train] epoch 322 Batch 20 Loss 0.13498225808143616
[Train] epoch 322 Batch 21 Loss 0.3383246064186096
[Train] epoch 322 Batch 22 Loss 0.167059063911438
[Train] epoch 322 Batch 23 Loss 0.1365395486354828
[Train] epoch 322 Batch 24 Loss 0.0690484419465065
[Train] epoch 322 Batch 25 Loss 0.37076514959335327
[Train] epoch 322 Batch 26 Loss 0.07008086144924164
[Train] epoch 322 Batch 27 Loss 0.06768758594989777
[Train] epoch 322 Batch 28 Loss 0.13721361756324768
[Train] epoch 322 Batch 29 Loss 0.16730427742004395
[Train] epoch 322 Batch 30 Loss 0.1693616807460785
[Train] epoch 322 Batch 31 Loss 0.13408520817756653
[Train] epoch 322 Batch 32 Loss 0.23653775453567505
[Train] epoch 322 Batch 33 Loss 0.16857068240642548
[Train] epoch 322 Batch 34 Loss 0.2020268589258194
[Train] epoch 322 Batch 35 Loss 0.1673002392053604
[Train] epoch 322 Batch 36 Loss 0.2020178735256195
[Train] epoch 322 Batch 37 Loss 0.134347602725029
[Train] epoch 322 Batch 38 Loss 0.2032446265220642
[Train] epoch 322 Batch 39 Loss 0.10038122534751892
[Train] epoch 322 Batch 40 Loss 0.1371024250984192
[Train] epoch 322 Batch 41 Loss 0.2701626718044281
[Train] epoch 322 Batch 42 Loss 0.06916259229183197
[Train] epoch 322 Batch 43 Loss 0.3363242745399475
[Train] epoch 322 Batch 44 Loss 0.30212128162384033
[Train] epoch 322 Batch 45 Loss 0.20098362863063812
[Train] epoch 322 Batch 46 Loss 0.1020822525024414
[Train] epoch 322 Batch 47 Loss 0.1690104603767395
[Train] epoch 323 Batch 0 Loss 0.16801241040229797
[Train] epoch 323 Batch 1 Loss 0.2676568329334259
[Train] epoch 323 Batch 2 Loss 0.1692492663860321
[Train] epoch 323 Batch 3 Loss 0.23643550276756287
[Train] epoch 323 Batch 4 Loss 0.3348315954208374
[Train] epoch 323 Batch 5 Loss 0.3699014484882355
[Train] epoch 323 Batch 6 Loss 0.20384985208511353
[Train] epoch 323 Batch 7 Loss 0.2349243015050888
[Train] epoch 323 Batch 8 Loss 0.06896132230758667
[Train] epoch 323 Batch 9 Loss 0.2404441237449646
[Train] epoch 323 Batch 10 Loss 0.13715901970863342
[Train] epoch 323 Batch 11 Loss 0.13463041186332703
[Train] epoch 323 Batch 12 Loss 0.13729943335056305
[Train] epoch 323 Batch 13 Loss 0.036539606750011444
[Train] epoch 323 Batch 14 Loss 0.06932827085256577
[Train] epoch 323 Batch 15 Loss 0.06787247955799103
[Train] epoch 323 Batch 16 Loss 0.2587863504886627
[Train] epoch 323 Batch 17 Loss 0.06945571303367615
[Train] epoch 323 Batch 18 Loss 0.4738907814025879
[Train] epoch 323 Batch 19 Loss 0.17166665196418762
[Train] epoch 323 Batch 20 Loss 0.2711649537086487
[Train] epoch 323 Batch 21 Loss 0.06963229924440384
[Train] epoch 323 Batch 22 Loss 0.2060006856918335
[Train] epoch 323 Batch 23 Loss 0.10382837057113647
[Train] epoch 323 Batch 24 Loss 0.14074213802814484
[Train] epoch 323 Batch 25 Loss 0.17046229541301727
[Train] epoch 323 Batch 26 Loss 0.2709285318851471
[Train] epoch 323 Batch 27 Loss 0.1397394835948944
[Train] epoch 323 Batch 28 Loss 0.07143930345773697
[Train] epoch 323 Batch 29 Loss 0.17045307159423828
[Train] epoch 323 Batch 30 Loss 0.23545989394187927
[Train] epoch 323 Batch 31 Loss 0.272335946559906
[Train] epoch 323 Batch 32 Loss 0.13501989841461182
[Train] epoch 323 Batch 33 Loss 0.06791245937347412
[Train] epoch 323 Batch 34 Loss 0.1742103397846222
[Train] epoch 323 Batch 35 Loss 0.20123326778411865
[Train] epoch 323 Batch 36 Loss 0.2387199103832245
[Train] epoch 323 Batch 37 Loss 0.20453503727912903
[Train] epoch 323 Batch 38 Loss 0.23745203018188477
[Train] epoch 323 Batch 39 Loss 0.0032585379667580128
[Train] epoch 323 Batch 40 Loss 0.16727511584758759
[Train] epoch 323 Batch 41 Loss 0.17230647802352905
[Train] epoch 323 Batch 42 Loss 0.13754940032958984
[Train] epoch 323 Batch 43 Loss 0.20260488986968994
[Train] epoch 323 Batch 44 Loss 0.06805285811424255
[Train] epoch 323 Batch 45 Loss 0.0696045458316803
[Train] epoch 323 Batch 46 Loss 0.3374585509300232
[Train] epoch 323 Batch 47 Loss 0.10060447454452515
[Train] epoch 324 Batch 0 Loss 0.10378308594226837
[Train] epoch 324 Batch 1 Loss 0.17012564837932587
[Train] epoch 324 Batch 2 Loss 0.20283713936805725
[Train] epoch 324 Batch 3 Loss 0.2352793961763382
[Train] epoch 324 Batch 4 Loss 0.2029295265674591
[Train] epoch 324 Batch 5 Loss 0.13599146902561188
[Train] epoch 324 Batch 6 Loss 0.20264679193496704
[Train] epoch 324 Batch 7 Loss 0.26787304878234863
[Train] epoch 324 Batch 8 Loss 0.20273402333259583
[Train] epoch 324 Batch 9 Loss 0.17149975895881653
[Train] epoch 324 Batch 10 Loss 0.16857263445854187
[Train] epoch 324 Batch 11 Loss 0.2067645788192749
[Train] epoch 324 Batch 12 Loss 0.0367765873670578
[Train] epoch 324 Batch 13 Loss 0.13454097509384155
[Train] epoch 324 Batch 14 Loss 0.06666764616966248
[Train] epoch 324 Batch 15 Loss 0.23911213874816895
[Train] epoch 324 Batch 16 Loss 0.17134374380111694
[Train] epoch 324 Batch 17 Loss 0.23641222715377808
[Train] epoch 324 Batch 18 Loss 0.2692943811416626
[Train] epoch 324 Batch 19 Loss 0.17103880643844604
[Train] epoch 324 Batch 20 Loss 0.2377743124961853
[Train] epoch 324 Batch 21 Loss 1.0728851975727594e-06
[Train] epoch 324 Batch 22 Loss 0.1358179748058319
[Train] epoch 324 Batch 23 Loss 0.20247608423233032
[Train] epoch 324 Batch 24 Loss 0.10186414420604706
[Train] epoch 324 Batch 25 Loss 0.10185734927654266
[Train] epoch 324 Batch 26 Loss 0.1370433121919632
[Train] epoch 324 Batch 27 Loss 0.23518656194210052
[Train] epoch 324 Batch 28 Loss 0.17092333734035492
[Train] epoch 324 Batch 29 Loss 0.23881196975708008
[Train] epoch 324 Batch 30 Loss 0.20242175459861755
[Train] epoch 324 Batch 31 Loss 0.3381631374359131
[Train] epoch 324 Batch 32 Loss 0.10420900583267212
[Train] epoch 324 Batch 33 Loss 0.13573378324508667
[Train] epoch 324 Batch 34 Loss 0.16962957382202148
[Train] epoch 324 Batch 35 Loss 0.10060587525367737
[Train] epoch 324 Batch 36 Loss 0.20355676114559174
[Train] epoch 324 Batch 37 Loss 0.3356853723526001
[Train] epoch 324 Batch 38 Loss 0.06787712126970291
[Train] epoch 324 Batch 39 Loss 0.03505904600024223
[Train] epoch 324 Batch 40 Loss 0.1695600152015686
[Train] epoch 324 Batch 41 Loss 0.10403057932853699
[Train] epoch 324 Batch 42 Loss 0.10173341631889343
[Train] epoch 324 Batch 43 Loss 0.4046827554702759
[Train] epoch 324 Batch 44 Loss 0.10397881269454956
[Train] epoch 324 Batch 45 Loss 0.10396060347557068
[Train] epoch 324 Batch 46 Loss 0.3356996476650238
[Train] epoch 324 Batch 47 Loss 0.2700193524360657
[Train] epoch 325 Batch 0 Loss 0.13679853081703186
[Train] epoch 325 Batch 1 Loss 0.16945594549179077
[Train] epoch 325 Batch 2 Loss 0.2383391559123993
[Train] epoch 325 Batch 3 Loss 0.03393928334116936
[Train] epoch 325 Batch 4 Loss 0.37062904238700867
[Train] epoch 325 Batch 5 Loss 0.16840702295303345
[Train] epoch 325 Batch 6 Loss 0.16946941614151
[Train] epoch 325 Batch 7 Loss 0.203324556350708
[Train] epoch 325 Batch 8 Loss 0.1672719419002533
[Train] epoch 325 Batch 9 Loss 0.2361139953136444
[Train] epoch 325 Batch 10 Loss 0.16943496465682983
[Train] epoch 325 Batch 11 Loss 0.1026846170425415
[Train] epoch 325 Batch 12 Loss 0.2699452042579651
[Train] epoch 325 Batch 13 Loss 0.23505167663097382
[Train] epoch 325 Batch 14 Loss 0.20223847031593323
[Train] epoch 325 Batch 15 Loss 0.23701129853725433
[Train] epoch 325 Batch 16 Loss 0.23708410561084747
[Train] epoch 325 Batch 17 Loss 0.2698031961917877
[Train] epoch 325 Batch 18 Loss 0.16837283968925476
[Train] epoch 325 Batch 19 Loss 0.1682789921760559
[Train] epoch 325 Batch 20 Loss 0.06877797096967697
[Train] epoch 325 Batch 21 Loss 0.13632625341415405
[Train] epoch 325 Batch 22 Loss 0.16825459897518158
[Train] epoch 325 Batch 23 Loss 0.10147865116596222
[Train] epoch 325 Batch 24 Loss 0.06886058300733566
[Train] epoch 325 Batch 25 Loss 0.20195898413658142
[Train] epoch 325 Batch 26 Loss 0.2722288966178894
[Train] epoch 325 Batch 27 Loss 0.172024205327034
[Train] epoch 325 Batch 28 Loss 0.1693243682384491
[Train] epoch 325 Batch 29 Loss 0.13633932173252106
[Train] epoch 325 Batch 30 Loss 0.1691868007183075
[Train] epoch 325 Batch 31 Loss 0.16823036968708038
[Train] epoch 325 Batch 32 Loss 0.13537022471427917
[Train] epoch 325 Batch 33 Loss 0.30262601375579834
[Train] epoch 325 Batch 34 Loss 0.13523094356060028
[Train] epoch 325 Batch 35 Loss 0.07069715112447739
[Train] epoch 325 Batch 36 Loss 0.10167475044727325
[Train] epoch 325 Batch 37 Loss 0.2021336704492569
[Train] epoch 325 Batch 38 Loss 0.13626191020011902
[Train] epoch 325 Batch 39 Loss 0.06772740185260773
[Train] epoch 325 Batch 40 Loss 0.2677316665649414
[Train] epoch 325 Batch 41 Loss 0.1004624143242836
[Train] epoch 325 Batch 42 Loss 0.10137467831373215
[Train] epoch 325 Batch 43 Loss 0.33770889043807983
[Train] epoch 325 Batch 44 Loss 0.26998594403266907
[Train] epoch 325 Batch 45 Loss 0.20436449348926544
[Train] epoch 325 Batch 46 Loss 0.1343889981508255
[Train] epoch 325 Batch 47 Loss 0.0686149150133133
[Train] epoch 326 Batch 0 Loss 0.20194479823112488
[Train] epoch 326 Batch 1 Loss 0.13737520575523376
[Train] epoch 326 Batch 2 Loss 0.4050823450088501
[Train] epoch 326 Batch 3 Loss 0.13632023334503174
[Train] epoch 326 Batch 4 Loss 0.0695035308599472
[Train] epoch 326 Batch 5 Loss 0.16904303431510925
[Train] epoch 326 Batch 6 Loss 0.30356311798095703
[Train] epoch 326 Batch 7 Loss 0.23673146963119507
[Train] epoch 326 Batch 8 Loss 0.1681469827890396
[Train] epoch 326 Batch 9 Loss 0.13596585392951965
[Train] epoch 326 Batch 10 Loss 0.20102860033512115
[Train] epoch 326 Batch 11 Loss 0.16845102608203888
[Train] epoch 326 Batch 12 Loss 0.10320182889699936
[Train] epoch 326 Batch 13 Loss 0.10178232938051224
[Train] epoch 326 Batch 14 Loss 0.16915002465248108
[Train] epoch 326 Batch 15 Loss 0.26957398653030396
[Train] epoch 326 Batch 16 Loss 0.1357041746377945
[Train] epoch 326 Batch 17 Loss 0.27091312408447266
[Train] epoch 326 Batch 18 Loss 0.13520237803459167
[Train] epoch 326 Batch 19 Loss 0.16913598775863647
[Train] epoch 326 Batch 20 Loss 0.10144694149494171
[Train] epoch 326 Batch 21 Loss 0.4018591046333313
[Train] epoch 326 Batch 22 Loss 0.16927942633628845
[Train] epoch 326 Batch 23 Loss 0.16793091595172882
[Train] epoch 326 Batch 24 Loss 0.23460185527801514
[Train] epoch 326 Batch 25 Loss 0.26937276124954224
[Train] epoch 326 Batch 26 Loss 0.1361980140209198
[Train] epoch 326 Batch 27 Loss 0.13434264063835144
[Train] epoch 326 Batch 28 Loss 0.16892945766448975
[Train] epoch 326 Batch 29 Loss 0.06666764616966248
[Train] epoch 326 Batch 30 Loss 0.2678384482860565
[Train] epoch 326 Batch 31 Loss 0.16925935447216034
[Train] epoch 326 Batch 32 Loss 0.30224180221557617
[Train] epoch 326 Batch 33 Loss 0.03557690978050232
[Train] epoch 326 Batch 34 Loss 0.10305142402648926
[Train] epoch 326 Batch 35 Loss 0.2000008225440979
[Train] epoch 326 Batch 36 Loss 0.33615541458129883
[Train] epoch 326 Batch 37 Loss 0.17070278525352478
[Train] epoch 326 Batch 38 Loss 0.10140743106603622
[Train] epoch 326 Batch 39 Loss 0.1706947386264801
[Train] epoch 326 Batch 40 Loss 0.13513924181461334
[Train] epoch 326 Batch 41 Loss 0.13693711161613464
[Train] epoch 326 Batch 42 Loss 0.0676504597067833
[Train] epoch 326 Batch 43 Loss 0.06927412748336792
[Train] epoch 326 Batch 44 Loss 0.0678311213850975
[Train] epoch 326 Batch 45 Loss 0.10121236741542816
[Train] epoch 326 Batch 46 Loss 0.23569265007972717
[Train] epoch 326 Batch 47 Loss 0.20195451378822327
[Train] epoch 327 Batch 0 Loss 0.23391491174697876
[Train] epoch 327 Batch 1 Loss 0.20116183161735535
[Train] epoch 327 Batch 2 Loss 0.10217311978340149
[Train] epoch 327 Batch 3 Loss 0.20177114009857178
[Train] epoch 327 Batch 4 Loss 0.13570955395698547
[Train] epoch 327 Batch 5 Loss 0.06745520979166031
[Train] epoch 327 Batch 6 Loss 0.16840505599975586
[Train] epoch 327 Batch 7 Loss 0.17076465487480164
[Train] epoch 327 Batch 8 Loss 0.16979193687438965
[Train] epoch 327 Batch 9 Loss 0.16959506273269653
[Train] epoch 327 Batch 10 Loss 0.06666764616966248
[Train] epoch 327 Batch 11 Loss 0.3350748121738434
[Train] epoch 327 Batch 12 Loss 0.13507932424545288
[Train] epoch 327 Batch 13 Loss 0.13760432600975037
[Train] epoch 327 Batch 14 Loss 0.06937840580940247
[Train] epoch 327 Batch 15 Loss 0.4369821548461914
[Train] epoch 327 Batch 16 Loss 0.23467954993247986
[Train] epoch 327 Batch 17 Loss 0.3699359893798828
[Train] epoch 327 Batch 18 Loss 0.2026820331811905
[Train] epoch 327 Batch 19 Loss 0.20248733460903168
[Train] epoch 327 Batch 20 Loss 0.26972857117652893
[Train] epoch 327 Batch 21 Loss 0.20229840278625488
[Train] epoch 327 Batch 22 Loss 0.20265817642211914
[Train] epoch 327 Batch 23 Loss 0.10248390585184097
[Train] epoch 327 Batch 24 Loss 0.2693295180797577
[Train] epoch 327 Batch 25 Loss 0.10057282447814941
[Train] epoch 327 Batch 26 Loss 0.033905621618032455
[Train] epoch 327 Batch 27 Loss 0.1679958701133728
[Train] epoch 327 Batch 28 Loss 0.13447438180446625
[Train] epoch 327 Batch 29 Loss 0.13428151607513428
[Train] epoch 327 Batch 30 Loss 0.20433098077774048
[Train] epoch 327 Batch 31 Loss 0.1013234555721283
[Train] epoch 327 Batch 32 Loss 0.10206764936447144
[Train] epoch 327 Batch 33 Loss 0.3696741461753845
[Train] epoch 327 Batch 34 Loss 0.2681678235530853
[Train] epoch 327 Batch 35 Loss 0.10185955464839935
[Train] epoch 327 Batch 36 Loss 0.13669565320014954
[Train] epoch 327 Batch 37 Loss 0.10298922657966614
[Train] epoch 327 Batch 38 Loss 0.1348087191581726
[Train] epoch 327 Batch 39 Loss 0.20186683535575867
[Train] epoch 327 Batch 40 Loss 0.23556220531463623
[Train] epoch 327 Batch 41 Loss 0.20113065838813782
[Train] epoch 327 Batch 42 Loss 0.03442748636007309
[Train] epoch 327 Batch 43 Loss 0.2690695822238922
[Train] epoch 327 Batch 44 Loss 0.10222411155700684
[Train] epoch 327 Batch 45 Loss 0.13518190383911133
[Train] epoch 327 Batch 46 Loss 0.23721688985824585
[Train] epoch 327 Batch 47 Loss 0.03513995558023453
[Train] epoch 328 Batch 0 Loss 0.16867461800575256
[Train] epoch 328 Batch 1 Loss 0.1702001541852951
[Train] epoch 328 Batch 2 Loss 0.13558274507522583
[Train] epoch 328 Batch 3 Loss 0.0683019608259201
[Train] epoch 328 Batch 4 Loss 0.10056206583976746
[Train] epoch 328 Batch 5 Loss 0.10272468626499176
[Train] epoch 328 Batch 6 Loss 0.20254838466644287
[Train] epoch 328 Batch 7 Loss 0.23481279611587524
[Train] epoch 328 Batch 8 Loss 0.1690627634525299
[Train] epoch 328 Batch 9 Loss 0.03460937738418579
[Train] epoch 328 Batch 10 Loss 0.30321088433265686
[Train] epoch 328 Batch 11 Loss 0.16905531287193298
[Train] epoch 328 Batch 12 Loss 0.20182174444198608
[Train] epoch 328 Batch 13 Loss 0.23459643125534058
[Train] epoch 328 Batch 14 Loss 0.2684786021709442
[Train] epoch 328 Batch 15 Loss 0.26919060945510864
[Train] epoch 328 Batch 16 Loss 0.16923847794532776
[Train] epoch 328 Batch 17 Loss 0.23438218235969543
[Train] epoch 328 Batch 18 Loss 0.13403353095054626
[Train] epoch 328 Batch 19 Loss 0.13473588228225708
[Train] epoch 328 Batch 20 Loss 0.20181159675121307
[Train] epoch 328 Batch 21 Loss 0.1360476315021515
[Train] epoch 328 Batch 22 Loss 0.23597201704978943
[Train] epoch 328 Batch 23 Loss 0.2677733898162842
[Train] epoch 328 Batch 24 Loss 0.2686745226383209
[Train] epoch 328 Batch 25 Loss 0.30304044485092163
[Train] epoch 328 Batch 26 Loss 0.13403108716011047
[Train] epoch 328 Batch 27 Loss 0.13699780404567719
[Train] epoch 328 Batch 28 Loss 0.10310729593038559
[Train] epoch 328 Batch 29 Loss 0.10123862326145172
[Train] epoch 328 Batch 30 Loss 0.16721788048744202
[Train] epoch 328 Batch 31 Loss 0.16859078407287598
[Train] epoch 328 Batch 32 Loss 0.1679001748561859
[Train] epoch 328 Batch 33 Loss 0.103974848985672
[Train] epoch 328 Batch 34 Loss 0.2022637277841568
[Train] epoch 328 Batch 35 Loss 0.3032177984714508
[Train] epoch 328 Batch 36 Loss 0.16856950521469116
[Train] epoch 328 Batch 37 Loss 0.06666764616966248
[Train] epoch 328 Batch 38 Loss 0.16986897587776184
[Train] epoch 328 Batch 39 Loss 0.13488805294036865
[Train] epoch 328 Batch 40 Loss 0.20222941040992737
[Train] epoch 328 Batch 41 Loss 0.1355646848678589
[Train] epoch 328 Batch 42 Loss 0.16922542452812195
[Train] epoch 328 Batch 43 Loss 0.26776161789894104
[Train] epoch 328 Batch 44 Loss 0.1689733862876892
[Train] epoch 328 Batch 45 Loss 0.13555017113685608
[Train] epoch 328 Batch 46 Loss 0.1680888831615448
[Train] epoch 328 Batch 47 Loss 0.10120852291584015
[Train] epoch 329 Batch 0 Loss 0.1687522530555725
[Train] epoch 329 Batch 1 Loss 0.06798763573169708
[Train] epoch 329 Batch 2 Loss 0.06799010932445526
[Train] epoch 329 Batch 3 Loss 0.1018604189157486
[Train] epoch 329 Batch 4 Loss 0.30230584740638733
[Train] epoch 329 Batch 5 Loss 0.10229451954364777
[Train] epoch 329 Batch 6 Loss 0.1359492838382721
[Train] epoch 329 Batch 7 Loss 0.1361643671989441
[Train] epoch 329 Batch 8 Loss 0.17091885209083557
[Train] epoch 329 Batch 9 Loss 0.20174270868301392
[Train] epoch 329 Batch 10 Loss 0.10097000002861023
[Train] epoch 329 Batch 11 Loss 0.1672101765871048
[Train] epoch 329 Batch 12 Loss 0.16916246712207794
[Train] epoch 329 Batch 13 Loss 0.26861274242401123
[Train] epoch 329 Batch 14 Loss 0.3348492383956909
[Train] epoch 329 Batch 15 Loss 0.10162126272916794
[Train] epoch 329 Batch 16 Loss 0.1357097327709198
[Train] epoch 329 Batch 17 Loss 0.1352730542421341
[Train] epoch 329 Batch 18 Loss 0.20280036330223083
[Train] epoch 329 Batch 19 Loss 0.16913338005542755
[Train] epoch 329 Batch 20 Loss 0.10096549242734909
[Train] epoch 329 Batch 21 Loss 0.13526611030101776
[Train] epoch 329 Batch 22 Loss 0.06837963312864304
[Train] epoch 329 Batch 23 Loss 0.2683776617050171
[Train] epoch 329 Batch 24 Loss 0.1360882818698883
[Train] epoch 329 Batch 25 Loss 0.1348285675048828
[Train] epoch 329 Batch 26 Loss 0.16783590614795685
[Train] epoch 329 Batch 27 Loss 0.13396015763282776
[Train] epoch 329 Batch 28 Loss 0.2700761556625366
[Train] epoch 329 Batch 29 Loss 0.2681441903114319
[Train] epoch 329 Batch 30 Loss 0.16845951974391937
[Train] epoch 329 Batch 31 Loss 0.13565845787525177
[Train] epoch 329 Batch 32 Loss 0.16720184683799744
[Train] epoch 329 Batch 33 Loss 0.270030677318573
[Train] epoch 329 Batch 34 Loss 0.20084398984909058
[Train] epoch 329 Batch 35 Loss 0.20275747776031494
[Train] epoch 329 Batch 36 Loss 0.300533652305603
[Train] epoch 329 Batch 37 Loss 0.20209036767482758
[Train] epoch 329 Batch 38 Loss 0.30263110995292664
[Train] epoch 329 Batch 39 Loss 0.13417327404022217
[Train] epoch 329 Batch 40 Loss 0.2338656187057495
[Train] epoch 329 Batch 41 Loss 0.16826099157333374
[Train] epoch 329 Batch 42 Loss 0.1360289603471756
[Train] epoch 329 Batch 43 Loss 0.10221417248249054
[Train] epoch 329 Batch 44 Loss 0.20229783654212952
[Train] epoch 329 Batch 45 Loss 0.20189423859119415
[Train] epoch 329 Batch 46 Loss 0.1684253215789795
[Train] epoch 329 Batch 47 Loss 0.16821503639221191
[Train] epoch 330 Batch 0 Loss 0.10176530480384827
[Train] epoch 330 Batch 1 Loss 0.06811101734638214
[Train] epoch 330 Batch 2 Loss 0.06789509952068329
[Train] epoch 330 Batch 3 Loss 0.2028908133506775
[Train] epoch 330 Batch 4 Loss 0.23424562811851501
[Train] epoch 330 Batch 5 Loss 0.23674428462982178
[Train] epoch 330 Batch 6 Loss 0.2008335292339325
[Train] epoch 330 Batch 7 Loss 0.23613044619560242
[Train] epoch 330 Batch 8 Loss 0.13560181856155396
[Train] epoch 330 Batch 9 Loss 0.13499529659748077
[Train] epoch 330 Batch 10 Loss 0.2000008225440979
[Train] epoch 330 Batch 11 Loss 0.30256444215774536
[Train] epoch 330 Batch 12 Loss 0.20308081805706024
[Train] epoch 330 Batch 13 Loss 0.10029850900173187
[Train] epoch 330 Batch 14 Loss 0.10135145485401154
[Train] epoch 330 Batch 15 Loss 0.23692357540130615
[Train] epoch 330 Batch 16 Loss 0.3015705347061157
[Train] epoch 330 Batch 17 Loss 0.13639840483665466
[Train] epoch 330 Batch 18 Loss 0.13747328519821167
[Train] epoch 330 Batch 19 Loss 0.16923663020133972
[Train] epoch 330 Batch 20 Loss 0.336229145526886
[Train] epoch 330 Batch 21 Loss 0.13480275869369507
[Train] epoch 330 Batch 22 Loss 0.06731444597244263
[Train] epoch 330 Batch 23 Loss 0.16783201694488525
[Train] epoch 330 Batch 24 Loss 0.03384188562631607
[Train] epoch 330 Batch 25 Loss 0.23467448353767395
[Train] epoch 330 Batch 26 Loss 0.20151516795158386
[Train] epoch 330 Batch 27 Loss 0.16785341501235962
[Train] epoch 330 Batch 28 Loss 0.23672741651535034
[Train] epoch 330 Batch 29 Loss 0.16954128444194794
[Train] epoch 330 Batch 30 Loss 0.16716694831848145
[Train] epoch 330 Batch 31 Loss 0.26850631833076477
[Train] epoch 330 Batch 32 Loss 0.2682144045829773
[Train] epoch 330 Batch 33 Loss 0.13473400473594666
[Train] epoch 330 Batch 34 Loss 0.26850253343582153
[Train] epoch 330 Batch 35 Loss 0.13716599345207214
[Train] epoch 330 Batch 36 Loss 0.26893070340156555
[Train] epoch 330 Batch 37 Loss 0.20225772261619568
[Train] epoch 330 Batch 38 Loss 0.06837031990289688
[Train] epoch 330 Batch 39 Loss 0.06822723895311356
[Train] epoch 330 Batch 40 Loss 0.1365879774093628
[Train] epoch 330 Batch 41 Loss 0.23525135219097137
[Train] epoch 330 Batch 42 Loss 0.26881086826324463
[Train] epoch 330 Batch 43 Loss 0.06737574934959412
[Train] epoch 330 Batch 44 Loss 0.06737580895423889
[Train] epoch 330 Batch 45 Loss 0.30190587043762207
[Train] epoch 330 Batch 46 Loss 0.13431504368782043
[Train] epoch 330 Batch 47 Loss 0.0682210773229599
[Train] epoch 331 Batch 0 Loss 0.10177703201770782
[Train] epoch 331 Batch 1 Loss 0.27047500014305115
[Train] epoch 331 Batch 2 Loss 0.16786858439445496
[Train] epoch 331 Batch 3 Loss 0.06821420788764954
[Train] epoch 331 Batch 4 Loss 0.20335224270820618
[Train] epoch 331 Batch 5 Loss 0.10258971899747849
[Train] epoch 331 Batch 6 Loss 0.13514664769172668
[Train] epoch 331 Batch 7 Loss 0.2676449716091156
[Train] epoch 331 Batch 8 Loss 0.30119314789772034
[Train] epoch 331 Batch 9 Loss 0.06737061589956284
[Train] epoch 331 Batch 10 Loss 0.23452453315258026
[Train] epoch 331 Batch 11 Loss 0.1714753359556198
[Train] epoch 331 Batch 12 Loss 0.26918020844459534
[Train] epoch 331 Batch 13 Loss 0.23549480736255646
[Train] epoch 331 Batch 14 Loss 0.0013869046233594418
[Train] epoch 331 Batch 15 Loss 0.13486486673355103
[Train] epoch 331 Batch 16 Loss 0.2030411958694458
[Train] epoch 331 Batch 17 Loss 0.03657468035817146
[Train] epoch 331 Batch 18 Loss 0.23615913093090057
[Train] epoch 331 Batch 19 Loss 0.2008240520954132
[Train] epoch 331 Batch 20 Loss 0.13430695235729218
[Train] epoch 331 Batch 21 Loss 0.3013080954551697
[Train] epoch 331 Batch 22 Loss 0.06763956695795059
[Train] epoch 331 Batch 23 Loss 0.10033503919839859
[Train] epoch 331 Batch 24 Loss 0.16985124349594116
[Train] epoch 331 Batch 25 Loss 0.2360072135925293
[Train] epoch 331 Batch 26 Loss 0.3333339989185333
[Train] epoch 331 Batch 27 Loss 0.20231148600578308
[Train] epoch 331 Batch 28 Loss 0.06815984845161438
[Train] epoch 331 Batch 29 Loss 0.20133653283119202
[Train] epoch 331 Batch 30 Loss 0.16850104928016663
[Train] epoch 331 Batch 31 Loss 0.06897597759962082
[Train] epoch 331 Batch 32 Loss 0.16781601309776306
[Train] epoch 331 Batch 33 Loss 0.06896931678056717
[Train] epoch 331 Batch 34 Loss 0.20096883177757263
[Train] epoch 331 Batch 35 Loss 0.20392456650733948
[Train] epoch 331 Batch 36 Loss 0.13592727482318878
[Train] epoch 331 Batch 37 Loss 0.3691160976886749
[Train] epoch 331 Batch 38 Loss 0.20309436321258545
[Train] epoch 331 Batch 39 Loss 0.1684674769639969
[Train] epoch 331 Batch 40 Loss 0.10032416135072708
[Train] epoch 331 Batch 41 Loss 0.16811473667621613
[Train] epoch 331 Batch 42 Loss 0.23447532951831818
[Train] epoch 331 Batch 43 Loss 0.1349485069513321
[Train] epoch 331 Batch 44 Loss 0.2690890431404114
[Train] epoch 331 Batch 45 Loss 0.033661965280771255
[Train] epoch 331 Batch 46 Loss 0.33429616689682007
[Train] epoch 331 Batch 47 Loss 0.13560348749160767
[Train] epoch 332 Batch 0 Loss 0.10323172807693481
[Train] epoch 332 Batch 1 Loss 0.13479191064834595
[Train] epoch 332 Batch 2 Loss 0.23445694148540497
[Train] epoch 332 Batch 3 Loss 0.20175781846046448
[Train] epoch 332 Batch 4 Loss 0.23590736091136932
[Train] epoch 332 Batch 5 Loss 0.0676262304186821
[Train] epoch 332 Batch 6 Loss 0.20287680625915527
[Train] epoch 332 Batch 7 Loss 0.20207816362380981
[Train] epoch 332 Batch 8 Loss 0.06826871633529663
[Train] epoch 332 Batch 9 Loss 0.23508378863334656
[Train] epoch 332 Batch 10 Loss 0.13620124757289886
[Train] epoch 332 Batch 11 Loss 0.36874133348464966
[Train] epoch 332 Batch 12 Loss 0.20222799479961395
[Train] epoch 332 Batch 13 Loss 0.10111702978610992
[Train] epoch 332 Batch 14 Loss 0.303177148103714
[Train] epoch 332 Batch 15 Loss 0.06888630241155624
[Train] epoch 332 Batch 16 Loss 0.2692016065120697
[Train] epoch 332 Batch 17 Loss 0.034277088940143585
[Train] epoch 332 Batch 18 Loss 0.23476219177246094
[Train] epoch 332 Batch 19 Loss 0.06793103367090225
[Train] epoch 332 Batch 20 Loss 0.13458728790283203
[Train] epoch 332 Batch 21 Loss 0.1374082863330841
[Train] epoch 332 Batch 22 Loss 0.16979996860027313
[Train] epoch 332 Batch 23 Loss 0.10126406699419022
[Train] epoch 332 Batch 24 Loss 0.13412152230739594
[Train] epoch 332 Batch 25 Loss 0.06868034601211548
[Train] epoch 332 Batch 26 Loss 0.2678912281990051
[Train] epoch 332 Batch 27 Loss 0.1355237513780594
[Train] epoch 332 Batch 28 Loss 0.10169368982315063
[Train] epoch 332 Batch 29 Loss 0.23565667867660522
[Train] epoch 332 Batch 30 Loss 0.1691371202468872
[Train] epoch 332 Batch 31 Loss 0.13410881161689758
[Train] epoch 332 Batch 32 Loss 0.1671411395072937
[Train] epoch 332 Batch 33 Loss 0.30220097303390503
[Train] epoch 332 Batch 34 Loss 0.3683447241783142
[Train] epoch 332 Batch 35 Loss 0.20155836641788483
[Train] epoch 332 Batch 36 Loss 0.3010765314102173
[Train] epoch 332 Batch 37 Loss 0.0680471658706665
[Train] epoch 332 Batch 38 Loss 0.06744402647018433
[Train] epoch 332 Batch 39 Loss 0.13505473732948303
[Train] epoch 332 Batch 40 Loss 0.23499852418899536
[Train] epoch 332 Batch 41 Loss 0.20077534019947052
[Train] epoch 332 Batch 42 Loss 0.100296750664711
[Train] epoch 332 Batch 43 Loss 0.10141512751579285
[Train] epoch 332 Batch 44 Loss 0.20231303572654724
[Train] epoch 332 Batch 45 Loss 0.23560652136802673
[Train] epoch 332 Batch 46 Loss 0.16790978610515594
[Train] epoch 332 Batch 47 Loss 0.2682092487812042
[Train] epoch 333 Batch 0 Loss 0.23534521460533142
[Train] epoch 333 Batch 1 Loss 0.16866321861743927
[Train] epoch 333 Batch 2 Loss 0.202724426984787
[Train] epoch 333 Batch 3 Loss 0.2024696320295334
[Train] epoch 333 Batch 4 Loss 0.034224506467580795
[Train] epoch 333 Batch 5 Loss 0.3025936484336853
[Train] epoch 333 Batch 6 Loss 0.03422868996858597
[Train] epoch 333 Batch 7 Loss 0.3698508143424988
[Train] epoch 333 Batch 8 Loss 0.20135998725891113
[Train] epoch 333 Batch 9 Loss 0.10046827793121338
[Train] epoch 333 Batch 10 Loss 0.06801809370517731
[Train] epoch 333 Batch 11 Loss 0.23651063442230225
[Train] epoch 333 Batch 12 Loss 0.23420746624469757
[Train] epoch 333 Batch 13 Loss 0.13391798734664917
[Train] epoch 333 Batch 14 Loss 0.06759991496801376
[Train] epoch 333 Batch 15 Loss 0.20093268156051636
[Train] epoch 333 Batch 16 Loss 0.10105466842651367
[Train] epoch 333 Batch 17 Loss 0.23630057275295258
[Train] epoch 333 Batch 18 Loss 0.06840123981237411
[Train] epoch 333 Batch 19 Loss 0.1357734501361847
[Train] epoch 333 Batch 20 Loss 0.20093044638633728
[Train] epoch 333 Batch 21 Loss 0.23547817766666412
[Train] epoch 333 Batch 22 Loss 0.06800699234008789
[Train] epoch 333 Batch 23 Loss 0.23361903429031372
[Train] epoch 333 Batch 24 Loss 0.13524070382118225
[Train] epoch 333 Batch 25 Loss 0.10179384052753448
[Train] epoch 333 Batch 26 Loss 0.13598895072937012
[Train] epoch 333 Batch 27 Loss 0.16845646500587463
[Train] epoch 333 Batch 28 Loss 0.26741307973861694
[Train] epoch 333 Batch 29 Loss 0.1688069850206375
[Train] epoch 333 Batch 30 Loss 0.16920249164104462
[Train] epoch 333 Batch 31 Loss 0.16845020651817322
[Train] epoch 333 Batch 32 Loss 0.16787903010845184
[Train] epoch 333 Batch 33 Loss 0.10217495262622833
[Train] epoch 333 Batch 34 Loss 0.16866514086723328
[Train] epoch 333 Batch 35 Loss 0.034942034631967545
[Train] epoch 333 Batch 36 Loss 0.23660409450531006
[Train] epoch 333 Batch 37 Loss 0.3344912528991699
[Train] epoch 333 Batch 38 Loss 0.10029231011867523
[Train] epoch 333 Batch 39 Loss 0.26741915941238403
[Train] epoch 333 Batch 40 Loss 0.035014260560274124
[Train] epoch 333 Batch 41 Loss 0.2020098865032196
[Train] epoch 333 Batch 42 Loss 0.16775278747081757
[Train] epoch 333 Batch 43 Loss 0.23531776666641235
[Train] epoch 333 Batch 44 Loss 0.3348711133003235
[Train] epoch 333 Batch 45 Loss 0.26886987686157227
[Train] epoch 333 Batch 46 Loss 0.23638013005256653
[Train] epoch 333 Batch 47 Loss 0.10110116750001907
[Train] epoch 334 Batch 0 Loss 0.034990858286619186
[Train] epoch 334 Batch 1 Loss 0.20221373438835144
[Train] epoch 334 Batch 2 Loss 0.033779434859752655
[Train] epoch 334 Batch 3 Loss 0.2693348526954651
[Train] epoch 334 Batch 4 Loss 0.16766437888145447
[Train] epoch 334 Batch 5 Loss 0.23524007201194763
[Train] epoch 334 Batch 6 Loss 0.1676798313856125
[Train] epoch 334 Batch 7 Loss 0.26843827962875366
[Train] epoch 334 Batch 8 Loss 0.26803451776504517
[Train] epoch 334 Batch 9 Loss 0.10121728479862213
[Train] epoch 334 Batch 10 Loss 0.10247897356748581
[Train] epoch 334 Batch 11 Loss 0.10044223070144653
[Train] epoch 334 Batch 12 Loss 0.36767661571502686
[Train] epoch 334 Batch 13 Loss 0.2014518678188324
[Train] epoch 334 Batch 14 Loss 0.16856831312179565
[Train] epoch 334 Batch 15 Loss 0.1347065418958664
[Train] epoch 334 Batch 16 Loss 0.20224279165267944
[Train] epoch 334 Batch 17 Loss 0.20077353715896606
[Train] epoch 334 Batch 18 Loss 0.10189849138259888
[Train] epoch 334 Batch 19 Loss 0.1694425642490387
[Train] epoch 334 Batch 20 Loss 0.13489674031734467
[Train] epoch 334 Batch 21 Loss 0.30112308263778687
[Train] epoch 334 Batch 22 Loss 0.202235147356987
[Train] epoch 334 Batch 23 Loss 0.2710229158401489
[Train] epoch 334 Batch 24 Loss 0.30180150270462036
[Train] epoch 334 Batch 25 Loss 0.16854386031627655
[Train] epoch 334 Batch 26 Loss 0.16778382658958435
[Train] epoch 334 Batch 27 Loss 0.0693371519446373
[Train] epoch 334 Batch 28 Loss 0.20287451148033142
[Train] epoch 334 Batch 29 Loss 0.06820747256278992
[Train] epoch 334 Batch 30 Loss 0.1686336100101471
[Train] epoch 334 Batch 31 Loss 0.10100844502449036
[Train] epoch 334 Batch 32 Loss 0.2008756846189499
[Train] epoch 334 Batch 33 Loss 0.20076274871826172
[Train] epoch 334 Batch 34 Loss 0.1691916584968567
[Train] epoch 334 Batch 35 Loss 0.2681038975715637
[Train] epoch 334 Batch 36 Loss 0.0006662795785814524
[Train] epoch 334 Batch 37 Loss 0.16830658912658691
[Train] epoch 334 Batch 38 Loss 0.035086680203676224
[Train] epoch 334 Batch 39 Loss 0.10240992903709412
[Train] epoch 334 Batch 40 Loss 0.23573851585388184
[Train] epoch 334 Batch 41 Loss 0.20305226743221283
[Train] epoch 334 Batch 42 Loss 0.20163807272911072
[Train] epoch 334 Batch 43 Loss 0.20292755961418152
[Train] epoch 334 Batch 44 Loss 0.20239868760108948
[Train] epoch 334 Batch 45 Loss 0.16762611269950867
[Train] epoch 334 Batch 46 Loss 0.16914597153663635
[Train] epoch 334 Batch 47 Loss 0.20162281394004822
[Train] epoch 335 Batch 0 Loss 0.23505479097366333
[Train] epoch 335 Batch 1 Loss 0.06818439811468124
[Train] epoch 335 Batch 2 Loss 0.23516181111335754
[Train] epoch 335 Batch 3 Loss 0.16988451778888702
[Train] epoch 335 Batch 4 Loss 0.13459128141403198
[Train] epoch 335 Batch 5 Loss 0.20414189994335175
[Train] epoch 335 Batch 6 Loss 0.23376864194869995
[Train] epoch 335 Batch 7 Loss 0.3355933725833893
[Train] epoch 335 Batch 8 Loss 0.20213201642036438
[Train] epoch 335 Batch 9 Loss 0.13747428357601166
[Train] epoch 335 Batch 10 Loss 0.1342019885778427
[Train] epoch 335 Batch 11 Loss 0.20161782205104828
[Train] epoch 335 Batch 12 Loss 0.23426145315170288
[Train] epoch 335 Batch 13 Loss 0.2357543408870697
[Train] epoch 335 Batch 14 Loss 0.06753390282392502
[Train] epoch 335 Batch 15 Loss 0.13408038020133972
[Train] epoch 335 Batch 16 Loss 0.10093817114830017
[Train] epoch 335 Batch 17 Loss 0.16783584654331207
[Train] epoch 335 Batch 18 Loss 0.1022847518324852
[Train] epoch 335 Batch 19 Loss 0.13481217622756958
[Train] epoch 335 Batch 20 Loss 0.06852082908153534
[Train] epoch 335 Batch 21 Loss 0.06986033916473389
[Train] epoch 335 Batch 22 Loss 0.20197737216949463
[Train] epoch 335 Batch 23 Loss 0.2352287769317627
[Train] epoch 335 Batch 24 Loss 0.2680128514766693
[Train] epoch 335 Batch 25 Loss 0.2352338433265686
[Train] epoch 335 Batch 26 Loss 0.13553868234157562
[Train] epoch 335 Batch 27 Loss 0.1696433126926422
[Train] epoch 335 Batch 28 Loss 0.06813104450702667
[Train] epoch 335 Batch 29 Loss 0.20180904865264893
[Train] epoch 335 Batch 30 Loss 0.20206794142723083
[Train] epoch 335 Batch 31 Loss 0.23449836671352386
[Train] epoch 335 Batch 32 Loss 0.26897740364074707
[Train] epoch 335 Batch 33 Loss 1.0728851975727594e-06
[Train] epoch 335 Batch 34 Loss 0.26752790808677673
[Train] epoch 335 Batch 35 Loss 0.13624846935272217
[Train] epoch 335 Batch 36 Loss 0.2355494499206543
[Train] epoch 335 Batch 37 Loss 0.134193554520607
[Train] epoch 335 Batch 38 Loss 0.16875293850898743
[Train] epoch 335 Batch 39 Loss 0.2000008225440979
[Train] epoch 335 Batch 40 Loss 0.10188426077365875
[Train] epoch 335 Batch 41 Loss 0.20085877180099487
[Train] epoch 335 Batch 42 Loss 0.13449829816818237
[Train] epoch 335 Batch 43 Loss 0.20118024945259094
[Train] epoch 335 Batch 44 Loss 0.26739221811294556
[Train] epoch 335 Batch 45 Loss 0.034946508705616
[Train] epoch 335 Batch 46 Loss 0.2013072669506073
[Train] epoch 335 Batch 47 Loss 0.2675236761569977
[Train] epoch 336 Batch 0 Loss 0.0684189721941948
[Train] epoch 336 Batch 1 Loss 0.23519808053970337
[Train] epoch 336 Batch 2 Loss 0.23577600717544556
[Train] epoch 336 Batch 3 Loss 0.16812506318092346
[Train] epoch 336 Batch 4 Loss 0.03551855310797691
[Train] epoch 336 Batch 5 Loss 0.16695158183574677
[Train] epoch 336 Batch 6 Loss 0.1683889925479889
[Train] epoch 336 Batch 7 Loss 0.23577213287353516
[Train] epoch 336 Batch 8 Loss 0.16780465841293335
[Train] epoch 336 Batch 9 Loss 0.2351955771446228
[Train] epoch 336 Batch 10 Loss 0.20141825079917908
[Train] epoch 336 Batch 11 Loss 0.23634108901023865
[Train] epoch 336 Batch 12 Loss 0.2005709409713745
[Train] epoch 336 Batch 13 Loss 0.16780835390090942
[Train] epoch 336 Batch 14 Loss 0.23474986851215363
[Train] epoch 336 Batch 15 Loss 0.06795573979616165
[Train] epoch 336 Batch 16 Loss 0.36922401189804077
[Train] epoch 336 Batch 17 Loss 0.13574226200580597
[Train] epoch 336 Batch 18 Loss 0.16751766204833984
[Train] epoch 336 Batch 19 Loss 0.13389797508716583
[Train] epoch 336 Batch 20 Loss 0.10269026458263397
[Train] epoch 336 Batch 21 Loss 0.20071041584014893
[Train] epoch 336 Batch 22 Loss 0.13488571345806122
[Train] epoch 336 Batch 23 Loss 0.1690686047077179
[Train] epoch 336 Batch 24 Loss 0.23445911705493927
[Train] epoch 336 Batch 25 Loss 0.23516561090946198
[Train] epoch 336 Batch 26 Loss 0.06737424433231354
[Train] epoch 336 Batch 27 Loss 0.30182945728302
[Train] epoch 336 Batch 28 Loss 0.03543936833739281
[Train] epoch 336 Batch 29 Loss 0.10082881152629852
[Train] epoch 336 Batch 30 Loss 0.1027982234954834
[Train] epoch 336 Batch 31 Loss 0.06806743890047073
[Train] epoch 336 Batch 32 Loss 0.2018081247806549
[Train] epoch 336 Batch 33 Loss 0.2684870958328247
[Train] epoch 336 Batch 34 Loss 0.36904382705688477
[Train] epoch 336 Batch 35 Loss 0.2020893096923828
[Train] epoch 336 Batch 36 Loss 0.16763082146644592
[Train] epoch 336 Batch 37 Loss 0.10097780078649521
[Train] epoch 336 Batch 38 Loss 0.0005544626619666815
[Train] epoch 336 Batch 39 Loss 0.26909491419792175
[Train] epoch 336 Batch 40 Loss 0.20186948776245117
[Train] epoch 336 Batch 41 Loss 0.268210232257843
[Train] epoch 336 Batch 42 Loss 0.13416226208209991
[Train] epoch 336 Batch 43 Loss 0.06878586113452911
[Train] epoch 336 Batch 44 Loss 0.3018208146095276
[Train] epoch 336 Batch 45 Loss 0.16907504200935364
[Train] epoch 336 Batch 46 Loss 0.10122069716453552
[Train] epoch 336 Batch 47 Loss 0.1678299456834793
[Train] epoch 337 Batch 0 Loss 0.16858208179473877
[Train] epoch 337 Batch 1 Loss 0.06819149851799011
[Train] epoch 337 Batch 2 Loss 0.23761041462421417
[Train] epoch 337 Batch 3 Loss 0.2679673135280609
[Train] epoch 337 Batch 4 Loss 0.10119208693504333
[Train] epoch 337 Batch 5 Loss 0.10198841989040375
[Train] epoch 337 Batch 6 Loss 0.06828227639198303
[Train] epoch 337 Batch 7 Loss 0.23453274369239807
[Train] epoch 337 Batch 8 Loss 0.36787164211273193
[Train] epoch 337 Batch 9 Loss 0.10202440619468689
[Train] epoch 337 Batch 10 Loss 0.06988869607448578
[Train] epoch 337 Batch 11 Loss 0.30203524231910706
[Train] epoch 337 Batch 12 Loss 0.16950899362564087
[Train] epoch 337 Batch 13 Loss 0.2674708366394043
[Train] epoch 337 Batch 14 Loss 0.06747409701347351
[Train] epoch 337 Batch 15 Loss 0.13661295175552368
[Train] epoch 337 Batch 16 Loss 0.20409001410007477
[Train] epoch 337 Batch 17 Loss 0.1020493134856224
[Train] epoch 337 Batch 18 Loss 0.20083197951316833
[Train] epoch 337 Batch 19 Loss 0.36868560314178467
[Train] epoch 337 Batch 20 Loss 0.03456876054406166
[Train] epoch 337 Batch 21 Loss 0.16791708767414093
[Train] epoch 337 Batch 22 Loss 0.16705775260925293
[Train] epoch 337 Batch 23 Loss 0.13416807353496552
[Train] epoch 337 Batch 24 Loss 0.20244717597961426
[Train] epoch 337 Batch 25 Loss 0.03375152871012688
[Train] epoch 337 Batch 26 Loss 0.16787955164909363
[Train] epoch 337 Batch 27 Loss 0.23536822199821472
[Train] epoch 337 Batch 28 Loss 0.13415689766407013
[Train] epoch 337 Batch 29 Loss 0.10122273862361908
[Train] epoch 337 Batch 30 Loss 0.2016441524028778
[Train] epoch 337 Batch 31 Loss 0.2691273093223572
[Train] epoch 337 Batch 32 Loss 0.1341048926115036
[Train] epoch 337 Batch 33 Loss 0.2369823157787323
[Train] epoch 337 Batch 34 Loss 0.13497260212898254
[Train] epoch 337 Batch 35 Loss 0.20240658521652222
[Train] epoch 337 Batch 36 Loss 0.10200229287147522
[Train] epoch 337 Batch 37 Loss 0.20476114749908447
[Train] epoch 337 Batch 38 Loss 0.23454871773719788
[Train] epoch 337 Batch 39 Loss 0.169470876455307
[Train] epoch 337 Batch 40 Loss 0.13579510152339935
[Train] epoch 337 Batch 41 Loss 0.26985231041908264
[Train] epoch 337 Batch 42 Loss 0.23607681691646576
[Train] epoch 337 Batch 43 Loss 0.16783416271209717
[Train] epoch 337 Batch 44 Loss 0.0337078757584095
[Train] epoch 337 Batch 45 Loss 0.2675015330314636
[Train] epoch 337 Batch 46 Loss 0.3043253421783447
[Train] epoch 337 Batch 47 Loss 0.10273748636245728
[Train] epoch 338 Batch 0 Loss 0.1012205183506012
[Train] epoch 338 Batch 1 Loss 0.16870296001434326
[Train] epoch 338 Batch 2 Loss 0.16708430647850037
[Train] epoch 338 Batch 3 Loss 0.06666764616966248
[Train] epoch 338 Batch 4 Loss 0.235262930393219
[Train] epoch 338 Batch 5 Loss 0.26820993423461914
[Train] epoch 338 Batch 6 Loss 0.20385974645614624
[Train] epoch 338 Batch 7 Loss 0.2353076934814453
[Train] epoch 338 Batch 8 Loss 0.1677846908569336
[Train] epoch 338 Batch 9 Loss 0.23452675342559814
[Train] epoch 338 Batch 10 Loss 0.10272099822759628
[Train] epoch 338 Batch 11 Loss 0.16856859624385834
[Train] epoch 338 Batch 12 Loss 0.2030784785747528
[Train] epoch 338 Batch 13 Loss 0.20239321887493134
[Train] epoch 338 Batch 14 Loss 0.17009837925434113
[Train] epoch 338 Batch 15 Loss 0.16786974668502808
[Train] epoch 338 Batch 16 Loss 0.033704858273267746
[Train] epoch 338 Batch 17 Loss 0.16703715920448303
[Train] epoch 338 Batch 18 Loss 0.13488516211509705
[Train] epoch 338 Batch 19 Loss 0.13410064578056335
[Train] epoch 338 Batch 20 Loss 0.10191524773836136
[Train] epoch 338 Batch 21 Loss 0.1678629219532013
[Train] epoch 338 Batch 22 Loss 0.20292505621910095
[Train] epoch 338 Batch 23 Loss 0.13416306674480438
[Train] epoch 338 Batch 24 Loss 0.23811723291873932
[Train] epoch 338 Batch 25 Loss 0.23661774396896362
[Train] epoch 338 Batch 26 Loss 0.16993997991085052
[Train] epoch 338 Batch 27 Loss 0.2681623101234436
[Train] epoch 338 Batch 28 Loss 0.23445095121860504
[Train] epoch 338 Batch 29 Loss 0.1684255301952362
[Train] epoch 338 Batch 30 Loss 0.20146995782852173
[Train] epoch 338 Batch 31 Loss 0.0006961675244383514
[Train] epoch 338 Batch 32 Loss 0.1693270355463028
[Train] epoch 338 Batch 33 Loss 0.30110597610473633
[Train] epoch 338 Batch 34 Loss 0.133334219455719
[Train] epoch 338 Batch 35 Loss 0.2694968581199646
[Train] epoch 338 Batch 36 Loss 0.13549891114234924
[Train] epoch 338 Batch 37 Loss 0.06956055015325546
[Train] epoch 338 Batch 38 Loss 0.23588642477989197
[Train] epoch 338 Batch 39 Loss 0.16845399141311646
[Train] epoch 338 Batch 40 Loss 0.23450788855552673
[Train] epoch 338 Batch 41 Loss 0.13416242599487305
[Train] epoch 338 Batch 42 Loss 0.03436536341905594
[Train] epoch 338 Batch 43 Loss 0.2681804299354553
[Train] epoch 338 Batch 44 Loss 0.20165681838989258
[Train] epoch 338 Batch 45 Loss 0.10115573555231094
[Train] epoch 338 Batch 46 Loss 0.30324384570121765
[Train] epoch 338 Batch 47 Loss 0.16917884349822998
[Train] epoch 339 Batch 0 Loss 0.3692217469215393
[Train] epoch 339 Batch 1 Loss 0.20202843844890594
[Train] epoch 339 Batch 2 Loss 0.03365788608789444
[Train] epoch 339 Batch 3 Loss 0.27082979679107666
[Train] epoch 339 Batch 4 Loss 0.1010705828666687
[Train] epoch 339 Batch 5 Loss 0.2688174247741699
[Train] epoch 339 Batch 6 Loss 0.03440028429031372
[Train] epoch 339 Batch 7 Loss 0.10311364382505417
[Train] epoch 339 Batch 8 Loss 0.06739871203899384
[Train] epoch 339 Batch 9 Loss 0.13545635342597961
[Train] epoch 339 Batch 10 Loss 0.1683729588985443
[Train] epoch 339 Batch 11 Loss 0.23448805510997772
[Train] epoch 339 Batch 12 Loss 0.06749281287193298
[Train] epoch 339 Batch 13 Loss 0.1346181035041809
[Train] epoch 339 Batch 14 Loss 0.20194795727729797
[Train] epoch 339 Batch 15 Loss 0.3011510372161865
[Train] epoch 339 Batch 16 Loss 0.13610808551311493
[Train] epoch 339 Batch 17 Loss 0.269412100315094
[Train] epoch 339 Batch 18 Loss 0.20209264755249023
[Train] epoch 339 Batch 19 Loss 0.13396701216697693
[Train] epoch 339 Batch 20 Loss 0.06804454326629639
[Train] epoch 339 Batch 21 Loss 0.10187850892543793
[Train] epoch 339 Batch 22 Loss 0.20208007097244263
[Train] epoch 339 Batch 23 Loss 0.33542323112487793
[Train] epoch 339 Batch 24 Loss 0.30196595191955566
[Train] epoch 339 Batch 25 Loss 0.16843171417713165
[Train] epoch 339 Batch 26 Loss 0.1355200707912445
[Train] epoch 339 Batch 27 Loss 0.4350818395614624
[Train] epoch 339 Batch 28 Loss 0.10175953060388565
[Train] epoch 339 Batch 29 Loss 0.20082253217697144
[Train] epoch 339 Batch 30 Loss 0.06728490442037582
[Train] epoch 339 Batch 31 Loss 0.16780272126197815
[Train] epoch 339 Batch 32 Loss 0.033648233860731125
[Train] epoch 339 Batch 33 Loss 0.3010134696960449
[Train] epoch 339 Batch 34 Loss 0.06935209035873413
[Train] epoch 339 Batch 35 Loss 0.06737785041332245
[Train] epoch 339 Batch 36 Loss 0.33415356278419495
[Train] epoch 339 Batch 37 Loss 0.10225430130958557
[Train] epoch 339 Batch 38 Loss 0.26881614327430725
[Train] epoch 339 Batch 39 Loss 0.1690264195203781
[Train] epoch 339 Batch 40 Loss 0.23374328017234802
[Train] epoch 339 Batch 41 Loss 0.10041002929210663
[Train] epoch 339 Batch 42 Loss 0.20336554944515228
[Train] epoch 339 Batch 43 Loss 0.06738492846488953
[Train] epoch 339 Batch 44 Loss 0.23638327419757843
[Train] epoch 339 Batch 45 Loss 0.23455952107906342
[Train] epoch 339 Batch 46 Loss 0.20190778374671936
[Train] epoch 339 Batch 47 Loss 0.03555630147457123
[Train] epoch 340 Batch 0 Loss 0.10111090540885925
[Train] epoch 340 Batch 1 Loss 0.10223983228206635
[Train] epoch 340 Batch 2 Loss 0.2672649025917053
[Train] epoch 340 Batch 3 Loss 0.4023425877094269
[Train] epoch 340 Batch 4 Loss 0.2693943381309509
[Train] epoch 340 Batch 5 Loss 0.06808751821517944
[Train] epoch 340 Batch 6 Loss 0.23564758896827698
[Train] epoch 340 Batch 7 Loss 0.20198772847652435
[Train] epoch 340 Batch 8 Loss 0.1016014814376831
[Train] epoch 340 Batch 9 Loss 0.000591194024309516
[Train] epoch 340 Batch 10 Loss 0.16847509145736694
[Train] epoch 340 Batch 11 Loss 0.13592150807380676
[Train] epoch 340 Batch 12 Loss 0.1347324252128601
[Train] epoch 340 Batch 13 Loss 0.20257925987243652
[Train] epoch 340 Batch 14 Loss 0.2337399125099182
[Train] epoch 340 Batch 15 Loss 0.10216735303401947
[Train] epoch 340 Batch 16 Loss 0.10109725594520569
[Train] epoch 340 Batch 17 Loss 0.20081155002117157
[Train] epoch 340 Batch 18 Loss 0.2026827037334442
[Train] epoch 340 Batch 19 Loss 0.13472308218479156
[Train] epoch 340 Batch 20 Loss 0.23651419579982758
[Train] epoch 340 Batch 21 Loss 0.0672447606921196
[Train] epoch 340 Batch 22 Loss 0.033627964556217194
[Train] epoch 340 Batch 23 Loss 0.10216224193572998
[Train] epoch 340 Batch 24 Loss 0.1009790450334549
[Train] epoch 340 Batch 25 Loss 0.4020776152610779
[Train] epoch 340 Batch 26 Loss 0.36821529269218445
[Train] epoch 340 Batch 27 Loss 0.1683480143547058
[Train] epoch 340 Batch 28 Loss 0.23430782556533813
[Train] epoch 340 Batch 29 Loss 0.06804352253675461
[Train] epoch 340 Batch 30 Loss 0.0354643240571022
[Train] epoch 340 Batch 31 Loss 0.10211753100156784
[Train] epoch 340 Batch 32 Loss 0.0683770626783371
[Train] epoch 340 Batch 33 Loss 0.06803852319717407
[Train] epoch 340 Batch 34 Loss 0.20080652832984924
[Train] epoch 340 Batch 35 Loss 0.23554210364818573
[Train] epoch 340 Batch 36 Loss 0.46802404522895813
[Train] epoch 340 Batch 37 Loss 0.16866758465766907
[Train] epoch 340 Batch 38 Loss 0.16694223880767822
[Train] epoch 340 Batch 39 Loss 0.2672262191772461
[Train] epoch 340 Batch 40 Loss 0.16763821244239807
[Train] epoch 340 Batch 41 Loss 0.23521606624126434
[Train] epoch 340 Batch 42 Loss 0.3346838355064392
[Train] epoch 340 Batch 43 Loss 0.13387933373451233
[Train] epoch 340 Batch 44 Loss 0.1352463960647583
[Train] epoch 340 Batch 45 Loss 0.2023656964302063
[Train] epoch 340 Batch 46 Loss 0.13582506775856018
[Train] epoch 340 Batch 47 Loss 0.10108472406864166
[Train] epoch 341 Batch 0 Loss 0.06776851415634155
[Train] epoch 341 Batch 1 Loss 0.034845441579818726
[Train] epoch 341 Batch 2 Loss 0.20303788781166077
[Train] epoch 341 Batch 3 Loss 0.30263227224349976
[Train] epoch 341 Batch 4 Loss 0.2680157423019409
[Train] epoch 341 Batch 5 Loss 0.10162580013275146
[Train] epoch 341 Batch 6 Loss 0.3016335964202881
[Train] epoch 341 Batch 7 Loss 0.1352214515209198
[Train] epoch 341 Batch 8 Loss 0.23574495315551758
[Train] epoch 341 Batch 9 Loss 0.3348015546798706
[Train] epoch 341 Batch 10 Loss 0.13578231632709503
[Train] epoch 341 Batch 11 Loss 0.10093982517719269
[Train] epoch 341 Batch 12 Loss 0.10148545354604721
[Train] epoch 341 Batch 13 Loss 0.133334219455719
[Train] epoch 341 Batch 14 Loss 0.20199964940547943
[Train] epoch 341 Batch 15 Loss 0.0678749680519104
[Train] epoch 341 Batch 16 Loss 0.23628225922584534
[Train] epoch 341 Batch 17 Loss 0.2671912610530853
[Train] epoch 341 Batch 18 Loss 0.20239697396755219
[Train] epoch 341 Batch 19 Loss 0.3346640169620514
[Train] epoch 341 Batch 20 Loss 0.03533433750271797
[Train] epoch 341 Batch 21 Loss 0.13533852994441986
[Train] epoch 341 Batch 22 Loss 0.10265415906906128
[Train] epoch 341 Batch 23 Loss 0.1345294564962387
[Train] epoch 341 Batch 24 Loss 0.102118581533432
[Train] epoch 341 Batch 25 Loss 0.3686333894729614
[Train] epoch 341 Batch 26 Loss 0.06666764616966248
[Train] epoch 341 Batch 27 Loss 0.20159263908863068
[Train] epoch 341 Batch 28 Loss 0.26772230863571167
[Train] epoch 341 Batch 29 Loss 0.2018309235572815
[Train] epoch 341 Batch 30 Loss 0.3685224652290344
[Train] epoch 341 Batch 31 Loss 0.10092738270759583
[Train] epoch 341 Batch 32 Loss 0.1669229120016098
[Train] epoch 341 Batch 33 Loss 0.067461758852005
[Train] epoch 341 Batch 34 Loss 0.23530332744121552
[Train] epoch 341 Batch 35 Loss 0.2356850653886795
[Train] epoch 341 Batch 36 Loss 0.2007940411567688
[Train] epoch 341 Batch 37 Loss 0.23518246412277222
[Train] epoch 341 Batch 38 Loss 0.23541896045207977
[Train] epoch 341 Batch 39 Loss 0.06745998561382294
[Train] epoch 341 Batch 40 Loss 0.13463962078094482
[Train] epoch 341 Batch 41 Loss 0.06783802062273026
[Train] epoch 341 Batch 42 Loss 0.2007921189069748
[Train] epoch 341 Batch 43 Loss 0.001563157420605421
[Train] epoch 341 Batch 44 Loss 0.2006472945213318
[Train] epoch 341 Batch 45 Loss 0.1344911754131317
[Train] epoch 341 Batch 46 Loss 0.16771717369556427
[Train] epoch 341 Batch 47 Loss 0.16691774129867554
[Train] epoch 342 Batch 0 Loss 0.10185784846544266
[Train] epoch 342 Batch 1 Loss 0.26731646060943604
[Train] epoch 342 Batch 2 Loss 0.1680043786764145
[Train] epoch 342 Batch 3 Loss 0.03372471407055855
[Train] epoch 342 Batch 4 Loss 0.2673388123512268
[Train] epoch 342 Batch 5 Loss 0.20238539576530457
[Train] epoch 342 Batch 6 Loss 0.06859491020441055
[Train] epoch 342 Batch 7 Loss 0.23556876182556152
[Train] epoch 342 Batch 8 Loss 0.13459032773971558
[Train] epoch 342 Batch 9 Loss 0.1676548719406128
[Train] epoch 342 Batch 10 Loss 0.03613921254873276
[Train] epoch 342 Batch 11 Loss 0.06857141852378845
[Train] epoch 342 Batch 12 Loss 0.10029634833335876
[Train] epoch 342 Batch 13 Loss 0.20137399435043335
[Train] epoch 342 Batch 14 Loss 0.20069512724876404
[Train] epoch 342 Batch 15 Loss 0.13597899675369263
[Train] epoch 342 Batch 16 Loss 0.20136615633964539
[Train] epoch 342 Batch 17 Loss 0.20339182019233704
[Train] epoch 342 Batch 18 Loss 0.10163365304470062
[Train] epoch 342 Batch 19 Loss 0.20063498616218567
[Train] epoch 342 Batch 20 Loss 0.3360078036785126
[Train] epoch 342 Batch 21 Loss 0.20139694213867188
[Train] epoch 342 Batch 22 Loss 0.06870125979185104
[Train] epoch 342 Batch 23 Loss 0.10162675380706787
[Train] epoch 342 Batch 24 Loss 0.10226277261972427
[Train] epoch 342 Batch 25 Loss 0.10101695358753204
[Train] epoch 342 Batch 26 Loss 0.2697805166244507
[Train] epoch 342 Batch 27 Loss 0.20318636298179626
[Train] epoch 342 Batch 28 Loss 0.2687425911426544
[Train] epoch 342 Batch 29 Loss 0.06734970211982727
[Train] epoch 342 Batch 30 Loss 0.20139113068580627
[Train] epoch 342 Batch 31 Loss 0.26798030734062195
[Train] epoch 342 Batch 32 Loss 0.3692411184310913
[Train] epoch 342 Batch 33 Loss 0.10170266032218933
[Train] epoch 342 Batch 34 Loss 0.10037937760353088
[Train] epoch 342 Batch 35 Loss 0.10100698471069336
[Train] epoch 342 Batch 36 Loss 0.10100603103637695
[Train] epoch 342 Batch 37 Loss 0.23492419719696045
[Train] epoch 342 Batch 38 Loss 0.3016154170036316
[Train] epoch 342 Batch 39 Loss 0.16903653740882874
[Train] epoch 342 Batch 40 Loss 0.23507679998874664
[Train] epoch 342 Batch 41 Loss 0.23433367908000946
[Train] epoch 342 Batch 42 Loss 0.1683274209499359
[Train] epoch 342 Batch 43 Loss 0.2013622522354126
[Train] epoch 342 Batch 44 Loss 0.16771817207336426
[Train] epoch 342 Batch 45 Loss 0.23582400381565094
[Train] epoch 342 Batch 46 Loss 0.1346922218799591
[Train] epoch 342 Batch 47 Loss 0.2336423099040985
[Train] epoch 343 Batch 0 Loss 0.1010618656873703
[Train] epoch 343 Batch 1 Loss 0.10159409046173096
[Train] epoch 343 Batch 2 Loss 0.13401779532432556
[Train] epoch 343 Batch 3 Loss 0.10150708258152008
[Train] epoch 343 Batch 4 Loss 0.0018110130913555622
[Train] epoch 343 Batch 5 Loss 0.16951826214790344
[Train] epoch 343 Batch 6 Loss 0.23424866795539856
[Train] epoch 343 Batch 7 Loss 0.33475273847579956
[Train] epoch 343 Batch 8 Loss 0.23430407047271729
[Train] epoch 343 Batch 9 Loss 0.16770900785923004
[Train] epoch 343 Batch 10 Loss 0.13535617291927338
[Train] epoch 343 Batch 11 Loss 0.10098046064376831
[Train] epoch 343 Batch 12 Loss 0.134614497423172
[Train] epoch 343 Batch 13 Loss 0.0673309713602066
[Train] epoch 343 Batch 14 Loss 0.13578802347183228
[Train] epoch 343 Batch 15 Loss 0.16821666061878204
[Train] epoch 343 Batch 16 Loss 0.33408403396606445
[Train] epoch 343 Batch 17 Loss 0.40184485912323
[Train] epoch 343 Batch 18 Loss 0.23497872054576874
[Train] epoch 343 Batch 19 Loss 0.201269268989563
[Train] epoch 343 Batch 20 Loss 0.36829620599746704
[Train] epoch 343 Batch 21 Loss 0.20193716883659363
[Train] epoch 343 Batch 22 Loss 0.034197863191366196
[Train] epoch 343 Batch 23 Loss 0.16763272881507874
[Train] epoch 343 Batch 24 Loss 0.3352375030517578
[Train] epoch 343 Batch 25 Loss 0.10161992162466049
[Train] epoch 343 Batch 26 Loss 0.10095053166151047
[Train] epoch 343 Batch 27 Loss 0.16769665479660034
[Train] epoch 343 Batch 28 Loss 0.4030412435531616
[Train] epoch 343 Batch 29 Loss 0.16778960824012756
[Train] epoch 343 Batch 30 Loss 0.3354003429412842
[Train] epoch 343 Batch 31 Loss 0.16837069392204285
[Train] epoch 343 Batch 32 Loss 0.13581298291683197
[Train] epoch 343 Batch 33 Loss 0.20387431979179382
[Train] epoch 343 Batch 34 Loss 0.201134592294693
[Train] epoch 343 Batch 35 Loss 0.1680750697851181
[Train] epoch 343 Batch 36 Loss 0.1683630645275116
[Train] epoch 343 Batch 37 Loss 0.10207614302635193
[Train] epoch 343 Batch 38 Loss 0.1340799331665039
[Train] epoch 343 Batch 39 Loss 0.03484083339571953
[Train] epoch 343 Batch 40 Loss 0.1669413447380066
[Train] epoch 343 Batch 41 Loss 0.13522011041641235
[Train] epoch 343 Batch 42 Loss 0.10225638002157211
[Train] epoch 343 Batch 43 Loss 0.13509109616279602
[Train] epoch 343 Batch 44 Loss 0.10037313401699066
[Train] epoch 343 Batch 45 Loss 0.23490357398986816
[Train] epoch 343 Batch 46 Loss 0.13538691401481628
[Train] epoch 343 Batch 47 Loss 0.16815543174743652
[Train] epoch 344 Batch 0 Loss 0.20212918519973755
[Train] epoch 344 Batch 1 Loss 0.20055130124092102
[Train] epoch 344 Batch 2 Loss 0.2025057077407837
[Train] epoch 344 Batch 3 Loss 0.1351853311061859
[Train] epoch 344 Batch 4 Loss 0.13407649099826813
[Train] epoch 344 Batch 5 Loss 0.26851382851600647
[Train] epoch 344 Batch 6 Loss 0.06887461245059967
[Train] epoch 344 Batch 7 Loss 0.1357100009918213
[Train] epoch 344 Batch 8 Loss 0.2350008636713028
[Train] epoch 344 Batch 9 Loss 0.16878139972686768
[Train] epoch 344 Batch 10 Loss 0.10092385113239288
[Train] epoch 344 Batch 11 Loss 0.3015572428703308
[Train] epoch 344 Batch 12 Loss 0.06785266101360321
[Train] epoch 344 Batch 13 Loss 0.16757571697235107
[Train] epoch 344 Batch 14 Loss 0.034253090620040894
[Train] epoch 344 Batch 15 Loss 0.20171692967414856
[Train] epoch 344 Batch 16 Loss 0.06774953752756119
[Train] epoch 344 Batch 17 Loss 0.2359379231929779
[Train] epoch 344 Batch 18 Loss 0.16821187734603882
[Train] epoch 344 Batch 19 Loss 0.23550744354724884
[Train] epoch 344 Batch 20 Loss 0.13471326231956482
[Train] epoch 344 Batch 21 Loss 0.46792495250701904
[Train] epoch 344 Batch 22 Loss 0.10027089715003967
[Train] epoch 344 Batch 23 Loss 0.1339622139930725
[Train] epoch 344 Batch 24 Loss 0.20136597752571106
[Train] epoch 344 Batch 25 Loss 0.101860910654068
[Train] epoch 344 Batch 26 Loss 0.13524490594863892
[Train] epoch 344 Batch 27 Loss 0.3350204825401306
[Train] epoch 344 Batch 28 Loss 0.20126160979270935
[Train] epoch 344 Batch 29 Loss 0.2023397982120514
[Train] epoch 344 Batch 30 Loss 0.13396912813186646
[Train] epoch 344 Batch 31 Loss 0.30204612016677856
[Train] epoch 344 Batch 32 Loss 0.10078689455986023
[Train] epoch 344 Batch 33 Loss 0.13490276038646698
[Train] epoch 344 Batch 34 Loss 0.16765731573104858
[Train] epoch 344 Batch 35 Loss 0.2347368448972702
[Train] epoch 344 Batch 36 Loss 0.2016756534576416
[Train] epoch 344 Batch 37 Loss 0.1007794663310051
[Train] epoch 344 Batch 38 Loss 0.10151363909244537
[Train] epoch 344 Batch 39 Loss 0.1348857283592224
[Train] epoch 344 Batch 40 Loss 0.1682829111814499
[Train] epoch 344 Batch 41 Loss 0.268020898103714
[Train] epoch 344 Batch 42 Loss 0.3340688943862915
[Train] epoch 344 Batch 43 Loss 0.0678057074546814
[Train] epoch 344 Batch 44 Loss 0.3027586042881012
[Train] epoch 344 Batch 45 Loss 0.10088659822940826
[Train] epoch 344 Batch 46 Loss 0.10088624060153961
[Train] epoch 344 Batch 47 Loss 0.06740143150091171
[Train] epoch 345 Batch 0 Loss 0.23421752452850342
[Train] epoch 345 Batch 1 Loss 0.16814430058002472
[Train] epoch 345 Batch 2 Loss 0.30036723613739014
[Train] epoch 345 Batch 3 Loss 0.10036735236644745
[Train] epoch 345 Batch 4 Loss 0.06831903755664825
[Train] epoch 345 Batch 5 Loss 0.13479891419410706
[Train] epoch 345 Batch 6 Loss 0.20175853371620178
[Train] epoch 345 Batch 7 Loss 0.23543694615364075
[Train] epoch 345 Batch 8 Loss 0.23408177495002747
[Train] epoch 345 Batch 9 Loss 0.03369997814297676
[Train] epoch 345 Batch 10 Loss 0.20163214206695557
[Train] epoch 345 Batch 11 Loss 0.23443016409873962
[Train] epoch 345 Batch 12 Loss 0.03408866375684738
[Train] epoch 345 Batch 13 Loss 0.10076387226581573
[Train] epoch 345 Batch 14 Loss 0.13506044447422028
[Train] epoch 345 Batch 15 Loss 0.26728612184524536
[Train] epoch 345 Batch 16 Loss 0.23541314899921417
[Train] epoch 345 Batch 17 Loss 0.301824152469635
[Train] epoch 345 Batch 18 Loss 0.16825687885284424
[Train] epoch 345 Batch 19 Loss 0.20173922181129456
[Train] epoch 345 Batch 20 Loss 0.10158868879079819
[Train] epoch 345 Batch 21 Loss 0.06716211140155792
[Train] epoch 345 Batch 22 Loss 0.23506712913513184
[Train] epoch 345 Batch 23 Loss 0.10086730867624283
[Train] epoch 345 Batch 24 Loss 0.23457014560699463
[Train] epoch 345 Batch 25 Loss 0.13393902778625488
[Train] epoch 345 Batch 26 Loss 0.20183241367340088
[Train] epoch 345 Batch 27 Loss 0.10150938481092453
[Train] epoch 345 Batch 28 Loss 0.13505405187606812
[Train] epoch 345 Batch 29 Loss 0.26800161600112915
[Train] epoch 345 Batch 30 Loss 0.10196049511432648
[Train] epoch 345 Batch 31 Loss 0.23495729267597198
[Train] epoch 345 Batch 32 Loss 0.13553833961486816
[Train] epoch 345 Batch 33 Loss 0.1670244336128235
[Train] epoch 345 Batch 34 Loss 0.168448343873024
[Train] epoch 345 Batch 35 Loss 0.16944856941699982
[Train] epoch 345 Batch 36 Loss 0.26731565594673157
[Train] epoch 345 Batch 37 Loss 0.10159863531589508
[Train] epoch 345 Batch 38 Loss 0.1681334525346756
[Train] epoch 345 Batch 39 Loss 0.3009275794029236
[Train] epoch 345 Batch 40 Loss 0.2025114893913269
[Train] epoch 345 Batch 41 Loss 0.23493891954421997
[Train] epoch 345 Batch 42 Loss 0.1694556176662445
[Train] epoch 345 Batch 43 Loss 0.10216759890317917
[Train] epoch 345 Batch 44 Loss 0.16942504048347473
[Train] epoch 345 Batch 45 Loss 0.26792460680007935
[Train] epoch 345 Batch 46 Loss 0.16946163773536682
[Train] epoch 345 Batch 47 Loss 0.06860831379890442
[Train] epoch 346 Batch 0 Loss 0.1358010470867157
[Train] epoch 346 Batch 1 Loss 0.13465890288352966
[Train] epoch 346 Batch 2 Loss 0.06797757744789124
[Train] epoch 346 Batch 3 Loss 0.1009046658873558
[Train] epoch 346 Batch 4 Loss 0.26864075660705566
[Train] epoch 346 Batch 5 Loss 0.23493480682373047
[Train] epoch 346 Batch 6 Loss 0.06790868937969208
[Train] epoch 346 Batch 7 Loss 0.23421436548233032
[Train] epoch 346 Batch 8 Loss 0.10102399438619614
[Train] epoch 346 Batch 9 Loss 0.1688840538263321
[Train] epoch 346 Batch 10 Loss 0.16835357248783112
[Train] epoch 346 Batch 11 Loss 0.10096392780542374
[Train] epoch 346 Batch 12 Loss 0.3010096549987793
[Train] epoch 346 Batch 13 Loss 0.23551201820373535
[Train] epoch 346 Batch 14 Loss 0.13398104906082153
[Train] epoch 346 Batch 15 Loss 0.26871418952941895
[Train] epoch 346 Batch 16 Loss 0.20196765661239624
[Train] epoch 346 Batch 17 Loss 0.20183569192886353
[Train] epoch 346 Batch 18 Loss 0.1689438819885254
[Train] epoch 346 Batch 19 Loss 0.2342890501022339
[Train] epoch 346 Batch 20 Loss 0.23549476265907288
[Train] epoch 346 Batch 21 Loss 0.06739407032728195
[Train] epoch 346 Batch 22 Loss 0.16703078150749207
[Train] epoch 346 Batch 23 Loss 0.20116150379180908
[Train] epoch 346 Batch 24 Loss 0.23492617905139923
[Train] epoch 346 Batch 25 Loss 0.20188455283641815
[Train] epoch 346 Batch 26 Loss 0.1352865993976593
[Train] epoch 346 Batch 27 Loss 0.20145386457443237
[Train] epoch 346 Batch 28 Loss 0.1345706582069397
[Train] epoch 346 Batch 29 Loss 0.06854243576526642
[Train] epoch 346 Batch 30 Loss 0.10085752606391907
[Train] epoch 346 Batch 31 Loss 0.13449281454086304
[Train] epoch 346 Batch 32 Loss 0.2673196494579315
[Train] epoch 346 Batch 33 Loss 0.0011426587589085102
[Train] epoch 346 Batch 34 Loss 0.10253985226154327
[Train] epoch 346 Batch 35 Loss 0.30172619223594666
[Train] epoch 346 Batch 36 Loss 0.10263131558895111
[Train] epoch 346 Batch 37 Loss 0.2685874402523041
[Train] epoch 346 Batch 38 Loss 0.4354597330093384
[Train] epoch 346 Batch 39 Loss 0.13455119729042053
[Train] epoch 346 Batch 40 Loss 0.13462767004966736
[Train] epoch 346 Batch 41 Loss 0.20120058953762054
[Train] epoch 346 Batch 42 Loss 0.20248989760875702
[Train] epoch 346 Batch 43 Loss 0.20173558592796326
[Train] epoch 346 Batch 44 Loss 0.0005510825430974364
[Train] epoch 346 Batch 45 Loss 0.1681405007839203
[Train] epoch 346 Batch 46 Loss 0.30154091119766235
[Train] epoch 346 Batch 47 Loss 0.13453525304794312
[Train] epoch 347 Batch 0 Loss 0.10154977440834045
[Train] epoch 347 Batch 1 Loss 0.13564574718475342
[Train] epoch 347 Batch 2 Loss 0.2024385929107666
[Train] epoch 347 Batch 3 Loss 0.2684749364852905
[Train] epoch 347 Batch 4 Loss 0.10152935981750488
[Train] epoch 347 Batch 5 Loss 0.10081588476896286
[Train] epoch 347 Batch 6 Loss 0.06666764616966248
[Train] epoch 347 Batch 7 Loss 0.10152420401573181
[Train] epoch 347 Batch 8 Loss 0.16765275597572327
[Train] epoch 347 Batch 9 Loss 0.23485347628593445
[Train] epoch 347 Batch 10 Loss 0.20063552260398865
[Train] epoch 347 Batch 11 Loss 0.2012690305709839
[Train] epoch 347 Batch 12 Loss 0.168296217918396
[Train] epoch 347 Batch 13 Loss 0.1680268943309784
[Train] epoch 347 Batch 14 Loss 0.0005319287301972508
[Train] epoch 347 Batch 15 Loss 0.06720978021621704
[Train] epoch 347 Batch 16 Loss 0.2017804980278015
[Train] epoch 347 Batch 17 Loss 0.16755634546279907
[Train] epoch 347 Batch 18 Loss 0.13458341360092163
[Train] epoch 347 Batch 19 Loss 0.20124903321266174
[Train] epoch 347 Batch 20 Loss 0.10078282654285431
[Train] epoch 347 Batch 21 Loss 0.20072226226329803
[Train] epoch 347 Batch 22 Loss 0.26800528168678284
[Train] epoch 347 Batch 23 Loss 0.16872653365135193
[Train] epoch 347 Batch 24 Loss 0.2351362556219101
[Train] epoch 347 Batch 25 Loss 0.33512282371520996
[Train] epoch 347 Batch 26 Loss 0.06834864616394043
[Train] epoch 347 Batch 27 Loss 0.10182902961969376
[Train] epoch 347 Batch 28 Loss 0.26885220408439636
[Train] epoch 347 Batch 29 Loss 0.13668183982372284
[Train] epoch 347 Batch 30 Loss 0.33477285504341125
[Train] epoch 347 Batch 31 Loss 0.36899375915527344
[Train] epoch 347 Batch 32 Loss 0.13394562900066376
[Train] epoch 347 Batch 33 Loss 0.13445967435836792
[Train] epoch 347 Batch 34 Loss 0.20228305459022522
[Train] epoch 347 Batch 35 Loss 0.2358754426240921
[Train] epoch 347 Batch 36 Loss 0.2676907777786255
[Train] epoch 347 Batch 37 Loss 0.3681562542915344
[Train] epoch 347 Batch 38 Loss 0.168045312166214
[Train] epoch 347 Batch 39 Loss 0.1680540144443512
[Train] epoch 347 Batch 40 Loss 0.1351657211780548
[Train] epoch 347 Batch 41 Loss 0.26769107580184937
[Train] epoch 347 Batch 42 Loss 0.03410935774445534
[Train] epoch 347 Batch 43 Loss 0.1681465357542038
[Train] epoch 347 Batch 44 Loss 0.16702574491500854
[Train] epoch 347 Batch 45 Loss 0.03469708189368248
[Train] epoch 347 Batch 46 Loss 0.16762888431549072
[Train] epoch 347 Batch 47 Loss 0.13517552614212036
[Train] epoch 348 Batch 0 Loss 0.1013588234782219
[Train] epoch 348 Batch 1 Loss 0.23562195897102356
[Train] epoch 348 Batch 2 Loss 0.3355547785758972
[Train] epoch 348 Batch 3 Loss 0.2007157802581787
[Train] epoch 348 Batch 4 Loss 0.10025462508201599
[Train] epoch 348 Batch 5 Loss 0.26809632778167725
[Train] epoch 348 Batch 6 Loss 0.06839416176080704
[Train] epoch 348 Batch 7 Loss 0.20071466267108917
[Train] epoch 348 Batch 8 Loss 0.30155426263809204
[Train] epoch 348 Batch 9 Loss 0.2358953356742859
[Train] epoch 348 Batch 10 Loss 0.1338273286819458
[Train] epoch 348 Batch 11 Loss 0.2346855252981186
[Train] epoch 348 Batch 12 Loss 0.16751563549041748
[Train] epoch 348 Batch 13 Loss 0.26908373832702637
[Train] epoch 348 Batch 14 Loss 0.1351429522037506
[Train] epoch 348 Batch 15 Loss 0.2012125551700592
[Train] epoch 348 Batch 16 Loss 0.068845734000206
[Train] epoch 348 Batch 17 Loss 0.4011996388435364
[Train] epoch 348 Batch 18 Loss 0.2016969621181488
[Train] epoch 348 Batch 19 Loss 0.17007075250148773
[Train] epoch 348 Batch 20 Loss 0.10035581886768341
[Train] epoch 348 Batch 21 Loss 0.2000008225440979
[Train] epoch 348 Batch 22 Loss 0.10085061192512512
[Train] epoch 348 Batch 23 Loss 0.10073152929544449
[Train] epoch 348 Batch 24 Loss 0.20048369467258453
[Train] epoch 348 Batch 25 Loss 0.16787849366664886
[Train] epoch 348 Batch 26 Loss 0.06737610697746277
[Train] epoch 348 Batch 27 Loss 0.13513359427452087
[Train] epoch 348 Batch 28 Loss 0.1020335853099823
[Train] epoch 348 Batch 29 Loss 0.2005893737077713
[Train] epoch 348 Batch 30 Loss 0.20313358306884766
[Train] epoch 348 Batch 31 Loss 0.10023481398820877
[Train] epoch 348 Batch 32 Loss 0.06786227226257324
[Train] epoch 348 Batch 33 Loss 0.10084116458892822
[Train] epoch 348 Batch 34 Loss 0.4017602205276489
[Train] epoch 348 Batch 35 Loss 0.20193234086036682
[Train] epoch 348 Batch 36 Loss 0.10155788064002991
[Train] epoch 348 Batch 37 Loss 0.16701942682266235
[Train] epoch 348 Batch 38 Loss 0.16741061210632324
[Train] epoch 348 Batch 39 Loss 0.2016434669494629
[Train] epoch 348 Batch 40 Loss 0.1350846290588379
[Train] epoch 348 Batch 41 Loss 0.1013440191745758
[Train] epoch 348 Batch 42 Loss 0.034782882779836655
[Train] epoch 348 Batch 43 Loss 0.16895745694637299
[Train] epoch 348 Batch 44 Loss 0.1344519853591919
[Train] epoch 348 Batch 45 Loss 0.1345086693763733
[Train] epoch 348 Batch 46 Loss 0.2019573450088501
[Train] epoch 348 Batch 47 Loss 0.33509156107902527
[Train] epoch 349 Batch 0 Loss 0.2012762427330017
[Train] epoch 349 Batch 1 Loss 0.10157519578933716
[Train] epoch 349 Batch 2 Loss 0.4012052118778229
[Train] epoch 349 Batch 3 Loss 0.3015678822994232
[Train] epoch 349 Batch 4 Loss 0.06968270987272263
[Train] epoch 349 Batch 5 Loss 0.2018343061208725
[Train] epoch 349 Batch 6 Loss 0.16949746012687683
[Train] epoch 349 Batch 7 Loss 0.23435808718204498
[Train] epoch 349 Batch 8 Loss 0.20191851258277893
[Train] epoch 349 Batch 9 Loss 0.26797744631767273
[Train] epoch 349 Batch 10 Loss 0.2685668170452118
[Train] epoch 349 Batch 11 Loss 0.06847997009754181
[Train] epoch 349 Batch 12 Loss 0.16817544400691986
[Train] epoch 349 Batch 13 Loss 0.236776202917099
[Train] epoch 349 Batch 14 Loss 0.1670074462890625
[Train] epoch 349 Batch 15 Loss 0.20116904377937317
[Train] epoch 349 Batch 16 Loss 0.20123623311519623
[Train] epoch 349 Batch 17 Loss 0.1682610660791397
[Train] epoch 349 Batch 18 Loss 0.10094718635082245
[Train] epoch 349 Batch 19 Loss 0.13574591279029846
[Train] epoch 349 Batch 20 Loss 0.1339598149061203
[Train] epoch 349 Batch 21 Loss 0.16754159331321716
[Train] epoch 349 Batch 22 Loss 0.3016054034233093
[Train] epoch 349 Batch 23 Loss 0.1676468402147293
[Train] epoch 349 Batch 24 Loss 1.0728851975727594e-06
[Train] epoch 349 Batch 25 Loss 0.3682846426963806
[Train] epoch 349 Batch 26 Loss 0.2006232589483261
[Train] epoch 349 Batch 27 Loss 0.30101674795150757
[Train] epoch 349 Batch 28 Loss 0.13523192703723907
[Train] epoch 349 Batch 29 Loss 0.06788688898086548
[Train] epoch 349 Batch 30 Loss 0.1351495087146759
[Train] epoch 349 Batch 31 Loss 0.1694229394197464
[Train] epoch 349 Batch 32 Loss 0.1681799590587616
[Train] epoch 349 Batch 33 Loss 0.10217199474573135
[Train] epoch 349 Batch 34 Loss 0.10210201144218445
[Train] epoch 349 Batch 35 Loss 0.100338876247406
[Train] epoch 349 Batch 36 Loss 0.06728513538837433
[Train] epoch 349 Batch 37 Loss 0.06787431240081787
[Train] epoch 349 Batch 38 Loss 0.16755059361457825
[Train] epoch 349 Batch 39 Loss 0.1683119833469391
[Train] epoch 349 Batch 40 Loss 0.06782408803701401
[Train] epoch 349 Batch 41 Loss 0.2342565953731537
[Train] epoch 349 Batch 42 Loss 0.13508516550064087
[Train] epoch 349 Batch 43 Loss 0.13448506593704224
[Train] epoch 349 Batch 44 Loss 0.26784592866897583
[Train] epoch 349 Batch 45 Loss 0.23429915308952332
[Train] epoch 349 Batch 46 Loss 0.16825847327709198
[Train] epoch 349 Batch 47 Loss 0.1699468493461609
[Train] epoch 350 Batch 0 Loss 0.16807955503463745
[Train] epoch 350 Batch 1 Loss 0.16820476949214935
[Train] epoch 350 Batch 2 Loss 0.20123375952243805
[Train] epoch 350 Batch 3 Loss 0.1669541597366333
[Train] epoch 350 Batch 4 Loss 0.10101176053285599
[Train] epoch 350 Batch 5 Loss 0.13518613576889038
[Train] epoch 350 Batch 6 Loss 0.1351325809955597
[Train] epoch 350 Batch 7 Loss 0.1026342362165451
[Train] epoch 350 Batch 8 Loss 0.23360297083854675
[Train] epoch 350 Batch 9 Loss 0.33448976278305054
[Train] epoch 350 Batch 10 Loss 0.16815875470638275
[Train] epoch 350 Batch 11 Loss 0.169173926115036
[Train] epoch 350 Batch 12 Loss 0.10094024240970612
[Train] epoch 350 Batch 13 Loss 0.16823799908161163
[Train] epoch 350 Batch 14 Loss 0.2359367161989212
[Train] epoch 350 Batch 15 Loss 0.1681777983903885
[Train] epoch 350 Batch 16 Loss 0.1676039695739746
[Train] epoch 350 Batch 17 Loss 0.034212321043014526
[Train] epoch 350 Batch 18 Loss 0.10210393369197845
[Train] epoch 350 Batch 19 Loss 0.10033684968948364
[Train] epoch 350 Batch 20 Loss 0.20174908638000488
[Train] epoch 350 Batch 21 Loss 0.16864314675331116
[Train] epoch 350 Batch 22 Loss 0.13503211736679077
[Train] epoch 350 Batch 23 Loss 0.23542475700378418
[Train] epoch 350 Batch 24 Loss 0.13446344435214996
[Train] epoch 350 Batch 25 Loss 0.06788493692874908
[Train] epoch 350 Batch 26 Loss 0.10148988664150238
[Train] epoch 350 Batch 27 Loss 0.23609907925128937
[Train] epoch 350 Batch 28 Loss 0.2677898705005646
[Train] epoch 350 Batch 29 Loss 0.23480352759361267
[Train] epoch 350 Batch 30 Loss 0.30079880356788635
[Train] epoch 350 Batch 31 Loss 0.13513517379760742
[Train] epoch 350 Batch 32 Loss 0.20067045092582703
[Train] epoch 350 Batch 33 Loss 0.16700226068496704
[Train] epoch 350 Batch 34 Loss 0.26787373423576355
[Train] epoch 350 Batch 35 Loss 0.20111292600631714
[Train] epoch 350 Batch 36 Loss 0.26876771450042725
[Train] epoch 350 Batch 37 Loss 0.03420284762978554
[Train] epoch 350 Batch 38 Loss 0.06718739867210388
[Train] epoch 350 Batch 39 Loss 0.1007988303899765
[Train] epoch 350 Batch 40 Loss 0.30247512459754944
[Train] epoch 350 Batch 41 Loss 0.1343809962272644
[Train] epoch 350 Batch 42 Loss 0.1349647045135498
[Train] epoch 350 Batch 43 Loss 0.23492157459259033
[Train] epoch 350 Batch 44 Loss 0.33458632230758667
[Train] epoch 350 Batch 45 Loss 0.13458600640296936
[Train] epoch 350 Batch 46 Loss 0.20162101089954376
[Train] epoch 350 Batch 47 Loss 0.20164382457733154
[Train] epoch 351 Batch 0 Loss 0.16833609342575073
[Train] epoch 351 Batch 1 Loss 0.1697302758693695
[Train] epoch 351 Batch 2 Loss 0.0678558200597763
[Train] epoch 351 Batch 3 Loss 0.13392743468284607
[Train] epoch 351 Batch 4 Loss 0.10143309086561203
[Train] epoch 351 Batch 5 Loss 0.23417261242866516
[Train] epoch 351 Batch 6 Loss 0.13484790921211243
[Train] epoch 351 Batch 7 Loss 0.13493219017982483
[Train] epoch 351 Batch 8 Loss 0.16810575127601624
[Train] epoch 351 Batch 9 Loss 0.06775902211666107
[Train] epoch 351 Batch 10 Loss 0.23575900495052338
[Train] epoch 351 Batch 11 Loss 0.10075642168521881
[Train] epoch 351 Batch 12 Loss 0.36800915002822876
[Train] epoch 351 Batch 13 Loss 0.2672547698020935
[Train] epoch 351 Batch 14 Loss 0.10033348202705383
[Train] epoch 351 Batch 15 Loss 0.20116190612316132
[Train] epoch 351 Batch 16 Loss 0.1349889487028122
[Train] epoch 351 Batch 17 Loss 0.20174503326416016
[Train] epoch 351 Batch 18 Loss 0.26782500743865967
[Train] epoch 351 Batch 19 Loss 0.3344787061214447
[Train] epoch 351 Batch 20 Loss 0.20066499710083008
[Train] epoch 351 Batch 21 Loss 0.16749079525470734
[Train] epoch 351 Batch 22 Loss 0.03567574918270111
[Train] epoch 351 Batch 23 Loss 0.16758191585540771
[Train] epoch 351 Batch 24 Loss 0.13399767875671387
[Train] epoch 351 Batch 25 Loss 0.23472340404987335
[Train] epoch 351 Batch 26 Loss 0.1344025880098343
[Train] epoch 351 Batch 27 Loss 0.13490039110183716
[Train] epoch 351 Batch 28 Loss 0.2687174379825592
[Train] epoch 351 Batch 29 Loss 0.2022254317998886
[Train] epoch 351 Batch 30 Loss 0.2348235845565796
[Train] epoch 351 Batch 31 Loss 0.30179375410079956
[Train] epoch 351 Batch 32 Loss 0.10120067000389099
[Train] epoch 351 Batch 33 Loss 0.16766038537025452
[Train] epoch 351 Batch 34 Loss 0.16797134280204773
[Train] epoch 351 Batch 35 Loss 0.10073764622211456
[Train] epoch 351 Batch 36 Loss 0.10128915309906006
[Train] epoch 351 Batch 37 Loss 0.26772069931030273
[Train] epoch 351 Batch 38 Loss 0.06715569645166397
[Train] epoch 351 Batch 39 Loss 0.10120810568332672
[Train] epoch 351 Batch 40 Loss 0.23527678847312927
[Train] epoch 351 Batch 41 Loss 0.1009046882390976
[Train] epoch 351 Batch 42 Loss 0.10128989070653915
[Train] epoch 351 Batch 43 Loss 0.20159654319286346
[Train] epoch 351 Batch 44 Loss 0.13430003821849823
[Train] epoch 351 Batch 45 Loss 0.33455488085746765
[Train] epoch 351 Batch 46 Loss 0.13502490520477295
[Train] epoch 351 Batch 47 Loss 0.23536483943462372
[Train] epoch 352 Batch 0 Loss 0.2012307047843933
[Train] epoch 352 Batch 1 Loss 0.13436099886894226
[Train] epoch 352 Batch 2 Loss 1.0728851975727594e-06
[Train] epoch 352 Batch 3 Loss 0.16861183941364288
[Train] epoch 352 Batch 4 Loss 0.16813340783119202
[Train] epoch 352 Batch 5 Loss 0.23451407253742218
[Train] epoch 352 Batch 6 Loss 0.30259889364242554
[Train] epoch 352 Batch 7 Loss 0.1686866134405136
[Train] epoch 352 Batch 8 Loss 0.10211435705423355
[Train] epoch 352 Batch 9 Loss 0.20169782638549805
[Train] epoch 352 Batch 10 Loss 0.06760194897651672
[Train] epoch 352 Batch 11 Loss 0.30200231075286865
[Train] epoch 352 Batch 12 Loss 0.06778507679700851
[Train] epoch 352 Batch 13 Loss 0.23579147458076477
[Train] epoch 352 Batch 14 Loss 0.20148113369941711
[Train] epoch 352 Batch 15 Loss 0.23402605950832367
[Train] epoch 352 Batch 16 Loss 0.23449231684207916
[Train] epoch 352 Batch 17 Loss 0.06814172863960266
[Train] epoch 352 Batch 18 Loss 0.2011222541332245
[Train] epoch 352 Batch 19 Loss 0.23513171076774597
[Train] epoch 352 Batch 20 Loss 0.16699525713920593
[Train] epoch 352 Batch 21 Loss 0.268229216337204
[Train] epoch 352 Batch 22 Loss 0.10166222602128983
[Train] epoch 352 Batch 23 Loss 0.16859692335128784
[Train] epoch 352 Batch 24 Loss 0.30526643991470337
[Train] epoch 352 Batch 25 Loss 0.06841174513101578
[Train] epoch 352 Batch 26 Loss 0.2684882879257202
[Train] epoch 352 Batch 27 Loss 0.3339972496032715
[Train] epoch 352 Batch 28 Loss 0.3021833896636963
[Train] epoch 352 Batch 29 Loss 0.10031160712242126
[Train] epoch 352 Batch 30 Loss 0.06727969646453857
[Train] epoch 352 Batch 31 Loss 0.1016487330198288
[Train] epoch 352 Batch 32 Loss 0.10030537843704224
[Train] epoch 352 Batch 33 Loss 0.20132991671562195
[Train] epoch 352 Batch 34 Loss 0.1340152770280838
[Train] epoch 352 Batch 35 Loss 0.06732997298240662
[Train] epoch 352 Batch 36 Loss 0.2013472467660904
[Train] epoch 352 Batch 37 Loss 0.133334219455719
[Train] epoch 352 Batch 38 Loss 0.1340385228395462
[Train] epoch 352 Batch 39 Loss 0.235727459192276
[Train] epoch 352 Batch 40 Loss 0.3024236559867859
[Train] epoch 352 Batch 41 Loss 0.1677277833223343
[Train] epoch 352 Batch 42 Loss 0.2687377631664276
[Train] epoch 352 Batch 43 Loss 0.13543540239334106
[Train] epoch 352 Batch 44 Loss 0.10174886137247086
[Train] epoch 352 Batch 45 Loss 0.1017751395702362
[Train] epoch 352 Batch 46 Loss 0.2680657207965851
[Train] epoch 352 Batch 47 Loss 0.03511163964867592
[Train] epoch 353 Batch 0 Loss 0.10247067362070084
[Train] epoch 353 Batch 1 Loss 0.1676807403564453
[Train] epoch 353 Batch 2 Loss 0.06806528568267822
[Train] epoch 353 Batch 3 Loss 0.06809645146131516
[Train] epoch 353 Batch 4 Loss 0.13405348360538483
[Train] epoch 353 Batch 5 Loss 0.10178375244140625
[Train] epoch 353 Batch 6 Loss 0.16836535930633545
[Train] epoch 353 Batch 7 Loss 0.2694253921508789
[Train] epoch 353 Batch 8 Loss 0.13540765643119812
[Train] epoch 353 Batch 9 Loss 0.16774892807006836
[Train] epoch 353 Batch 10 Loss 0.10316751897335052
[Train] epoch 353 Batch 11 Loss 0.13546080887317657
[Train] epoch 353 Batch 12 Loss 0.30103614926338196
[Train] epoch 353 Batch 13 Loss 0.200700044631958
[Train] epoch 353 Batch 14 Loss 0.23507696390151978
[Train] epoch 353 Batch 15 Loss 0.13472667336463928
[Train] epoch 353 Batch 16 Loss 0.07010288536548615
[Train] epoch 353 Batch 17 Loss 0.20137521624565125
[Train] epoch 353 Batch 18 Loss 0.2344174087047577
[Train] epoch 353 Batch 19 Loss 0.2007230520248413
[Train] epoch 353 Batch 20 Loss 0.2013930380344391
[Train] epoch 353 Batch 21 Loss 0.3010839819908142
[Train] epoch 353 Batch 22 Loss 0.16771313548088074
[Train] epoch 353 Batch 23 Loss 0.20338287949562073
[Train] epoch 353 Batch 24 Loss 0.3690694570541382
[Train] epoch 353 Batch 25 Loss 0.16978314518928528
[Train] epoch 353 Batch 26 Loss 0.26802077889442444
[Train] epoch 353 Batch 27 Loss 0.10231916606426239
[Train] epoch 353 Batch 28 Loss 0.10103549063205719
[Train] epoch 353 Batch 29 Loss 0.23369485139846802
[Train] epoch 353 Batch 30 Loss 0.06729120016098022
[Train] epoch 353 Batch 31 Loss 0.23436659574508667
[Train] epoch 353 Batch 32 Loss 0.1353941708803177
[Train] epoch 353 Batch 33 Loss 0.16839250922203064
[Train] epoch 353 Batch 34 Loss 0.13466809689998627
[Train] epoch 353 Batch 35 Loss 0.2020016610622406
[Train] epoch 353 Batch 36 Loss 0.2014126032590866
[Train] epoch 353 Batch 37 Loss 0.26805537939071655
[Train] epoch 353 Batch 38 Loss 0.2013569325208664
[Train] epoch 353 Batch 39 Loss 0.03366318345069885
[Train] epoch 353 Batch 40 Loss 0.10220741480588913
[Train] epoch 353 Batch 41 Loss 0.2349584996700287
[Train] epoch 353 Batch 42 Loss 0.1010138988494873
[Train] epoch 353 Batch 43 Loss 0.30236077308654785
[Train] epoch 353 Batch 44 Loss 0.06732988357543945
[Train] epoch 353 Batch 45 Loss 0.2025865763425827
[Train] epoch 353 Batch 46 Loss 0.2343052327632904
[Train] epoch 353 Batch 47 Loss 0.17024801671504974
[Train] epoch 354 Batch 0 Loss 0.20065999031066895
[Train] epoch 354 Batch 1 Loss 0.10236331075429916
[Train] epoch 354 Batch 2 Loss 0.2343336045742035
[Train] epoch 354 Batch 3 Loss 0.10093718767166138
[Train] epoch 354 Batch 4 Loss 0.3030087351799011
[Train] epoch 354 Batch 5 Loss 0.03430700674653053
[Train] epoch 354 Batch 6 Loss 0.2686741352081299
[Train] epoch 354 Batch 7 Loss 0.10155943036079407
[Train] epoch 354 Batch 8 Loss 0.23628024756908417
[Train] epoch 354 Batch 9 Loss 0.1346600204706192
[Train] epoch 354 Batch 10 Loss 0.13584449887275696
[Train] epoch 354 Batch 11 Loss 0.16756299138069153
[Train] epoch 354 Batch 12 Loss 0.10035991668701172
[Train] epoch 354 Batch 13 Loss 0.3008914589881897
[Train] epoch 354 Batch 14 Loss 0.03362385556101799
[Train] epoch 354 Batch 15 Loss 0.2018650472164154
[Train] epoch 354 Batch 16 Loss 0.1340014636516571
[Train] epoch 354 Batch 17 Loss 0.20124214887619019
[Train] epoch 354 Batch 18 Loss 0.20140644907951355
[Train] epoch 354 Batch 19 Loss 0.10336080938577652
[Train] epoch 354 Batch 20 Loss 0.269455224275589
[Train] epoch 354 Batch 21 Loss 0.10091085731983185
[Train] epoch 354 Batch 22 Loss 0.06797785311937332
[Train] epoch 354 Batch 23 Loss 0.26997295022010803
[Train] epoch 354 Batch 24 Loss 0.20193535089492798
[Train] epoch 354 Batch 25 Loss 0.23495766520500183
[Train] epoch 354 Batch 26 Loss 0.13471351563930511
[Train] epoch 354 Batch 27 Loss 0.30227887630462646
[Train] epoch 354 Batch 28 Loss 0.3009692430496216
[Train] epoch 354 Batch 29 Loss 0.03367544338107109
[Train] epoch 354 Batch 30 Loss 0.26860755681991577
[Train] epoch 354 Batch 31 Loss 0.1346176415681839
[Train] epoch 354 Batch 32 Loss 0.03493192791938782
[Train] epoch 354 Batch 33 Loss 0.03427775204181671
[Train] epoch 354 Batch 34 Loss 0.3352530002593994
[Train] epoch 354 Batch 35 Loss 0.3022943437099457
[Train] epoch 354 Batch 36 Loss 0.10164288431406021
[Train] epoch 354 Batch 37 Loss 0.2691951096057892
[Train] epoch 354 Batch 38 Loss 0.10096915066242218
[Train] epoch 354 Batch 39 Loss 0.20063336193561554
[Train] epoch 354 Batch 40 Loss 0.2012704312801361
[Train] epoch 354 Batch 41 Loss 0.13523295521736145
[Train] epoch 354 Batch 42 Loss 0.16887444257736206
[Train] epoch 354 Batch 43 Loss 0.13524039089679718
[Train] epoch 354 Batch 44 Loss 0.13521802425384521
[Train] epoch 354 Batch 45 Loss 0.16826844215393066
[Train] epoch 354 Batch 46 Loss 0.40128132700920105
[Train] epoch 354 Batch 47 Loss 0.03550179302692413
[Train] epoch 355 Batch 0 Loss 0.1695220023393631
[Train] epoch 355 Batch 1 Loss 0.133334219455719
[Train] epoch 355 Batch 2 Loss 0.06789384037256241
[Train] epoch 355 Batch 3 Loss 0.06733281910419464
[Train] epoch 355 Batch 4 Loss 0.13514767587184906
[Train] epoch 355 Batch 5 Loss 0.23494502902030945
[Train] epoch 355 Batch 6 Loss 0.4361449182033539
[Train] epoch 355 Batch 7 Loss 0.26727792620658875
[Train] epoch 355 Batch 8 Loss 0.2348841428756714
[Train] epoch 355 Batch 9 Loss 0.13462874293327332
[Train] epoch 355 Batch 10 Loss 0.2019001543521881
[Train] epoch 355 Batch 11 Loss 0.23492352664470673
[Train] epoch 355 Batch 12 Loss 0.1357840746641159
[Train] epoch 355 Batch 13 Loss 0.133334219455719
[Train] epoch 355 Batch 14 Loss 0.20126420259475708
[Train] epoch 355 Batch 15 Loss 0.202426016330719
[Train] epoch 355 Batch 16 Loss 0.10151509940624237
[Train] epoch 355 Batch 17 Loss 0.16822944581508636
[Train] epoch 355 Batch 18 Loss 0.20063486695289612
[Train] epoch 355 Batch 19 Loss 0.16937726736068726
[Train] epoch 355 Batch 20 Loss 0.23426812887191772
[Train] epoch 355 Batch 21 Loss 0.133334219455719
[Train] epoch 355 Batch 22 Loss 0.16820715367794037
[Train] epoch 355 Batch 23 Loss 0.10148400813341141
[Train] epoch 355 Batch 24 Loss 0.10091762244701385
[Train] epoch 355 Batch 25 Loss 0.16753871738910675
[Train] epoch 355 Batch 26 Loss 0.20189641416072845
[Train] epoch 355 Batch 27 Loss 0.26795661449432373
[Train] epoch 355 Batch 28 Loss 0.1356460601091385
[Train] epoch 355 Batch 29 Loss 0.06724678725004196
[Train] epoch 355 Batch 30 Loss 0.13571903109550476
[Train] epoch 355 Batch 31 Loss 0.10095617175102234
[Train] epoch 355 Batch 32 Loss 0.23485241830348969
[Train] epoch 355 Batch 33 Loss 0.1357053816318512
[Train] epoch 355 Batch 34 Loss 0.13445723056793213
[Train] epoch 355 Batch 35 Loss 0.30095237493515015
[Train] epoch 355 Batch 36 Loss 0.13511303067207336
[Train] epoch 355 Batch 37 Loss 0.1014261394739151
[Train] epoch 355 Batch 38 Loss 0.26798900961875916
[Train] epoch 355 Batch 39 Loss 0.26973822712898254
[Train] epoch 355 Batch 40 Loss 0.10140541195869446
[Train] epoch 355 Batch 41 Loss 0.2347249984741211
[Train] epoch 355 Batch 42 Loss 0.23427996039390564
[Train] epoch 355 Batch 43 Loss 0.1669524610042572
[Train] epoch 355 Batch 44 Loss 0.13515736162662506
[Train] epoch 355 Batch 45 Loss 0.16815821826457977
[Train] epoch 355 Batch 46 Loss 0.13567206263542175
[Train] epoch 355 Batch 47 Loss 0.16820132732391357
[Train] epoch 356 Batch 0 Loss 0.2678701877593994
[Train] epoch 356 Batch 1 Loss 1.0728851975727594e-06
[Train] epoch 356 Batch 2 Loss 0.06732669472694397
[Train] epoch 356 Batch 3 Loss 0.30027085542678833
[Train] epoch 356 Batch 4 Loss 0.1681356132030487
[Train] epoch 356 Batch 5 Loss 0.16867364943027496
[Train] epoch 356 Batch 6 Loss 0.10080765932798386
[Train] epoch 356 Batch 7 Loss 0.13562238216400146
[Train] epoch 356 Batch 8 Loss 0.10152412205934525
[Train] epoch 356 Batch 9 Loss 0.3349664807319641
[Train] epoch 356 Batch 10 Loss 0.2005966603755951
[Train] epoch 356 Batch 11 Loss 0.26792967319488525
[Train] epoch 356 Batch 12 Loss 0.20174923539161682
[Train] epoch 356 Batch 13 Loss 0.13393741846084595
[Train] epoch 356 Batch 14 Loss 0.26899564266204834
[Train] epoch 356 Batch 15 Loss 0.33557629585266113
[Train] epoch 356 Batch 16 Loss 0.10151344537734985
[Train] epoch 356 Batch 17 Loss 0.16917526721954346
[Train] epoch 356 Batch 18 Loss 0.1344590187072754
[Train] epoch 356 Batch 19 Loss 0.03418630361557007
[Train] epoch 356 Batch 20 Loss 0.10199129581451416
[Train] epoch 356 Batch 21 Loss 0.1003289669752121
[Train] epoch 356 Batch 22 Loss 0.23478876054286957
[Train] epoch 356 Batch 23 Loss 0.10084835439920425
[Train] epoch 356 Batch 24 Loss 0.10137465596199036
[Train] epoch 356 Batch 25 Loss 0.2684442698955536
[Train] epoch 356 Batch 26 Loss 0.06876043975353241
[Train] epoch 356 Batch 27 Loss 0.1339893639087677
[Train] epoch 356 Batch 28 Loss 0.10196807235479355
[Train] epoch 356 Batch 29 Loss 0.20176175236701965
[Train] epoch 356 Batch 30 Loss 0.06718844175338745
[Train] epoch 356 Batch 31 Loss 0.16918309032917023
[Train] epoch 356 Batch 32 Loss 0.26717785000801086
[Train] epoch 356 Batch 33 Loss 0.26827603578567505
[Train] epoch 356 Batch 34 Loss 0.30214428901672363
[Train] epoch 356 Batch 35 Loss 0.10098185390233994
[Train] epoch 356 Batch 36 Loss 0.2348288893699646
[Train] epoch 356 Batch 37 Loss 0.13442692160606384
[Train] epoch 356 Batch 38 Loss 0.20167092978954315
[Train] epoch 356 Batch 39 Loss 0.1349279284477234
[Train] epoch 356 Batch 40 Loss 0.23366045951843262
[Train] epoch 356 Batch 41 Loss 0.1002516895532608
[Train] epoch 356 Batch 42 Loss 0.1013450175523758
[Train] epoch 356 Batch 43 Loss 0.1685178279876709
[Train] epoch 356 Batch 44 Loss 0.33493244647979736
[Train] epoch 356 Batch 45 Loss 0.36829715967178345
[Train] epoch 356 Batch 46 Loss 0.20303204655647278
[Train] epoch 356 Batch 47 Loss 0.06724943965673447
[Train] epoch 357 Batch 0 Loss 0.2678923010826111
[Train] epoch 357 Batch 1 Loss 0.1008283793926239
[Train] epoch 357 Batch 2 Loss 0.2010737806558609
[Train] epoch 357 Batch 3 Loss 0.26889002323150635
[Train] epoch 357 Batch 4 Loss 0.13554660975933075
[Train] epoch 357 Batch 5 Loss 1.0728851975727594e-06
[Train] epoch 357 Batch 6 Loss 0.23523053526878357
[Train] epoch 357 Batch 7 Loss 0.1674809753894806
[Train] epoch 357 Batch 8 Loss 0.06871407479047775
[Train] epoch 357 Batch 9 Loss 0.20170599222183228
[Train] epoch 357 Batch 10 Loss 0.06821359694004059
[Train] epoch 357 Batch 11 Loss 0.20106005668640137
[Train] epoch 357 Batch 12 Loss 0.23479938507080078
[Train] epoch 357 Batch 13 Loss 0.1680479645729065
[Train] epoch 357 Batch 14 Loss 0.20291200280189514
[Train] epoch 357 Batch 15 Loss 0.2004818618297577
[Train] epoch 357 Batch 16 Loss 0.133334219455719
[Train] epoch 357 Batch 17 Loss 0.3349549472332001
[Train] epoch 357 Batch 18 Loss 0.33493858575820923
[Train] epoch 357 Batch 19 Loss 0.10128721594810486
[Train] epoch 357 Batch 20 Loss 0.2677137851715088
[Train] epoch 357 Batch 21 Loss 0.13485458493232727
[Train] epoch 357 Batch 22 Loss 0.16699132323265076
[Train] epoch 357 Batch 23 Loss 0.26666736602783203
[Train] epoch 357 Batch 24 Loss 0.13454177975654602
[Train] epoch 357 Batch 25 Loss 0.1675509363412857
[Train] epoch 357 Batch 26 Loss 0.20095214247703552
[Train] epoch 357 Batch 27 Loss 0.10079555213451385
[Train] epoch 357 Batch 28 Loss 0.13541412353515625
[Train] epoch 357 Batch 29 Loss 0.03357639163732529
[Train] epoch 357 Batch 30 Loss 0.40177667140960693
[Train] epoch 357 Batch 31 Loss 0.23460176587104797
[Train] epoch 357 Batch 32 Loss 0.33493688702583313
[Train] epoch 357 Batch 33 Loss 0.20149873197078705
[Train] epoch 357 Batch 34 Loss 0.16858316957950592
[Train] epoch 357 Batch 35 Loss 0.10117236524820328
[Train] epoch 357 Batch 36 Loss 0.1345861256122589
[Train] epoch 357 Batch 37 Loss 0.16796228289604187
[Train] epoch 357 Batch 38 Loss 0.10032081604003906
[Train] epoch 357 Batch 39 Loss 0.20159251987934113
[Train] epoch 357 Batch 40 Loss 0.1691983938217163
[Train] epoch 357 Batch 41 Loss 0.10188420116901398
[Train] epoch 357 Batch 42 Loss 0.13509780168533325
[Train] epoch 357 Batch 43 Loss 0.10091343522071838
[Train] epoch 357 Batch 44 Loss 0.20234933495521545
[Train] epoch 357 Batch 45 Loss 0.16818037629127502
[Train] epoch 357 Batch 46 Loss 0.10145270079374313
[Train] epoch 357 Batch 47 Loss 0.10086296498775482
[Train] epoch 358 Batch 0 Loss 0.2354273498058319
[Train] epoch 358 Batch 1 Loss 0.23364605009555817
[Train] epoch 358 Batch 2 Loss 0.33575934171676636
[Train] epoch 358 Batch 3 Loss 0.20061743259429932
[Train] epoch 358 Batch 4 Loss 0.16940726339817047
[Train] epoch 358 Batch 5 Loss 0.16880697011947632
[Train] epoch 358 Batch 6 Loss 0.06787698715925217
[Train] epoch 358 Batch 7 Loss 0.20184233784675598
[Train] epoch 358 Batch 8 Loss 0.101524218916893
[Train] epoch 358 Batch 9 Loss 0.23426339030265808
[Train] epoch 358 Batch 10 Loss 0.10091426223516464
[Train] epoch 358 Batch 11 Loss 0.16820016503334045
[Train] epoch 358 Batch 12 Loss 0.2678975760936737
[Train] epoch 358 Batch 13 Loss 0.10091596841812134
[Train] epoch 358 Batch 14 Loss 0.06851041316986084
[Train] epoch 358 Batch 15 Loss 0.3345722556114197
[Train] epoch 358 Batch 16 Loss 0.20245081186294556
[Train] epoch 358 Batch 17 Loss 0.2360924929380417
[Train] epoch 358 Batch 18 Loss 0.1694231480360031
[Train] epoch 358 Batch 19 Loss 0.168196439743042
[Train] epoch 358 Batch 20 Loss 0.13516537845134735
[Train] epoch 358 Batch 21 Loss 0.16820767521858215
[Train] epoch 358 Batch 22 Loss 0.16820110380649567
[Train] epoch 358 Batch 23 Loss 0.2000008225440979
[Train] epoch 358 Batch 24 Loss 0.23546448349952698
[Train] epoch 358 Batch 25 Loss 0.23663926124572754
[Train] epoch 358 Batch 26 Loss 0.13455452024936676
[Train] epoch 358 Batch 27 Loss 0.1681922972202301
[Train] epoch 358 Batch 28 Loss 0.2354305535554886
[Train] epoch 358 Batch 29 Loss 0.1669723093509674
[Train] epoch 358 Batch 30 Loss 0.16756175458431244
[Train] epoch 358 Batch 31 Loss 0.10030388832092285
[Train] epoch 358 Batch 32 Loss 0.16697467863559723
[Train] epoch 358 Batch 33 Loss 0.034809406846761703
[Train] epoch 358 Batch 34 Loss 0.06784616410732269
[Train] epoch 358 Batch 35 Loss 0.2354479283094406
[Train] epoch 358 Batch 36 Loss 0.16756510734558105
[Train] epoch 358 Batch 37 Loss 0.1687500774860382
[Train] epoch 358 Batch 38 Loss 0.3015095591545105
[Train] epoch 358 Batch 39 Loss 0.20176933705806732
[Train] epoch 358 Batch 40 Loss 0.1339482069015503
[Train] epoch 358 Batch 41 Loss 0.16810563206672668
[Train] epoch 358 Batch 42 Loss 0.2678549587726593
[Train] epoch 358 Batch 43 Loss 0.20118701457977295
[Train] epoch 358 Batch 44 Loss 0.033641230314970016
[Train] epoch 358 Batch 45 Loss 0.03534488007426262
[Train] epoch 358 Batch 46 Loss 0.13394783437252045
[Train] epoch 358 Batch 47 Loss 0.16811639070510864
[Train] epoch 359 Batch 0 Loss 0.20059821009635925
[Train] epoch 359 Batch 1 Loss 0.1680876612663269
[Train] epoch 359 Batch 2 Loss 0.16870522499084473
[Train] epoch 359 Batch 3 Loss 0.13449892401695251
[Train] epoch 359 Batch 4 Loss 0.10089461505413055
[Train] epoch 359 Batch 5 Loss 0.13392803072929382
[Train] epoch 359 Batch 6 Loss 0.20117983222007751
[Train] epoch 359 Batch 7 Loss 0.26894670724868774
[Train] epoch 359 Batch 8 Loss 0.2017829716205597
[Train] epoch 359 Batch 9 Loss 0.16861611604690552
[Train] epoch 359 Batch 10 Loss 0.1680884063243866
[Train] epoch 359 Batch 11 Loss 0.1345060020685196
[Train] epoch 359 Batch 12 Loss 0.10144650936126709
[Train] epoch 359 Batch 13 Loss 0.3350910246372223
[Train] epoch 359 Batch 14 Loss 0.20231056213378906
[Train] epoch 359 Batch 15 Loss 0.13455942273139954
[Train] epoch 359 Batch 16 Loss 0.2678922414779663
[Train] epoch 359 Batch 17 Loss 0.23476949334144592
[Train] epoch 359 Batch 18 Loss 0.13453055918216705
[Train] epoch 359 Batch 19 Loss 0.06833547353744507
[Train] epoch 359 Batch 20 Loss 0.23479902744293213
[Train] epoch 359 Batch 21 Loss 0.3339095711708069
[Train] epoch 359 Batch 22 Loss 0.10136798769235611
[Train] epoch 359 Batch 23 Loss 0.13387854397296906
[Train] epoch 359 Batch 24 Loss 0.1680658906698227
[Train] epoch 359 Batch 25 Loss 0.06888583302497864
[Train] epoch 359 Batch 26 Loss 0.10138839483261108
[Train] epoch 359 Batch 27 Loss 0.2357916533946991
[Train] epoch 359 Batch 28 Loss 0.20221346616744995
[Train] epoch 359 Batch 29 Loss 0.10084268450737
[Train] epoch 359 Batch 30 Loss 0.23424968123435974
[Train] epoch 359 Batch 31 Loss 0.20105671882629395
[Train] epoch 359 Batch 32 Loss 0.23466262221336365
[Train] epoch 359 Batch 33 Loss 0.1371443122625351
[Train] epoch 359 Batch 34 Loss 0.10079222917556763
[Train] epoch 359 Batch 35 Loss 0.13390035927295685
[Train] epoch 359 Batch 36 Loss 0.30148693919181824
[Train] epoch 359 Batch 37 Loss 0.16749781370162964
[Train] epoch 359 Batch 38 Loss 0.10139958560466766
[Train] epoch 359 Batch 39 Loss 0.06718447804450989
[Train] epoch 359 Batch 40 Loss 0.13441257178783417
[Train] epoch 359 Batch 41 Loss 0.10082647949457169
[Train] epoch 359 Batch 42 Loss 0.10081952065229416
[Train] epoch 359 Batch 43 Loss 0.2005617916584015
[Train] epoch 359 Batch 44 Loss 0.06881155073642731
[Train] epoch 359 Batch 45 Loss 0.23410558700561523
[Train] epoch 359 Batch 46 Loss 0.33558303117752075
[Train] epoch 359 Batch 47 Loss 0.300914466381073
[Train] epoch 360 Batch 0 Loss 0.13445085287094116
[Train] epoch 360 Batch 1 Loss 0.26717379689216614
[Train] epoch 360 Batch 2 Loss 0.30193042755126953
[Train] epoch 360 Batch 3 Loss 0.16799263656139374
[Train] epoch 360 Batch 4 Loss 0.23577508330345154
[Train] epoch 360 Batch 5 Loss 0.16904059052467346
[Train] epoch 360 Batch 6 Loss 0.23520725965499878
[Train] epoch 360 Batch 7 Loss 0.1339423954486847
[Train] epoch 360 Batch 8 Loss 0.20060878992080688
[Train] epoch 360 Batch 9 Loss 0.13444049656391144
[Train] epoch 360 Batch 10 Loss 0.10180196166038513
[Train] epoch 360 Batch 11 Loss 0.3339415192604065
[Train] epoch 360 Batch 12 Loss 0.1679731011390686
[Train] epoch 360 Batch 13 Loss 0.16752760112285614
[Train] epoch 360 Batch 14 Loss 0.23424473404884338
[Train] epoch 360 Batch 15 Loss 0.1674635261297226
[Train] epoch 360 Batch 16 Loss 0.16797101497650146
[Train] epoch 360 Batch 17 Loss 0.20115616917610168
[Train] epoch 360 Batch 18 Loss 0.20110294222831726
[Train] epoch 360 Batch 19 Loss 0.06770536303520203
[Train] epoch 360 Batch 20 Loss 0.20055368542671204
[Train] epoch 360 Batch 21 Loss 0.30226171016693115
[Train] epoch 360 Batch 22 Loss 0.03505135327577591
[Train] epoch 360 Batch 23 Loss 0.16850033402442932
[Train] epoch 360 Batch 24 Loss 0.13486137986183167
[Train] epoch 360 Batch 25 Loss 0.06770235300064087
[Train] epoch 360 Batch 26 Loss 0.13540515303611755
[Train] epoch 360 Batch 27 Loss 0.13490892946720123
[Train] epoch 360 Batch 28 Loss 0.26775866746902466
[Train] epoch 360 Batch 29 Loss 0.16690747439861298
[Train] epoch 360 Batch 30 Loss 0.23466292023658752
[Train] epoch 360 Batch 31 Loss 0.20096737146377563
[Train] epoch 360 Batch 32 Loss 0.16690601408481598
[Train] epoch 360 Batch 33 Loss 0.10138413310050964
[Train] epoch 360 Batch 34 Loss 0.1343546211719513
[Train] epoch 360 Batch 35 Loss 0.2022889405488968
[Train] epoch 360 Batch 36 Loss 0.0676145851612091
[Train] epoch 360 Batch 37 Loss 0.13441623747348785
[Train] epoch 360 Batch 38 Loss 0.2672054171562195
[Train] epoch 360 Batch 39 Loss 0.23513129353523254
[Train] epoch 360 Batch 40 Loss 0.06774681061506271
[Train] epoch 360 Batch 41 Loss 0.23411047458648682
[Train] epoch 360 Batch 42 Loss 0.20114564895629883
[Train] epoch 360 Batch 43 Loss 0.16852381825447083
[Train] epoch 360 Batch 44 Loss 0.26948732137680054
[Train] epoch 360 Batch 45 Loss 0.10077380388975143
[Train] epoch 360 Batch 46 Loss 0.10076826810836792
[Train] epoch 360 Batch 47 Loss 0.06820464879274368
[Train] epoch 361 Batch 0 Loss 0.16696888208389282
[Train] epoch 361 Batch 1 Loss 0.23510360717773438
[Train] epoch 361 Batch 2 Loss 0.2015416920185089
[Train] epoch 361 Batch 3 Loss 0.2682628631591797
[Train] epoch 361 Batch 4 Loss 0.1011565774679184
[Train] epoch 361 Batch 5 Loss 0.20205295085906982
[Train] epoch 361 Batch 6 Loss 0.16749870777130127
[Train] epoch 361 Batch 7 Loss 0.2009975016117096
[Train] epoch 361 Batch 8 Loss 0.10129263252019882
[Train] epoch 361 Batch 9 Loss 0.13485252857208252
[Train] epoch 361 Batch 10 Loss 0.2009163200855255
[Train] epoch 361 Batch 11 Loss 0.2676539421081543
[Train] epoch 361 Batch 12 Loss 0.03363488242030144
[Train] epoch 361 Batch 13 Loss 0.1343185007572174
[Train] epoch 361 Batch 14 Loss 0.13379530608654022
[Train] epoch 361 Batch 15 Loss 0.06764955818653107
[Train] epoch 361 Batch 16 Loss 0.16749787330627441
[Train] epoch 361 Batch 17 Loss 0.23415958881378174
[Train] epoch 361 Batch 18 Loss 0.1342378407716751
[Train] epoch 361 Batch 19 Loss 0.23408286273479462
[Train] epoch 361 Batch 20 Loss 0.13475856184959412
[Train] epoch 361 Batch 21 Loss 0.16787534952163696
[Train] epoch 361 Batch 22 Loss 0.20203036069869995
[Train] epoch 361 Batch 23 Loss 0.16749033331871033
[Train] epoch 361 Batch 24 Loss 0.16875679790973663
[Train] epoch 361 Batch 25 Loss 0.13437846302986145
[Train] epoch 361 Batch 26 Loss 0.1015622541308403
[Train] epoch 361 Batch 27 Loss 0.16785283386707306
[Train] epoch 361 Batch 28 Loss 0.2683079242706299
[Train] epoch 361 Batch 29 Loss 0.034445200115442276
[Train] epoch 361 Batch 30 Loss 0.2677108347415924
[Train] epoch 361 Batch 31 Loss 0.10065978765487671
[Train] epoch 361 Batch 32 Loss 0.13393324613571167
[Train] epoch 361 Batch 33 Loss 0.36889106035232544
[Train] epoch 361 Batch 34 Loss 0.2672661542892456
[Train] epoch 361 Batch 35 Loss 0.10117314755916595
[Train] epoch 361 Batch 36 Loss 0.2681412100791931
[Train] epoch 361 Batch 37 Loss 0.13488805294036865
[Train] epoch 361 Batch 38 Loss 0.2345874309539795
[Train] epoch 361 Batch 39 Loss 0.20139165222644806
[Train] epoch 361 Batch 40 Loss 0.13480548560619354
[Train] epoch 361 Batch 41 Loss 0.10081861913204193
[Train] epoch 361 Batch 42 Loss 0.16928914189338684
[Train] epoch 361 Batch 43 Loss 0.10145600140094757
[Train] epoch 361 Batch 44 Loss 0.33438223600387573
[Train] epoch 361 Batch 45 Loss 0.13438528776168823
[Train] epoch 361 Batch 46 Loss 0.16808880865573883
[Train] epoch 361 Batch 47 Loss 0.20107650756835938
[Train] epoch 362 Batch 0 Loss 0.0676591545343399
[Train] epoch 362 Batch 1 Loss 0.3680487275123596
[Train] epoch 362 Batch 2 Loss 0.13388735055923462
[Train] epoch 362 Batch 3 Loss 0.2352231740951538
[Train] epoch 362 Batch 4 Loss 0.13498224318027496
[Train] epoch 362 Batch 5 Loss 0.13445496559143066
[Train] epoch 362 Batch 6 Loss 0.23415514826774597
[Train] epoch 362 Batch 7 Loss 0.06833876669406891
[Train] epoch 362 Batch 8 Loss 0.23472484946250916
[Train] epoch 362 Batch 9 Loss 0.2683718204498291
[Train] epoch 362 Batch 10 Loss 0.16751447319984436
[Train] epoch 362 Batch 11 Loss 0.03475112095475197
[Train] epoch 362 Batch 12 Loss 0.10085360705852509
[Train] epoch 362 Batch 13 Loss 0.16865965723991394
[Train] epoch 362 Batch 14 Loss 0.13448575139045715
[Train] epoch 362 Batch 15 Loss 0.36753007769584656
[Train] epoch 362 Batch 16 Loss 0.20172423124313354
[Train] epoch 362 Batch 17 Loss 0.16695941984653473
[Train] epoch 362 Batch 18 Loss 0.20172345638275146
[Train] epoch 362 Batch 19 Loss 0.3014538288116455
[Train] epoch 362 Batch 20 Loss 0.169266015291214
[Train] epoch 362 Batch 21 Loss 0.16752839088439941
[Train] epoch 362 Batch 22 Loss 0.0005819142097607255
[Train] epoch 362 Batch 23 Loss 0.10201097279787064
[Train] epoch 362 Batch 24 Loss 0.235943004488945
[Train] epoch 362 Batch 25 Loss 0.0011613712413236499
[Train] epoch 362 Batch 26 Loss 0.36926987767219543
[Train] epoch 362 Batch 27 Loss 0.13391797244548798
[Train] epoch 362 Batch 28 Loss 0.3361993730068207
[Train] epoch 362 Batch 29 Loss 0.3681012690067291
[Train] epoch 362 Batch 30 Loss 0.10200119018554688
[Train] epoch 362 Batch 31 Loss 0.268377423286438
[Train] epoch 362 Batch 32 Loss 0.1675235480070114
[Train] epoch 362 Batch 33 Loss 0.13389995694160461
[Train] epoch 362 Batch 34 Loss 0.1344771534204483
[Train] epoch 362 Batch 35 Loss 0.0672401487827301
[Train] epoch 362 Batch 36 Loss 0.06723442673683167
[Train] epoch 362 Batch 37 Loss 0.23475705087184906
[Train] epoch 362 Batch 38 Loss 0.16695302724838257
[Train] epoch 362 Batch 39 Loss 0.1339035928249359
[Train] epoch 362 Batch 40 Loss 0.2028329223394394
[Train] epoch 362 Batch 41 Loss 0.267794132232666
[Train] epoch 362 Batch 42 Loss 0.16750699281692505
[Train] epoch 362 Batch 43 Loss 0.13557548820972443
[Train] epoch 362 Batch 44 Loss 0.10195319354534149
[Train] epoch 362 Batch 45 Loss 0.2347380518913269
[Train] epoch 362 Batch 46 Loss 0.10140742361545563
[Train] epoch 362 Batch 47 Loss 0.06777782738208771
[Train] epoch 363 Batch 0 Loss 0.20057085156440735
[Train] epoch 363 Batch 1 Loss 0.13499712944030762
[Train] epoch 363 Batch 2 Loss 0.20110520720481873
[Train] epoch 363 Batch 3 Loss 0.13444887101650238
[Train] epoch 363 Batch 4 Loss 0.10138635337352753
[Train] epoch 363 Batch 5 Loss 0.23528257012367249
[Train] epoch 363 Batch 6 Loss 0.03470559045672417
[Train] epoch 363 Batch 7 Loss 0.1344372034072876
[Train] epoch 363 Batch 8 Loss 0.13549725711345673
[Train] epoch 363 Batch 9 Loss 0.23417207598686218
[Train] epoch 363 Batch 10 Loss 0.0346984937787056
[Train] epoch 363 Batch 11 Loss 0.26831376552581787
[Train] epoch 363 Batch 12 Loss 0.13497307896614075
[Train] epoch 363 Batch 13 Loss 0.20214885473251343
[Train] epoch 363 Batch 14 Loss 0.13549290597438812
[Train] epoch 363 Batch 15 Loss 0.2672159671783447
[Train] epoch 363 Batch 16 Loss 0.4672151207923889
[Train] epoch 363 Batch 17 Loss 0.10081474483013153
[Train] epoch 363 Batch 18 Loss 0.1674799621105194
[Train] epoch 363 Batch 19 Loss 0.16800524294376373
[Train] epoch 363 Batch 20 Loss 0.23416776955127716
[Train] epoch 363 Batch 21 Loss 0.20218655467033386
[Train] epoch 363 Batch 22 Loss 0.26775896549224854
[Train] epoch 363 Batch 23 Loss 0.201604962348938
[Train] epoch 363 Batch 24 Loss 0.16747628152370453
[Train] epoch 363 Batch 25 Loss 0.06719107925891876
[Train] epoch 363 Batch 26 Loss 0.13441681861877441
[Train] epoch 363 Batch 27 Loss 0.2352130115032196
[Train] epoch 363 Batch 28 Loss 0.20108109712600708
[Train] epoch 363 Batch 29 Loss 0.20113706588745117
[Train] epoch 363 Batch 30 Loss 0.26825955510139465
[Train] epoch 363 Batch 31 Loss 0.16903287172317505
[Train] epoch 363 Batch 32 Loss 0.16743353009223938
[Train] epoch 363 Batch 33 Loss 0.20050789415836334
[Train] epoch 363 Batch 34 Loss 0.20212441682815552
[Train] epoch 363 Batch 35 Loss 0.23466268181800842
[Train] epoch 363 Batch 36 Loss 0.10183857381343842
[Train] epoch 363 Batch 37 Loss 0.20265337824821472
[Train] epoch 363 Batch 38 Loss 0.20050200819969177
[Train] epoch 363 Batch 39 Loss 0.1002509742975235
[Train] epoch 363 Batch 40 Loss 0.23415401577949524
[Train] epoch 363 Batch 41 Loss 0.13542932271957397
[Train] epoch 363 Batch 42 Loss 0.10081955790519714
[Train] epoch 363 Batch 43 Loss 0.16748547554016113
[Train] epoch 363 Batch 44 Loss 0.06719833612442017
[Train] epoch 363 Batch 45 Loss 0.10127569735050201
[Train] epoch 363 Batch 46 Loss 0.1353544294834137
[Train] epoch 363 Batch 47 Loss 0.16793811321258545
[Train] epoch 364 Batch 0 Loss 0.16793614625930786
[Train] epoch 364 Batch 1 Loss 0.23410698771476746
[Train] epoch 364 Batch 2 Loss 0.16793158650398254
[Train] epoch 364 Batch 3 Loss 0.23467054963111877
[Train] epoch 364 Batch 4 Loss 0.3013033866882324
[Train] epoch 364 Batch 5 Loss 0.302839070558548
[Train] epoch 364 Batch 6 Loss 0.3008086085319519
[Train] epoch 364 Batch 7 Loss 0.16804322600364685
[Train] epoch 364 Batch 8 Loss 0.06820465624332428
[Train] epoch 364 Batch 9 Loss 0.10173864662647247
[Train] epoch 364 Batch 10 Loss 0.3343859910964966
[Train] epoch 364 Batch 11 Loss 0.23361647129058838
[Train] epoch 364 Batch 12 Loss 0.03549852594733238
[Train] epoch 364 Batch 13 Loss 0.06867188215255737
[Train] epoch 364 Batch 14 Loss 0.1343751698732376
[Train] epoch 364 Batch 15 Loss 0.10080598294734955
[Train] epoch 364 Batch 16 Loss 0.1344178467988968
[Train] epoch 364 Batch 17 Loss 0.23513025045394897
[Train] epoch 364 Batch 18 Loss 0.13389810919761658
[Train] epoch 364 Batch 19 Loss 0.1017041951417923
[Train] epoch 364 Batch 20 Loss 0.03503461182117462
[Train] epoch 364 Batch 21 Loss 0.0004708130145445466
[Train] epoch 364 Batch 22 Loss 0.20047250390052795
[Train] epoch 364 Batch 23 Loss 0.167884960770607
[Train] epoch 364 Batch 24 Loss 0.33488208055496216
[Train] epoch 364 Batch 25 Loss 0.10074876993894577
[Train] epoch 364 Batch 26 Loss 0.23403185606002808
[Train] epoch 364 Batch 27 Loss 0.10131238400936127
[Train] epoch 364 Batch 28 Loss 0.10023544728755951
[Train] epoch 364 Batch 29 Loss 0.0676485002040863
[Train] epoch 364 Batch 30 Loss 0.2345421016216278
[Train] epoch 364 Batch 31 Loss 0.26722997426986694
[Train] epoch 364 Batch 32 Loss 0.23546470701694489
[Train] epoch 364 Batch 33 Loss 0.20199859142303467
[Train] epoch 364 Batch 34 Loss 0.03356356918811798
[Train] epoch 364 Batch 35 Loss 0.30191633105278015
[Train] epoch 364 Batch 36 Loss 0.30180996656417847
[Train] epoch 364 Batch 37 Loss 0.23402360081672668
[Train] epoch 364 Batch 38 Loss 0.20158249139785767
[Train] epoch 364 Batch 39 Loss 0.13475415110588074
[Train] epoch 364 Batch 40 Loss 0.13384446501731873
[Train] epoch 364 Batch 41 Loss 0.10119007527828217
[Train] epoch 364 Batch 42 Loss 0.16780048608779907
[Train] epoch 364 Batch 43 Loss 0.06712169945240021
[Train] epoch 364 Batch 44 Loss 0.16689550876617432
[Train] epoch 364 Batch 45 Loss 0.13480031490325928
[Train] epoch 364 Batch 46 Loss 0.2355223149061203
[Train] epoch 364 Batch 47 Loss 0.3011261820793152
[Train] epoch 365 Batch 0 Loss 0.13434210419654846
[Train] epoch 365 Batch 1 Loss 0.23501580953598022
[Train] epoch 365 Batch 2 Loss 0.06761890649795532
[Train] epoch 365 Batch 3 Loss 0.3002808690071106
[Train] epoch 365 Batch 4 Loss 0.06761620193719864
[Train] epoch 365 Batch 5 Loss 0.10028103739023209
[Train] epoch 365 Batch 6 Loss 0.0671125203371048
[Train] epoch 365 Batch 7 Loss 0.20094841718673706
[Train] epoch 365 Batch 8 Loss 0.03355732932686806
[Train] epoch 365 Batch 9 Loss 0.30178359150886536
[Train] epoch 365 Batch 10 Loss 0.10172276198863983
[Train] epoch 365 Batch 11 Loss 0.1675070971250534
[Train] epoch 365 Batch 12 Loss 0.167947918176651
[Train] epoch 365 Batch 13 Loss 0.13433149456977844
[Train] epoch 365 Batch 14 Loss 0.1015973910689354
[Train] epoch 365 Batch 15 Loss 0.30028021335601807
[Train] epoch 365 Batch 16 Loss 0.13427037000656128
[Train] epoch 365 Batch 17 Loss 0.20093345642089844
[Train] epoch 365 Batch 18 Loss 0.10196556150913239
[Train] epoch 365 Batch 19 Loss 0.2675405740737915
[Train] epoch 365 Batch 20 Loss 0.1673174500465393
[Train] epoch 365 Batch 21 Loss 0.36744439601898193
[Train] epoch 365 Batch 22 Loss 0.2004983127117157
[Train] epoch 365 Batch 23 Loss 0.16836965084075928
[Train] epoch 365 Batch 24 Loss 0.1683683693408966
[Train] epoch 365 Batch 25 Loss 0.20142114162445068
[Train] epoch 365 Batch 26 Loss 0.2690083384513855
[Train] epoch 365 Batch 27 Loss 0.10107649862766266
[Train] epoch 365 Batch 28 Loss 0.20092308521270752
[Train] epoch 365 Batch 29 Loss 0.1006409302353859
[Train] epoch 365 Batch 30 Loss 0.26814693212509155
[Train] epoch 365 Batch 31 Loss 0.16786465048789978
[Train] epoch 365 Batch 32 Loss 0.16743700206279755
[Train] epoch 365 Batch 33 Loss 0.16743652522563934
[Train] epoch 365 Batch 34 Loss 0.20140337944030762
[Train] epoch 365 Batch 35 Loss 0.16821691393852234
[Train] epoch 365 Batch 36 Loss 0.23550797998905182
[Train] epoch 365 Batch 37 Loss 0.16736868023872375
[Train] epoch 365 Batch 38 Loss 0.13431303203105927
[Train] epoch 365 Batch 39 Loss 0.10063205659389496
[Train] epoch 365 Batch 40 Loss 0.2336122691631317
[Train] epoch 365 Batch 41 Loss 0.0680638775229454
[Train] epoch 365 Batch 42 Loss 0.10146552324295044
[Train] epoch 365 Batch 43 Loss 0.1678524613380432
[Train] epoch 365 Batch 44 Loss 0.16736111044883728
[Train] epoch 365 Batch 45 Loss 0.2350001037120819
[Train] epoch 365 Batch 46 Loss 0.2689597010612488
[Train] epoch 365 Batch 47 Loss 0.20235255360603333
[Train] epoch 366 Batch 0 Loss 0.23458199203014374
[Train] epoch 366 Batch 1 Loss 0.1677691787481308
[Train] epoch 366 Batch 2 Loss 0.16818487644195557
[Train] epoch 366 Batch 3 Loss 0.0340244323015213
[Train] epoch 366 Batch 4 Loss 0.23450320959091187
[Train] epoch 366 Batch 5 Loss 0.20130211114883423
[Train] epoch 366 Batch 6 Loss 0.1673569679260254
[Train] epoch 366 Batch 7 Loss 0.034020863473415375
[Train] epoch 366 Batch 8 Loss 0.1681685596704483
[Train] epoch 366 Batch 9 Loss 0.3006855845451355
[Train] epoch 366 Batch 10 Loss 0.30068278312683105
[Train] epoch 366 Batch 11 Loss 0.16734886169433594
[Train] epoch 366 Batch 12 Loss 0.2336110770702362
[Train] epoch 366 Batch 13 Loss 0.03394116088747978
[Train] epoch 366 Batch 14 Loss 0.16820810735225677
[Train] epoch 366 Batch 15 Loss 0.23811590671539307
[Train] epoch 366 Batch 16 Loss 0.0685078576207161
[Train] epoch 366 Batch 17 Loss 0.3011590242385864
[Train] epoch 366 Batch 18 Loss 0.20095497369766235
[Train] epoch 366 Batch 19 Loss 0.1013035923242569
[Train] epoch 366 Batch 20 Loss 0.36792948842048645
[Train] epoch 366 Batch 21 Loss 0.03408726304769516
[Train] epoch 366 Batch 22 Loss 0.13490653038024902
[Train] epoch 366 Batch 23 Loss 0.26777249574661255
[Train] epoch 366 Batch 24 Loss 0.1013503223657608
[Train] epoch 366 Batch 25 Loss 0.13386750221252441
[Train] epoch 366 Batch 26 Loss 0.16946099698543549
[Train] epoch 366 Batch 27 Loss 0.1674545407295227
[Train] epoch 366 Batch 28 Loss 0.16695928573608398
[Train] epoch 366 Batch 29 Loss 0.10174993425607681
[Train] epoch 366 Batch 30 Loss 0.16846787929534912
[Train] epoch 366 Batch 31 Loss 0.20167653262615204
[Train] epoch 366 Batch 32 Loss 0.16805468499660492
[Train] epoch 366 Batch 33 Loss 0.10231571644544601
[Train] epoch 366 Batch 34 Loss 0.33544474840164185
[Train] epoch 366 Batch 35 Loss 0.20211343467235565
[Train] epoch 366 Batch 36 Loss 0.10088567435741425
[Train] epoch 366 Batch 37 Loss 0.36755263805389404
[Train] epoch 366 Batch 38 Loss 0.20118200778961182
[Train] epoch 366 Batch 39 Loss 0.0340973362326622
[Train] epoch 366 Batch 40 Loss 0.16747018694877625
[Train] epoch 366 Batch 41 Loss 0.16844768822193146
[Train] epoch 366 Batch 42 Loss 0.034097157418727875
[Train] epoch 366 Batch 43 Loss 0.10084600746631622
[Train] epoch 366 Batch 44 Loss 0.10182483494281769
[Train] epoch 366 Batch 45 Loss 0.23464636504650116
[Train] epoch 366 Batch 46 Loss 0.30135512351989746
[Train] epoch 366 Batch 47 Loss 0.2021160125732422
[Train] epoch 367 Batch 0 Loss 0.43514585494995117
[Train] epoch 367 Batch 1 Loss 0.13451898097991943
[Train] epoch 367 Batch 2 Loss 0.20205914974212646
[Train] epoch 367 Batch 3 Loss 0.06767021864652634
[Train] epoch 367 Batch 4 Loss 0.10025104880332947
[Train] epoch 367 Batch 5 Loss 0.3023452162742615
[Train] epoch 367 Batch 6 Loss 0.0004995138151571155
[Train] epoch 367 Batch 7 Loss 0.33447161316871643
[Train] epoch 367 Batch 8 Loss 0.06775684654712677
[Train] epoch 367 Batch 9 Loss 0.000993763213045895
[Train] epoch 367 Batch 10 Loss 0.10079183429479599
[Train] epoch 367 Batch 11 Loss 0.16691628098487854
[Train] epoch 367 Batch 12 Loss 0.23526033759117126
[Train] epoch 367 Batch 13 Loss 0.10133130848407745
[Train] epoch 367 Batch 14 Loss 0.2010374367237091
[Train] epoch 367 Batch 15 Loss 0.2011365294456482
[Train] epoch 367 Batch 16 Loss 0.13382375240325928
[Train] epoch 367 Batch 17 Loss 0.10078583657741547
[Train] epoch 367 Batch 18 Loss 0.20054090023040771
[Train] epoch 367 Batch 19 Loss 0.0004881100030615926
[Train] epoch 367 Batch 20 Loss 0.3012755513191223
[Train] epoch 367 Batch 21 Loss 0.03363032639026642
[Train] epoch 367 Batch 22 Loss 0.16745242476463318
[Train] epoch 367 Batch 23 Loss 0.26833707094192505
[Train] epoch 367 Batch 24 Loss 0.2683364152908325
[Train] epoch 367 Batch 25 Loss 0.10072925686836243
[Train] epoch 367 Batch 26 Loss 0.13639573752880096
[Train] epoch 367 Batch 27 Loss 0.16846610605716705
[Train] epoch 367 Batch 28 Loss 0.20053842663764954
[Train] epoch 367 Batch 29 Loss 0.2686992883682251
[Train] epoch 367 Batch 30 Loss 0.13440382480621338
[Train] epoch 367 Batch 31 Loss 0.13547152280807495
[Train] epoch 367 Batch 32 Loss 0.06773502379655838
[Train] epoch 367 Batch 33 Loss 0.23362919688224792
[Train] epoch 367 Batch 34 Loss 0.20154514908790588
[Train] epoch 367 Batch 35 Loss 0.335410475730896
[Train] epoch 367 Batch 36 Loss 0.06820686161518097
[Train] epoch 367 Batch 37 Loss 0.16986621916294098
[Train] epoch 367 Batch 38 Loss 0.13434159755706787
[Train] epoch 367 Batch 39 Loss 0.10123687982559204
[Train] epoch 367 Batch 40 Loss 0.26713865995407104
[Train] epoch 367 Batch 41 Loss 0.2676662504673004
[Train] epoch 367 Batch 42 Loss 0.36743229627609253
[Train] epoch 367 Batch 43 Loss 0.10122860968112946
[Train] epoch 367 Batch 44 Loss 0.20146240293979645
[Train] epoch 367 Batch 45 Loss 0.16795308887958527
[Train] epoch 367 Batch 46 Loss 0.1686037927865982
[Train] epoch 367 Batch 47 Loss 0.23508161306381226
[Train] epoch 368 Batch 0 Loss 0.40197813510894775
[Train] epoch 368 Batch 1 Loss 0.10029493272304535
[Train] epoch 368 Batch 2 Loss 0.20052455365657806
[Train] epoch 368 Batch 3 Loss 0.10127685964107513
[Train] epoch 368 Batch 4 Loss 0.13431507349014282
[Train] epoch 368 Batch 5 Loss 0.20052441954612732
[Train] epoch 368 Batch 6 Loss 0.26927781105041504
[Train] epoch 368 Batch 7 Loss 0.16741937398910522
[Train] epoch 368 Batch 8 Loss 0.3343755900859833
[Train] epoch 368 Batch 9 Loss 0.4015654921531677
[Train] epoch 368 Batch 10 Loss 0.2336273193359375
[Train] epoch 368 Batch 11 Loss 0.1682557463645935
[Train] epoch 368 Batch 12 Loss 0.20136025547981262
[Train] epoch 368 Batch 13 Loss 0.0689902976155281
[Train] epoch 368 Batch 14 Loss 0.13482032716274261
[Train] epoch 368 Batch 15 Loss 0.10119304060935974
[Train] epoch 368 Batch 16 Loss 0.10126123577356339
[Train] epoch 368 Batch 17 Loss 0.23465976119041443
[Train] epoch 368 Batch 18 Loss 0.03489815071225166
[Train] epoch 368 Batch 19 Loss 0.16740652918815613
[Train] epoch 368 Batch 20 Loss 0.13391950726509094
[Train] epoch 368 Batch 21 Loss 0.20102941989898682
[Train] epoch 368 Batch 22 Loss 0.23451299965381622
[Train] epoch 368 Batch 23 Loss 0.1347333788871765
[Train] epoch 368 Batch 24 Loss 0.06718054413795471
[Train] epoch 368 Batch 25 Loss 0.2015390694141388
[Train] epoch 368 Batch 26 Loss 0.13472695648670197
[Train] epoch 368 Batch 27 Loss 0.33487069606781006
[Train] epoch 368 Batch 28 Loss 0.1677640974521637
[Train] epoch 368 Batch 29 Loss 0.06812651455402374
[Train] epoch 368 Batch 30 Loss 0.1011662483215332
[Train] epoch 368 Batch 31 Loss 0.16826575994491577
[Train] epoch 368 Batch 32 Loss 0.16746966540813446
[Train] epoch 368 Batch 33 Loss 0.133334219455719
[Train] epoch 368 Batch 34 Loss 0.23413410782814026
[Train] epoch 368 Batch 35 Loss 0.10123465955257416
[Train] epoch 368 Batch 36 Loss 0.10078594833612442
[Train] epoch 368 Batch 37 Loss 0.10075277090072632
[Train] epoch 368 Batch 38 Loss 0.20205742120742798
[Train] epoch 368 Batch 39 Loss 0.16770480573177338
[Train] epoch 368 Batch 40 Loss 0.16804103553295135
[Train] epoch 368 Batch 41 Loss 0.23463624715805054
[Train] epoch 368 Batch 42 Loss 0.20161069929599762
[Train] epoch 368 Batch 43 Loss 0.09041327238082886
[Train] epoch 368 Batch 44 Loss 0.06666764616966248
[Train] epoch 368 Batch 45 Loss 0.2706320583820343
[Train] epoch 368 Batch 46 Loss 0.23357175290584564
[Train] epoch 368 Batch 47 Loss 0.2381315529346466
[Train] epoch 369 Batch 0 Loss 0.3377473056316376
[Train] epoch 369 Batch 1 Loss 0.24612632393836975
[Train] epoch 369 Batch 2 Loss 0.2800476551055908
[Train] epoch 369 Batch 3 Loss 0.2671263515949249
[Train] epoch 369 Batch 4 Loss 0.10085749626159668
[Train] epoch 369 Batch 5 Loss 0.03563014790415764
[Train] epoch 369 Batch 6 Loss 0.2383042424917221
[Train] epoch 369 Batch 7 Loss 0.2678264379501343
[Train] epoch 369 Batch 8 Loss 0.1350986659526825
[Train] epoch 369 Batch 9 Loss 0.2020891010761261
[Train] epoch 369 Batch 10 Loss 0.2694202661514282
[Train] epoch 369 Batch 11 Loss 0.1339624524116516
[Train] epoch 369 Batch 12 Loss 0.23705217242240906
[Train] epoch 369 Batch 13 Loss 1.0728851975727594e-06
[Train] epoch 369 Batch 14 Loss 0.06931596249341965
[Train] epoch 369 Batch 15 Loss 0.166998028755188
[Train] epoch 369 Batch 16 Loss 0.1019960269331932
[Train] epoch 369 Batch 17 Loss 0.09079103171825409
[Train] epoch 369 Batch 18 Loss 0.06134328246116638
[Train] epoch 369 Batch 19 Loss 0.11420995742082596
[Train] epoch 369 Batch 20 Loss 0.23480772972106934
[Train] epoch 369 Batch 21 Loss 0.1110633909702301
[Train] epoch 369 Batch 22 Loss 0.13466721773147583
[Train] epoch 369 Batch 23 Loss 0.20662079751491547
[Train] epoch 369 Batch 24 Loss 0.10175615549087524
[Train] epoch 369 Batch 25 Loss 0.1354357898235321
[Train] epoch 369 Batch 26 Loss 0.204186350107193
[Train] epoch 369 Batch 27 Loss 0.23568660020828247
[Train] epoch 369 Batch 28 Loss 0.31578612327575684
[Train] epoch 369 Batch 29 Loss 0.3356282114982605
[Train] epoch 369 Batch 30 Loss 0.26842328906059265
[Train] epoch 369 Batch 31 Loss 0.3014328181743622
[Train] epoch 369 Batch 32 Loss 0.2354941964149475
[Train] epoch 369 Batch 33 Loss 0.06863030791282654
[Train] epoch 369 Batch 34 Loss 0.26861077547073364
[Train] epoch 369 Batch 35 Loss 0.06900031864643097
[Train] epoch 369 Batch 36 Loss 0.1343204826116562
[Train] epoch 369 Batch 37 Loss 0.13432630896568298
[Train] epoch 369 Batch 38 Loss 0.271597683429718
[Train] epoch 369 Batch 39 Loss 0.10397253185510635
[Train] epoch 369 Batch 40 Loss 0.23658832907676697
[Train] epoch 369 Batch 41 Loss 0.2028113454580307
[Train] epoch 369 Batch 42 Loss 0.07357393950223923
[Train] epoch 369 Batch 43 Loss 0.20225918292999268
[Train] epoch 369 Batch 44 Loss 0.143794983625412
[Train] epoch 369 Batch 45 Loss 0.10565982013940811
[Train] epoch 369 Batch 46 Loss 0.0678730309009552
[Train] epoch 369 Batch 47 Loss 0.304290235042572
[Train] epoch 370 Batch 0 Loss 0.22161400318145752
[Train] epoch 370 Batch 1 Loss 0.26808828115463257
[Train] epoch 370 Batch 2 Loss 0.23505441844463348
[Train] epoch 370 Batch 3 Loss 0.1355246901512146
[Train] epoch 370 Batch 4 Loss 0.10087904334068298
[Train] epoch 370 Batch 5 Loss 0.20618659257888794
[Train] epoch 370 Batch 6 Loss 0.06990262866020203
[Train] epoch 370 Batch 7 Loss 0.2678002119064331
[Train] epoch 370 Batch 8 Loss 0.16828423738479614
[Train] epoch 370 Batch 9 Loss 0.23617523908615112
[Train] epoch 370 Batch 10 Loss 0.1721847951412201
[Train] epoch 370 Batch 11 Loss 0.13733074069023132
[Train] epoch 370 Batch 12 Loss 0.2034371793270111
[Train] epoch 370 Batch 13 Loss 0.06972561776638031
[Train] epoch 370 Batch 14 Loss 0.2037116438150406
[Train] epoch 370 Batch 15 Loss 0.20083963871002197
[Train] epoch 370 Batch 16 Loss 0.11679805815219879
[Train] epoch 370 Batch 17 Loss 0.16931584477424622
[Train] epoch 370 Batch 18 Loss 0.0008714300347492099
[Train] epoch 370 Batch 19 Loss 0.23599368333816528
[Train] epoch 370 Batch 20 Loss 0.10084550082683563
[Train] epoch 370 Batch 21 Loss 0.24960850179195404
[Train] epoch 370 Batch 22 Loss 0.3094840943813324
[Train] epoch 370 Batch 23 Loss 0.3029705882072449
[Train] epoch 370 Batch 24 Loss 0.10262587666511536
[Train] epoch 370 Batch 25 Loss 0.20391181111335754
[Train] epoch 370 Batch 26 Loss 0.2347804605960846
[Train] epoch 370 Batch 27 Loss 0.16949225962162018
[Train] epoch 370 Batch 28 Loss 0.10379095375537872
[Train] epoch 370 Batch 29 Loss 0.2687762677669525
[Train] epoch 370 Batch 30 Loss 0.10047878324985504
[Train] epoch 370 Batch 31 Loss 0.3695988059043884
[Train] epoch 370 Batch 32 Loss 0.3028242290019989
[Train] epoch 370 Batch 33 Loss 0.27116653323173523
[Train] epoch 370 Batch 34 Loss 0.2038019299507141
[Train] epoch 370 Batch 35 Loss 0.03523596376180649
[Train] epoch 370 Batch 36 Loss 0.20476123690605164
[Train] epoch 370 Batch 37 Loss 0.07061213999986649
[Train] epoch 370 Batch 38 Loss 0.20110949873924255
[Train] epoch 370 Batch 39 Loss 0.1356711983680725
[Train] epoch 370 Batch 40 Loss 0.13834519684314728
[Train] epoch 370 Batch 41 Loss 0.03661595657467842
[Train] epoch 370 Batch 42 Loss 0.30530649423599243
[Train] epoch 370 Batch 43 Loss 0.06770463287830353
[Train] epoch 370 Batch 44 Loss 0.20343129336833954
[Train] epoch 370 Batch 45 Loss 0.20627430081367493
[Train] epoch 370 Batch 46 Loss 0.2349056601524353
[Train] epoch 370 Batch 47 Loss 0.16829125583171844
[Train] epoch 371 Batch 0 Loss 0.13448795676231384
[Train] epoch 371 Batch 1 Loss 0.2702314853668213
[Train] epoch 371 Batch 2 Loss 0.16847747564315796
[Train] epoch 371 Batch 3 Loss 0.33699923753738403
[Train] epoch 371 Batch 4 Loss 0.13465166091918945
[Train] epoch 371 Batch 5 Loss 0.16720591485500336
[Train] epoch 371 Batch 6 Loss 0.30274075269699097
[Train] epoch 371 Batch 7 Loss 0.16958020627498627
[Train] epoch 371 Batch 8 Loss 0.03498858958482742
[Train] epoch 371 Batch 9 Loss 0.1344091296195984
[Train] epoch 371 Batch 10 Loss 0.16959601640701294
[Train] epoch 371 Batch 11 Loss 0.23818808794021606
[Train] epoch 371 Batch 12 Loss 0.13440807163715363
[Train] epoch 371 Batch 13 Loss 0.20243725180625916
[Train] epoch 371 Batch 14 Loss 0.20235368609428406
[Train] epoch 371 Batch 15 Loss 0.1017923653125763
[Train] epoch 371 Batch 16 Loss 0.1343291699886322
[Train] epoch 371 Batch 17 Loss 0.1358223855495453
[Train] epoch 371 Batch 18 Loss 0.26881667971611023
[Train] epoch 371 Batch 19 Loss 0.1730450838804245
[Train] epoch 371 Batch 20 Loss 0.2042686641216278
[Train] epoch 371 Batch 21 Loss 0.17071494460105896
[Train] epoch 371 Batch 22 Loss 0.0024208049289882183
[Train] epoch 371 Batch 23 Loss 0.10497598350048065
[Train] epoch 371 Batch 24 Loss 0.171560138463974
[Train] epoch 371 Batch 25 Loss 0.10389190167188644
[Train] epoch 371 Batch 26 Loss 0.10264819115400314
[Train] epoch 371 Batch 27 Loss 0.1696876883506775
[Train] epoch 371 Batch 28 Loss 0.20106077194213867
[Train] epoch 371 Batch 29 Loss 0.06878283619880676
[Train] epoch 371 Batch 30 Loss 0.1692695915699005
[Train] epoch 371 Batch 31 Loss 0.3364626169204712
[Train] epoch 371 Batch 32 Loss 0.20353010296821594
[Train] epoch 371 Batch 33 Loss 0.2046796679496765
[Train] epoch 371 Batch 34 Loss 0.27016592025756836
[Train] epoch 371 Batch 35 Loss 0.07251446694135666
[Train] epoch 371 Batch 36 Loss 0.3352711498737335
[Train] epoch 371 Batch 37 Loss 0.168345645070076
[Train] epoch 371 Batch 38 Loss 0.3036702871322632
[Train] epoch 371 Batch 39 Loss 0.16835501790046692
[Train] epoch 371 Batch 40 Loss 0.13549937307834625
[Train] epoch 371 Batch 41 Loss 0.23596853017807007
[Train] epoch 371 Batch 42 Loss 0.20263361930847168
[Train] epoch 371 Batch 43 Loss 0.10282336175441742
[Train] epoch 371 Batch 44 Loss 0.13445892930030823
[Train] epoch 371 Batch 45 Loss 0.03521771356463432
[Train] epoch 371 Batch 46 Loss 0.30385228991508484
[Train] epoch 371 Batch 47 Loss 0.13437245786190033
[Train] epoch 372 Batch 0 Loss 0.07038356363773346
[Train] epoch 372 Batch 1 Loss 0.23398184776306152
[Train] epoch 372 Batch 2 Loss 0.1055903360247612
[Train] epoch 372 Batch 3 Loss 0.26666736602783203
[Train] epoch 372 Batch 4 Loss 0.20341336727142334
[Train] epoch 372 Batch 5 Loss 0.13426068425178528
[Train] epoch 372 Batch 6 Loss 0.13805446028709412
[Train] epoch 372 Batch 7 Loss 0.17083851993083954
[Train] epoch 372 Batch 8 Loss 0.07134009897708893
[Train] epoch 372 Batch 9 Loss 0.06784726679325104
[Train] epoch 372 Batch 10 Loss 0.23481932282447815
[Train] epoch 372 Batch 11 Loss 0.16815102100372314
[Train] epoch 372 Batch 12 Loss 0.16814926266670227
[Train] epoch 372 Batch 13 Loss 0.13652142882347107
[Train] epoch 372 Batch 14 Loss 0.06880131363868713
[Train] epoch 372 Batch 15 Loss 0.3026748299598694
[Train] epoch 372 Batch 16 Loss 0.16835197806358337
[Train] epoch 372 Batch 17 Loss 0.1682673841714859
[Train] epoch 372 Batch 18 Loss 0.06772268563508987
[Train] epoch 372 Batch 19 Loss 0.2349240779876709
[Train] epoch 372 Batch 20 Loss 0.1693725734949112
[Train] epoch 372 Batch 21 Loss 0.16713322699069977
[Train] epoch 372 Batch 22 Loss 0.30273449420928955
[Train] epoch 372 Batch 23 Loss 0.20219603180885315
[Train] epoch 372 Batch 24 Loss 0.23687438666820526
[Train] epoch 372 Batch 25 Loss 0.10249695926904678
[Train] epoch 372 Batch 26 Loss 0.10266347974538803
[Train] epoch 372 Batch 27 Loss 0.16925477981567383
[Train] epoch 372 Batch 28 Loss 0.3374116122722626
[Train] epoch 372 Batch 29 Loss 0.20196273922920227
[Train] epoch 372 Batch 30 Loss 0.13748840987682343
[Train] epoch 372 Batch 31 Loss 0.30264830589294434
[Train] epoch 372 Batch 32 Loss 0.20102135837078094
[Train] epoch 372 Batch 33 Loss 0.2686612010002136
[Train] epoch 372 Batch 34 Loss 0.23692695796489716
[Train] epoch 372 Batch 35 Loss 0.1362966150045395
[Train] epoch 372 Batch 36 Loss 0.205161452293396
[Train] epoch 372 Batch 37 Loss 0.2040354609489441
[Train] epoch 372 Batch 38 Loss 0.1692177802324295
[Train] epoch 372 Batch 39 Loss 0.234833225607872
[Train] epoch 372 Batch 40 Loss 0.3373246192932129
[Train] epoch 372 Batch 41 Loss 0.1363142877817154
[Train] epoch 372 Batch 42 Loss 0.26868072152137756
[Train] epoch 372 Batch 43 Loss 0.003077684435993433
[Train] epoch 372 Batch 44 Loss 0.03581845387816429
[Train] epoch 372 Batch 45 Loss 0.1352744698524475
[Train] epoch 372 Batch 46 Loss 0.1691211611032486
[Train] epoch 372 Batch 47 Loss 0.06765188276767731
[Train] epoch 373 Batch 0 Loss 0.20192109048366547
[Train] epoch 373 Batch 1 Loss 0.06764790415763855
[Train] epoch 373 Batch 2 Loss 0.26952221989631653
[Train] epoch 373 Batch 3 Loss 0.1342787891626358
[Train] epoch 373 Batch 4 Loss 0.20101311802864075
[Train] epoch 373 Batch 5 Loss 0.068614661693573
[Train] epoch 373 Batch 6 Loss 0.23474064469337463
[Train] epoch 373 Batch 7 Loss 0.33711278438568115
[Train] epoch 373 Batch 8 Loss 0.26960206031799316
[Train] epoch 373 Batch 9 Loss 0.10146738588809967
[Train] epoch 373 Batch 10 Loss 0.16902905702590942
[Train] epoch 373 Batch 11 Loss 0.13631051778793335
[Train] epoch 373 Batch 12 Loss 0.23665720224380493
[Train] epoch 373 Batch 13 Loss 0.16808803379535675
[Train] epoch 373 Batch 14 Loss 0.13809025287628174
[Train] epoch 373 Batch 15 Loss 0.10331794619560242
[Train] epoch 373 Batch 16 Loss 0.13523179292678833
[Train] epoch 373 Batch 17 Loss 0.16809087991714478
[Train] epoch 373 Batch 18 Loss 0.13427184522151947
[Train] epoch 373 Batch 19 Loss 0.16996298730373383
[Train] epoch 373 Batch 20 Loss 0.033803362399339676
[Train] epoch 373 Batch 21 Loss 0.13613584637641907
[Train] epoch 373 Batch 22 Loss 0.10047000646591187
[Train] epoch 373 Batch 23 Loss 0.2037106454372406
[Train] epoch 373 Batch 24 Loss 0.2027740180492401
[Train] epoch 373 Batch 25 Loss 0.20279532670974731
[Train] epoch 373 Batch 26 Loss 0.16987180709838867
[Train] epoch 373 Batch 27 Loss 0.2347148060798645
[Train] epoch 373 Batch 28 Loss 0.2037504017353058
[Train] epoch 373 Batch 29 Loss 0.13427014648914337
[Train] epoch 373 Batch 30 Loss 0.26760023832321167
[Train] epoch 373 Batch 31 Loss 0.10509343445301056
[Train] epoch 373 Batch 32 Loss 0.1689988374710083
[Train] epoch 373 Batch 33 Loss 0.2346971482038498
[Train] epoch 373 Batch 34 Loss 0.13425573706626892
[Train] epoch 373 Batch 35 Loss 0.1360417753458023
[Train] epoch 373 Batch 36 Loss 0.1031595841050148
[Train] epoch 373 Batch 37 Loss 0.13517135381698608
[Train] epoch 373 Batch 38 Loss 0.13606184720993042
[Train] epoch 373 Batch 39 Loss 0.20354487001895905
[Train] epoch 373 Batch 40 Loss 0.26755988597869873
[Train] epoch 373 Batch 41 Loss 0.16894550621509552
[Train] epoch 373 Batch 42 Loss 0.2364674210548401
[Train] epoch 373 Batch 43 Loss 0.4009374976158142
[Train] epoch 373 Batch 44 Loss 0.26931172609329224
[Train] epoch 373 Batch 45 Loss 0.23550128936767578
[Train] epoch 373 Batch 46 Loss 0.03466309607028961
[Train] epoch 373 Batch 47 Loss 0.10223717987537384
[Train] epoch 374 Batch 0 Loss 0.06843128800392151
[Train] epoch 374 Batch 1 Loss 0.20360609889030457
[Train] epoch 374 Batch 2 Loss 0.2684548497200012
[Train] epoch 374 Batch 3 Loss 0.20269125699996948
[Train] epoch 374 Batch 4 Loss 0.1350501924753189
[Train] epoch 374 Batch 5 Loss 0.2355833649635315
[Train] epoch 374 Batch 6 Loss 0.2364468276500702
[Train] epoch 374 Batch 7 Loss 0.1342344582080841
[Train] epoch 374 Batch 8 Loss 0.10214340686798096
[Train] epoch 374 Batch 9 Loss 0.27101701498031616
[Train] epoch 374 Batch 10 Loss 0.16884952783584595
[Train] epoch 374 Batch 11 Loss 0.1679900884628296
[Train] epoch 374 Batch 12 Loss 0.23544025421142578
[Train] epoch 374 Batch 13 Loss 0.10133872926235199
[Train] epoch 374 Batch 14 Loss 0.10216159373521805
[Train] epoch 374 Batch 15 Loss 0.0008458513766527176
[Train] epoch 374 Batch 16 Loss 0.20168745517730713
[Train] epoch 374 Batch 17 Loss 0.23639746010303497
[Train] epoch 374 Batch 18 Loss 0.3696773648262024
[Train] epoch 374 Batch 19 Loss 0.2018011212348938
[Train] epoch 374 Batch 20 Loss 0.20169830322265625
[Train] epoch 374 Batch 21 Loss 0.20341959595680237
[Train] epoch 374 Batch 22 Loss 0.06841184198856354
[Train] epoch 374 Batch 23 Loss 0.23380181193351746
[Train] epoch 374 Batch 24 Loss 0.16972452402114868
[Train] epoch 374 Batch 25 Loss 0.1679932326078415
[Train] epoch 374 Batch 26 Loss 0.2008247673511505
[Train] epoch 374 Batch 27 Loss 0.20080167055130005
[Train] epoch 374 Batch 28 Loss 0.2025335133075714
[Train] epoch 374 Batch 29 Loss 0.03452068939805031
[Train] epoch 374 Batch 30 Loss 0.20079734921455383
[Train] epoch 374 Batch 31 Loss 0.2034204602241516
[Train] epoch 374 Batch 32 Loss 0.10046746581792831
[Train] epoch 374 Batch 33 Loss 0.1349996030330658
[Train] epoch 374 Batch 34 Loss 0.10119780898094177
[Train] epoch 374 Batch 35 Loss 0.13420575857162476
[Train] epoch 374 Batch 36 Loss 0.20093324780464172
[Train] epoch 374 Batch 37 Loss 0.10291127115488052
[Train] epoch 374 Batch 38 Loss 0.16705001890659332
[Train] epoch 374 Batch 39 Loss 0.2057657241821289
[Train] epoch 374 Batch 40 Loss 0.16958743333816528
[Train] epoch 374 Batch 41 Loss 0.23542729020118713
[Train] epoch 374 Batch 42 Loss 0.135865718126297
[Train] epoch 374 Batch 43 Loss 0.13495665788650513
[Train] epoch 374 Batch 44 Loss 0.23712685704231262
[Train] epoch 374 Batch 45 Loss 0.20338375866413116
[Train] epoch 374 Batch 46 Loss 0.20084248483181
[Train] epoch 374 Batch 47 Loss 0.20242393016815186
[Train] epoch 375 Batch 0 Loss 0.3366124629974365
[Train] epoch 375 Batch 1 Loss 0.20239494740962982
[Train] epoch 375 Batch 2 Loss 0.13576287031173706
[Train] epoch 375 Batch 3 Loss 0.27002039551734924
[Train] epoch 375 Batch 4 Loss 0.16713227331638336
[Train] epoch 375 Batch 5 Loss 0.3027656376361847
[Train] epoch 375 Batch 6 Loss 0.034481681883335114
[Train] epoch 375 Batch 7 Loss 0.13560466468334198
[Train] epoch 375 Batch 8 Loss 0.16941532492637634
[Train] epoch 375 Batch 9 Loss 0.23540201783180237
[Train] epoch 375 Batch 10 Loss 0.40253037214279175
[Train] epoch 375 Batch 11 Loss 0.23614555597305298
[Train] epoch 375 Batch 12 Loss 0.13585829734802246
[Train] epoch 375 Batch 13 Loss 0.13577264547348022
[Train] epoch 375 Batch 14 Loss 0.236995130777359
[Train] epoch 375 Batch 15 Loss 0.1686517745256424
[Train] epoch 375 Batch 16 Loss 0.10046520829200745
[Train] epoch 375 Batch 17 Loss 0.03529369831085205
[Train] epoch 375 Batch 18 Loss 0.1356501281261444
[Train] epoch 375 Batch 19 Loss 0.10036017000675201
[Train] epoch 375 Batch 20 Loss 0.23472587764263153
[Train] epoch 375 Batch 21 Loss 0.20250004529953003
[Train] epoch 375 Batch 22 Loss 0.16857746243476868
[Train] epoch 375 Batch 23 Loss 0.33564862608909607
[Train] epoch 375 Batch 24 Loss 0.06981470435857773
[Train] epoch 375 Batch 25 Loss 0.20249012112617493
[Train] epoch 375 Batch 26 Loss 0.10189962387084961
[Train] epoch 375 Batch 27 Loss 0.03598816692829132
[Train] epoch 375 Batch 28 Loss 0.1341504007577896
[Train] epoch 375 Batch 29 Loss 0.06905312091112137
[Train] epoch 375 Batch 30 Loss 0.13414879143238068
[Train] epoch 375 Batch 31 Loss 0.26759228110313416
[Train] epoch 375 Batch 32 Loss 0.10119760036468506
[Train] epoch 375 Batch 33 Loss 0.3695830702781677
[Train] epoch 375 Batch 34 Loss 0.23449568450450897
[Train] epoch 375 Batch 35 Loss 0.03369995579123497
[Train] epoch 375 Batch 36 Loss 0.20235174894332886
[Train] epoch 375 Batch 37 Loss 0.2017490565776825
[Train] epoch 375 Batch 38 Loss 0.13415935635566711
[Train] epoch 375 Batch 39 Loss 0.10272499173879623
[Train] epoch 375 Batch 40 Loss 0.20172938704490662
[Train] epoch 375 Batch 41 Loss 0.20255114138126373
[Train] epoch 375 Batch 42 Loss 0.3020077347755432
[Train] epoch 375 Batch 43 Loss 0.1357014775276184
[Train] epoch 375 Batch 44 Loss 0.10116739571094513
[Train] epoch 375 Batch 45 Loss 0.13404080271720886
[Train] epoch 375 Batch 46 Loss 0.20080429315567017
[Train] epoch 375 Batch 47 Loss 0.10116422176361084
[Train] epoch 376 Batch 0 Loss 0.0695006474852562
[Train] epoch 376 Batch 1 Loss 0.13495326042175293
[Train] epoch 376 Batch 2 Loss 0.2681708335876465
[Train] epoch 376 Batch 3 Loss 0.06738486140966415
[Train] epoch 376 Batch 4 Loss 0.1671248972415924
[Train] epoch 376 Batch 5 Loss 0.1694387048482895
[Train] epoch 376 Batch 6 Loss 0.10117243975400925
[Train] epoch 376 Batch 7 Loss 0.16712437570095062
[Train] epoch 376 Batch 8 Loss 0.2682935893535614
[Train] epoch 376 Batch 9 Loss 0.06970150023698807
[Train] epoch 376 Batch 10 Loss 0.06959779560565948
[Train] epoch 376 Batch 11 Loss 0.06818898022174835
[Train] epoch 376 Batch 12 Loss 0.33573484420776367
[Train] epoch 376 Batch 13 Loss 0.13485203683376312
[Train] epoch 376 Batch 14 Loss 0.1362185925245285
[Train] epoch 376 Batch 15 Loss 0.2689596116542816
[Train] epoch 376 Batch 16 Loss 0.20277352631092072
[Train] epoch 376 Batch 17 Loss 0.20290175080299377
[Train] epoch 376 Batch 18 Loss 0.16780957579612732
[Train] epoch 376 Batch 19 Loss 0.2352800816297531
[Train] epoch 376 Batch 20 Loss 0.2337893545627594
[Train] epoch 376 Batch 21 Loss 0.26894354820251465
[Train] epoch 376 Batch 22 Loss 0.1003345251083374
[Train] epoch 376 Batch 23 Loss 0.13698120415210724
[Train] epoch 376 Batch 24 Loss 0.06757757812738419
[Train] epoch 376 Batch 25 Loss 0.2343442142009735
[Train] epoch 376 Batch 26 Loss 0.23526659607887268
[Train] epoch 376 Batch 27 Loss 0.26917657256126404
[Train] epoch 376 Batch 28 Loss 0.10272905975580215
[Train] epoch 376 Batch 29 Loss 0.16961301863193512
[Train] epoch 376 Batch 30 Loss 0.3342418074607849
[Train] epoch 376 Batch 31 Loss 0.16802823543548584
[Train] epoch 376 Batch 32 Loss 0.20159339904785156
[Train] epoch 376 Batch 33 Loss 0.0363910011947155
[Train] epoch 376 Batch 34 Loss 0.3012479543685913
[Train] epoch 376 Batch 35 Loss 0.10258664190769196
[Train] epoch 376 Batch 36 Loss 0.10112172365188599
[Train] epoch 376 Batch 37 Loss 0.10191325843334198
[Train] epoch 376 Batch 38 Loss 0.10124415159225464
[Train] epoch 376 Batch 39 Loss 0.20134776830673218
[Train] epoch 376 Batch 40 Loss 0.13626043498516083
[Train] epoch 376 Batch 41 Loss 0.2013167142868042
[Train] epoch 376 Batch 42 Loss 0.23523744940757751
[Train] epoch 376 Batch 43 Loss 0.23613610863685608
[Train] epoch 376 Batch 44 Loss 0.13478407263755798
[Train] epoch 376 Batch 45 Loss 0.3012239336967468
[Train] epoch 376 Batch 46 Loss 0.16801583766937256
[Train] epoch 376 Batch 47 Loss 0.2014462947845459
[Train] epoch 377 Batch 0 Loss 0.06812524050474167
[Train] epoch 377 Batch 1 Loss 0.20077183842658997
[Train] epoch 377 Batch 2 Loss 0.26812222599983215
[Train] epoch 377 Batch 3 Loss 0.06756379455327988
[Train] epoch 377 Batch 4 Loss 0.06810671091079712
[Train] epoch 377 Batch 5 Loss 0.10121733695268631
[Train] epoch 377 Batch 6 Loss 0.06823071837425232
[Train] epoch 377 Batch 7 Loss 0.23456206917762756
[Train] epoch 377 Batch 8 Loss 0.06821529567241669
[Train] epoch 377 Batch 9 Loss 0.26929569244384766
[Train] epoch 377 Batch 10 Loss 0.2023123800754547
[Train] epoch 377 Batch 11 Loss 0.13463914394378662
[Train] epoch 377 Batch 12 Loss 0.3012244701385498
[Train] epoch 377 Batch 13 Loss 0.3354265093803406
[Train] epoch 377 Batch 14 Loss 0.30262404680252075
[Train] epoch 377 Batch 15 Loss 0.2674306631088257
[Train] epoch 377 Batch 16 Loss 0.20155221223831177
[Train] epoch 377 Batch 17 Loss 0.17075951397418976
[Train] epoch 377 Batch 18 Loss 0.26986634731292725
[Train] epoch 377 Batch 19 Loss 0.10199227184057236
[Train] epoch 377 Batch 20 Loss 0.26860541105270386
[Train] epoch 377 Batch 21 Loss 0.20217761397361755
[Train] epoch 377 Batch 22 Loss 0.1346355378627777
[Train] epoch 377 Batch 23 Loss 0.16776636242866516
[Train] epoch 377 Batch 24 Loss 0.03560266271233559
[Train] epoch 377 Batch 25 Loss 0.1340910792350769
[Train] epoch 377 Batch 26 Loss 0.13397501409053802
[Train] epoch 377 Batch 27 Loss 0.06755171716213226
[Train] epoch 377 Batch 28 Loss 0.20267339050769806
[Train] epoch 377 Batch 29 Loss 0.3355976939201355
[Train] epoch 377 Batch 30 Loss 0.2007547914981842
[Train] epoch 377 Batch 31 Loss 0.06796596944332123
[Train] epoch 377 Batch 32 Loss 0.2354106903076172
[Train] epoch 377 Batch 33 Loss 0.033775363117456436
[Train] epoch 377 Batch 34 Loss 0.23570320010185242
[Train] epoch 377 Batch 35 Loss 0.20064698159694672
[Train] epoch 377 Batch 36 Loss 0.06730063259601593
[Train] epoch 377 Batch 37 Loss 0.10170582681894302
[Train] epoch 377 Batch 38 Loss 0.136134073138237
[Train] epoch 377 Batch 39 Loss 0.06934612989425659
[Train] epoch 377 Batch 40 Loss 0.20088084042072296
[Train] epoch 377 Batch 41 Loss 0.23540203273296356
[Train] epoch 377 Batch 42 Loss 0.17038026452064514
[Train] epoch 377 Batch 43 Loss 0.26894524693489075
[Train] epoch 377 Batch 44 Loss 0.20342180132865906
[Train] epoch 377 Batch 45 Loss 0.1349703073501587
[Train] epoch 377 Batch 46 Loss 0.2021518498659134
[Train] epoch 377 Batch 47 Loss 0.23438462615013123
[Train] epoch 378 Batch 0 Loss 0.10131607204675674
[Train] epoch 378 Batch 1 Loss 0.13622194528579712
[Train] epoch 378 Batch 2 Loss 0.23653559386730194
[Train] epoch 378 Batch 3 Loss 0.2008756697177887
[Train] epoch 378 Batch 4 Loss 0.06791944801807404
[Train] epoch 378 Batch 5 Loss 0.06803934276103973
[Train] epoch 378 Batch 6 Loss 0.10194084793329239
[Train] epoch 378 Batch 7 Loss 0.2013697475194931
[Train] epoch 378 Batch 8 Loss 0.30317190289497375
[Train] epoch 378 Batch 9 Loss 0.2017437219619751
[Train] epoch 378 Batch 10 Loss 0.3009301424026489
[Train] epoch 378 Batch 11 Loss 0.30305230617523193
[Train] epoch 378 Batch 12 Loss 0.30030232667922974
[Train] epoch 378 Batch 13 Loss 0.20210857689380646
[Train] epoch 378 Batch 14 Loss 0.20221760869026184
[Train] epoch 378 Batch 15 Loss 0.1683262139558792
[Train] epoch 378 Batch 16 Loss 0.13394585251808167
[Train] epoch 378 Batch 17 Loss 0.2686227262020111
[Train] epoch 378 Batch 18 Loss 0.10178844630718231
[Train] epoch 378 Batch 19 Loss 0.13529634475708008
[Train] epoch 378 Batch 20 Loss 0.0674104243516922
[Train] epoch 378 Batch 21 Loss 0.3354372978210449
[Train] epoch 378 Batch 22 Loss 0.03423966094851494
[Train] epoch 378 Batch 23 Loss 0.2678910791873932
[Train] epoch 378 Batch 24 Loss 0.10150955617427826
[Train] epoch 378 Batch 25 Loss 0.10164286196231842
[Train] epoch 378 Batch 26 Loss 0.06801114231348038
[Train] epoch 378 Batch 27 Loss 0.06799909472465515
[Train] epoch 378 Batch 28 Loss 0.16844061017036438
[Train] epoch 378 Batch 29 Loss 0.2681329846382141
[Train] epoch 378 Batch 30 Loss 0.10176055878400803
[Train] epoch 378 Batch 31 Loss 0.2345031052827835
[Train] epoch 378 Batch 32 Loss 0.16818198561668396
[Train] epoch 378 Batch 33 Loss 0.3017670512199402
[Train] epoch 378 Batch 34 Loss 0.13566839694976807
[Train] epoch 378 Batch 35 Loss 0.1339314877986908
[Train] epoch 378 Batch 36 Loss 0.30249762535095215
[Train] epoch 378 Batch 37 Loss 0.06666764616966248
[Train] epoch 378 Batch 38 Loss 0.1348014771938324
[Train] epoch 378 Batch 39 Loss 0.16854289174079895
[Train] epoch 378 Batch 40 Loss 0.10043103992938995
[Train] epoch 378 Batch 41 Loss 0.1351374238729477
[Train] epoch 378 Batch 42 Loss 0.3691537380218506
[Train] epoch 378 Batch 43 Loss 0.10282309353351593
[Train] epoch 378 Batch 44 Loss 0.20204363763332367
[Train] epoch 378 Batch 45 Loss 0.20279288291931152
[Train] epoch 378 Batch 46 Loss 0.23522183299064636
[Train] epoch 378 Batch 47 Loss 0.06811492145061493
[Train] epoch 379 Batch 0 Loss 0.06811374425888062
[Train] epoch 379 Batch 1 Loss 0.16781288385391235
[Train] epoch 379 Batch 2 Loss 0.10207560658454895
[Train] epoch 379 Batch 3 Loss 0.10207335650920868
[Train] epoch 379 Batch 4 Loss 0.16887611150741577
[Train] epoch 379 Batch 5 Loss 0.03376157581806183
[Train] epoch 379 Batch 6 Loss 0.10101337730884552
[Train] epoch 379 Batch 7 Loss 0.16794833540916443
[Train] epoch 379 Batch 8 Loss 0.0690341368317604
[Train] epoch 379 Batch 9 Loss 0.16709411144256592
[Train] epoch 379 Batch 10 Loss 0.26896587014198303
[Train] epoch 379 Batch 11 Loss 0.135500967502594
[Train] epoch 379 Batch 12 Loss 0.3346273899078369
[Train] epoch 379 Batch 13 Loss 0.1346265971660614
[Train] epoch 379 Batch 14 Loss 0.300876259803772
[Train] epoch 379 Batch 15 Loss 0.23447957634925842
[Train] epoch 379 Batch 16 Loss 0.3683816194534302
[Train] epoch 379 Batch 17 Loss 0.3024330139160156
[Train] epoch 379 Batch 18 Loss 0.16969557106494904
[Train] epoch 379 Batch 19 Loss 0.26893290877342224
[Train] epoch 379 Batch 20 Loss 0.10042499005794525
[Train] epoch 379 Batch 21 Loss 0.13605186343193054
[Train] epoch 379 Batch 22 Loss 0.16864438354969025
[Train] epoch 379 Batch 23 Loss 0.3008594512939453
[Train] epoch 379 Batch 24 Loss 0.13546991348266602
[Train] epoch 379 Batch 25 Loss 0.06751226633787155
[Train] epoch 379 Batch 26 Loss 0.2693740427494049
[Train] epoch 379 Batch 27 Loss 0.23618140816688538
[Train] epoch 379 Batch 28 Loss 0.30156877636909485
[Train] epoch 379 Batch 29 Loss 0.03477136790752411
[Train] epoch 379 Batch 30 Loss 0.1686408817768097
[Train] epoch 379 Batch 31 Loss 0.06854137778282166
[Train] epoch 379 Batch 32 Loss 0.16766825318336487
[Train] epoch 379 Batch 33 Loss 0.20142045617103577
[Train] epoch 379 Batch 34 Loss 0.06736733764410019
[Train] epoch 379 Batch 35 Loss 0.16882389783859253
[Train] epoch 379 Batch 36 Loss 0.1682339608669281
[Train] epoch 379 Batch 37 Loss 0.23432117700576782
[Train] epoch 379 Batch 38 Loss 0.10214176774024963
[Train] epoch 379 Batch 39 Loss 0.20112565159797668
[Train] epoch 379 Batch 40 Loss 0.1345975399017334
[Train] epoch 379 Batch 41 Loss 0.1684969812631607
[Train] epoch 379 Batch 42 Loss 0.20114052295684814
[Train] epoch 379 Batch 43 Loss 0.06723225116729736
[Train] epoch 379 Batch 44 Loss 0.23559319972991943
[Train] epoch 379 Batch 45 Loss 0.10111305117607117
[Train] epoch 379 Batch 46 Loss 0.23528969287872314
[Train] epoch 379 Batch 47 Loss 0.26838168501853943
[Train] epoch 380 Batch 0 Loss 0.10168196260929108
[Train] epoch 380 Batch 1 Loss 0.16778625547885895
[Train] epoch 380 Batch 2 Loss 0.2694639265537262
[Train] epoch 380 Batch 3 Loss 0.2357122302055359
[Train] epoch 380 Batch 4 Loss 0.134725883603096
[Train] epoch 380 Batch 5 Loss 0.034745391458272934
[Train] epoch 380 Batch 6 Loss 0.16819995641708374
[Train] epoch 380 Batch 7 Loss 0.16833943128585815
[Train] epoch 380 Batch 8 Loss 0.16847896575927734
[Train] epoch 380 Batch 9 Loss 0.1340230405330658
[Train] epoch 380 Batch 10 Loss 0.23612383008003235
[Train] epoch 380 Batch 11 Loss 0.3011115789413452
[Train] epoch 380 Batch 12 Loss 0.2684652805328369
[Train] epoch 380 Batch 13 Loss 0.06833187490701675
[Train] epoch 380 Batch 14 Loss 0.10445185005664825
[Train] epoch 380 Batch 15 Loss 0.10167091339826584
[Train] epoch 380 Batch 16 Loss 0.20068608224391937
[Train] epoch 380 Batch 17 Loss 0.23471790552139282
[Train] epoch 380 Batch 18 Loss 0.10179999470710754
[Train] epoch 380 Batch 19 Loss 0.16998298466205597
[Train] epoch 380 Batch 20 Loss 0.234430193901062
[Train] epoch 380 Batch 21 Loss 0.16887757182121277
[Train] epoch 380 Batch 22 Loss 0.16693732142448425
[Train] epoch 380 Batch 23 Loss 0.2006910890340805
[Train] epoch 380 Batch 24 Loss 0.1345708817243576
[Train] epoch 380 Batch 25 Loss 0.1676342785358429
[Train] epoch 380 Batch 26 Loss 0.20192433893680573
[Train] epoch 380 Batch 27 Loss 0.2013777196407318
[Train] epoch 380 Batch 28 Loss 0.10123557597398758
[Train] epoch 380 Batch 29 Loss 0.06790748238563538
[Train] epoch 380 Batch 30 Loss 0.2031322717666626
[Train] epoch 380 Batch 31 Loss 0.13497762382030487
[Train] epoch 380 Batch 32 Loss 0.1684500277042389
[Train] epoch 380 Batch 33 Loss 0.2352502942085266
[Train] epoch 380 Batch 34 Loss 0.26775944232940674
[Train] epoch 380 Batch 35 Loss 0.06666764616966248
[Train] epoch 380 Batch 36 Loss 0.2012176811695099
[Train] epoch 380 Batch 37 Loss 0.30081596970558167
[Train] epoch 380 Batch 38 Loss 0.06802542507648468
[Train] epoch 380 Batch 39 Loss 0.16762414574623108
[Train] epoch 380 Batch 40 Loss 0.16762343049049377
[Train] epoch 380 Batch 41 Loss 0.20176085829734802
[Train] epoch 380 Batch 42 Loss 0.1676141321659088
[Train] epoch 380 Batch 43 Loss 0.13495750725269318
[Train] epoch 380 Batch 44 Loss 0.16761288046836853
[Train] epoch 380 Batch 45 Loss 0.23509348928928375
[Train] epoch 380 Batch 46 Loss 0.2684209942817688
[Train] epoch 380 Batch 47 Loss 0.20135928690433502
[Train] epoch 381 Batch 0 Loss 0.23644015192985535
[Train] epoch 381 Batch 1 Loss 0.10040745139122009
[Train] epoch 381 Batch 2 Loss 0.10162030160427094
[Train] epoch 381 Batch 3 Loss 0.16842834651470184
[Train] epoch 381 Batch 4 Loss 0.26788681745529175
[Train] epoch 381 Batch 5 Loss 0.13522136211395264
[Train] epoch 381 Batch 6 Loss 0.2350911647081375
[Train] epoch 381 Batch 7 Loss 0.10080499202013016
[Train] epoch 381 Batch 8 Loss 0.20121672749519348
[Train] epoch 381 Batch 9 Loss 0.1690877377986908
[Train] epoch 381 Batch 10 Loss 0.1340004801750183
[Train] epoch 381 Batch 11 Loss 0.2013479471206665
[Train] epoch 381 Batch 12 Loss 0.13400736451148987
[Train] epoch 381 Batch 13 Loss 0.2693392038345337
[Train] epoch 381 Batch 14 Loss 0.13452956080436707
[Train] epoch 381 Batch 15 Loss 0.16881036758422852
[Train] epoch 381 Batch 16 Loss 0.13572880625724792
[Train] epoch 381 Batch 17 Loss 0.13387107849121094
[Train] epoch 381 Batch 18 Loss 0.43492764234542847
[Train] epoch 381 Batch 19 Loss 0.1694658398628235
[Train] epoch 381 Batch 20 Loss 0.034263841807842255
[Train] epoch 381 Batch 21 Loss 0.06720223277807236
[Train] epoch 381 Batch 22 Loss 0.10145556926727295
[Train] epoch 381 Batch 23 Loss 0.035336267203092575
[Train] epoch 381 Batch 24 Loss 0.3350600302219391
[Train] epoch 381 Batch 25 Loss 0.23492000997066498
[Train] epoch 381 Batch 26 Loss 0.1339937001466751
[Train] epoch 381 Batch 27 Loss 0.20132634043693542
[Train] epoch 381 Batch 28 Loss 0.06719815731048584
[Train] epoch 381 Batch 29 Loss 0.1007959395647049
[Train] epoch 381 Batch 30 Loss 0.2685200572013855
[Train] epoch 381 Batch 31 Loss 0.3681110441684723
[Train] epoch 381 Batch 32 Loss 0.26893317699432373
[Train] epoch 381 Batch 33 Loss 0.23373420536518097
[Train] epoch 381 Batch 34 Loss 0.10092838108539581
[Train] epoch 381 Batch 35 Loss 0.13518071174621582
[Train] epoch 381 Batch 36 Loss 0.20169568061828613
[Train] epoch 381 Batch 37 Loss 0.10196469724178314
[Train] epoch 381 Batch 38 Loss 0.20146113634109497
[Train] epoch 381 Batch 39 Loss 0.2691703140735626
[Train] epoch 381 Batch 40 Loss 0.168769970536232
[Train] epoch 381 Batch 41 Loss 0.20130792260169983
[Train] epoch 381 Batch 42 Loss 0.16875946521759033
[Train] epoch 381 Batch 43 Loss 0.10119495540857315
[Train] epoch 381 Batch 44 Loss 0.13385716080665588
[Train] epoch 381 Batch 45 Loss 0.20065255463123322
[Train] epoch 381 Batch 46 Loss 0.10142144560813904
[Train] epoch 381 Batch 47 Loss 0.2023390829563141
[Train] epoch 382 Batch 0 Loss 0.10144039243459702
[Train] epoch 382 Batch 1 Loss 0.2691521644592285
[Train] epoch 382 Batch 2 Loss 0.06769423931837082
[Train] epoch 382 Batch 3 Loss 0.23437950015068054
[Train] epoch 382 Batch 4 Loss 0.16808125376701355
[Train] epoch 382 Batch 5 Loss 0.1348767876625061
[Train] epoch 382 Batch 6 Loss 0.13515526056289673
[Train] epoch 382 Batch 7 Loss 0.16809162497520447
[Train] epoch 382 Batch 8 Loss 0.2688961923122406
[Train] epoch 382 Batch 9 Loss 0.23592600226402283
[Train] epoch 382 Batch 10 Loss 0.10090513527393341
[Train] epoch 382 Batch 11 Loss 0.3360675573348999
[Train] epoch 382 Batch 12 Loss 0.20064598321914673
[Train] epoch 382 Batch 13 Loss 0.10309204459190369
[Train] epoch 382 Batch 14 Loss 0.1007654070854187
[Train] epoch 382 Batch 15 Loss 0.16821876168251038
[Train] epoch 382 Batch 16 Loss 0.06666764616966248
[Train] epoch 382 Batch 17 Loss 0.10154995322227478
[Train] epoch 382 Batch 18 Loss 0.3016924560070038
[Train] epoch 382 Batch 19 Loss 0.2350178360939026
[Train] epoch 382 Batch 20 Loss 0.10039354860782623
[Train] epoch 382 Batch 21 Loss 0.16820520162582397
[Train] epoch 382 Batch 22 Loss 0.13550744950771332
[Train] epoch 382 Batch 23 Loss 0.3015500009059906
[Train] epoch 382 Batch 24 Loss 0.13398082554340363
[Train] epoch 382 Batch 25 Loss 0.16972991824150085
[Train] epoch 382 Batch 26 Loss 0.2005099356174469
[Train] epoch 382 Batch 27 Loss 0.10168241709470749
[Train] epoch 382 Batch 28 Loss 0.10089987516403198
[Train] epoch 382 Batch 29 Loss 0.13447979092597961
[Train] epoch 382 Batch 30 Loss 0.2693142890930176
[Train] epoch 382 Batch 31 Loss 0.10039110481739044
[Train] epoch 382 Batch 32 Loss 0.20164331793785095
[Train] epoch 382 Batch 33 Loss 0.16820597648620605
[Train] epoch 382 Batch 34 Loss 0.10089592635631561
[Train] epoch 382 Batch 35 Loss 0.2684366703033447
[Train] epoch 382 Batch 36 Loss 0.33461710810661316
[Train] epoch 382 Batch 37 Loss 0.20269611477851868
[Train] epoch 382 Batch 38 Loss 0.16790693998336792
[Train] epoch 382 Batch 39 Loss 0.16791877150535583
[Train] epoch 382 Batch 40 Loss 0.30089181661605835
[Train] epoch 382 Batch 41 Loss 0.16768896579742432
[Train] epoch 382 Batch 42 Loss 0.10038914531469345
[Train] epoch 382 Batch 43 Loss 0.10074663162231445
[Train] epoch 382 Batch 44 Loss 0.06779422610998154
[Train] epoch 382 Batch 45 Loss 0.23499144613742828
[Train] epoch 382 Batch 46 Loss 0.16804276406764984
[Train] epoch 382 Batch 47 Loss 0.20155009627342224
[Train] epoch 383 Batch 0 Loss 0.13560055196285248
[Train] epoch 383 Batch 1 Loss 0.03357761353254318
[Train] epoch 383 Batch 2 Loss 0.13531699776649475
[Train] epoch 383 Batch 3 Loss 0.10038740932941437
[Train] epoch 383 Batch 4 Loss 0.1679125428199768
[Train] epoch 383 Batch 5 Loss 0.06829141080379486
[Train] epoch 383 Batch 6 Loss 0.33481255173683167
[Train] epoch 383 Batch 7 Loss 0.3003867268562317
[Train] epoch 383 Batch 8 Loss 0.2018965184688568
[Train] epoch 383 Batch 9 Loss 0.13432547450065613
[Train] epoch 383 Batch 10 Loss 0.20140549540519714
[Train] epoch 383 Batch 11 Loss 0.1675478219985962
[Train] epoch 383 Batch 12 Loss 0.13521970808506012
[Train] epoch 383 Batch 13 Loss 0.13459253311157227
[Train] epoch 383 Batch 14 Loss 0.1007351502776146
[Train] epoch 383 Batch 15 Loss 0.20251454412937164
[Train] epoch 383 Batch 16 Loss 0.20062582194805145
[Train] epoch 383 Batch 17 Loss 0.03421125188469887
[Train] epoch 383 Batch 18 Loss 0.1685887724161148
[Train] epoch 383 Batch 19 Loss 0.16705147922039032
[Train] epoch 383 Batch 20 Loss 0.034059856086969376
[Train] epoch 383 Batch 21 Loss 0.1680217981338501
[Train] epoch 383 Batch 22 Loss 0.20236030220985413
[Train] epoch 383 Batch 23 Loss 0.23545873165130615
[Train] epoch 383 Batch 24 Loss 0.16865326464176178
[Train] epoch 383 Batch 25 Loss 0.03406364843249321
[Train] epoch 383 Batch 26 Loss 0.13507238030433655
[Train] epoch 383 Batch 27 Loss 0.16878655552864075
[Train] epoch 383 Batch 28 Loss 0.33506977558135986
[Train] epoch 383 Batch 29 Loss 0.3013477325439453
[Train] epoch 383 Batch 30 Loss 0.26714974641799927
[Train] epoch 383 Batch 31 Loss 0.16801266372203827
[Train] epoch 383 Batch 32 Loss 0.2688799202442169
[Train] epoch 383 Batch 33 Loss 0.16766658425331116
[Train] epoch 383 Batch 34 Loss 0.3364414572715759
[Train] epoch 383 Batch 35 Loss 0.20137876272201538
[Train] epoch 383 Batch 36 Loss 0.2006237506866455
[Train] epoch 383 Batch 37 Loss 0.1680126041173935
[Train] epoch 383 Batch 38 Loss 0.13457250595092773
[Train] epoch 383 Batch 39 Loss 0.10133826732635498
[Train] epoch 383 Batch 40 Loss 0.13567084074020386
[Train] epoch 383 Batch 41 Loss 0.16690373420715332
[Train] epoch 383 Batch 42 Loss 0.1354004144668579
[Train] epoch 383 Batch 43 Loss 0.1680067777633667
[Train] epoch 383 Batch 44 Loss 0.16814231872558594
[Train] epoch 383 Batch 45 Loss 0.16786828637123108
[Train] epoch 383 Batch 46 Loss 0.1353272646665573
[Train] epoch 383 Batch 47 Loss 0.3677997589111328
[Train] epoch 384 Batch 0 Loss 0.2685213088989258
[Train] epoch 384 Batch 1 Loss 0.16833391785621643
[Train] epoch 384 Batch 2 Loss 0.13442032039165497
[Train] epoch 384 Batch 3 Loss 0.1351725459098816
[Train] epoch 384 Batch 4 Loss 0.10146751999855042
[Train] epoch 384 Batch 5 Loss 0.13531216979026794
[Train] epoch 384 Batch 6 Loss 0.1344229280948639
[Train] epoch 384 Batch 7 Loss 0.1003764420747757
[Train] epoch 384 Batch 8 Loss 0.2010822296142578
[Train] epoch 384 Batch 9 Loss 0.2685037851333618
[Train] epoch 384 Batch 10 Loss 0.1687416136264801
[Train] epoch 384 Batch 11 Loss 0.03512418270111084
[Train] epoch 384 Batch 12 Loss 0.13455981016159058
[Train] epoch 384 Batch 13 Loss 0.10132282227277756
[Train] epoch 384 Batch 14 Loss 0.10159260779619217
[Train] epoch 384 Batch 15 Loss 0.06760860979557037
[Train] epoch 384 Batch 16 Loss 0.2010820508003235
[Train] epoch 384 Batch 17 Loss 0.16751596331596375
[Train] epoch 384 Batch 18 Loss 0.2016851007938385
[Train] epoch 384 Batch 19 Loss 0.26944106817245483
[Train] epoch 384 Batch 20 Loss 0.2344510704278946
[Train] epoch 384 Batch 21 Loss 0.23445028066635132
[Train] epoch 384 Batch 22 Loss 0.1339428722858429
[Train] epoch 384 Batch 23 Loss 0.2671352028846741
[Train] epoch 384 Batch 24 Loss 0.2020171582698822
[Train] epoch 384 Batch 25 Loss 0.20275774598121643
[Train] epoch 384 Batch 26 Loss 0.1344081312417984
[Train] epoch 384 Batch 27 Loss 0.20060749351978302
[Train] epoch 384 Batch 28 Loss 0.26773419976234436
[Train] epoch 384 Batch 29 Loss 0.06761064380407333
[Train] epoch 384 Batch 30 Loss 0.20093166828155518
[Train] epoch 384 Batch 31 Loss 0.20153048634529114
[Train] epoch 384 Batch 32 Loss 0.06820175796747208
[Train] epoch 384 Batch 33 Loss 0.3009750247001648
[Train] epoch 384 Batch 34 Loss 0.20093944668769836
[Train] epoch 384 Batch 35 Loss 0.06867268681526184
[Train] epoch 384 Batch 36 Loss 0.10144239664077759
[Train] epoch 384 Batch 37 Loss 0.034166064113378525
[Train] epoch 384 Batch 38 Loss 0.200739324092865
[Train] epoch 384 Batch 39 Loss 0.2683287560939789
[Train] epoch 384 Batch 40 Loss 0.033703356981277466
[Train] epoch 384 Batch 41 Loss 0.2683268189430237
[Train] epoch 384 Batch 42 Loss 0.16823409497737885
[Train] epoch 384 Batch 43 Loss 0.2027251124382019
[Train] epoch 384 Batch 44 Loss 0.2671326994895935
[Train] epoch 384 Batch 45 Loss 0.2349034547805786
[Train] epoch 384 Batch 46 Loss 0.2684626579284668
[Train] epoch 384 Batch 47 Loss 0.23416605591773987
[Train] epoch 385 Batch 0 Loss 0.13378748297691345
[Train] epoch 385 Batch 1 Loss 0.20225630700588226
[Train] epoch 385 Batch 2 Loss 0.06772425770759583
[Train] epoch 385 Batch 3 Loss 0.034621842205524445
[Train] epoch 385 Batch 4 Loss 0.2347559928894043
[Train] epoch 385 Batch 5 Loss 0.36794769763946533
[Train] epoch 385 Batch 6 Loss 0.2681831419467926
[Train] epoch 385 Batch 7 Loss 0.13497890532016754
[Train] epoch 385 Batch 8 Loss 0.3351181149482727
[Train] epoch 385 Batch 9 Loss 0.30293041467666626
[Train] epoch 385 Batch 10 Loss 0.26799407601356506
[Train] epoch 385 Batch 11 Loss 0.40104007720947266
[Train] epoch 385 Batch 12 Loss 0.033558934926986694
[Train] epoch 385 Batch 13 Loss 0.16689711809158325
[Train] epoch 385 Batch 14 Loss 0.03415273502469063
[Train] epoch 385 Batch 15 Loss 0.10036545991897583
[Train] epoch 385 Batch 16 Loss 0.03355830907821655
[Train] epoch 385 Batch 17 Loss 0.1009531319141388
[Train] epoch 385 Batch 18 Loss 0.30081209540367126
[Train] epoch 385 Batch 19 Loss 0.1674889326095581
[Train] epoch 385 Batch 20 Loss 0.06816954910755157
[Train] epoch 385 Batch 21 Loss 0.16852688789367676
[Train] epoch 385 Batch 22 Loss 0.16762268543243408
[Train] epoch 385 Batch 23 Loss 0.13558560609817505
[Train] epoch 385 Batch 24 Loss 0.23442339897155762
[Train] epoch 385 Batch 25 Loss 0.1691133826971054
[Train] epoch 385 Batch 26 Loss 0.33496004343032837
[Train] epoch 385 Batch 27 Loss 0.03369692340493202
[Train] epoch 385 Batch 28 Loss 0.16702991724014282
[Train] epoch 385 Batch 29 Loss 0.06712229549884796
[Train] epoch 385 Batch 30 Loss 0.20130881667137146
[Train] epoch 385 Batch 31 Loss 0.2017674595117569
[Train] epoch 385 Batch 32 Loss 0.13689957559108734
[Train] epoch 385 Batch 33 Loss 0.20117178559303284
[Train] epoch 385 Batch 34 Loss 0.23473617434501648
[Train] epoch 385 Batch 35 Loss 0.03414818271994591
[Train] epoch 385 Batch 36 Loss 0.20162740349769592
[Train] epoch 385 Batch 37 Loss 0.2349066138267517
[Train] epoch 385 Batch 38 Loss 0.10185115039348602
[Train] epoch 385 Batch 39 Loss 0.10170498490333557
[Train] epoch 385 Batch 40 Loss 0.33377984166145325
[Train] epoch 385 Batch 41 Loss 0.1349550485610962
[Train] epoch 385 Batch 42 Loss 0.16747738420963287
[Train] epoch 385 Batch 43 Loss 0.16747185587882996
[Train] epoch 385 Batch 44 Loss 0.16774585843086243
[Train] epoch 385 Batch 45 Loss 0.1353849470615387
[Train] epoch 385 Batch 46 Loss 0.23571287095546722
[Train] epoch 385 Batch 47 Loss 0.1349484771490097
[Train] epoch 386 Batch 0 Loss 0.26858407258987427
[Train] epoch 386 Batch 1 Loss 0.20103052258491516
[Train] epoch 386 Batch 2 Loss 0.26796531677246094
[Train] epoch 386 Batch 3 Loss 0.16862531006336212
[Train] epoch 386 Batch 4 Loss 0.16774027049541473
[Train] epoch 386 Batch 5 Loss 0.10022416710853577
[Train] epoch 386 Batch 6 Loss 0.13435569405555725
[Train] epoch 386 Batch 7 Loss 0.1346226930618286
[Train] epoch 386 Batch 8 Loss 0.16817784309387207
[Train] epoch 386 Batch 9 Loss 0.10123847424983978
[Train] epoch 386 Batch 10 Loss 0.10066395252943039
[Train] epoch 386 Batch 11 Loss 0.30079174041748047
[Train] epoch 386 Batch 12 Loss 0.13479667901992798
[Train] epoch 386 Batch 13 Loss 0.1343466341495514
[Train] epoch 386 Batch 14 Loss 0.1349278837442398
[Train] epoch 386 Batch 15 Loss 0.20203256607055664
[Train] epoch 386 Batch 16 Loss 0.20172998309135437
[Train] epoch 386 Batch 17 Loss 0.23443737626075745
[Train] epoch 386 Batch 18 Loss 0.1683361530303955
[Train] epoch 386 Batch 19 Loss 0.3019384741783142
[Train] epoch 386 Batch 20 Loss 0.1337715983390808
[Train] epoch 386 Batch 21 Loss 0.03355050086975098
[Train] epoch 386 Batch 22 Loss 0.1682121753692627
[Train] epoch 386 Batch 23 Loss 0.16772815585136414
[Train] epoch 386 Batch 24 Loss 0.16876912117004395
[Train] epoch 386 Batch 25 Loss 0.16816289722919464
[Train] epoch 386 Batch 26 Loss 0.03412726894021034
[Train] epoch 386 Batch 27 Loss 0.13552674651145935
[Train] epoch 386 Batch 28 Loss 0.1349133551120758
[Train] epoch 386 Batch 29 Loss 0.1009257584810257
[Train] epoch 386 Batch 30 Loss 0.26666736602783203
[Train] epoch 386 Batch 31 Loss 0.2673724889755249
[Train] epoch 386 Batch 32 Loss 0.16802844405174255
[Train] epoch 386 Batch 33 Loss 0.23454701900482178
[Train] epoch 386 Batch 34 Loss 0.23569166660308838
[Train] epoch 386 Batch 35 Loss 0.13446995615959167
[Train] epoch 386 Batch 36 Loss 0.26737087965011597
[Train] epoch 386 Batch 37 Loss 0.2682376503944397
[Train] epoch 386 Batch 38 Loss 0.06853002309799194
[Train] epoch 386 Batch 39 Loss 0.20240050554275513
[Train] epoch 386 Batch 40 Loss 0.2021407186985016
[Train] epoch 386 Batch 41 Loss 0.23424822092056274
[Train] epoch 386 Batch 42 Loss 0.23354685306549072
[Train] epoch 386 Batch 43 Loss 0.10121037811040878
[Train] epoch 386 Batch 44 Loss 0.1681511104106903
[Train] epoch 386 Batch 45 Loss 0.20099636912345886
[Train] epoch 386 Batch 46 Loss 0.03411267697811127
[Train] epoch 386 Batch 47 Loss 0.20113232731819153
[Train] epoch 387 Batch 0 Loss 0.2006988525390625
[Train] epoch 387 Batch 1 Loss 0.20155023038387299
[Train] epoch 387 Batch 2 Loss 1.0728851975727594e-06
[Train] epoch 387 Batch 3 Loss 0.10133688151836395
[Train] epoch 387 Batch 4 Loss 0.23466932773590088
[Train] epoch 387 Batch 5 Loss 0.20099622011184692
[Train] epoch 387 Batch 6 Loss 0.30104368925094604
[Train] epoch 387 Batch 7 Loss 0.1686953455209732
[Train] epoch 387 Batch 8 Loss 0.10147347301244736
[Train] epoch 387 Batch 9 Loss 0.33389630913734436
[Train] epoch 387 Batch 10 Loss 0.13461792469024658
[Train] epoch 387 Batch 11 Loss 0.03368066996335983
[Train] epoch 387 Batch 12 Loss 0.2028319537639618
[Train] epoch 387 Batch 13 Loss 0.10133354365825653
[Train] epoch 387 Batch 14 Loss 0.20183807611465454
[Train] epoch 387 Batch 15 Loss 0.1010662391781807
[Train] epoch 387 Batch 16 Loss 0.06752169132232666
[Train] epoch 387 Batch 17 Loss 0.2011200487613678
[Train] epoch 387 Batch 18 Loss 0.23509100079536438
[Train] epoch 387 Batch 19 Loss 0.26794302463531494
[Train] epoch 387 Batch 20 Loss 0.13431629538536072
[Train] epoch 387 Batch 21 Loss 0.2012697160243988
[Train] epoch 387 Batch 22 Loss 0.16701218485832214
[Train] epoch 387 Batch 23 Loss 0.06764763593673706
[Train] epoch 387 Batch 24 Loss 0.1675695925951004
[Train] epoch 387 Batch 25 Loss 0.3351288437843323
[Train] epoch 387 Batch 26 Loss 0.23354682326316833
[Train] epoch 387 Batch 27 Loss 0.2691792845726013
[Train] epoch 387 Batch 28 Loss 0.23354652523994446
[Train] epoch 387 Batch 29 Loss 0.16743165254592896
[Train] epoch 387 Batch 30 Loss 0.1341785490512848
[Train] epoch 387 Batch 31 Loss 0.3010314404964447
[Train] epoch 387 Batch 32 Loss 0.06735450029373169
[Train] epoch 387 Batch 33 Loss 0.13430850207805634
[Train] epoch 387 Batch 34 Loss 0.3358404040336609
[Train] epoch 387 Batch 35 Loss 0.06709065288305283
[Train] epoch 387 Batch 36 Loss 0.1681184470653534
[Train] epoch 387 Batch 37 Loss 0.10131558030843735
[Train] epoch 387 Batch 38 Loss 0.1341787725687027
[Train] epoch 387 Batch 39 Loss 0.10144536197185516
[Train] epoch 387 Batch 40 Loss 0.20097121596336365
[Train] epoch 387 Batch 41 Loss 0.10117319226264954
[Train] epoch 387 Batch 42 Loss 0.2351973056793213
[Train] epoch 387 Batch 43 Loss 0.1682634949684143
[Train] epoch 387 Batch 44 Loss 0.20165151357650757
[Train] epoch 387 Batch 45 Loss 0.2015194445848465
[Train] epoch 387 Batch 46 Loss 0.1687878966331482
[Train] epoch 387 Batch 47 Loss 0.1688138246536255
[Train] epoch 388 Batch 0 Loss 0.23435527086257935
[Train] epoch 388 Batch 1 Loss 0.10130584239959717
[Train] epoch 388 Batch 2 Loss 0.13401387631893158
[Train] epoch 388 Batch 3 Loss 0.36823076009750366
[Train] epoch 388 Batch 4 Loss 0.20219072699546814
[Train] epoch 388 Batch 5 Loss 0.23589041829109192
[Train] epoch 388 Batch 6 Loss 0.23476381599903107
[Train] epoch 388 Batch 7 Loss 0.10075701028108597
[Train] epoch 388 Batch 8 Loss 0.16741910576820374
[Train] epoch 388 Batch 9 Loss 0.40151065587997437
[Train] epoch 388 Batch 10 Loss 0.2009599208831787
[Train] epoch 388 Batch 11 Loss 0.13592921197414398
[Train] epoch 388 Batch 12 Loss 0.20108702778816223
[Train] epoch 388 Batch 13 Loss 0.1011662632226944
[Train] epoch 388 Batch 14 Loss 0.16864879429340363
[Train] epoch 388 Batch 15 Loss 0.1353740245103836
[Train] epoch 388 Batch 16 Loss 0.2024308741092682
[Train] epoch 388 Batch 17 Loss 0.3678291440010071
[Train] epoch 388 Batch 18 Loss 0.06749343872070312
[Train] epoch 388 Batch 19 Loss 0.20108133554458618
[Train] epoch 388 Batch 20 Loss 0.26787468791007996
[Train] epoch 388 Batch 21 Loss 0.23408252000808716
[Train] epoch 388 Batch 22 Loss 0.23354098200798035
[Train] epoch 388 Batch 23 Loss 0.23610566556453705
[Train] epoch 388 Batch 24 Loss 0.06762117147445679
[Train] epoch 388 Batch 25 Loss 0.03408069908618927
[Train] epoch 388 Batch 26 Loss 0.20082241296768188
[Train] epoch 388 Batch 27 Loss 0.1351068913936615
[Train] epoch 388 Batch 28 Loss 0.20161747932434082
[Train] epoch 388 Batch 29 Loss 0.16686967015266418
[Train] epoch 388 Batch 30 Loss 0.13481095433235168
[Train] epoch 388 Batch 31 Loss 0.10033327341079712
[Train] epoch 388 Batch 32 Loss 0.10127788782119751
[Train] epoch 388 Batch 33 Loss 0.06666764616966248
[Train] epoch 388 Batch 34 Loss 0.1683533787727356
[Train] epoch 388 Batch 35 Loss 0.20107059180736542
[Train] epoch 388 Batch 36 Loss 0.2340681254863739
[Train] epoch 388 Batch 37 Loss 0.10115152597427368
[Train] epoch 388 Batch 38 Loss 0.03476714342832565
[Train] epoch 388 Batch 39 Loss 0.20162244141101837
[Train] epoch 388 Batch 40 Loss 0.06732964515686035
[Train] epoch 388 Batch 41 Loss 0.20146852731704712
[Train] epoch 388 Batch 42 Loss 0.2009400874376297
[Train] epoch 388 Batch 43 Loss 0.20134009420871735
[Train] epoch 388 Batch 44 Loss 0.16740188002586365
[Train] epoch 388 Batch 45 Loss 0.13414116203784943
[Train] epoch 388 Batch 46 Loss 0.06707078218460083
[Train] epoch 388 Batch 47 Loss 0.23366445302963257
[Train] epoch 389 Batch 0 Loss 0.06747272610664368
[Train] epoch 389 Batch 1 Loss 0.30154120922088623
[Train] epoch 389 Batch 2 Loss 0.10113851726055145
[Train] epoch 389 Batch 3 Loss 0.06713449954986572
[Train] epoch 389 Batch 4 Loss 0.26896020770072937
[Train] epoch 389 Batch 5 Loss 0.10130168497562408
[Train] epoch 389 Batch 6 Loss 0.1669960916042328
[Train] epoch 389 Batch 7 Loss 0.23354606330394745
[Train] epoch 389 Batch 8 Loss 0.20041851699352264
[Train] epoch 389 Batch 9 Loss 0.10105857253074646
[Train] epoch 389 Batch 10 Loss 0.20178422331809998
[Train] epoch 389 Batch 11 Loss 0.16743040084838867
[Train] epoch 389 Batch 12 Loss 0.33475378155708313
[Train] epoch 389 Batch 13 Loss 0.1017637848854065
[Train] epoch 389 Batch 14 Loss 0.2685260772705078
[Train] epoch 389 Batch 15 Loss 0.13389334082603455
[Train] epoch 389 Batch 16 Loss 0.10164931416511536
[Train] epoch 389 Batch 17 Loss 0.16932275891304016
[Train] epoch 389 Batch 18 Loss 0.10165423154830933
[Train] epoch 389 Batch 19 Loss 0.3016166687011719
[Train] epoch 389 Batch 20 Loss 0.2011343538761139
[Train] epoch 389 Batch 21 Loss 0.30210211873054504
[Train] epoch 389 Batch 22 Loss 0.10035169124603271
[Train] epoch 389 Batch 23 Loss 0.13403655588626862
[Train] epoch 389 Batch 24 Loss 0.167448952794075
[Train] epoch 389 Batch 25 Loss 0.16832849383354187
[Train] epoch 389 Batch 26 Loss 0.20070487260818481
[Train] epoch 389 Batch 27 Loss 0.10022074729204178
[Train] epoch 389 Batch 28 Loss 0.10179533064365387
[Train] epoch 389 Batch 29 Loss 0.03398897498846054
[Train] epoch 389 Batch 30 Loss 1.0728851975727594e-06
[Train] epoch 389 Batch 31 Loss 0.1682935208082199
[Train] epoch 389 Batch 32 Loss 0.13477110862731934
[Train] epoch 389 Batch 33 Loss 0.33548587560653687
[Train] epoch 389 Batch 34 Loss 0.13446947932243347
[Train] epoch 389 Batch 35 Loss 0.23539897799491882
[Train] epoch 389 Batch 36 Loss 0.3344782590866089
[Train] epoch 389 Batch 37 Loss 0.16833624243736267
[Train] epoch 389 Batch 38 Loss 0.16890250146389008
[Train] epoch 389 Batch 39 Loss 0.067539282143116
[Train] epoch 389 Batch 40 Loss 0.2683764100074768
[Train] epoch 389 Batch 41 Loss 0.16916561126708984
[Train] epoch 389 Batch 42 Loss 0.2017081379890442
[Train] epoch 389 Batch 43 Loss 0.2336859405040741
[Train] epoch 389 Batch 44 Loss 0.1340375542640686
[Train] epoch 389 Batch 45 Loss 0.23438848555088043
[Train] epoch 389 Batch 46 Loss 0.20140568912029266
[Train] epoch 389 Batch 47 Loss 0.1681564897298813
[Train] epoch 390 Batch 0 Loss 0.06780502200126648
[Train] epoch 390 Batch 1 Loss 0.20113277435302734
[Train] epoch 390 Batch 2 Loss 0.23454192280769348
[Train] epoch 390 Batch 3 Loss 0.16802051663398743
[Train] epoch 390 Batch 4 Loss 0.20169782638549805
[Train] epoch 390 Batch 5 Loss 0.30078059434890747
[Train] epoch 390 Batch 6 Loss 0.0671028345823288
[Train] epoch 390 Batch 7 Loss 0.267228901386261
[Train] epoch 390 Batch 8 Loss 0.033982016146183014
[Train] epoch 390 Batch 9 Loss 0.1678849756717682
[Train] epoch 390 Batch 10 Loss 0.2676624655723572
[Train] epoch 390 Batch 11 Loss 0.23649749159812927
[Train] epoch 390 Batch 12 Loss 0.13489270210266113
[Train] epoch 390 Batch 13 Loss 0.33558163046836853
[Train] epoch 390 Batch 14 Loss 0.23496782779693604
[Train] epoch 390 Batch 15 Loss 0.10133976489305496
[Train] epoch 390 Batch 16 Loss 0.10104077309370041
[Train] epoch 390 Batch 17 Loss 0.16701385378837585
[Train] epoch 390 Batch 18 Loss 0.06752326339483261
[Train] epoch 390 Batch 19 Loss 0.13560637831687927
[Train] epoch 390 Batch 20 Loss 0.16830389201641083
[Train] epoch 390 Batch 21 Loss 0.1347491592168808
[Train] epoch 390 Batch 22 Loss 0.2687673568725586
[Train] epoch 390 Batch 23 Loss 0.20055678486824036
[Train] epoch 390 Batch 24 Loss 0.23466935753822327
[Train] epoch 390 Batch 25 Loss 0.10132627189159393
[Train] epoch 390 Batch 26 Loss 0.3013296127319336
[Train] epoch 390 Batch 27 Loss 0.20068968832492828
[Train] epoch 390 Batch 28 Loss 0.13445156812667847
[Train] epoch 390 Batch 29 Loss 0.03367838263511658
[Train] epoch 390 Batch 30 Loss 0.1351727992296219
[Train] epoch 390 Batch 31 Loss 0.06778290122747421
[Train] epoch 390 Batch 32 Loss 0.1684192419052124
[Train] epoch 390 Batch 33 Loss 0.13444362580776215
[Train] epoch 390 Batch 34 Loss 0.13375690579414368
[Train] epoch 390 Batch 35 Loss 0.06722392141819
[Train] epoch 390 Batch 36 Loss 0.30132144689559937
[Train] epoch 390 Batch 37 Loss 0.06735263764858246
[Train] epoch 390 Batch 38 Loss 0.13528817892074585
[Train] epoch 390 Batch 39 Loss 0.3027256429195404
[Train] epoch 390 Batch 40 Loss 0.13401803374290466
[Train] epoch 390 Batch 41 Loss 0.20110931992530823
[Train] epoch 390 Batch 42 Loss 0.3674249053001404
[Train] epoch 390 Batch 43 Loss 0.1343037188053131
[Train] epoch 390 Batch 44 Loss 0.234819233417511
[Train] epoch 390 Batch 45 Loss 0.30076128244400024
[Train] epoch 390 Batch 46 Loss 0.06848271191120148
[Train] epoch 390 Batch 47 Loss 0.1344345211982727
[Train] epoch 391 Batch 0 Loss 0.13430914282798767
[Train] epoch 391 Batch 1 Loss 0.10089295357465744
[Train] epoch 391 Batch 2 Loss 0.1677105575799942
[Train] epoch 391 Batch 3 Loss 0.035353705286979675
[Train] epoch 391 Batch 4 Loss 0.16742905974388123
[Train] epoch 391 Batch 5 Loss 0.30227965116500854
[Train] epoch 391 Batch 6 Loss 0.3019866943359375
[Train] epoch 391 Batch 7 Loss 0.10185626149177551
[Train] epoch 391 Batch 8 Loss 0.16783857345581055
[Train] epoch 391 Batch 9 Loss 0.10101861506700516
[Train] epoch 391 Batch 10 Loss 0.20096872746944427
[Train] epoch 391 Batch 11 Loss 0.26734504103660583
[Train] epoch 391 Batch 12 Loss 0.23463523387908936
[Train] epoch 391 Batch 13 Loss 0.1674243062734604
[Train] epoch 391 Batch 14 Loss 0.16741982102394104
[Train] epoch 391 Batch 15 Loss 0.16729426383972168
[Train] epoch 391 Batch 16 Loss 0.20137454569339752
[Train] epoch 391 Batch 17 Loss 0.23436927795410156
[Train] epoch 391 Batch 18 Loss 0.1683809906244278
[Train] epoch 391 Batch 19 Loss 0.06749693304300308
[Train] epoch 391 Batch 20 Loss 0.2682957649230957
[Train] epoch 391 Batch 21 Loss 0.20178170502185822
[Train] epoch 391 Batch 22 Loss 0.10103568434715271
[Train] epoch 391 Batch 23 Loss 0.0012384576257318258
[Train] epoch 391 Batch 24 Loss 0.3342888653278351
[Train] epoch 391 Batch 25 Loss 0.2346252053976059
[Train] epoch 391 Batch 26 Loss 0.20134805142879486
[Train] epoch 391 Batch 27 Loss 0.1348266750574112
[Train] epoch 391 Batch 28 Loss 0.30074256658554077
[Train] epoch 391 Batch 29 Loss 0.10088010132312775
[Train] epoch 391 Batch 30 Loss 0.13428914546966553
[Train] epoch 391 Batch 31 Loss 0.13428467512130737
[Train] epoch 391 Batch 32 Loss 0.1340060830116272
[Train] epoch 391 Batch 33 Loss 0.26856210827827454
[Train] epoch 391 Batch 34 Loss 0.2682873010635376
[Train] epoch 391 Batch 35 Loss 0.20174969732761383
[Train] epoch 391 Batch 36 Loss 0.10087671875953674
[Train] epoch 391 Batch 37 Loss 0.16794562339782715
[Train] epoch 391 Batch 38 Loss 0.2010767161846161
[Train] epoch 391 Batch 39 Loss 0.16740825772285461
[Train] epoch 391 Batch 40 Loss 0.16767022013664246
[Train] epoch 391 Batch 41 Loss 0.06855334341526031
[Train] epoch 391 Batch 42 Loss 0.16781648993492126
[Train] epoch 391 Batch 43 Loss 0.2010732740163803
[Train] epoch 391 Batch 44 Loss 0.20174294710159302
[Train] epoch 391 Batch 45 Loss 0.06748539954423904
[Train] epoch 391 Batch 46 Loss 0.16686804592609406
[Train] epoch 391 Batch 47 Loss 0.20175525546073914
[Train] epoch 392 Batch 0 Loss 0.26827293634414673
[Train] epoch 392 Batch 1 Loss 0.1349387764930725
[Train] epoch 392 Batch 2 Loss 0.13440197706222534
[Train] epoch 392 Batch 3 Loss 0.133334219455719
[Train] epoch 392 Batch 4 Loss 0.2343445122241974
[Train] epoch 392 Batch 5 Loss 0.20053565502166748
[Train] epoch 392 Batch 6 Loss 0.1684744656085968
[Train] epoch 392 Batch 7 Loss 0.26813095808029175
[Train] epoch 392 Batch 8 Loss 0.20040321350097656
[Train] epoch 392 Batch 9 Loss 0.1337326467037201
[Train] epoch 392 Batch 10 Loss 0.3008646070957184
[Train] epoch 392 Batch 11 Loss 0.10099203884601593
[Train] epoch 392 Batch 12 Loss 0.16726797819137573
[Train] epoch 392 Batch 13 Loss 0.06747789680957794
[Train] epoch 392 Batch 14 Loss 0.20292851328849792
[Train] epoch 392 Batch 15 Loss 0.16832713782787323
[Train] epoch 392 Batch 16 Loss 0.10113538801670074
[Train] epoch 392 Batch 17 Loss 0.16793230175971985
[Train] epoch 392 Batch 18 Loss 0.20146286487579346
[Train] epoch 392 Batch 19 Loss 0.16739997267723083
[Train] epoch 392 Batch 20 Loss 0.16765423119068146
[Train] epoch 392 Batch 21 Loss 0.1676536649465561
[Train] epoch 392 Batch 22 Loss 0.3012542426586151
[Train] epoch 392 Batch 23 Loss 0.13426624238491058
[Train] epoch 392 Batch 24 Loss 0.06746848672628403
[Train] epoch 392 Batch 25 Loss 0.33506518602371216
[Train] epoch 392 Batch 26 Loss 0.10138580948114395
[Train] epoch 392 Batch 27 Loss 0.06759002804756165
[Train] epoch 392 Batch 28 Loss 0.16751918196678162
[Train] epoch 392 Batch 29 Loss 0.302033931016922
[Train] epoch 392 Batch 30 Loss 0.10085520893335342
[Train] epoch 392 Batch 31 Loss 0.23470745980739594
[Train] epoch 392 Batch 32 Loss 0.13438382744789124
[Train] epoch 392 Batch 33 Loss 0.13413101434707642
[Train] epoch 392 Batch 34 Loss 0.13373057544231415
[Train] epoch 392 Batch 35 Loss 0.23472604155540466
[Train] epoch 392 Batch 36 Loss 0.20249086618423462
[Train] epoch 392 Batch 37 Loss 0.134129136800766
[Train] epoch 392 Batch 38 Loss 0.2345830798149109
[Train] epoch 392 Batch 39 Loss 0.3688313364982605
[Train] epoch 392 Batch 40 Loss 0.13451839983463287
[Train] epoch 392 Batch 41 Loss 0.1679103821516037
[Train] epoch 392 Batch 42 Loss 0.16778382658958435
[Train] epoch 392 Batch 43 Loss 0.13569463789463043
[Train] epoch 392 Batch 44 Loss 0.16764038801193237
[Train] epoch 392 Batch 45 Loss 0.10111472755670547
[Train] epoch 392 Batch 46 Loss 0.1672583818435669
[Train] epoch 392 Batch 47 Loss 0.06745956838130951
[Train] epoch 393 Batch 0 Loss 0.13398155570030212
[Train] epoch 393 Batch 1 Loss 0.20170073211193085
[Train] epoch 393 Batch 2 Loss 0.3343721926212311
[Train] epoch 393 Batch 3 Loss 0.0684874951839447
[Train] epoch 393 Batch 4 Loss 0.06863200664520264
[Train] epoch 393 Batch 5 Loss 0.10162463784217834
[Train] epoch 393 Batch 6 Loss 0.20194965600967407
[Train] epoch 393 Batch 7 Loss 0.0674501284956932
[Train] epoch 393 Batch 8 Loss 0.03353062644600868
[Train] epoch 393 Batch 9 Loss 0.06744509190320969
[Train] epoch 393 Batch 10 Loss 0.10096866637468338
[Train] epoch 393 Batch 11 Loss 0.23469291627407074
[Train] epoch 393 Batch 12 Loss 0.2349565029144287
[Train] epoch 393 Batch 13 Loss 0.03391711413860321
[Train] epoch 393 Batch 14 Loss 0.13411176204681396
[Train] epoch 393 Batch 15 Loss 0.36750298738479614
[Train] epoch 393 Batch 16 Loss 0.13514070212841034
[Train] epoch 393 Batch 17 Loss 0.23468881845474243
[Train] epoch 393 Batch 18 Loss 0.10058141499757767
[Train] epoch 393 Batch 19 Loss 0.201294407248497
[Train] epoch 393 Batch 20 Loss 0.16801688075065613
[Train] epoch 393 Batch 21 Loss 0.167500838637352
[Train] epoch 393 Batch 22 Loss 0.1676342785358429
[Train] epoch 393 Batch 23 Loss 0.16801153123378754
[Train] epoch 393 Batch 24 Loss 0.16750288009643555
[Train] epoch 393 Batch 25 Loss 0.23416903614997864
[Train] epoch 393 Batch 26 Loss 0.06744115799665451
[Train] epoch 393 Batch 27 Loss 0.10108484327793121
[Train] epoch 393 Batch 28 Loss 0.2670503556728363
[Train] epoch 393 Batch 29 Loss 0.30160215497016907
[Train] epoch 393 Batch 30 Loss 0.16737326979637146
[Train] epoch 393 Batch 31 Loss 0.33499300479888916
[Train] epoch 393 Batch 32 Loss 0.2689681649208069
[Train] epoch 393 Batch 33 Loss 0.30032020807266235
[Train] epoch 393 Batch 34 Loss 0.20128241181373596
[Train] epoch 393 Batch 35 Loss 0.1676231175661087
[Train] epoch 393 Batch 36 Loss 0.20127153396606445
[Train] epoch 393 Batch 37 Loss 0.10133977234363556
[Train] epoch 393 Batch 38 Loss 0.10159486532211304
[Train] epoch 393 Batch 39 Loss 0.3014627993106842
[Train] epoch 393 Batch 40 Loss 0.16736915707588196
[Train] epoch 393 Batch 41 Loss 0.1346009373664856
[Train] epoch 393 Batch 42 Loss 0.1677481085062027
[Train] epoch 393 Batch 43 Loss 0.16723529994487762
[Train] epoch 393 Batch 44 Loss 0.2010151743888855
[Train] epoch 393 Batch 45 Loss 0.2019052356481552
[Train] epoch 393 Batch 46 Loss 0.2341594099998474
[Train] epoch 393 Batch 47 Loss 0.06730152666568756
[Train] epoch 394 Batch 0 Loss 0.20127154886722565
[Train] epoch 394 Batch 1 Loss 0.23441028594970703
[Train] epoch 394 Batch 2 Loss 0.10133101046085358
[Train] epoch 394 Batch 3 Loss 0.1688782274723053
[Train] epoch 394 Batch 4 Loss 0.0675516128540039
[Train] epoch 394 Batch 5 Loss 0.23428091406822205
[Train] epoch 394 Batch 6 Loss 0.23453234136104584
[Train] epoch 394 Batch 7 Loss 0.23453161120414734
[Train] epoch 394 Batch 8 Loss 0.3011974096298218
[Train] epoch 394 Batch 9 Loss 0.3338354527950287
[Train] epoch 394 Batch 10 Loss 0.10018777847290039
[Train] epoch 394 Batch 11 Loss 0.13434208929538727
[Train] epoch 394 Batch 12 Loss 0.16824091970920563
[Train] epoch 394 Batch 13 Loss 0.0680505558848381
[Train] epoch 394 Batch 14 Loss 0.10194559395313263
[Train] epoch 394 Batch 15 Loss 0.13458745181560516
[Train] epoch 394 Batch 16 Loss 0.16798533499240875
[Train] epoch 394 Batch 17 Loss 0.13420870900154114
[Train] epoch 394 Batch 18 Loss 0.2356504648923874
[Train] epoch 394 Batch 19 Loss 0.13471198081970215
[Train] epoch 394 Batch 20 Loss 0.03402131423354149
[Train] epoch 394 Batch 21 Loss 0.10106527805328369
[Train] epoch 394 Batch 22 Loss 0.16735360026359558
[Train] epoch 394 Batch 23 Loss 0.06779973208904266
[Train] epoch 394 Batch 24 Loss 0.1669786274433136
[Train] epoch 394 Batch 25 Loss 0.06804029643535614
[Train] epoch 394 Batch 26 Loss 0.23451465368270874
[Train] epoch 394 Batch 27 Loss 0.06666764616966248
[Train] epoch 394 Batch 28 Loss 0.13432833552360535
[Train] epoch 394 Batch 29 Loss 0.16697773337364197
[Train] epoch 394 Batch 30 Loss 0.10105696320533752
[Train] epoch 394 Batch 31 Loss 0.06704042851924896
[Train] epoch 394 Batch 32 Loss 0.36834463477134705
[Train] epoch 394 Batch 33 Loss 0.2679094672203064
[Train] epoch 394 Batch 34 Loss 0.20124512910842896
[Train] epoch 394 Batch 35 Loss 0.3015506863594055
[Train] epoch 394 Batch 36 Loss 0.1685853749513626
[Train] epoch 394 Batch 37 Loss 0.20049411058425903
[Train] epoch 394 Batch 38 Loss 0.2682742178440094
[Train] epoch 394 Batch 39 Loss 0.30068033933639526
[Train] epoch 394 Batch 40 Loss 0.06740899384021759
[Train] epoch 394 Batch 41 Loss 0.13408097624778748
[Train] epoch 394 Batch 42 Loss 0.20036806166172028
[Train] epoch 394 Batch 43 Loss 0.16809135675430298
[Train] epoch 394 Batch 44 Loss 0.20086777210235596
[Train] epoch 394 Batch 45 Loss 0.10130095481872559
[Train] epoch 394 Batch 46 Loss 0.23462717235088348
[Train] epoch 394 Batch 47 Loss 0.3016619086265564
[Train] epoch 395 Batch 0 Loss 0.2342575192451477
[Train] epoch 395 Batch 1 Loss 0.1673433631658554
[Train] epoch 395 Batch 2 Loss 0.20172090828418732
[Train] epoch 395 Batch 3 Loss 0.23450177907943726
[Train] epoch 395 Batch 4 Loss 0.20049026608467102
[Train] epoch 395 Batch 5 Loss 0.1337016224861145
[Train] epoch 395 Batch 6 Loss 0.034011200070381165
[Train] epoch 395 Batch 7 Loss 0.13369840383529663
[Train] epoch 395 Batch 8 Loss 0.16795656085014343
[Train] epoch 395 Batch 9 Loss 0.20110148191452026
[Train] epoch 395 Batch 10 Loss 0.06739788502454758
[Train] epoch 395 Batch 11 Loss 0.23351585865020752
[Train] epoch 395 Batch 12 Loss 0.13517141342163086
[Train] epoch 395 Batch 13 Loss 0.13431143760681152
[Train] epoch 395 Batch 14 Loss 0.23522990942001343
[Train] epoch 395 Batch 15 Loss 0.23412886261940002
[Train] epoch 395 Batch 16 Loss 0.10116073489189148
[Train] epoch 395 Batch 17 Loss 0.10128379613161087
[Train] epoch 395 Batch 18 Loss 0.13394370675086975
[Train] epoch 395 Batch 19 Loss 0.26788851618766785
[Train] epoch 395 Batch 20 Loss 0.10103465616703033
[Train] epoch 395 Batch 21 Loss 0.26861631870269775
[Train] epoch 395 Batch 22 Loss 0.1679469645023346
[Train] epoch 395 Batch 23 Loss 0.06800922006368637
[Train] epoch 395 Batch 24 Loss 0.20036165416240692
[Train] epoch 395 Batch 25 Loss 0.26703375577926636
[Train] epoch 395 Batch 26 Loss 0.13455015420913696
[Train] epoch 395 Batch 27 Loss 0.034366633743047714
[Train] epoch 395 Batch 28 Loss 0.2340000718832016
[Train] epoch 395 Batch 29 Loss 0.33527135848999023
[Train] epoch 395 Batch 30 Loss 0.2343617081642151
[Train] epoch 395 Batch 31 Loss 0.13479389250278473
[Train] epoch 395 Batch 32 Loss 0.16781410574913025
[Train] epoch 395 Batch 33 Loss 0.2005838006734848
[Train] epoch 395 Batch 34 Loss 0.13419148325920105
[Train] epoch 395 Batch 35 Loss 0.16868877410888672
[Train] epoch 395 Batch 36 Loss 0.13381880521774292
[Train] epoch 395 Batch 37 Loss 0.20195293426513672
[Train] epoch 395 Batch 38 Loss 0.40078622102737427
[Train] epoch 395 Batch 39 Loss 0.13391634821891785
[Train] epoch 395 Batch 40 Loss 0.06805425137281418
[Train] epoch 395 Batch 41 Loss 0.134959876537323
[Train] epoch 395 Batch 42 Loss 0.13472262024879456
[Train] epoch 395 Batch 43 Loss 0.06748700886964798
[Train] epoch 395 Batch 44 Loss 0.3026215732097626
[Train] epoch 395 Batch 45 Loss 0.20116180181503296
[Train] epoch 395 Batch 46 Loss 0.26766514778137207
[Train] epoch 395 Batch 47 Loss 0.10121071338653564
[Train] epoch 396 Batch 0 Loss 0.13453862071037292
[Train] epoch 396 Batch 1 Loss 0.06717255711555481
[Train] epoch 396 Batch 2 Loss 0.20153002440929413
[Train] epoch 396 Batch 3 Loss 0.13435615599155426
[Train] epoch 396 Batch 4 Loss 0.16790074110031128
[Train] epoch 396 Batch 5 Loss 0.16819819808006287
[Train] epoch 396 Batch 6 Loss 0.10060730576515198
[Train] epoch 396 Batch 7 Loss 0.20080167055130005
[Train] epoch 396 Batch 8 Loss 0.10031761229038239
[Train] epoch 396 Batch 9 Loss 0.13425226509571075
[Train] epoch 396 Batch 10 Loss 0.2350965142250061
[Train] epoch 396 Batch 11 Loss 0.4009192883968353
[Train] epoch 396 Batch 12 Loss 0.26771244406700134
[Train] epoch 396 Batch 13 Loss 0.201039120554924
[Train] epoch 396 Batch 14 Loss 0.2344549000263214
[Train] epoch 396 Batch 15 Loss 0.10112550854682922
[Train] epoch 396 Batch 16 Loss 0.23457589745521545
[Train] epoch 396 Batch 17 Loss 0.2687646746635437
[Train] epoch 396 Batch 18 Loss 0.13450554013252258
[Train] epoch 396 Batch 19 Loss 0.10044680535793304
[Train] epoch 396 Batch 20 Loss 0.033539555966854095
[Train] epoch 396 Batch 21 Loss 0.03363904356956482
[Train] epoch 396 Batch 22 Loss 0.16887065768241882
[Train] epoch 396 Batch 23 Loss 0.23502597212791443
[Train] epoch 396 Batch 24 Loss 0.10124999284744263
[Train] epoch 396 Batch 25 Loss 0.30073082447052
[Train] epoch 396 Batch 26 Loss 0.23823368549346924
[Train] epoch 396 Batch 27 Loss 0.2681797444820404
[Train] epoch 396 Batch 28 Loss 0.23416569828987122
[Train] epoch 396 Batch 29 Loss 0.1696733981370926
[Train] epoch 396 Batch 30 Loss 0.10122944414615631
[Train] epoch 396 Batch 31 Loss 0.16786831617355347
[Train] epoch 396 Batch 32 Loss 0.13488028943538666
[Train] epoch 396 Batch 33 Loss 0.0675177127122879
[Train] epoch 396 Batch 34 Loss 0.06757650524377823
[Train] epoch 396 Batch 35 Loss 0.16806715726852417
[Train] epoch 396 Batch 36 Loss 0.06757201999425888
[Train] epoch 396 Batch 37 Loss 0.1675727367401123
[Train] epoch 396 Batch 38 Loss 0.1692410111427307
[Train] epoch 396 Batch 39 Loss 0.0677754133939743
[Train] epoch 396 Batch 40 Loss 0.23466069996356964
[Train] epoch 396 Batch 41 Loss 0.23576873540878296
[Train] epoch 396 Batch 42 Loss 0.302286297082901
[Train] epoch 396 Batch 43 Loss 0.134502574801445
[Train] epoch 396 Batch 44 Loss 0.200654536485672
[Train] epoch 396 Batch 45 Loss 0.23423627018928528
[Train] epoch 396 Batch 46 Loss 0.33524590730667114
[Train] epoch 396 Batch 47 Loss 0.13530415296554565
[Train] epoch 397 Batch 0 Loss 0.1346614956855774
[Train] epoch 397 Batch 1 Loss 0.20145165920257568
[Train] epoch 397 Batch 2 Loss 0.23429735004901886
[Train] epoch 397 Batch 3 Loss 0.06796447187662125
[Train] epoch 397 Batch 4 Loss 0.1340988725423813
[Train] epoch 397 Batch 5 Loss 0.10249710828065872
[Train] epoch 397 Batch 6 Loss 0.37000250816345215
[Train] epoch 397 Batch 7 Loss 0.034383874386548996
[Train] epoch 397 Batch 8 Loss 0.20237967371940613
[Train] epoch 397 Batch 9 Loss 0.201783686876297
[Train] epoch 397 Batch 10 Loss 0.26837652921676636
[Train] epoch 397 Batch 11 Loss 0.0680282786488533
[Train] epoch 397 Batch 12 Loss 0.06730196624994278
[Train] epoch 397 Batch 13 Loss 0.1347026377916336
[Train] epoch 397 Batch 14 Loss 0.16874422132968903
[Train] epoch 397 Batch 15 Loss 0.1374683529138565
[Train] epoch 397 Batch 16 Loss 0.20126712322235107
[Train] epoch 397 Batch 17 Loss 0.1684720814228058
[Train] epoch 397 Batch 18 Loss 0.10215438902378082
[Train] epoch 397 Batch 19 Loss 0.06750234961509705
[Train] epoch 397 Batch 20 Loss 0.33623629808425903
[Train] epoch 397 Batch 21 Loss 0.3684508800506592
[Train] epoch 397 Batch 22 Loss 0.23637937009334564
[Train] epoch 397 Batch 23 Loss 0.10332782566547394
[Train] epoch 397 Batch 24 Loss 0.03453800827264786
[Train] epoch 397 Batch 25 Loss 0.10263124108314514
[Train] epoch 397 Batch 26 Loss 0.06892290711402893
[Train] epoch 397 Batch 27 Loss 0.16972492635250092
[Train] epoch 397 Batch 28 Loss 0.2697906494140625
[Train] epoch 397 Batch 29 Loss 0.16835011541843414
[Train] epoch 397 Batch 30 Loss 0.13575807213783264
[Train] epoch 397 Batch 31 Loss 0.20231954753398895
[Train] epoch 397 Batch 32 Loss 0.4020867943763733
[Train] epoch 397 Batch 33 Loss 0.23509922623634338
[Train] epoch 397 Batch 34 Loss 0.3012184500694275
[Train] epoch 397 Batch 35 Loss 0.20162032544612885
[Train] epoch 397 Batch 36 Loss 0.033650632947683334
[Train] epoch 397 Batch 37 Loss 0.20198068022727966
[Train] epoch 397 Batch 38 Loss 0.10035731643438339
[Train] epoch 397 Batch 39 Loss 0.06915096938610077
[Train] epoch 397 Batch 40 Loss 0.26733797788619995
[Train] epoch 397 Batch 41 Loss 0.10031719505786896
[Train] epoch 397 Batch 42 Loss 0.13429370522499084
[Train] epoch 397 Batch 43 Loss 0.20229239761829376
[Train] epoch 397 Batch 44 Loss 0.2019670307636261
[Train] epoch 397 Batch 45 Loss 0.23580607771873474
[Train] epoch 397 Batch 46 Loss 0.1347878873348236
[Train] epoch 397 Batch 47 Loss 0.3003484606742859
[Train] epoch 398 Batch 0 Loss 0.1690344512462616
[Train] epoch 398 Batch 1 Loss 0.20298145711421967
[Train] epoch 398 Batch 2 Loss 0.2352420538663864
[Train] epoch 398 Batch 3 Loss 0.2346046268939972
[Train] epoch 398 Batch 4 Loss 0.4020959734916687
[Train] epoch 398 Batch 5 Loss 0.1684425175189972
[Train] epoch 398 Batch 6 Loss 0.23501262068748474
[Train] epoch 398 Batch 7 Loss 0.23512405157089233
[Train] epoch 398 Batch 8 Loss 0.23432721197605133
[Train] epoch 398 Batch 9 Loss 0.1347978115081787
[Train] epoch 398 Batch 10 Loss 0.06879878789186478
[Train] epoch 398 Batch 11 Loss 0.1342293620109558
[Train] epoch 398 Batch 12 Loss 0.20154254138469696
[Train] epoch 398 Batch 13 Loss 1.0728851975727594e-06
[Train] epoch 398 Batch 14 Loss 0.10161466896533966
[Train] epoch 398 Batch 15 Loss 0.1355099380016327
[Train] epoch 398 Batch 16 Loss 0.0007697613909840584
[Train] epoch 398 Batch 17 Loss 0.20412927865982056
[Train] epoch 398 Batch 18 Loss 0.06872044503688812
[Train] epoch 398 Batch 19 Loss 0.13484403491020203
[Train] epoch 398 Batch 20 Loss 0.06666764616966248
[Train] epoch 398 Batch 21 Loss 0.16847671568393707
[Train] epoch 398 Batch 22 Loss 0.16763271391391754
[Train] epoch 398 Batch 23 Loss 0.13397441804409027
[Train] epoch 398 Batch 24 Loss 0.33663296699523926
[Train] epoch 398 Batch 25 Loss 0.20202744007110596
[Train] epoch 398 Batch 26 Loss 0.3690018057823181
[Train] epoch 398 Batch 27 Loss 0.20137442648410797
[Train] epoch 398 Batch 28 Loss 0.13470548391342163
[Train] epoch 398 Batch 29 Loss 0.06740160286426544
[Train] epoch 398 Batch 30 Loss 0.3368000388145447
[Train] epoch 398 Batch 31 Loss 0.2686651051044464
[Train] epoch 398 Batch 32 Loss 0.1352321356534958
[Train] epoch 398 Batch 33 Loss 0.001357879489660263
[Train] epoch 398 Batch 34 Loss 0.20126646757125854
[Train] epoch 398 Batch 35 Loss 0.30219870805740356
[Train] epoch 398 Batch 36 Loss 0.16779914498329163
[Train] epoch 398 Batch 37 Loss 0.23508727550506592
[Train] epoch 398 Batch 38 Loss 0.13458910584449768
[Train] epoch 398 Batch 39 Loss 0.201875239610672
[Train] epoch 398 Batch 40 Loss 0.10174773633480072
[Train] epoch 398 Batch 41 Loss 0.2343604415655136
[Train] epoch 398 Batch 42 Loss 0.1352987140417099
[Train] epoch 398 Batch 43 Loss 0.033642061054706573
[Train] epoch 398 Batch 44 Loss 0.43436312675476074
[Train] epoch 398 Batch 45 Loss 0.0693989247083664
[Train] epoch 398 Batch 46 Loss 0.10102763026952744
[Train] epoch 398 Batch 47 Loss 0.13526415824890137
[Train] epoch 399 Batch 0 Loss 0.16768041253089905
[Train] epoch 399 Batch 1 Loss 0.06728684902191162
[Train] epoch 399 Batch 2 Loss 0.26790449023246765
[Train] epoch 399 Batch 3 Loss 0.10239274799823761
[Train] epoch 399 Batch 4 Loss 0.20187968015670776
[Train] epoch 399 Batch 5 Loss 0.2006893754005432
[Train] epoch 399 Batch 6 Loss 0.23625504970550537
[Train] epoch 399 Batch 7 Loss 0.13396473228931427
[Train] epoch 399 Batch 8 Loss 0.13463225960731506
[Train] epoch 399 Batch 9 Loss 0.20187754929065704
[Train] epoch 399 Batch 10 Loss 0.10031601786613464
[Train] epoch 399 Batch 11 Loss 0.06787499785423279
[Train] epoch 399 Batch 12 Loss 0.10153964906930923
[Train] epoch 399 Batch 13 Loss 0.13529683649539948
[Train] epoch 399 Batch 14 Loss 0.13720741868019104
[Train] epoch 399 Batch 15 Loss 0.03371157869696617
[Train] epoch 399 Batch 16 Loss 0.20186907052993774
[Train] epoch 399 Batch 17 Loss 0.13467161357402802
[Train] epoch 399 Batch 18 Loss 0.20063035190105438
[Train] epoch 399 Batch 19 Loss 0.16886159777641296
[Train] epoch 399 Batch 20 Loss 0.20187705755233765
[Train] epoch 399 Batch 21 Loss 0.16822600364685059
[Train] epoch 399 Batch 22 Loss 0.30031532049179077
[Train] epoch 399 Batch 23 Loss 0.10031551122665405
[Train] epoch 399 Batch 24 Loss 0.16758587956428528
[Train] epoch 399 Batch 25 Loss 0.3683450520038605
[Train] epoch 399 Batch 26 Loss 0.1351684331893921
[Train] epoch 399 Batch 27 Loss 0.2686028480529785
[Train] epoch 399 Batch 28 Loss 0.20125429332256317
[Train] epoch 399 Batch 29 Loss 0.06786955147981644
[Train] epoch 399 Batch 30 Loss 0.33473673462867737
[Train] epoch 399 Batch 31 Loss 0.17000015079975128
[Train] epoch 399 Batch 32 Loss 0.20193204283714294
[Train] epoch 399 Batch 33 Loss 0.23489129543304443
[Train] epoch 399 Batch 34 Loss 0.20183992385864258
[Train] epoch 399 Batch 35 Loss 0.13503527641296387
[Train] epoch 399 Batch 36 Loss 0.1358516961336136
[Train] epoch 399 Batch 37 Loss 0.13400417566299438
[Train] epoch 399 Batch 38 Loss 0.16829688847064972
[Train] epoch 399 Batch 39 Loss 0.23428291082382202
[Train] epoch 399 Batch 40 Loss 0.10094808042049408
[Train] epoch 399 Batch 41 Loss 0.16698098182678223
[Train] epoch 399 Batch 42 Loss 0.23364752531051636
[Train] epoch 399 Batch 43 Loss 0.13692735135555267
[Train] epoch 399 Batch 44 Loss 0.16813015937805176
[Train] epoch 399 Batch 45 Loss 0.23493602871894836
[Train] epoch 399 Batch 46 Loss 0.2024676352739334
[Train] epoch 399 Batch 47 Loss 0.20173314213752747
[Train] epoch 400 Batch 0 Loss 0.23419903218746185
[Train] epoch 400 Batch 1 Loss 0.1687718629837036
[Train] epoch 400 Batch 2 Loss 0.20196503400802612
[Train] epoch 400 Batch 3 Loss 0.13566462695598602
[Train] epoch 400 Batch 4 Loss 0.034262750297784805
[Train] epoch 400 Batch 5 Loss 0.167525976896286
[Train] epoch 400 Batch 6 Loss 0.23430019617080688
[Train] epoch 400 Batch 7 Loss 0.16810816526412964
[Train] epoch 400 Batch 8 Loss 0.0005429371958598495
[Train] epoch 400 Batch 9 Loss 0.3022463321685791
[Train] epoch 400 Batch 10 Loss 0.06725051999092102
[Train] epoch 400 Batch 11 Loss 0.1003139317035675
[Train] epoch 400 Batch 12 Loss 0.06789734959602356
[Train] epoch 400 Batch 13 Loss 0.06787283718585968
[Train] epoch 400 Batch 14 Loss 0.23489466309547424
[Train] epoch 400 Batch 15 Loss 0.26787346601486206
[Train] epoch 400 Batch 16 Loss 0.1008480116724968
[Train] epoch 400 Batch 17 Loss 0.2012057602405548
[Train] epoch 400 Batch 18 Loss 0.20057983696460724
[Train] epoch 400 Batch 19 Loss 0.13450905680656433
[Train] epoch 400 Batch 20 Loss 0.26729241013526917
[Train] epoch 400 Batch 21 Loss 0.10092455893754959
[Train] epoch 400 Batch 22 Loss 0.2683211863040924
[Train] epoch 400 Batch 23 Loss 0.268461674451828
[Train] epoch 400 Batch 24 Loss 0.23603074252605438
[Train] epoch 400 Batch 25 Loss 0.3339729309082031
[Train] epoch 400 Batch 26 Loss 0.20116612315177917
[Train] epoch 400 Batch 27 Loss 0.3014140725135803
[Train] epoch 400 Batch 28 Loss 0.2017017900943756
[Train] epoch 400 Batch 29 Loss 0.1351064145565033
[Train] epoch 400 Batch 30 Loss 0.10083654522895813
[Train] epoch 400 Batch 31 Loss 0.13495346903800964
[Train] epoch 400 Batch 32 Loss 0.20063500106334686
[Train] epoch 400 Batch 33 Loss 0.1008339375257492
[Train] epoch 400 Batch 34 Loss 0.20120564103126526
[Train] epoch 400 Batch 35 Loss 0.2366340458393097
[Train] epoch 400 Batch 36 Loss 0.13511665165424347
[Train] epoch 400 Batch 37 Loss 0.2016683965921402
[Train] epoch 400 Batch 38 Loss 0.23541532456874847
[Train] epoch 400 Batch 39 Loss 0.20165616273880005
[Train] epoch 400 Batch 40 Loss 0.26853999495506287
[Train] epoch 400 Batch 41 Loss 0.1356201171875
[Train] epoch 400 Batch 42 Loss 0.168173149228096
[Train] epoch 400 Batch 43 Loss 0.2011997401714325
[Train] epoch 400 Batch 44 Loss 0.1674952208995819
[Train] epoch 400 Batch 45 Loss 0.10241669416427612
[Train] epoch 400 Batch 46 Loss 0.03415897116065025
[Train] epoch 400 Batch 47 Loss 0.136165589094162
[Train] epoch 401 Batch 0 Loss 0.10093122720718384
[Train] epoch 401 Batch 1 Loss 0.20180851221084595
[Train] epoch 401 Batch 2 Loss 0.3355877697467804
[Train] epoch 401 Batch 3 Loss 0.13491040468215942
[Train] epoch 401 Batch 4 Loss 0.13502195477485657
[Train] epoch 401 Batch 5 Loss 0.1675388514995575
[Train] epoch 401 Batch 6 Loss 0.2000008225440979
[Train] epoch 401 Batch 7 Loss 0.2688489556312561
[Train] epoch 401 Batch 8 Loss 0.2347053438425064
[Train] epoch 401 Batch 9 Loss 0.1689799726009369
[Train] epoch 401 Batch 10 Loss 0.13457128405570984
[Train] epoch 401 Batch 11 Loss 0.20173262059688568
[Train] epoch 401 Batch 12 Loss 0.13482853770256042
[Train] epoch 401 Batch 13 Loss 0.20184502005577087
[Train] epoch 401 Batch 14 Loss 0.3009219765663147
[Train] epoch 401 Batch 15 Loss 0.0678301751613617
[Train] epoch 401 Batch 16 Loss 0.10202665627002716
[Train] epoch 401 Batch 17 Loss 0.20122843980789185
[Train] epoch 401 Batch 18 Loss 0.16753113269805908
[Train] epoch 401 Batch 19 Loss 0.06716031581163406
[Train] epoch 401 Batch 20 Loss 0.06819802522659302
[Train] epoch 401 Batch 21 Loss 0.13455846905708313
[Train] epoch 401 Batch 22 Loss 0.20170626044273376
[Train] epoch 401 Batch 23 Loss 0.200607568025589
[Train] epoch 401 Batch 24 Loss 0.13443930447101593
[Train] epoch 401 Batch 25 Loss 0.06884661316871643
[Train] epoch 401 Batch 26 Loss 0.10029831528663635
[Train] epoch 401 Batch 27 Loss 0.000488472986035049
[Train] epoch 401 Batch 28 Loss 0.034721460193395615
[Train] epoch 401 Batch 29 Loss 0.23412764072418213
[Train] epoch 401 Batch 30 Loss 0.16866594552993774
[Train] epoch 401 Batch 31 Loss 0.2017425000667572
[Train] epoch 401 Batch 32 Loss 0.26770079135894775
[Train] epoch 401 Batch 33 Loss 0.23527467250823975
[Train] epoch 401 Batch 34 Loss 0.16900955140590668
[Train] epoch 401 Batch 35 Loss 0.3344961106777191
[Train] epoch 401 Batch 36 Loss 0.20170992612838745
[Train] epoch 401 Batch 37 Loss 0.16749118268489838
[Train] epoch 401 Batch 38 Loss 0.2682095766067505
[Train] epoch 401 Batch 39 Loss 0.1680346429347992
[Train] epoch 401 Batch 40 Loss 0.16798178851604462
[Train] epoch 401 Batch 41 Loss 0.2341860830783844
[Train] epoch 401 Batch 42 Loss 0.16796091198921204
[Train] epoch 401 Batch 43 Loss 0.20175324380397797
[Train] epoch 401 Batch 44 Loss 0.10130850970745087
[Train] epoch 401 Batch 45 Loss 0.3339466154575348
[Train] epoch 401 Batch 46 Loss 0.26778459548950195
[Train] epoch 401 Batch 47 Loss 0.0009978635935112834
[Train] epoch 402 Batch 0 Loss 0.20118498802185059
[Train] epoch 402 Batch 1 Loss 0.10030697286128998
[Train] epoch 402 Batch 2 Loss 0.13437607884407043
[Train] epoch 402 Batch 3 Loss 0.16848497092723846
[Train] epoch 402 Batch 4 Loss 0.302519828081131
[Train] epoch 402 Batch 5 Loss 0.13444219529628754
[Train] epoch 402 Batch 6 Loss 0.43403762578964233
[Train] epoch 402 Batch 7 Loss 0.06713618338108063
[Train] epoch 402 Batch 8 Loss 0.13446156680583954
[Train] epoch 402 Batch 9 Loss 0.267206609249115
[Train] epoch 402 Batch 10 Loss 0.1339210569858551
[Train] epoch 402 Batch 11 Loss 0.26835423707962036
[Train] epoch 402 Batch 12 Loss 0.2697746157646179
[Train] epoch 402 Batch 13 Loss 0.4022216796875
[Train] epoch 402 Batch 14 Loss 0.20117026567459106
[Train] epoch 402 Batch 15 Loss 0.16697263717651367
[Train] epoch 402 Batch 16 Loss 0.0672776848077774
[Train] epoch 402 Batch 17 Loss 0.2683497667312622
[Train] epoch 402 Batch 18 Loss 0.13387012481689453
[Train] epoch 402 Batch 19 Loss 0.202818363904953
[Train] epoch 402 Batch 20 Loss 0.06717532873153687
[Train] epoch 402 Batch 21 Loss 0.1344224214553833
[Train] epoch 402 Batch 22 Loss 0.13437512516975403
[Train] epoch 402 Batch 23 Loss 0.20162078738212585
[Train] epoch 402 Batch 24 Loss 0.169330894947052
[Train] epoch 402 Batch 25 Loss 0.23424625396728516
[Train] epoch 402 Batch 26 Loss 0.2341415286064148
[Train] epoch 402 Batch 27 Loss 0.2015686333179474
[Train] epoch 402 Batch 28 Loss 0.10136903822422028
[Train] epoch 402 Batch 29 Loss 0.10118653625249863
[Train] epoch 402 Batch 30 Loss 0.034062717109918594
[Train] epoch 402 Batch 31 Loss 0.16810907423496246
[Train] epoch 402 Batch 32 Loss 0.16697093844413757
[Train] epoch 402 Batch 33 Loss 0.06815054267644882
[Train] epoch 402 Batch 34 Loss 0.23610210418701172
[Train] epoch 402 Batch 35 Loss 0.2351289689540863
[Train] epoch 402 Batch 36 Loss 0.10075615346431732
[Train] epoch 402 Batch 37 Loss 0.2672402858734131
[Train] epoch 402 Batch 38 Loss 0.2361348271369934
[Train] epoch 402 Batch 39 Loss 0.2015949934720993
[Train] epoch 402 Batch 40 Loss 0.03445848822593689
[Train] epoch 402 Batch 41 Loss 0.20105504989624023
[Train] epoch 402 Batch 42 Loss 0.1684020459651947
[Train] epoch 402 Batch 43 Loss 0.16741766035556793
[Train] epoch 402 Batch 44 Loss 0.03408381715416908
[Train] epoch 402 Batch 45 Loss 0.10030333697795868
[Train] epoch 402 Batch 46 Loss 0.134873628616333
[Train] epoch 402 Batch 47 Loss 0.16801956295967102
[Train] epoch 403 Batch 0 Loss 0.2004455327987671
[Train] epoch 403 Batch 1 Loss 0.13438263535499573
[Train] epoch 403 Batch 2 Loss 0.2682444155216217
[Train] epoch 403 Batch 3 Loss 0.10078877955675125
[Train] epoch 403 Batch 4 Loss 0.10074549913406372
[Train] epoch 403 Batch 5 Loss 0.1674921214580536
[Train] epoch 403 Batch 6 Loss 0.20056581497192383
[Train] epoch 403 Batch 7 Loss 0.23451843857765198
[Train] epoch 403 Batch 8 Loss 0.2342386096715927
[Train] epoch 403 Batch 9 Loss 0.23467887938022614
[Train] epoch 403 Batch 10 Loss 0.1682927906513214
[Train] epoch 403 Batch 11 Loss 0.1680530309677124
[Train] epoch 403 Batch 12 Loss 0.06666764616966248
[Train] epoch 403 Batch 13 Loss 0.16893188655376434
[Train] epoch 403 Batch 14 Loss 0.23355333507061005
[Train] epoch 403 Batch 15 Loss 0.10078165680170059
[Train] epoch 403 Batch 16 Loss 0.3339354395866394
[Train] epoch 403 Batch 17 Loss 0.1020921915769577
[Train] epoch 403 Batch 18 Loss 0.2341536581516266
[Train] epoch 403 Batch 19 Loss 0.16812923550605774
[Train] epoch 403 Batch 20 Loss 0.13476595282554626
[Train] epoch 403 Batch 21 Loss 0.30164891481399536
[Train] epoch 403 Batch 22 Loss 0.10125388205051422
[Train] epoch 403 Batch 23 Loss 0.06766082346439362
[Train] epoch 403 Batch 24 Loss 0.10085919499397278
[Train] epoch 403 Batch 25 Loss 0.23561696708202362
[Train] epoch 403 Batch 26 Loss 0.16791564226150513
[Train] epoch 403 Batch 27 Loss 0.1017637699842453
[Train] epoch 403 Batch 28 Loss 0.23414745926856995
[Train] epoch 403 Batch 29 Loss 0.06757144629955292
[Train] epoch 403 Batch 30 Loss 0.10137099027633667
[Train] epoch 403 Batch 31 Loss 0.2678213119506836
[Train] epoch 403 Batch 32 Loss 0.202749565243721
[Train] epoch 403 Batch 33 Loss 0.13525743782520294
[Train] epoch 403 Batch 34 Loss 0.13436128199100494
[Train] epoch 403 Batch 35 Loss 0.16833144426345825
[Train] epoch 403 Batch 36 Loss 0.30119484663009644
[Train] epoch 403 Batch 37 Loss 0.06760139763355255
[Train] epoch 403 Batch 38 Loss 0.03409930318593979
[Train] epoch 403 Batch 39 Loss 0.03443850576877594
[Train] epoch 403 Batch 40 Loss 0.2021249681711197
[Train] epoch 403 Batch 41 Loss 0.334442138671875
[Train] epoch 403 Batch 42 Loss 0.20110049843788147
[Train] epoch 403 Batch 43 Loss 0.1008012592792511
[Train] epoch 403 Batch 44 Loss 0.334392786026001
[Train] epoch 403 Batch 45 Loss 0.23459427058696747
[Train] epoch 403 Batch 46 Loss 0.3023356795310974
[Train] epoch 403 Batch 47 Loss 0.06767547130584717
[Train] epoch 404 Batch 0 Loss 0.13393011689186096
[Train] epoch 404 Batch 1 Loss 0.2691207528114319
[Train] epoch 404 Batch 2 Loss 0.06768325716257095
[Train] epoch 404 Batch 3 Loss 0.16696509718894958
[Train] epoch 404 Batch 4 Loss 0.16806697845458984
[Train] epoch 404 Batch 5 Loss 0.1342981904745102
[Train] epoch 404 Batch 6 Loss 0.10066697746515274
[Train] epoch 404 Batch 7 Loss 0.06717381626367569
[Train] epoch 404 Batch 8 Loss 0.16792619228363037
[Train] epoch 404 Batch 9 Loss 0.23462983965873718
[Train] epoch 404 Batch 10 Loss 0.2681708037853241
[Train] epoch 404 Batch 11 Loss 0.23537343740463257
[Train] epoch 404 Batch 12 Loss 0.2350938618183136
[Train] epoch 404 Batch 13 Loss 0.23399552702903748
[Train] epoch 404 Batch 14 Loss 0.23496520519256592
[Train] epoch 404 Batch 15 Loss 0.10261007398366928
[Train] epoch 404 Batch 16 Loss 0.23498515784740448
[Train] epoch 404 Batch 17 Loss 0.10029694437980652
[Train] epoch 404 Batch 18 Loss 0.16741374135017395
[Train] epoch 404 Batch 19 Loss 0.03449263051152229
[Train] epoch 404 Batch 20 Loss 0.13433799147605896
[Train] epoch 404 Batch 21 Loss 0.13514457643032074
[Train] epoch 404 Batch 22 Loss 0.20112991333007812
[Train] epoch 404 Batch 23 Loss 0.13428236544132233
[Train] epoch 404 Batch 24 Loss 0.20098453760147095
[Train] epoch 404 Batch 25 Loss 0.10150782763957977
[Train] epoch 404 Batch 26 Loss 0.034038886427879333
[Train] epoch 404 Batch 27 Loss 0.2005366086959839
[Train] epoch 404 Batch 28 Loss 0.23525434732437134
[Train] epoch 404 Batch 29 Loss 0.10129406303167343
[Train] epoch 404 Batch 30 Loss 0.033629342913627625
[Train] epoch 404 Batch 31 Loss 0.20094209909439087
[Train] epoch 404 Batch 32 Loss 0.16746042668819427
[Train] epoch 404 Batch 33 Loss 0.16784629225730896
[Train] epoch 404 Batch 34 Loss 0.16749531030654907
[Train] epoch 404 Batch 35 Loss 0.2009037435054779
[Train] epoch 404 Batch 36 Loss 0.30226245522499084
[Train] epoch 404 Batch 37 Loss 0.26756906509399414
[Train] epoch 404 Batch 38 Loss 0.06802285462617874
[Train] epoch 404 Batch 39 Loss 0.26866573095321655
[Train] epoch 404 Batch 40 Loss 0.23493129014968872
[Train] epoch 404 Batch 41 Loss 0.23362796008586884
[Train] epoch 404 Batch 42 Loss 0.26763543486595154
[Train] epoch 404 Batch 43 Loss 0.16776606440544128
[Train] epoch 404 Batch 44 Loss 0.3012953996658325
[Train] epoch 404 Batch 45 Loss 0.06756354868412018
[Train] epoch 404 Batch 46 Loss 0.1347000002861023
[Train] epoch 404 Batch 47 Loss 0.26765480637550354
[Train] epoch 405 Batch 0 Loss 0.06799629330635071
[Train] epoch 405 Batch 1 Loss 0.10063523054122925
[Train] epoch 405 Batch 2 Loss 0.23576202988624573
[Train] epoch 405 Batch 3 Loss 0.06765270233154297
[Train] epoch 405 Batch 4 Loss 0.3350302577018738
[Train] epoch 405 Batch 5 Loss 0.13425807654857635
[Train] epoch 405 Batch 6 Loss 0.20092371106147766
[Train] epoch 405 Batch 7 Loss 0.16696038842201233
[Train] epoch 405 Batch 8 Loss 0.0007938663475215435
[Train] epoch 405 Batch 9 Loss 0.13452205061912537
[Train] epoch 405 Batch 10 Loss 0.1007227748632431
[Train] epoch 405 Batch 11 Loss 0.13526687026023865
[Train] epoch 405 Batch 12 Loss 0.20137502253055573
[Train] epoch 405 Batch 13 Loss 0.10087881237268448
[Train] epoch 405 Batch 14 Loss 0.3677469491958618
[Train] epoch 405 Batch 15 Loss 0.3014432191848755
[Train] epoch 405 Batch 16 Loss 0.1679374724626541
[Train] epoch 405 Batch 17 Loss 0.10062240809202194
[Train] epoch 405 Batch 18 Loss 0.23392170667648315
[Train] epoch 405 Batch 19 Loss 0.20156370103359222
[Train] epoch 405 Batch 20 Loss 0.20182377099990845
[Train] epoch 405 Batch 21 Loss 0.20094437897205353
[Train] epoch 405 Batch 22 Loss 0.20116901397705078
[Train] epoch 405 Batch 23 Loss 0.1669594943523407
[Train] epoch 405 Batch 24 Loss 0.20100653171539307
[Train] epoch 405 Batch 25 Loss 0.10081160068511963
[Train] epoch 405 Batch 26 Loss 0.20110270380973816
[Train] epoch 405 Batch 27 Loss 0.10058342665433884
[Train] epoch 405 Batch 28 Loss 0.3689980208873749
[Train] epoch 405 Batch 29 Loss 0.16928710043430328
[Train] epoch 405 Batch 30 Loss 0.26724973320961
[Train] epoch 405 Batch 31 Loss 0.13375353813171387
[Train] epoch 405 Batch 32 Loss 0.034849874675273895
[Train] epoch 405 Batch 33 Loss 0.16737684607505798
[Train] epoch 405 Batch 34 Loss 0.3342357873916626
[Train] epoch 405 Batch 35 Loss 0.1673758327960968
[Train] epoch 405 Batch 36 Loss 0.0676659345626831
[Train] epoch 405 Batch 37 Loss 0.13507023453712463
[Train] epoch 405 Batch 38 Loss 0.06798328459262848
[Train] epoch 405 Batch 39 Loss 0.0008015017374418676
[Train] epoch 405 Batch 40 Loss 0.16823932528495789
[Train] epoch 405 Batch 41 Loss 0.10063949227333069
[Train] epoch 405 Batch 42 Loss 0.30125367641448975
[Train] epoch 405 Batch 43 Loss 0.26824116706848145
[Train] epoch 405 Batch 44 Loss 0.2346172332763672
[Train] epoch 405 Batch 45 Loss 0.26782599091529846
[Train] epoch 405 Batch 46 Loss 0.23396936058998108
[Train] epoch 405 Batch 47 Loss 0.13449174165725708
[Train] epoch 406 Batch 0 Loss 0.1343250870704651
[Train] epoch 406 Batch 1 Loss 0.1682603508234024
[Train] epoch 406 Batch 2 Loss 0.2676570415496826
[Train] epoch 406 Batch 3 Loss 0.16832014918327332
[Train] epoch 406 Batch 4 Loss 0.2348925620317459
[Train] epoch 406 Batch 5 Loss 0.20108716189861298
[Train] epoch 406 Batch 6 Loss 0.23457875847816467
[Train] epoch 406 Batch 7 Loss 0.06800252199172974
[Train] epoch 406 Batch 8 Loss 0.13409198820590973
[Train] epoch 406 Batch 9 Loss 0.2012283354997635
[Train] epoch 406 Batch 10 Loss 0.1677422821521759
[Train] epoch 406 Batch 11 Loss 0.134695902466774
[Train] epoch 406 Batch 12 Loss 0.16786989569664001
[Train] epoch 406 Batch 13 Loss 0.23508036136627197
[Train] epoch 406 Batch 14 Loss 0.06717376410961151
[Train] epoch 406 Batch 15 Loss 0.2683325707912445
[Train] epoch 406 Batch 16 Loss 0.1337404102087021
[Train] epoch 406 Batch 17 Loss 0.13465973734855652
[Train] epoch 406 Batch 18 Loss 0.0339273102581501
[Train] epoch 406 Batch 19 Loss 0.10116715729236603
[Train] epoch 406 Batch 20 Loss 0.1682674139738083
[Train] epoch 406 Batch 21 Loss 0.20087869465351105
[Train] epoch 406 Batch 22 Loss 0.16817539930343628
[Train] epoch 406 Batch 23 Loss 0.16803386807441711
[Train] epoch 406 Batch 24 Loss 0.16752710938453674
[Train] epoch 406 Batch 25 Loss 0.16765820980072021
[Train] epoch 406 Batch 26 Loss 0.3345392048358917
[Train] epoch 406 Batch 27 Loss 0.1343790888786316
[Train] epoch 406 Batch 28 Loss 0.10156069695949554
[Train] epoch 406 Batch 29 Loss 0.133334219455719
[Train] epoch 406 Batch 30 Loss 0.10028703510761261
[Train] epoch 406 Batch 31 Loss 0.36819422245025635
[Train] epoch 406 Batch 32 Loss 0.13464602828025818
[Train] epoch 406 Batch 33 Loss 0.40136969089508057
[Train] epoch 406 Batch 34 Loss 0.1014816164970398
[Train] epoch 406 Batch 35 Loss 0.2672388255596161
[Train] epoch 406 Batch 36 Loss 0.20057207345962524
[Train] epoch 406 Batch 37 Loss 0.26770809292793274
[Train] epoch 406 Batch 38 Loss 0.10058166086673737
[Train] epoch 406 Batch 39 Loss 0.23564556241035461
[Train] epoch 406 Batch 40 Loss 0.133803129196167
[Train] epoch 406 Batch 41 Loss 0.33380261063575745
[Train] epoch 406 Batch 42 Loss 0.06797117739915848
[Train] epoch 406 Batch 43 Loss 0.13466554880142212
[Train] epoch 406 Batch 44 Loss 0.10085563361644745
[Train] epoch 406 Batch 45 Loss 0.13429808616638184
[Train] epoch 406 Batch 46 Loss 0.10078150033950806
[Train] epoch 406 Batch 47 Loss 0.16741928458213806
[Train] epoch 407 Batch 0 Loss 0.16823415458202362
[Train] epoch 407 Batch 1 Loss 0.23401153087615967
[Train] epoch 407 Batch 2 Loss 0.13422182202339172
[Train] epoch 407 Batch 3 Loss 0.10187229514122009
[Train] epoch 407 Batch 4 Loss 0.26772958040237427
[Train] epoch 407 Batch 5 Loss 0.2339816689491272
[Train] epoch 407 Batch 6 Loss 0.033981576561927795
[Train] epoch 407 Batch 7 Loss 0.13432085514068604
[Train] epoch 407 Batch 8 Loss 0.13390137255191803
[Train] epoch 407 Batch 9 Loss 0.166950985789299
[Train] epoch 407 Batch 10 Loss 0.13465383648872375
[Train] epoch 407 Batch 11 Loss 0.03354339674115181
[Train] epoch 407 Batch 12 Loss 0.16808322072029114
[Train] epoch 407 Batch 13 Loss 0.1685279905796051
[Train] epoch 407 Batch 14 Loss 0.3675159215927124
[Train] epoch 407 Batch 15 Loss 0.10054311156272888
[Train] epoch 407 Batch 16 Loss 0.16819137334823608
[Train] epoch 407 Batch 17 Loss 0.13467666506767273
[Train] epoch 407 Batch 18 Loss 0.16762474179267883
[Train] epoch 407 Batch 19 Loss 0.10100415349006653
[Train] epoch 407 Batch 20 Loss 0.10028313100337982
[Train] epoch 407 Batch 21 Loss 0.16779915988445282
[Train] epoch 407 Batch 22 Loss 0.03392884507775307
[Train] epoch 407 Batch 23 Loss 0.2338731586933136
[Train] epoch 407 Batch 24 Loss 0.2009236216545105
[Train] epoch 407 Batch 25 Loss 0.23456569015979767
[Train] epoch 407 Batch 26 Loss 0.26810503005981445
[Train] epoch 407 Batch 27 Loss 0.23510035872459412
[Train] epoch 407 Batch 28 Loss 0.16733434796333313
[Train] epoch 407 Batch 29 Loss 0.13466712832450867
[Train] epoch 407 Batch 30 Loss 0.03471561148762703
[Train] epoch 407 Batch 31 Loss 0.10112631320953369
[Train] epoch 407 Batch 32 Loss 0.26792237162590027
[Train] epoch 407 Batch 33 Loss 0.13371804356575012
[Train] epoch 407 Batch 34 Loss 0.16860631108283997
[Train] epoch 407 Batch 35 Loss 0.2018624246120453
[Train] epoch 407 Batch 36 Loss 0.133334219455719
[Train] epoch 407 Batch 37 Loss 0.2349134385585785
[Train] epoch 407 Batch 38 Loss 0.16694799065589905
[Train] epoch 407 Batch 39 Loss 0.20137813687324524
[Train] epoch 407 Batch 40 Loss 0.33536577224731445
[Train] epoch 407 Batch 41 Loss 0.20126940310001373
[Train] epoch 407 Batch 42 Loss 0.20167529582977295
[Train] epoch 407 Batch 43 Loss 0.1006607934832573
[Train] epoch 407 Batch 44 Loss 0.30149587988853455
[Train] epoch 407 Batch 45 Loss 0.16740357875823975
[Train] epoch 407 Batch 46 Loss 0.30028048157691956
[Train] epoch 407 Batch 47 Loss 0.16800305247306824
[Train] epoch 408 Batch 0 Loss 0.035021595656871796
[Train] epoch 408 Batch 1 Loss 0.300839364528656
[Train] epoch 408 Batch 2 Loss 0.03434167802333832
[Train] epoch 408 Batch 3 Loss 0.20080594718456268
[Train] epoch 408 Batch 4 Loss 0.06666764616966248
[Train] epoch 408 Batch 5 Loss 0.10063004493713379
[Train] epoch 408 Batch 6 Loss 0.1342681348323822
[Train] epoch 408 Batch 7 Loss 0.2687791883945465
[Train] epoch 408 Batch 8 Loss 0.10145733505487442
[Train] epoch 408 Batch 9 Loss 0.13378749787807465
[Train] epoch 408 Batch 10 Loss 0.10182945430278778
[Train] epoch 408 Batch 11 Loss 0.03361312672495842
[Train] epoch 408 Batch 12 Loss 0.10097506642341614
[Train] epoch 408 Batch 13 Loss 0.23510026931762695
[Train] epoch 408 Batch 14 Loss 0.23478461802005768
[Train] epoch 408 Batch 15 Loss 0.30065152049064636
[Train] epoch 408 Batch 16 Loss 0.23433108627796173
[Train] epoch 408 Batch 17 Loss 0.16758427023887634
[Train] epoch 408 Batch 18 Loss 0.20124883949756622
[Train] epoch 408 Batch 19 Loss 0.20055684447288513
[Train] epoch 408 Batch 20 Loss 0.33426058292388916
[Train] epoch 408 Batch 21 Loss 0.10064923763275146
[Train] epoch 408 Batch 22 Loss 0.06703784316778183
[Train] epoch 408 Batch 23 Loss 0.13407406210899353
[Train] epoch 408 Batch 24 Loss 0.201875701546669
[Train] epoch 408 Batch 25 Loss 0.3013860583305359
[Train] epoch 408 Batch 26 Loss 0.1343383491039276
[Train] epoch 408 Batch 27 Loss 0.23442906141281128
[Train] epoch 408 Batch 28 Loss 0.13496840000152588
[Train] epoch 408 Batch 29 Loss 0.20155316591262817
[Train] epoch 408 Batch 30 Loss 0.20184403657913208
[Train] epoch 408 Batch 31 Loss 0.23432040214538574
[Train] epoch 408 Batch 32 Loss 0.23471824824810028
[Train] epoch 408 Batch 33 Loss 0.20055419206619263
[Train] epoch 408 Batch 34 Loss 0.3007493019104004
[Train] epoch 408 Batch 35 Loss 0.16783791780471802
[Train] epoch 408 Batch 36 Loss 0.16694380342960358
[Train] epoch 408 Batch 37 Loss 0.23431633412837982
[Train] epoch 408 Batch 38 Loss 0.13422676920890808
[Train] epoch 408 Batch 39 Loss 0.10056059062480927
[Train] epoch 408 Batch 40 Loss 0.0682639479637146
[Train] epoch 408 Batch 41 Loss 0.30119210481643677
[Train] epoch 408 Batch 42 Loss 0.16767126321792603
[Train] epoch 408 Batch 43 Loss 0.1352100372314453
[Train] epoch 408 Batch 44 Loss 0.0670066773891449
[Train] epoch 408 Batch 45 Loss 0.06747540831565857
[Train] epoch 408 Batch 46 Loss 0.33414119482040405
[Train] epoch 408 Batch 47 Loss 0.2004449963569641
[Train] epoch 409 Batch 0 Loss 0.13418890535831451
[Train] epoch 409 Batch 1 Loss 0.06711141765117645
[Train] epoch 409 Batch 2 Loss 0.20085430145263672
[Train] epoch 409 Batch 3 Loss 0.23521819710731506
[Train] epoch 409 Batch 4 Loss 0.23399388790130615
[Train] epoch 409 Batch 5 Loss 0.16854938864707947
[Train] epoch 409 Batch 6 Loss 0.16749121248722076
[Train] epoch 409 Batch 7 Loss 0.20033693313598633
[Train] epoch 409 Batch 8 Loss 0.10027530789375305
[Train] epoch 409 Batch 9 Loss 0.2344338446855545
[Train] epoch 409 Batch 10 Loss 0.2341964691877365
[Train] epoch 409 Batch 11 Loss 0.23506364226341248
[Train] epoch 409 Batch 12 Loss 0.26790904998779297
[Train] epoch 409 Batch 13 Loss 0.0675501897931099
[Train] epoch 409 Batch 14 Loss 0.06746682524681091
[Train] epoch 409 Batch 15 Loss 0.13377505540847778
[Train] epoch 409 Batch 16 Loss 0.2004414200782776
[Train] epoch 409 Batch 17 Loss 0.06821621209383011
[Train] epoch 409 Batch 18 Loss 0.13446521759033203
[Train] epoch 409 Batch 19 Loss 0.1002742350101471
[Train] epoch 409 Batch 20 Loss 0.10154716670513153
[Train] epoch 409 Batch 21 Loss 0.16793933510780334
[Train] epoch 409 Batch 22 Loss 0.20136575400829315
[Train] epoch 409 Batch 23 Loss 0.133334219455719
[Train] epoch 409 Batch 24 Loss 0.13421212136745453
[Train] epoch 409 Batch 25 Loss 0.16694039106369019
[Train] epoch 409 Batch 26 Loss 0.26782941818237305
[Train] epoch 409 Batch 27 Loss 0.2349783331155777
[Train] epoch 409 Batch 28 Loss 0.06755509972572327
[Train] epoch 409 Batch 29 Loss 0.10027056932449341
[Train] epoch 409 Batch 30 Loss 0.167681485414505
[Train] epoch 409 Batch 31 Loss 0.1345990151166916
[Train] epoch 409 Batch 32 Loss 0.20101642608642578
[Train] epoch 409 Batch 33 Loss 0.23453788459300995
[Train] epoch 409 Batch 34 Loss 0.20165234804153442
[Train] epoch 409 Batch 35 Loss 0.13503096997737885
[Train] epoch 409 Batch 36 Loss 0.20144596695899963
[Train] epoch 409 Batch 37 Loss 0.16823256015777588
[Train] epoch 409 Batch 38 Loss 0.23441354930400848
[Train] epoch 409 Batch 39 Loss 0.16817879676818848
[Train] epoch 409 Batch 40 Loss 0.13462069630622864
[Train] epoch 409 Batch 41 Loss 0.16742616891860962
[Train] epoch 409 Batch 42 Loss 0.40145599842071533
[Train] epoch 409 Batch 43 Loss 0.2345220148563385
[Train] epoch 409 Batch 44 Loss 0.20177429914474487
[Train] epoch 409 Batch 45 Loss 0.23443710803985596
[Train] epoch 409 Batch 46 Loss 0.16783185303211212
[Train] epoch 409 Batch 47 Loss 0.133334219455719
[Train] epoch 410 Batch 0 Loss 0.30164283514022827
[Train] epoch 410 Batch 1 Loss 0.23411738872528076
[Train] epoch 410 Batch 2 Loss 0.16733500361442566
[Train] epoch 410 Batch 3 Loss 0.26885223388671875
[Train] epoch 410 Batch 4 Loss 0.10116854310035706
[Train] epoch 410 Batch 5 Loss 0.3357260525226593
[Train] epoch 410 Batch 6 Loss 0.30116820335388184
[Train] epoch 410 Batch 7 Loss 0.201020747423172
[Train] epoch 410 Batch 8 Loss 0.20090779662132263
[Train] epoch 410 Batch 9 Loss 0.20148351788520813
[Train] epoch 410 Batch 10 Loss 0.23405729234218597
[Train] epoch 410 Batch 11 Loss 0.16739042103290558
[Train] epoch 410 Batch 12 Loss 0.1337416172027588
[Train] epoch 410 Batch 13 Loss 0.1681843400001526
[Train] epoch 410 Batch 14 Loss 0.0008508916362188756
[Train] epoch 410 Batch 15 Loss 0.0008503854041919112
[Train] epoch 410 Batch 16 Loss 0.10155089944601059
[Train] epoch 410 Batch 17 Loss 0.06836379319429398
[Train] epoch 410 Batch 18 Loss 0.2344961017370224
[Train] epoch 410 Batch 19 Loss 0.13427184522151947
[Train] epoch 410 Batch 20 Loss 0.2004762589931488
[Train] epoch 410 Batch 21 Loss 0.16825295984745026
[Train] epoch 410 Batch 22 Loss 0.13385173678398132
[Train] epoch 410 Batch 23 Loss 0.20183421671390533
[Train] epoch 410 Batch 24 Loss 0.1338515281677246
[Train] epoch 410 Batch 25 Loss 0.23576833307743073
[Train] epoch 410 Batch 26 Loss 0.2349490225315094
[Train] epoch 410 Batch 27 Loss 0.13468940556049347
[Train] epoch 410 Batch 28 Loss 0.20101121068000793
[Train] epoch 410 Batch 29 Loss 0.06797342747449875
[Train] epoch 410 Batch 30 Loss 0.16732603311538696
[Train] epoch 410 Batch 31 Loss 0.20129263401031494
[Train] epoch 410 Batch 32 Loss 0.10161782801151276
[Train] epoch 410 Batch 33 Loss 0.1681310087442398
[Train] epoch 410 Batch 34 Loss 0.10023389756679535
[Train] epoch 410 Batch 35 Loss 0.16778820753097534
[Train] epoch 410 Batch 36 Loss 0.23408231139183044
[Train] epoch 410 Batch 37 Loss 0.16775190830230713
[Train] epoch 410 Batch 38 Loss 0.23447732627391815
[Train] epoch 410 Batch 39 Loss 0.16732078790664673
[Train] epoch 410 Batch 40 Loss 0.13376237452030182
[Train] epoch 410 Batch 41 Loss 0.1019633337855339
[Train] epoch 410 Batch 42 Loss 0.06718333810567856
[Train] epoch 410 Batch 43 Loss 0.36783409118652344
[Train] epoch 410 Batch 44 Loss 0.10025869309902191
[Train] epoch 410 Batch 45 Loss 0.16744060814380646
[Train] epoch 410 Batch 46 Loss 0.16692514717578888
[Train] epoch 410 Batch 47 Loss 0.26757439970970154
[Train] epoch 411 Batch 0 Loss 0.10158928483724594
[Train] epoch 411 Batch 1 Loss 0.13421116769313812
[Train] epoch 411 Batch 2 Loss 0.13453954458236694
[Train] epoch 411 Batch 3 Loss 0.1346653252840042
[Train] epoch 411 Batch 4 Loss 0.1349593549966812
[Train] epoch 411 Batch 5 Loss 0.06754153221845627
[Train] epoch 411 Batch 6 Loss 0.2671513557434082
[Train] epoch 411 Batch 7 Loss 0.13495157659053802
[Train] epoch 411 Batch 8 Loss 0.1681532859802246
[Train] epoch 411 Batch 9 Loss 0.06744281947612762
[Train] epoch 411 Batch 10 Loss 0.10112755745649338
[Train] epoch 411 Batch 11 Loss 0.2676636576652527
[Train] epoch 411 Batch 12 Loss 0.06747139990329742
[Train] epoch 411 Batch 13 Loss 0.3674057126045227
[Train] epoch 411 Batch 14 Loss 0.13384810090065002
[Train] epoch 411 Batch 15 Loss 0.23400713503360748
[Train] epoch 411 Batch 16 Loss 0.0674990564584732
[Train] epoch 411 Batch 17 Loss 0.3338475823402405
[Train] epoch 411 Batch 18 Loss 0.06718116253614426
[Train] epoch 411 Batch 19 Loss 0.03355724364519119
[Train] epoch 411 Batch 20 Loss 0.20082898437976837
[Train] epoch 411 Batch 21 Loss 0.23438681662082672
[Train] epoch 411 Batch 22 Loss 0.2343827337026596
[Train] epoch 411 Batch 23 Loss 0.301530122756958
[Train] epoch 411 Batch 24 Loss 0.13464078307151794
[Train] epoch 411 Batch 25 Loss 0.10184251517057419
[Train] epoch 411 Batch 26 Loss 0.3352484703063965
[Train] epoch 411 Batch 27 Loss 0.1672372817993164
[Train] epoch 411 Batch 28 Loss 0.13384701311588287
[Train] epoch 411 Batch 29 Loss 0.20120450854301453
[Train] epoch 411 Batch 30 Loss 0.26888906955718994
[Train] epoch 411 Batch 31 Loss 0.13425517082214355
[Train] epoch 411 Batch 32 Loss 0.20092110335826874
[Train] epoch 411 Batch 33 Loss 0.268204003572464
[Train] epoch 411 Batch 34 Loss 0.2018086314201355
[Train] epoch 411 Batch 35 Loss 0.20044490694999695
[Train] epoch 411 Batch 36 Loss 0.16780342161655426
[Train] epoch 411 Batch 37 Loss 0.233589768409729
[Train] epoch 411 Batch 38 Loss 0.03396535664796829
[Train] epoch 411 Batch 39 Loss 0.20138968527317047
[Train] epoch 411 Batch 40 Loss 0.13424962759017944
[Train] epoch 411 Batch 41 Loss 0.1677398383617401
[Train] epoch 411 Batch 42 Loss 0.1011405885219574
[Train] epoch 411 Batch 43 Loss 0.1337081491947174
[Train] epoch 411 Batch 44 Loss 0.06666764616966248
[Train] epoch 411 Batch 45 Loss 0.20181739330291748
[Train] epoch 411 Batch 46 Loss 0.4014222025871277
[Train] epoch 411 Batch 47 Loss 0.1688452959060669
[Train] epoch 412 Batch 0 Loss 0.03509866073727608
[Train] epoch 412 Batch 1 Loss 0.23392140865325928
[Train] epoch 412 Batch 2 Loss 0.2344294786453247
[Train] epoch 412 Batch 3 Loss 0.13384296000003815
[Train] epoch 412 Batch 4 Loss 0.30164283514022827
[Train] epoch 412 Batch 5 Loss 0.16762235760688782
[Train] epoch 412 Batch 6 Loss 0.06710672378540039
[Train] epoch 412 Batch 7 Loss 0.13461031019687653
[Train] epoch 412 Batch 8 Loss 0.23351864516735077
[Train] epoch 412 Batch 9 Loss 0.16771674156188965
[Train] epoch 412 Batch 10 Loss 0.16779746115207672
[Train] epoch 412 Batch 11 Loss 0.1340702921152115
[Train] epoch 412 Batch 12 Loss 0.26757124066352844
[Train] epoch 412 Batch 13 Loss 0.16742847859859467
[Train] epoch 412 Batch 14 Loss 0.2361559122800827
[Train] epoch 412 Batch 15 Loss 0.1349852979183197
[Train] epoch 412 Batch 16 Loss 0.20133881270885468
[Train] epoch 412 Batch 17 Loss 0.034643158316612244
[Train] epoch 412 Batch 18 Loss 0.13426285982131958
[Train] epoch 412 Batch 19 Loss 0.16731393337249756
[Train] epoch 412 Batch 20 Loss 0.16742680966854095
[Train] epoch 412 Batch 21 Loss 0.23437175154685974
[Train] epoch 412 Batch 22 Loss 0.23455584049224854
[Train] epoch 412 Batch 23 Loss 0.23390726745128632
[Train] epoch 412 Batch 24 Loss 0.06708665937185287
[Train] epoch 412 Batch 25 Loss 0.13413098454475403
[Train] epoch 412 Batch 26 Loss 0.2675350308418274
[Train] epoch 412 Batch 27 Loss 0.10104911029338837
[Train] epoch 412 Batch 28 Loss 0.2674185633659363
[Train] epoch 412 Batch 29 Loss 0.4010102450847626
[Train] epoch 412 Batch 30 Loss 0.20128293335437775
[Train] epoch 412 Batch 31 Loss 0.03426384925842285
[Train] epoch 412 Batch 32 Loss 0.10148903727531433
[Train] epoch 412 Batch 33 Loss 0.30102789402008057
[Train] epoch 412 Batch 34 Loss 0.034692902117967606
[Train] epoch 412 Batch 35 Loss 0.16772010922431946
[Train] epoch 412 Batch 36 Loss 0.1668742150068283
[Train] epoch 412 Batch 37 Loss 0.13489514589309692
[Train] epoch 412 Batch 38 Loss 0.06776881217956543
[Train] epoch 412 Batch 39 Loss 0.03463989496231079
[Train] epoch 412 Batch 40 Loss 0.13426831364631653
[Train] epoch 412 Batch 41 Loss 0.16819000244140625
[Train] epoch 412 Batch 42 Loss 0.23408947885036469
[Train] epoch 412 Batch 43 Loss 0.16727501153945923
[Train] epoch 412 Batch 44 Loss 0.06752637028694153
[Train] epoch 412 Batch 45 Loss 0.36765557527542114
[Train] epoch 412 Batch 46 Loss 0.23408877849578857
[Train] epoch 412 Batch 47 Loss 0.2676733136177063
[Train] epoch 413 Batch 0 Loss 0.10098688304424286
[Train] epoch 413 Batch 1 Loss 0.26750221848487854
[Train] epoch 413 Batch 2 Loss 0.1349281519651413
[Train] epoch 413 Batch 3 Loss 0.334542453289032
[Train] epoch 413 Batch 4 Loss 0.2342158854007721
[Train] epoch 413 Batch 5 Loss 0.40045398473739624
[Train] epoch 413 Batch 6 Loss 0.16815057396888733
[Train] epoch 413 Batch 7 Loss 0.1677228957414627
[Train] epoch 413 Batch 8 Loss 0.1341380625963211
[Train] epoch 413 Batch 9 Loss 0.1349899023771286
[Train] epoch 413 Batch 10 Loss 0.23408620059490204
[Train] epoch 413 Batch 11 Loss 0.33456164598464966
[Train] epoch 413 Batch 12 Loss 0.0681687444448471
[Train] epoch 413 Batch 13 Loss 0.16774442791938782
[Train] epoch 413 Batch 14 Loss 0.06754335016012192
[Train] epoch 413 Batch 15 Loss 0.10132341086864471
[Train] epoch 413 Batch 16 Loss 0.30192404985427856
[Train] epoch 413 Batch 17 Loss 0.034679871052503586
[Train] epoch 413 Batch 18 Loss 0.16835922002792358
[Train] epoch 413 Batch 19 Loss 0.10057272017002106
[Train] epoch 413 Batch 20 Loss 0.13420630991458893
[Train] epoch 413 Batch 21 Loss 0.20050057768821716
[Train] epoch 413 Batch 22 Loss 0.03358418866991997
[Train] epoch 413 Batch 23 Loss 0.1340506374835968
[Train] epoch 413 Batch 24 Loss 0.23442842066287994
[Train] epoch 413 Batch 25 Loss 0.20094731450080872
[Train] epoch 413 Batch 26 Loss 0.06666764616966248
[Train] epoch 413 Batch 27 Loss 0.20123864710330963
[Train] epoch 413 Batch 28 Loss 0.2011604607105255
[Train] epoch 413 Batch 29 Loss 0.13494160771369934
[Train] epoch 413 Batch 30 Loss 0.23402930796146393
[Train] epoch 413 Batch 31 Loss 0.3346211910247803
[Train] epoch 413 Batch 32 Loss 0.20120954513549805
[Train] epoch 413 Batch 33 Loss 0.1674145609140396
[Train] epoch 413 Batch 34 Loss 0.16728350520133972
[Train] epoch 413 Batch 35 Loss 0.16841168701648712
[Train] epoch 413 Batch 36 Loss 0.20070886611938477
[Train] epoch 413 Batch 37 Loss 0.0674530491232872
[Train] epoch 413 Batch 38 Loss 0.4013359546661377
[Train] epoch 413 Batch 39 Loss 0.10061478614807129
[Train] epoch 413 Batch 40 Loss 0.16767507791519165
[Train] epoch 413 Batch 41 Loss 0.13372346758842468
[Train] epoch 413 Batch 42 Loss 0.20091554522514343
[Train] epoch 413 Batch 43 Loss 0.20086124539375305
[Train] epoch 413 Batch 44 Loss 0.06666764616966248
[Train] epoch 413 Batch 45 Loss 0.06744876503944397
[Train] epoch 413 Batch 46 Loss 0.16769611835479736
[Train] epoch 413 Batch 47 Loss 0.10092060267925262
[Train] epoch 414 Batch 0 Loss 0.16733232140541077
[Train] epoch 414 Batch 1 Loss 0.16836488246917725
[Train] epoch 414 Batch 2 Loss 0.2352723330259323
[Train] epoch 414 Batch 3 Loss 0.2003384232521057
[Train] epoch 414 Batch 4 Loss 0.3680229187011719
[Train] epoch 414 Batch 5 Loss 0.03456176817417145
[Train] epoch 414 Batch 6 Loss 0.16769114136695862
[Train] epoch 414 Batch 7 Loss 0.1002482920885086
[Train] epoch 414 Batch 8 Loss 0.16753116250038147
[Train] epoch 414 Batch 9 Loss 0.301237016916275
[Train] epoch 414 Batch 10 Loss 0.0673382505774498
[Train] epoch 414 Batch 11 Loss 0.23435452580451965
[Train] epoch 414 Batch 12 Loss 0.06716178357601166
[Train] epoch 414 Batch 13 Loss 0.23401889204978943
[Train] epoch 414 Batch 14 Loss 0.13410593569278717
[Train] epoch 414 Batch 15 Loss 0.23437568545341492
[Train] epoch 414 Batch 16 Loss 0.20074805617332458
[Train] epoch 414 Batch 17 Loss 0.16776448488235474
[Train] epoch 414 Batch 18 Loss 0.16812045872211456
[Train] epoch 414 Batch 19 Loss 0.13371385633945465
[Train] epoch 414 Batch 20 Loss 0.33457231521606445
[Train] epoch 414 Batch 21 Loss 0.20115835964679718
[Train] epoch 414 Batch 22 Loss 0.16724595427513123
[Train] epoch 414 Batch 23 Loss 0.16770417988300323
[Train] epoch 414 Batch 24 Loss 0.20134006440639496
[Train] epoch 414 Batch 25 Loss 0.13404327630996704
[Train] epoch 414 Batch 26 Loss 0.20049268007278442
[Train] epoch 414 Batch 27 Loss 0.13382592797279358
[Train] epoch 414 Batch 28 Loss 0.23465237021446228
[Train] epoch 414 Batch 29 Loss 0.23426371812820435
[Train] epoch 414 Batch 30 Loss 0.1005767285823822
[Train] epoch 414 Batch 31 Loss 0.20119769871234894
[Train] epoch 414 Batch 32 Loss 0.13447275757789612
[Train] epoch 414 Batch 33 Loss 0.20150277018547058
[Train] epoch 414 Batch 34 Loss 0.20084334909915924
[Train] epoch 414 Batch 35 Loss 0.10090392827987671
[Train] epoch 414 Batch 36 Loss 0.2678148150444031
[Train] epoch 414 Batch 37 Loss 0.30100592970848083
[Train] epoch 414 Batch 38 Loss 0.16788358986377716
[Train] epoch 414 Batch 39 Loss 0.1340932846069336
[Train] epoch 414 Batch 40 Loss 0.10162298381328583
[Train] epoch 414 Batch 41 Loss 0.06742545962333679
[Train] epoch 414 Batch 42 Loss 0.1010618805885315
[Train] epoch 414 Batch 43 Loss 0.13419488072395325
[Train] epoch 414 Batch 44 Loss 0.16723813116550446
[Train] epoch 414 Batch 45 Loss 0.16793379187583923
[Train] epoch 414 Batch 46 Loss 0.20083753764629364
[Train] epoch 414 Batch 47 Loss 0.033578842878341675
[Train] epoch 415 Batch 0 Loss 0.03392573073506355
[Train] epoch 415 Batch 1 Loss 0.23494282364845276
[Train] epoch 415 Batch 2 Loss 0.16723594069480896
[Train] epoch 415 Batch 3 Loss 0.268358439207077
[Train] epoch 415 Batch 4 Loss 0.26741892099380493
[Train] epoch 415 Batch 5 Loss 0.20083433389663696
[Train] epoch 415 Batch 6 Loss 0.13382238149642944
[Train] epoch 415 Batch 7 Loss 0.13446761667728424
[Train] epoch 415 Batch 8 Loss 0.16685065627098083
[Train] epoch 415 Batch 9 Loss 0.10024479031562805
[Train] epoch 415 Batch 10 Loss 0.36757683753967285
[Train] epoch 415 Batch 11 Loss 0.13456979393959045
[Train] epoch 415 Batch 12 Loss 0.16739845275878906
[Train] epoch 415 Batch 13 Loss 0.13414266705513
[Train] epoch 415 Batch 14 Loss 0.16739793121814728
[Train] epoch 415 Batch 15 Loss 0.13424649834632874
[Train] epoch 415 Batch 16 Loss 0.13382074236869812
[Train] epoch 415 Batch 17 Loss 0.10122771561145782
[Train] epoch 415 Batch 18 Loss 0.30113309621810913
[Train] epoch 415 Batch 19 Loss 0.2007458209991455
[Train] epoch 415 Batch 20 Loss 0.1672520935535431
[Train] epoch 415 Batch 21 Loss 0.16733452677726746
[Train] epoch 415 Batch 22 Loss 0.3013286292552948
[Train] epoch 415 Batch 23 Loss 0.1681385338306427
[Train] epoch 415 Batch 24 Loss 0.16801542043685913
[Train] epoch 415 Batch 25 Loss 0.16829094290733337
[Train] epoch 415 Batch 26 Loss 0.16722871363162994
[Train] epoch 415 Batch 27 Loss 0.23385503888130188
[Train] epoch 415 Batch 28 Loss 0.23415178060531616
[Train] epoch 415 Batch 29 Loss 0.16720888018608093
[Train] epoch 415 Batch 30 Loss 0.13430944085121155
[Train] epoch 415 Batch 31 Loss 0.16767019033432007
[Train] epoch 415 Batch 32 Loss 0.20109966397285461
[Train] epoch 415 Batch 33 Loss 0.167247474193573
[Train] epoch 415 Batch 34 Loss 0.20048417150974274
[Train] epoch 415 Batch 35 Loss 0.20149680972099304
[Train] epoch 415 Batch 36 Loss 0.10110781341791153
[Train] epoch 415 Batch 37 Loss 0.20115762948989868
[Train] epoch 415 Batch 38 Loss 0.10081084072589874
[Train] epoch 415 Batch 39 Loss 0.1010405644774437
[Train] epoch 415 Batch 40 Loss 0.13543343544006348
[Train] epoch 415 Batch 41 Loss 0.1337328851222992
[Train] epoch 415 Batch 42 Loss 0.16755810379981995
[Train] epoch 415 Batch 43 Loss 0.06813337653875351
[Train] epoch 415 Batch 44 Loss 0.10055573284626007
[Train] epoch 415 Batch 45 Loss 0.1675557941198349
[Train] epoch 415 Batch 46 Loss 0.20127823948860168
[Train] epoch 415 Batch 47 Loss 0.3005748689174652
[Train] epoch 416 Batch 0 Loss 0.10097189247608185
[Train] epoch 416 Batch 1 Loss 0.2677292823791504
[Train] epoch 416 Batch 2 Loss 0.033490221947431564
[Train] epoch 416 Batch 3 Loss 0.0675465539097786
[Train] epoch 416 Batch 4 Loss 0.16796737909317017
[Train] epoch 416 Batch 5 Loss 0.20220518112182617
[Train] epoch 416 Batch 6 Loss 0.16840654611587524
[Train] epoch 416 Batch 7 Loss 0.40152108669281006
[Train] epoch 416 Batch 8 Loss 0.13380484282970428
[Train] epoch 416 Batch 9 Loss 0.10131470859050751
[Train] epoch 416 Batch 10 Loss 0.301059752702713
[Train] epoch 416 Batch 11 Loss 0.23431992530822754
[Train] epoch 416 Batch 12 Loss 0.13414520025253296
[Train] epoch 416 Batch 13 Loss 0.23479986190795898
[Train] epoch 416 Batch 14 Loss 0.10060617327690125
[Train] epoch 416 Batch 15 Loss 0.2343369722366333
[Train] epoch 416 Batch 16 Loss 0.3010927736759186
[Train] epoch 416 Batch 17 Loss 0.13419993221759796
[Train] epoch 416 Batch 18 Loss 0.0004168518353253603
[Train] epoch 416 Batch 19 Loss 0.10149390250444412
[Train] epoch 416 Batch 20 Loss 0.2013380378484726
[Train] epoch 416 Batch 21 Loss 0.2679043412208557
[Train] epoch 416 Batch 22 Loss 0.3337915539741516
[Train] epoch 416 Batch 23 Loss 0.2671245038509369
[Train] epoch 416 Batch 24 Loss 0.268039733171463
[Train] epoch 416 Batch 25 Loss 0.1672896146774292
[Train] epoch 416 Batch 26 Loss 0.1337900459766388
[Train] epoch 416 Batch 27 Loss 0.1346513032913208
[Train] epoch 416 Batch 28 Loss 0.23487615585327148
[Train] epoch 416 Batch 29 Loss 0.16778451204299927
[Train] epoch 416 Batch 30 Loss 0.033963534981012344
[Train] epoch 416 Batch 31 Loss 0.20180484652519226
[Train] epoch 416 Batch 32 Loss 0.33424732089042664
[Train] epoch 416 Batch 33 Loss 0.13419115543365479
[Train] epoch 416 Batch 34 Loss 0.10022766888141632
[Train] epoch 416 Batch 35 Loss 0.06752452999353409
[Train] epoch 416 Batch 36 Loss 0.13462236523628235
[Train] epoch 416 Batch 37 Loss 0.236439049243927
[Train] epoch 416 Batch 38 Loss 0.2004258632659912
[Train] epoch 416 Batch 39 Loss 0.20039786398410797
[Train] epoch 416 Batch 40 Loss 0.13458025455474854
[Train] epoch 416 Batch 41 Loss 0.1341603547334671
[Train] epoch 416 Batch 42 Loss 0.10065637528896332
[Train] epoch 416 Batch 43 Loss 0.16728925704956055
[Train] epoch 416 Batch 44 Loss 0.06711991131305695
[Train] epoch 416 Batch 45 Loss 0.20124271512031555
[Train] epoch 416 Batch 46 Loss 0.16734996438026428
[Train] epoch 416 Batch 47 Loss 0.13376137614250183
[Train] epoch 417 Batch 0 Loss 0.3678087890148163
[Train] epoch 417 Batch 1 Loss 0.03441283851861954
[Train] epoch 417 Batch 2 Loss 0.2675189673900604
[Train] epoch 417 Batch 3 Loss 0.10022684186697006
[Train] epoch 417 Batch 4 Loss 0.33421045541763306
[Train] epoch 417 Batch 5 Loss 0.1668933629989624
[Train] epoch 417 Batch 6 Loss 0.16689333319664001
[Train] epoch 417 Batch 7 Loss 0.16771003603935242
[Train] epoch 417 Batch 8 Loss 0.06790436804294586
[Train] epoch 417 Batch 9 Loss 0.20090706646442413
[Train] epoch 417 Batch 10 Loss 0.10110018402338028
[Train] epoch 417 Batch 11 Loss 0.06793087720870972
[Train] epoch 417 Batch 12 Loss 0.13498426973819733
[Train] epoch 417 Batch 13 Loss 0.20132358372211456
[Train] epoch 417 Batch 14 Loss 0.23439902067184448
[Train] epoch 417 Batch 15 Loss 0.06750611960887909
[Train] epoch 417 Batch 16 Loss 0.1349770426750183
[Train] epoch 417 Batch 17 Loss 0.2675049304962158
[Train] epoch 417 Batch 18 Loss 0.034363023936748505
[Train] epoch 417 Batch 19 Loss 0.10102846473455429
[Train] epoch 417 Batch 20 Loss 0.23603200912475586
[Train] epoch 417 Batch 21 Loss 0.10105924308300018
[Train] epoch 417 Batch 22 Loss 0.10229653120040894
[Train] epoch 417 Batch 23 Loss 0.20086844265460968
[Train] epoch 417 Batch 24 Loss 0.06753135472536087
[Train] epoch 417 Batch 25 Loss 0.13460928201675415
[Train] epoch 417 Batch 26 Loss 0.13413086533546448
[Train] epoch 417 Batch 27 Loss 0.23355941474437714
[Train] epoch 417 Batch 28 Loss 0.23480477929115295
[Train] epoch 417 Batch 29 Loss 0.2004512995481491
[Train] epoch 417 Batch 30 Loss 0.20037946105003357
[Train] epoch 417 Batch 31 Loss 0.00037924706703051925
[Train] epoch 417 Batch 32 Loss 0.3346121311187744
[Train] epoch 417 Batch 33 Loss 0.13456889986991882
[Train] epoch 417 Batch 34 Loss 0.23396585881710052
[Train] epoch 417 Batch 35 Loss 0.16726887226104736
[Train] epoch 417 Batch 36 Loss 0.26752305030822754
[Train] epoch 417 Batch 37 Loss 0.16733479499816895
[Train] epoch 417 Batch 38 Loss 0.33493900299072266
[Train] epoch 417 Batch 39 Loss 0.1017918586730957
[Train] epoch 417 Batch 40 Loss 0.20086205005645752
[Train] epoch 417 Batch 41 Loss 0.23432783782482147
[Train] epoch 417 Batch 42 Loss 0.13414835929870605
[Train] epoch 417 Batch 43 Loss 0.13417690992355347
[Train] epoch 417 Batch 44 Loss 0.26748889684677124
[Train] epoch 417 Batch 45 Loss 0.13374470174312592
[Train] epoch 417 Batch 46 Loss 0.3353564441204071
[Train] epoch 417 Batch 47 Loss 0.10062548518180847
[Train] epoch 418 Batch 0 Loss 0.1680615097284317
[Train] epoch 418 Batch 1 Loss 0.26740729808807373
[Train] epoch 418 Batch 2 Loss 0.20044958591461182
[Train] epoch 418 Batch 3 Loss 0.1672607958316803
[Train] epoch 418 Batch 4 Loss 0.135325625538826
[Train] epoch 418 Batch 5 Loss 0.10104716569185257
[Train] epoch 418 Batch 6 Loss 0.20159690082073212
[Train] epoch 418 Batch 7 Loss 0.3009994626045227
[Train] epoch 418 Batch 8 Loss 0.10106842964887619
[Train] epoch 418 Batch 9 Loss 0.10102638602256775
[Train] epoch 418 Batch 10 Loss 0.16847896575927734
[Train] epoch 418 Batch 11 Loss 0.16684985160827637
[Train] epoch 418 Batch 12 Loss 0.20116330683231354
[Train] epoch 418 Batch 13 Loss 0.13376817107200623
[Train] epoch 418 Batch 14 Loss 0.03432578966021538
[Train] epoch 418 Batch 15 Loss 0.23394860327243805
[Train] epoch 418 Batch 16 Loss 0.10106303542852402
[Train] epoch 418 Batch 17 Loss 0.334949791431427
[Train] epoch 418 Batch 18 Loss 0.13421452045440674
[Train] epoch 418 Batch 19 Loss 0.13491888344287872
[Train] epoch 418 Batch 20 Loss 0.20155631005764008
[Train] epoch 418 Batch 21 Loss 0.2670711278915405
[Train] epoch 418 Batch 22 Loss 0.16689147055149078
[Train] epoch 418 Batch 23 Loss 0.13488487899303436
[Train] epoch 418 Batch 24 Loss 0.20044857263565063
[Train] epoch 418 Batch 25 Loss 0.16727599501609802
[Train] epoch 418 Batch 26 Loss 0.2339872419834137
[Train] epoch 418 Batch 27 Loss 0.16796186566352844
[Train] epoch 418 Batch 28 Loss 0.267452597618103
[Train] epoch 418 Batch 29 Loss 0.26709580421447754
[Train] epoch 418 Batch 30 Loss 0.13413718342781067
[Train] epoch 418 Batch 31 Loss 0.10171817243099213
[Train] epoch 418 Batch 32 Loss 0.20087552070617676
[Train] epoch 418 Batch 33 Loss 0.13497045636177063
[Train] epoch 418 Batch 34 Loss 0.23426568508148193
[Train] epoch 418 Batch 35 Loss 0.20044764876365662
[Train] epoch 418 Batch 36 Loss 0.16807039082050323
[Train] epoch 418 Batch 37 Loss 0.16769593954086304
[Train] epoch 418 Batch 38 Loss 0.16771593689918518
[Train] epoch 418 Batch 39 Loss 0.06706688553094864
[Train] epoch 418 Batch 40 Loss 0.1344628632068634
[Train] epoch 418 Batch 41 Loss 0.13408434391021729
[Train] epoch 418 Batch 42 Loss 0.23390808701515198
[Train] epoch 418 Batch 43 Loss 0.13448566198349
[Train] epoch 418 Batch 44 Loss 0.10066962987184525
[Train] epoch 418 Batch 45 Loss 0.1672661304473877
[Train] epoch 418 Batch 46 Loss 0.2007995843887329
[Train] epoch 418 Batch 47 Loss 0.20119629800319672
[Train] epoch 419 Batch 0 Loss 0.03355704993009567
[Train] epoch 419 Batch 1 Loss 0.3352988362312317
[Train] epoch 419 Batch 2 Loss 0.06813704967498779
[Train] epoch 419 Batch 3 Loss 0.1347992867231369
[Train] epoch 419 Batch 4 Loss 0.16763538122177124
[Train] epoch 419 Batch 5 Loss 0.16763263940811157
[Train] epoch 419 Batch 6 Loss 0.20081733167171478
[Train] epoch 419 Batch 7 Loss 0.16802731156349182
[Train] epoch 419 Batch 8 Loss 0.16768062114715576
[Train] epoch 419 Batch 9 Loss 0.1672598421573639
[Train] epoch 419 Batch 10 Loss 0.10064288228750229
[Train] epoch 419 Batch 11 Loss 0.10101192444562912
[Train] epoch 419 Batch 12 Loss 0.16799600422382355
[Train] epoch 419 Batch 13 Loss 0.20149879157543182
[Train] epoch 419 Batch 14 Loss 0.13446417450904846
[Train] epoch 419 Batch 15 Loss 0.06747891753911972
[Train] epoch 419 Batch 16 Loss 0.2008891999721527
[Train] epoch 419 Batch 17 Loss 0.16722893714904785
[Train] epoch 419 Batch 18 Loss 0.13443362712860107
[Train] epoch 419 Batch 19 Loss 0.133334219455719
[Train] epoch 419 Batch 20 Loss 0.13417008519172668
[Train] epoch 419 Batch 21 Loss 0.20109719038009644
[Train] epoch 419 Batch 22 Loss 0.1344505250453949
[Train] epoch 419 Batch 23 Loss 0.23431085050106049
[Train] epoch 419 Batch 24 Loss 0.16764354705810547
[Train] epoch 419 Batch 25 Loss 0.2008592188358307
[Train] epoch 419 Batch 26 Loss 0.23467093706130981
[Train] epoch 419 Batch 27 Loss 0.1668604016304016
[Train] epoch 419 Batch 28 Loss 0.20039108395576477
[Train] epoch 419 Batch 29 Loss 0.23500484228134155
[Train] epoch 419 Batch 30 Loss 0.1002223938703537
[Train] epoch 419 Batch 31 Loss 0.2343347668647766
[Train] epoch 419 Batch 32 Loss 0.16789135336875916
[Train] epoch 419 Batch 33 Loss 0.1341126412153244
[Train] epoch 419 Batch 34 Loss 0.13483016192913055
[Train] epoch 419 Batch 35 Loss 0.20074810087680817
[Train] epoch 419 Batch 36 Loss 0.10019173473119736
[Train] epoch 419 Batch 37 Loss 0.33421868085861206
[Train] epoch 419 Batch 38 Loss 0.13444440066814423
[Train] epoch 419 Batch 39 Loss 0.16724556684494019
[Train] epoch 419 Batch 40 Loss 0.26748931407928467
[Train] epoch 419 Batch 41 Loss 0.20044270157814026
[Train] epoch 419 Batch 42 Loss 0.2011081874370575
[Train] epoch 419 Batch 43 Loss 0.23468473553657532
[Train] epoch 419 Batch 44 Loss 0.33440840244293213
[Train] epoch 419 Batch 45 Loss 0.1679617166519165
[Train] epoch 419 Batch 46 Loss 0.2674083709716797
[Train] epoch 419 Batch 47 Loss 0.03355495259165764
[Train] epoch 420 Batch 0 Loss 0.30016613006591797
[Train] epoch 420 Batch 1 Loss 0.2339310646057129
[Train] epoch 420 Batch 2 Loss 0.13410542905330658
[Train] epoch 420 Batch 3 Loss 0.16757085919380188
[Train] epoch 420 Batch 4 Loss 0.03456679731607437
[Train] epoch 420 Batch 5 Loss 0.13440091907978058
[Train] epoch 420 Batch 6 Loss 0.16762447357177734
[Train] epoch 420 Batch 7 Loss 0.13409297168254852
[Train] epoch 420 Batch 8 Loss 0.10087794065475464
[Train] epoch 420 Batch 9 Loss 0.16688770055770874
[Train] epoch 420 Batch 10 Loss 0.16685396432876587
[Train] epoch 420 Batch 11 Loss 0.13441801071166992
[Train] epoch 420 Batch 12 Loss 0.10057061165571213
[Train] epoch 420 Batch 13 Loss 0.03423045575618744
[Train] epoch 420 Batch 14 Loss 0.2674563527107239
[Train] epoch 420 Batch 15 Loss 0.1341797560453415
[Train] epoch 420 Batch 16 Loss 0.3008376955986023
[Train] epoch 420 Batch 17 Loss 0.13377413153648376
[Train] epoch 420 Batch 18 Loss 0.300545871257782
[Train] epoch 420 Batch 19 Loss 0.16826701164245605
[Train] epoch 420 Batch 20 Loss 0.20150330662727356
[Train] epoch 420 Batch 21 Loss 0.3337736129760742
[Train] epoch 420 Batch 22 Loss 0.16785940527915955
[Train] epoch 420 Batch 23 Loss 0.13432744145393372
[Train] epoch 420 Batch 24 Loss 0.10117657482624054
[Train] epoch 420 Batch 25 Loss 0.06704878062009811
[Train] epoch 420 Batch 26 Loss 0.1337735652923584
[Train] epoch 420 Batch 27 Loss 0.23443233966827393
[Train] epoch 420 Batch 28 Loss 0.16763323545455933
[Train] epoch 420 Batch 29 Loss 0.26825419068336487
[Train] epoch 420 Batch 30 Loss 0.1672671139240265
[Train] epoch 420 Batch 31 Loss 0.1673256754875183
[Train] epoch 420 Batch 32 Loss 0.1675717830657959
[Train] epoch 420 Batch 33 Loss 0.20106461644172668
[Train] epoch 420 Batch 34 Loss 0.16808360815048218
[Train] epoch 420 Batch 35 Loss 0.2344295084476471
[Train] epoch 420 Batch 36 Loss 0.26837390661239624
[Train] epoch 420 Batch 37 Loss 0.16684873402118683
[Train] epoch 420 Batch 38 Loss 0.3013168275356293
[Train] epoch 420 Batch 39 Loss 0.13443073630332947
[Train] epoch 420 Batch 40 Loss 0.26738518476486206
[Train] epoch 420 Batch 41 Loss 0.2342698872089386
[Train] epoch 420 Batch 42 Loss 0.16837884485721588
[Train] epoch 420 Batch 43 Loss 0.16760197281837463
[Train] epoch 420 Batch 44 Loss 0.0006567736272700131
[Train] epoch 420 Batch 45 Loss 0.10218431055545807
[Train] epoch 420 Batch 46 Loss 0.23355233669281006
[Train] epoch 420 Batch 47 Loss 0.0671040341258049
[Train] epoch 421 Batch 0 Loss 0.16726171970367432
[Train] epoch 421 Batch 1 Loss 0.06769540905952454
[Train] epoch 421 Batch 2 Loss 0.20096725225448608
[Train] epoch 421 Batch 3 Loss 0.06769353151321411
[Train] epoch 421 Batch 4 Loss 0.10130449384450912
[Train] epoch 421 Batch 5 Loss 0.1677875518798828
[Train] epoch 421 Batch 6 Loss 0.3001575469970703
[Train] epoch 421 Batch 7 Loss 0.06766875088214874
[Train] epoch 421 Batch 8 Loss 0.20043644309043884
[Train] epoch 421 Batch 9 Loss 0.2007080316543579
[Train] epoch 421 Batch 10 Loss 0.2677685022354126
[Train] epoch 421 Batch 11 Loss 0.1682562232017517
[Train] epoch 421 Batch 12 Loss 0.16792267560958862
[Train] epoch 421 Batch 13 Loss 0.13447436690330505
[Train] epoch 421 Batch 14 Loss 0.36725789308547974
[Train] epoch 421 Batch 15 Loss 0.06774399429559708
[Train] epoch 421 Batch 16 Loss 0.20072411000728607
[Train] epoch 421 Batch 17 Loss 0.1683320552110672
[Train] epoch 421 Batch 18 Loss 0.1001758873462677
[Train] epoch 421 Batch 19 Loss 0.06798483431339264
[Train] epoch 421 Batch 20 Loss 0.2673679292201996
[Train] epoch 421 Batch 21 Loss 0.16719314455986023
[Train] epoch 421 Batch 22 Loss 0.20113468170166016
[Train] epoch 421 Batch 23 Loss 0.3012444078922272
[Train] epoch 421 Batch 24 Loss 0.23398560285568237
[Train] epoch 421 Batch 25 Loss 0.1676657497882843
[Train] epoch 421 Batch 26 Loss 0.13438184559345245
[Train] epoch 421 Batch 27 Loss 0.23420369625091553
[Train] epoch 421 Batch 28 Loss 0.16770806908607483
[Train] epoch 421 Batch 29 Loss 0.26710107922554016
[Train] epoch 421 Batch 30 Loss 0.16782107949256897
[Train] epoch 421 Batch 31 Loss 0.10106994211673737
[Train] epoch 421 Batch 32 Loss 0.13448108732700348
[Train] epoch 421 Batch 33 Loss 0.1012156754732132
[Train] epoch 421 Batch 34 Loss 0.200822114944458
[Train] epoch 421 Batch 35 Loss 0.3006051778793335
[Train] epoch 421 Batch 36 Loss 0.10060512274503708
[Train] epoch 421 Batch 37 Loss 0.16688378155231476
[Train] epoch 421 Batch 38 Loss 0.13430316746234894
[Train] epoch 421 Batch 39 Loss 0.13372141122817993
[Train] epoch 421 Batch 40 Loss 0.16798630356788635
[Train] epoch 421 Batch 41 Loss 0.13432657718658447
[Train] epoch 421 Batch 42 Loss 0.0670541524887085
[Train] epoch 421 Batch 43 Loss 0.1676366627216339
[Train] epoch 421 Batch 44 Loss 0.13397684693336487
[Train] epoch 421 Batch 45 Loss 0.26741987466812134
[Train] epoch 421 Batch 46 Loss 0.23354974389076233
[Train] epoch 421 Batch 47 Loss 0.2338053584098816
[Train] epoch 422 Batch 0 Loss 0.03412555903196335
[Train] epoch 422 Batch 1 Loss 0.30198103189468384
[Train] epoch 422 Batch 2 Loss 0.30096670985221863
[Train] epoch 422 Batch 3 Loss 0.06726852804422379
[Train] epoch 422 Batch 4 Loss 0.26735198497772217
[Train] epoch 422 Batch 5 Loss 0.20043131709098816
[Train] epoch 422 Batch 6 Loss 0.06709804385900497
[Train] epoch 422 Batch 7 Loss 0.06735095381736755
[Train] epoch 422 Batch 8 Loss 0.13426996767520905
[Train] epoch 422 Batch 9 Loss 0.06741559505462646
[Train] epoch 422 Batch 10 Loss 0.1676112413406372
[Train] epoch 422 Batch 11 Loss 0.26766636967658997
[Train] epoch 422 Batch 12 Loss 0.30155909061431885
[Train] epoch 422 Batch 13 Loss 0.16747848689556122
[Train] epoch 422 Batch 14 Loss 0.16787895560264587
[Train] epoch 422 Batch 15 Loss 0.16785934567451477
[Train] epoch 422 Batch 16 Loss 0.13437654078006744
[Train] epoch 422 Batch 17 Loss 0.16713149845600128
[Train] epoch 422 Batch 18 Loss 0.2344067543745041
[Train] epoch 422 Batch 19 Loss 0.10118928551673889
[Train] epoch 422 Batch 20 Loss 0.30122533440589905
[Train] epoch 422 Batch 21 Loss 0.2669631838798523
[Train] epoch 422 Batch 22 Loss 0.10075819492340088
[Train] epoch 422 Batch 23 Loss 0.23392857611179352
[Train] epoch 422 Batch 24 Loss 0.2015790194272995
[Train] epoch 422 Batch 25 Loss 0.16719463467597961
[Train] epoch 422 Batch 26 Loss 0.16721263527870178
[Train] epoch 422 Batch 27 Loss 0.0673593282699585
[Train] epoch 422 Batch 28 Loss 0.16721183061599731
[Train] epoch 422 Batch 29 Loss 0.20074039697647095
[Train] epoch 422 Batch 30 Loss 0.13407346606254578
[Train] epoch 422 Batch 31 Loss 0.20037931203842163
[Train] epoch 422 Batch 32 Loss 0.10045810043811798
[Train] epoch 422 Batch 33 Loss 0.20117920637130737
[Train] epoch 422 Batch 34 Loss 0.13596609234809875
[Train] epoch 422 Batch 35 Loss 0.10126079618930817
[Train] epoch 422 Batch 36 Loss 0.06705032289028168
[Train] epoch 422 Batch 37 Loss 0.10021518170833588
[Train] epoch 422 Batch 38 Loss 0.23473578691482544
[Train] epoch 422 Batch 39 Loss 0.30062034726142883
[Train] epoch 422 Batch 40 Loss 0.2671009302139282
[Train] epoch 422 Batch 41 Loss 0.20098067820072174
[Train] epoch 422 Batch 42 Loss 0.234431654214859
[Train] epoch 422 Batch 43 Loss 0.10107764601707458
[Train] epoch 422 Batch 44 Loss 0.13515765964984894
[Train] epoch 422 Batch 45 Loss 0.1677832007408142
[Train] epoch 422 Batch 46 Loss 0.23529650270938873
[Train] epoch 422 Batch 47 Loss 0.1678023487329483
[Train] epoch 423 Batch 0 Loss 0.1337801218032837
[Train] epoch 423 Batch 1 Loss 0.17069165408611298
[Train] epoch 423 Batch 2 Loss 0.06855155527591705
[Train] epoch 423 Batch 3 Loss 0.26641565561294556
[Train] epoch 423 Batch 4 Loss 0.1450578272342682
[Train] epoch 423 Batch 5 Loss 0.06761406362056732
[Train] epoch 423 Batch 6 Loss 0.16733315587043762
[Train] epoch 423 Batch 7 Loss 0.20168150961399078
[Train] epoch 423 Batch 8 Loss 0.201236754655838
[Train] epoch 423 Batch 9 Loss 0.36726951599121094
[Train] epoch 423 Batch 10 Loss 0.1742066591978073
[Train] epoch 423 Batch 11 Loss 0.1378098428249359
[Train] epoch 423 Batch 12 Loss 0.1673160046339035
[Train] epoch 423 Batch 13 Loss 0.23408126831054688
[Train] epoch 423 Batch 14 Loss 0.06814152002334595
[Train] epoch 423 Batch 15 Loss 0.1354198157787323
[Train] epoch 423 Batch 16 Loss 0.13442085683345795
[Train] epoch 423 Batch 17 Loss 0.13451476395130157
[Train] epoch 423 Batch 18 Loss 0.1345752626657486
[Train] epoch 423 Batch 19 Loss 0.13458286225795746
[Train] epoch 423 Batch 20 Loss 0.23498576879501343
[Train] epoch 423 Batch 21 Loss 0.2029241919517517
[Train] epoch 423 Batch 22 Loss 0.16892555356025696
[Train] epoch 423 Batch 23 Loss 0.1698477566242218
[Train] epoch 423 Batch 24 Loss 0.13390183448791504
[Train] epoch 423 Batch 25 Loss 0.1348818987607956
[Train] epoch 423 Batch 26 Loss 0.2343900203704834
[Train] epoch 423 Batch 27 Loss 0.10218854248523712
[Train] epoch 423 Batch 28 Loss 0.1342325210571289
[Train] epoch 423 Batch 29 Loss 0.33599868416786194
[Train] epoch 423 Batch 30 Loss 0.10312498360872269
[Train] epoch 423 Batch 31 Loss 0.20118454098701477
[Train] epoch 423 Batch 32 Loss 0.13817565143108368
[Train] epoch 423 Batch 33 Loss 0.36860787868499756
[Train] epoch 423 Batch 34 Loss 0.20137880742549896
[Train] epoch 423 Batch 35 Loss 0.23527583479881287
[Train] epoch 423 Batch 36 Loss 0.10133954882621765
[Train] epoch 423 Batch 37 Loss 0.13664260506629944
[Train] epoch 423 Batch 38 Loss 0.13525709509849548
[Train] epoch 423 Batch 39 Loss 0.10241870582103729
[Train] epoch 423 Batch 40 Loss 0.10206851363182068
[Train] epoch 423 Batch 41 Loss 0.3026614785194397
[Train] epoch 423 Batch 42 Loss 0.034504905343055725
[Train] epoch 423 Batch 43 Loss 0.3683820366859436
[Train] epoch 423 Batch 44 Loss 0.16800308227539062
[Train] epoch 423 Batch 45 Loss 0.23707282543182373
[Train] epoch 423 Batch 46 Loss 0.2682304084300995
[Train] epoch 423 Batch 47 Loss 0.20143988728523254
[Train] epoch 424 Batch 0 Loss 0.26918619871139526
[Train] epoch 424 Batch 1 Loss 0.10284562408924103
[Train] epoch 424 Batch 2 Loss 0.2688078284263611
[Train] epoch 424 Batch 3 Loss 0.13395094871520996
[Train] epoch 424 Batch 4 Loss 0.13568785786628723
[Train] epoch 424 Batch 5 Loss 0.1676512062549591
[Train] epoch 424 Batch 6 Loss 0.2023594081401825
[Train] epoch 424 Batch 7 Loss 0.133334219455719
[Train] epoch 424 Batch 8 Loss 0.10201747715473175
[Train] epoch 424 Batch 9 Loss 0.20146557688713074
[Train] epoch 424 Batch 10 Loss 0.13565972447395325
[Train] epoch 424 Batch 11 Loss 0.16761016845703125
[Train] epoch 424 Batch 12 Loss 0.20260396599769592
[Train] epoch 424 Batch 13 Loss 0.03682653233408928
[Train] epoch 424 Batch 14 Loss 0.20206134021282196
[Train] epoch 424 Batch 15 Loss 0.2013353407382965
[Train] epoch 424 Batch 16 Loss 0.07020579278469086
[Train] epoch 424 Batch 17 Loss 0.20148898661136627
[Train] epoch 424 Batch 18 Loss 0.10101145505905151
[Train] epoch 424 Batch 19 Loss 0.23495088517665863
[Train] epoch 424 Batch 20 Loss 0.03440993279218674
[Train] epoch 424 Batch 21 Loss 0.3024407625198364
[Train] epoch 424 Batch 22 Loss 0.23502004146575928
[Train] epoch 424 Batch 23 Loss 0.2686304450035095
[Train] epoch 424 Batch 24 Loss 0.3016591966152191
[Train] epoch 424 Batch 25 Loss 0.06732885539531708
[Train] epoch 424 Batch 26 Loss 0.3010420799255371
[Train] epoch 424 Batch 27 Loss 0.3345794379711151
[Train] epoch 424 Batch 28 Loss 0.10228359699249268
[Train] epoch 424 Batch 29 Loss 0.1339568793773651
[Train] epoch 424 Batch 30 Loss 0.23498106002807617
[Train] epoch 424 Batch 31 Loss 0.1683281660079956
[Train] epoch 424 Batch 32 Loss 0.23361827433109283
[Train] epoch 424 Batch 33 Loss 0.16901704668998718
[Train] epoch 424 Batch 34 Loss 0.16890951991081238
[Train] epoch 424 Batch 35 Loss 0.16961655020713806
[Train] epoch 424 Batch 36 Loss 0.20065680146217346
[Train] epoch 424 Batch 37 Loss 0.03364556282758713
[Train] epoch 424 Batch 38 Loss 0.3365219235420227
[Train] epoch 424 Batch 39 Loss 0.2349458783864975
[Train] epoch 424 Batch 40 Loss 0.13450506329536438
[Train] epoch 424 Batch 41 Loss 0.16823357343673706
[Train] epoch 424 Batch 42 Loss 0.30152273178100586
[Train] epoch 424 Batch 43 Loss 0.13455908000469208
[Train] epoch 424 Batch 44 Loss 0.0336039736866951
[Train] epoch 424 Batch 45 Loss 0.06794717907905579
[Train] epoch 424 Batch 46 Loss 0.06790092587471008
[Train] epoch 424 Batch 47 Loss 0.1681784689426422
[Train] epoch 425 Batch 0 Loss 0.1345016062259674
[Train] epoch 425 Batch 1 Loss 0.2341875582933426
[Train] epoch 425 Batch 2 Loss 0.1009448766708374
[Train] epoch 425 Batch 3 Loss 0.3015176057815552
[Train] epoch 425 Batch 4 Loss 0.20179696381092072
[Train] epoch 425 Batch 5 Loss 0.20185697078704834
[Train] epoch 425 Batch 6 Loss 0.3021390736103058
[Train] epoch 425 Batch 7 Loss 0.26729416847229004
[Train] epoch 425 Batch 8 Loss 0.30088096857070923
[Train] epoch 425 Batch 9 Loss 0.13457956910133362
[Train] epoch 425 Batch 10 Loss 0.035468269139528275
[Train] epoch 425 Batch 11 Loss 0.3015005886554718
[Train] epoch 425 Batch 12 Loss 0.1351436972618103
[Train] epoch 425 Batch 13 Loss 0.1345738172531128
[Train] epoch 425 Batch 14 Loss 0.1669762134552002
[Train] epoch 425 Batch 15 Loss 0.26841306686401367
[Train] epoch 425 Batch 16 Loss 0.03481455519795418
[Train] epoch 425 Batch 17 Loss 0.20118266344070435
[Train] epoch 425 Batch 18 Loss 0.10264301300048828
[Train] epoch 425 Batch 19 Loss 0.1368843913078308
[Train] epoch 425 Batch 20 Loss 0.16747067868709564
[Train] epoch 425 Batch 21 Loss 0.10141973197460175
[Train] epoch 425 Batch 22 Loss 0.10146728157997131
[Train] epoch 425 Batch 23 Loss 0.16741123795509338
[Train] epoch 425 Batch 24 Loss 0.13568514585494995
[Train] epoch 425 Batch 25 Loss 0.10149343311786652
[Train] epoch 425 Batch 26 Loss 0.1675952970981598
[Train] epoch 425 Batch 27 Loss 0.16862359642982483
[Train] epoch 425 Batch 28 Loss 0.1681794673204422
[Train] epoch 425 Batch 29 Loss 0.30320829153060913
[Train] epoch 425 Batch 30 Loss 0.23525796830654144
[Train] epoch 425 Batch 31 Loss 0.20174601674079895
[Train] epoch 425 Batch 32 Loss 0.3015020489692688
[Train] epoch 425 Batch 33 Loss 0.0683375895023346
[Train] epoch 425 Batch 34 Loss 0.10124075412750244
[Train] epoch 425 Batch 35 Loss 0.3014943599700928
[Train] epoch 425 Batch 36 Loss 0.26784995198249817
[Train] epoch 425 Batch 37 Loss 0.03420599177479744
[Train] epoch 425 Batch 38 Loss 0.20061799883842468
[Train] epoch 425 Batch 39 Loss 0.06835858523845673
[Train] epoch 425 Batch 40 Loss 0.3338471055030823
[Train] epoch 425 Batch 41 Loss 0.13501831889152527
[Train] epoch 425 Batch 42 Loss 0.13446101546287537
[Train] epoch 425 Batch 43 Loss 0.1339506208896637
[Train] epoch 425 Batch 44 Loss 0.13391774892807007
[Train] epoch 425 Batch 45 Loss 0.03360908478498459
[Train] epoch 425 Batch 46 Loss 0.13491810858249664
[Train] epoch 425 Batch 47 Loss 0.267206072807312
[Train] epoch 426 Batch 0 Loss 0.2022458016872406
[Train] epoch 426 Batch 1 Loss 0.13383634388446808
[Train] epoch 426 Batch 2 Loss 0.23533675074577332
[Train] epoch 426 Batch 3 Loss 0.33499062061309814
[Train] epoch 426 Batch 4 Loss 0.1008070856332779
[Train] epoch 426 Batch 5 Loss 0.30138254165649414
[Train] epoch 426 Batch 6 Loss 0.0010358489817008376
[Train] epoch 426 Batch 7 Loss 0.06716319173574448
[Train] epoch 426 Batch 8 Loss 0.10092171281576157
[Train] epoch 426 Batch 9 Loss 0.1353081315755844
[Train] epoch 426 Batch 10 Loss 0.20209193229675293
[Train] epoch 426 Batch 11 Loss 0.10132987797260284
[Train] epoch 426 Batch 12 Loss 0.23470187187194824
[Train] epoch 426 Batch 13 Loss 0.20052888989448547
[Train] epoch 426 Batch 14 Loss 0.13492123782634735
[Train] epoch 426 Batch 15 Loss 0.30140605568885803
[Train] epoch 426 Batch 16 Loss 0.23420903086662292
[Train] epoch 426 Batch 17 Loss 0.13385650515556335
[Train] epoch 426 Batch 18 Loss 0.2678471505641937
[Train] epoch 426 Batch 19 Loss 0.2346877157688141
[Train] epoch 426 Batch 20 Loss 0.06819340586662292
[Train] epoch 426 Batch 21 Loss 0.2688884437084198
[Train] epoch 426 Batch 22 Loss 0.13441458344459534
[Train] epoch 426 Batch 23 Loss 0.10130907595157623
[Train] epoch 426 Batch 24 Loss 0.20215338468551636
[Train] epoch 426 Batch 25 Loss 0.167497456073761
[Train] epoch 426 Batch 26 Loss 0.26878687739372253
[Train] epoch 426 Batch 27 Loss 0.20250171422958374
[Train] epoch 426 Batch 28 Loss 0.033639732748270035
[Train] epoch 426 Batch 29 Loss 0.13394473493099213
[Train] epoch 426 Batch 30 Loss 0.23527662456035614
[Train] epoch 426 Batch 31 Loss 0.3024296760559082
[Train] epoch 426 Batch 32 Loss 0.13446398079395294
[Train] epoch 426 Batch 33 Loss 0.26774275302886963
[Train] epoch 426 Batch 34 Loss 0.2682243585586548
[Train] epoch 426 Batch 35 Loss 0.16793638467788696
[Train] epoch 426 Batch 36 Loss 0.1349235326051712
[Train] epoch 426 Batch 37 Loss 0.23447227478027344
[Train] epoch 426 Batch 38 Loss 0.13434796035289764
[Train] epoch 426 Batch 39 Loss 0.10091180354356766
[Train] epoch 426 Batch 40 Loss 0.13434484601020813
[Train] epoch 426 Batch 41 Loss 0.13483735918998718
[Train] epoch 426 Batch 42 Loss 0.10125494003295898
[Train] epoch 426 Batch 43 Loss 0.13443221151828766
[Train] epoch 426 Batch 44 Loss 0.10070231556892395
[Train] epoch 426 Batch 45 Loss 0.26708775758743286
[Train] epoch 426 Batch 46 Loss 0.16691191494464874
[Train] epoch 426 Batch 47 Loss 0.10122047364711761
[Train] epoch 427 Batch 0 Loss 0.16736340522766113
[Train] epoch 427 Batch 1 Loss 0.06717893481254578
[Train] epoch 427 Batch 2 Loss 0.1683824211359024
[Train] epoch 427 Batch 3 Loss 0.20115017890930176
[Train] epoch 427 Batch 4 Loss 0.06717771291732788
[Train] epoch 427 Batch 5 Loss 0.06817512214183807
[Train] epoch 427 Batch 6 Loss 0.13387703895568848
[Train] epoch 427 Batch 7 Loss 0.16744990646839142
[Train] epoch 427 Batch 8 Loss 0.16843679547309875
[Train] epoch 427 Batch 9 Loss 0.20060493052005768
[Train] epoch 427 Batch 10 Loss 0.16836605966091156
[Train] epoch 427 Batch 11 Loss 0.13526909053325653
[Train] epoch 427 Batch 12 Loss 0.2019018977880478
[Train] epoch 427 Batch 13 Loss 0.1342834085226059
[Train] epoch 427 Batch 14 Loss 0.2019919902086258
[Train] epoch 427 Batch 15 Loss 0.0681505799293518
[Train] epoch 427 Batch 16 Loss 0.10074129700660706
[Train] epoch 427 Batch 17 Loss 0.3679775297641754
[Train] epoch 427 Batch 18 Loss 0.2008747160434723
[Train] epoch 427 Batch 19 Loss 0.3011740446090698
[Train] epoch 427 Batch 20 Loss 0.10170700401067734
[Train] epoch 427 Batch 21 Loss 0.10123348236083984
[Train] epoch 427 Batch 22 Loss 0.1344010829925537
[Train] epoch 427 Batch 23 Loss 0.3013361096382141
[Train] epoch 427 Batch 24 Loss 0.1680329591035843
[Train] epoch 427 Batch 25 Loss 0.16796159744262695
[Train] epoch 427 Batch 26 Loss 0.30176234245300293
[Train] epoch 427 Batch 27 Loss 0.2013891339302063
[Train] epoch 427 Batch 28 Loss 0.400459349155426
[Train] epoch 427 Batch 29 Loss 0.2676239609718323
[Train] epoch 427 Batch 30 Loss 0.13446345925331116
[Train] epoch 427 Batch 31 Loss 0.13383205235004425
[Train] epoch 427 Batch 32 Loss 0.03483716398477554
[Train] epoch 427 Batch 33 Loss 0.30177903175354004
[Train] epoch 427 Batch 34 Loss 0.13393385708332062
[Train] epoch 427 Batch 35 Loss 0.13526172935962677
[Train] epoch 427 Batch 36 Loss 0.0013266042806208134
[Train] epoch 427 Batch 37 Loss 0.4009910225868225
[Train] epoch 427 Batch 38 Loss 0.1683768332004547
[Train] epoch 427 Batch 39 Loss 0.06716196984052658
[Train] epoch 427 Batch 40 Loss 0.06726594269275665
[Train] epoch 427 Batch 41 Loss 0.06726568192243576
[Train] epoch 427 Batch 42 Loss 0.13437879085540771
[Train] epoch 427 Batch 43 Loss 0.4020122289657593
[Train] epoch 427 Batch 44 Loss 0.10119053721427917
[Train] epoch 427 Batch 45 Loss 0.4019499123096466
[Train] epoch 427 Batch 46 Loss 0.16790121793746948
[Train] epoch 427 Batch 47 Loss 0.06708209961652756
[Train] epoch 428 Batch 0 Loss 0.2340172529220581
[Train] epoch 428 Batch 1 Loss 0.10112517327070236
[Train] epoch 428 Batch 2 Loss 0.13374680280685425
[Train] epoch 428 Batch 3 Loss 0.034072309732437134
[Train] epoch 428 Batch 4 Loss 0.2005959153175354
[Train] epoch 428 Batch 5 Loss 0.10114821791648865
[Train] epoch 428 Batch 6 Loss 0.10114684700965881
[Train] epoch 428 Batch 7 Loss 0.16863131523132324
[Train] epoch 428 Batch 8 Loss 0.3008922040462494
[Train] epoch 428 Batch 9 Loss 0.16899730265140533
[Train] epoch 428 Batch 10 Loss 0.3012198805809021
[Train] epoch 428 Batch 11 Loss 0.13509713113307953
[Train] epoch 428 Batch 12 Loss 0.33428484201431274
[Train] epoch 428 Batch 13 Loss 0.33481892943382263
[Train] epoch 428 Batch 14 Loss 0.36726677417755127
[Train] epoch 428 Batch 15 Loss 0.033551886677742004
[Train] epoch 428 Batch 16 Loss 0.16754809021949768
[Train] epoch 428 Batch 17 Loss 0.16957397758960724
[Train] epoch 428 Batch 18 Loss 0.2014075219631195
[Train] epoch 428 Batch 19 Loss 0.16737055778503418
[Train] epoch 428 Batch 20 Loss 0.26817038655281067
[Train] epoch 428 Batch 21 Loss 0.13425402343273163
[Train] epoch 428 Batch 22 Loss 0.06751350313425064
[Train] epoch 428 Batch 23 Loss 0.1674649715423584
[Train] epoch 428 Batch 24 Loss 0.3008703887462616
[Train] epoch 428 Batch 25 Loss 0.16879194974899292
[Train] epoch 428 Batch 26 Loss 0.10113402456045151
[Train] epoch 428 Batch 27 Loss 0.1674400269985199
[Train] epoch 428 Batch 28 Loss 0.20091594755649567
[Train] epoch 428 Batch 29 Loss 0.2018507868051529
[Train] epoch 428 Batch 30 Loss 0.03405341878533363
[Train] epoch 428 Batch 31 Loss 0.16786810755729675
[Train] epoch 428 Batch 32 Loss 0.0016990440199151635
[Train] epoch 428 Batch 33 Loss 0.13415104150772095
[Train] epoch 428 Batch 34 Loss 0.167362779378891
[Train] epoch 428 Batch 35 Loss 0.2010563164949417
[Train] epoch 428 Batch 36 Loss 0.13433536887168884
[Train] epoch 428 Batch 37 Loss 0.13424052298069
[Train] epoch 428 Batch 38 Loss 0.23404645919799805
[Train] epoch 428 Batch 39 Loss 0.20147858560085297
[Train] epoch 428 Batch 40 Loss 0.16785743832588196
[Train] epoch 428 Batch 41 Loss 0.13456587493419647
[Train] epoch 428 Batch 42 Loss 0.23409879207611084
[Train] epoch 428 Batch 43 Loss 0.36848196387290955
[Train] epoch 428 Batch 44 Loss 0.06714527308940887
[Train] epoch 428 Batch 45 Loss 0.10110989212989807
[Train] epoch 428 Batch 46 Loss 0.16829031705856323
[Train] epoch 428 Batch 47 Loss 0.16784945130348206
[Train] epoch 429 Batch 0 Loss 0.16779135167598724
[Train] epoch 429 Batch 1 Loss 0.20098994672298431
[Train] epoch 429 Batch 2 Loss 0.06757952272891998
[Train] epoch 429 Batch 3 Loss 0.2675594985485077
[Train] epoch 429 Batch 4 Loss 0.16890676319599152
[Train] epoch 429 Batch 5 Loss 0.10151457786560059
[Train] epoch 429 Batch 6 Loss 0.16736724972724915
[Train] epoch 429 Batch 7 Loss 0.33477240800857544
[Train] epoch 429 Batch 8 Loss 0.1351073980331421
[Train] epoch 429 Batch 9 Loss 0.20184946060180664
[Train] epoch 429 Batch 10 Loss 0.1338244080543518
[Train] epoch 429 Batch 11 Loss 0.03401169553399086
[Train] epoch 429 Batch 12 Loss 0.16744062304496765
[Train] epoch 429 Batch 13 Loss 0.10097228735685349
[Train] epoch 429 Batch 14 Loss 0.10067608952522278
[Train] epoch 429 Batch 15 Loss 0.23451422154903412
[Train] epoch 429 Batch 16 Loss 0.2340872585773468
[Train] epoch 429 Batch 17 Loss 0.20191362500190735
[Train] epoch 429 Batch 18 Loss 0.13380318880081177
[Train] epoch 429 Batch 19 Loss 0.3679050803184509
[Train] epoch 429 Batch 20 Loss 0.3675158619880676
[Train] epoch 429 Batch 21 Loss 0.23494037985801697
[Train] epoch 429 Batch 22 Loss 0.33420634269714355
[Train] epoch 429 Batch 23 Loss 0.16782137751579285
[Train] epoch 429 Batch 24 Loss 0.20127540826797485
[Train] epoch 429 Batch 25 Loss 0.20040419697761536
[Train] epoch 429 Batch 26 Loss 0.0007893740548752248
[Train] epoch 429 Batch 27 Loss 0.23353521525859833
[Train] epoch 429 Batch 28 Loss 0.03432135283946991
[Train] epoch 429 Batch 29 Loss 0.16781526803970337
[Train] epoch 429 Batch 30 Loss 0.10074718296527863
[Train] epoch 429 Batch 31 Loss 0.2684131860733032
[Train] epoch 429 Batch 32 Loss 0.034380316734313965
[Train] epoch 429 Batch 33 Loss 0.03389843925833702
[Train] epoch 429 Batch 34 Loss 0.26799219846725464
[Train] epoch 429 Batch 35 Loss 0.13389654457569122
[Train] epoch 429 Batch 36 Loss 0.1675107181072235
[Train] epoch 429 Batch 37 Loss 0.10028189420700073
[Train] epoch 429 Batch 38 Loss 0.10151900351047516
[Train] epoch 429 Batch 39 Loss 0.20211076736450195
[Train] epoch 429 Batch 40 Loss 0.30074262619018555
[Train] epoch 429 Batch 41 Loss 0.23525869846343994
[Train] epoch 429 Batch 42 Loss 0.26788222789764404
[Train] epoch 429 Batch 43 Loss 0.0003941780887544155
[Train] epoch 429 Batch 44 Loss 0.10162641853094101
[Train] epoch 429 Batch 45 Loss 0.2343813180923462
[Train] epoch 429 Batch 46 Loss 0.13495036959648132
[Train] epoch 429 Batch 47 Loss 0.20091837644577026
[Train] epoch 430 Batch 0 Loss 0.000374496856238693
[Train] epoch 430 Batch 1 Loss 0.20076268911361694
[Train] epoch 430 Batch 2 Loss 0.10229206085205078
[Train] epoch 430 Batch 3 Loss 0.26807165145874023
[Train] epoch 430 Batch 4 Loss 0.23493054509162903
[Train] epoch 430 Batch 5 Loss 0.16684460639953613
[Train] epoch 430 Batch 6 Loss 0.03361374884843826
[Train] epoch 430 Batch 7 Loss 0.2008097618818283
[Train] epoch 430 Batch 8 Loss 0.3344508409500122
[Train] epoch 430 Batch 9 Loss 0.13380523025989532
[Train] epoch 430 Batch 10 Loss 0.16796180605888367
[Train] epoch 430 Batch 11 Loss 0.2341708093881607
[Train] epoch 430 Batch 12 Loss 0.23390749096870422
[Train] epoch 430 Batch 13 Loss 0.20036691427230835
[Train] epoch 430 Batch 14 Loss 0.3011142313480377
[Train] epoch 430 Batch 15 Loss 0.034270770847797394
[Train] epoch 430 Batch 16 Loss 0.1007479727268219
[Train] epoch 430 Batch 17 Loss 0.10140305757522583
[Train] epoch 430 Batch 18 Loss 0.20173734426498413
[Train] epoch 430 Batch 19 Loss 0.2684485912322998
[Train] epoch 430 Batch 20 Loss 0.1672038584947586
[Train] epoch 430 Batch 21 Loss 0.3347929120063782
[Train] epoch 430 Batch 22 Loss 0.16778868436813354
[Train] epoch 430 Batch 23 Loss 0.26832157373428345
[Train] epoch 430 Batch 24 Loss 0.10056458413600922
[Train] epoch 430 Batch 25 Loss 0.23352167010307312
[Train] epoch 430 Batch 26 Loss 0.20173972845077515
[Train] epoch 430 Batch 27 Loss 0.3009207844734192
[Train] epoch 430 Batch 28 Loss 0.16730332374572754
[Train] epoch 430 Batch 29 Loss 0.100560262799263
[Train] epoch 430 Batch 30 Loss 0.13414010405540466
[Train] epoch 430 Batch 31 Loss 0.16803020238876343
[Train] epoch 430 Batch 32 Loss 0.16822610795497894
[Train] epoch 430 Batch 33 Loss 0.2011086642742157
[Train] epoch 430 Batch 34 Loss 0.20146355032920837
[Train] epoch 430 Batch 35 Loss 0.20081719756126404
[Train] epoch 430 Batch 36 Loss 0.2349647879600525
[Train] epoch 430 Batch 37 Loss 0.16774412989616394
[Train] epoch 430 Batch 38 Loss 0.13425493240356445
[Train] epoch 430 Batch 39 Loss 0.06757301837205887
[Train] epoch 430 Batch 40 Loss 0.10098236799240112
[Train] epoch 430 Batch 41 Loss 0.134330615401268
[Train] epoch 430 Batch 42 Loss 0.10099489241838455
[Train] epoch 430 Batch 43 Loss 0.13478784263134003
[Train] epoch 430 Batch 44 Loss 0.10145111382007599
[Train] epoch 430 Batch 45 Loss 0.2339743673801422
[Train] epoch 430 Batch 46 Loss 0.13485687971115112
[Train] epoch 430 Batch 47 Loss 0.16719946265220642
[Train] epoch 431 Batch 0 Loss 0.06703130900859833
[Train] epoch 431 Batch 1 Loss 0.23485597968101501
[Train] epoch 431 Batch 2 Loss 0.400334894657135
[Train] epoch 431 Batch 3 Loss 0.23459884524345398
[Train] epoch 431 Batch 4 Loss 0.23433201014995575
[Train] epoch 431 Batch 5 Loss 0.16728895902633667
[Train] epoch 431 Batch 6 Loss 0.1679302155971527
[Train] epoch 431 Batch 7 Loss 0.13449546694755554
[Train] epoch 431 Batch 8 Loss 0.23440784215927124
[Train] epoch 431 Batch 9 Loss 0.13378772139549255
[Train] epoch 431 Batch 10 Loss 0.1345859318971634
[Train] epoch 431 Batch 11 Loss 0.10152501612901688
[Train] epoch 431 Batch 12 Loss 0.13378672301769257
[Train] epoch 431 Batch 13 Loss 0.23404553532600403
[Train] epoch 431 Batch 14 Loss 0.3006175458431244
[Train] epoch 431 Batch 15 Loss 0.13528171181678772
[Train] epoch 431 Batch 16 Loss 0.10095992684364319
[Train] epoch 431 Batch 17 Loss 0.16855469346046448
[Train] epoch 431 Batch 18 Loss 0.1001652255654335
[Train] epoch 431 Batch 19 Loss 0.16781282424926758
[Train] epoch 431 Batch 20 Loss 0.10084765404462814
[Train] epoch 431 Batch 21 Loss 0.13447919487953186
[Train] epoch 431 Batch 22 Loss 0.13412386178970337
[Train] epoch 431 Batch 23 Loss 0.10027289390563965
[Train] epoch 431 Batch 24 Loss 0.10201162099838257
[Train] epoch 431 Batch 25 Loss 0.2016976773738861
[Train] epoch 431 Batch 26 Loss 0.30062443017959595
[Train] epoch 431 Batch 27 Loss 0.1007065623998642
[Train] epoch 431 Batch 28 Loss 0.1681841015815735
[Train] epoch 431 Batch 29 Loss 0.3006093204021454
[Train] epoch 431 Batch 30 Loss 0.13378053903579712
[Train] epoch 431 Batch 31 Loss 0.13411661982536316
[Train] epoch 431 Batch 32 Loss 0.2678947150707245
[Train] epoch 431 Batch 33 Loss 0.16771945357322693
[Train] epoch 431 Batch 34 Loss 0.13444966077804565
[Train] epoch 431 Batch 35 Loss 0.20199137926101685
[Train] epoch 431 Batch 36 Loss 0.16781380772590637
[Train] epoch 431 Batch 37 Loss 0.20076563954353333
[Train] epoch 431 Batch 38 Loss 0.16771498322486877
[Train] epoch 431 Batch 39 Loss 0.033937666565179825
[Train] epoch 431 Batch 40 Loss 0.30017343163490295
[Train] epoch 431 Batch 41 Loss 0.16816788911819458
[Train] epoch 431 Batch 42 Loss 0.201119527220726
[Train] epoch 431 Batch 43 Loss 0.16737931966781616
[Train] epoch 431 Batch 44 Loss 0.06822216510772705
[Train] epoch 431 Batch 45 Loss 0.167742520570755
[Train] epoch 431 Batch 46 Loss 0.1676945686340332
[Train] epoch 431 Batch 47 Loss 0.2675761580467224
[Train] epoch 432 Batch 0 Loss 0.2010049670934677
[Train] epoch 432 Batch 1 Loss 0.23410603404045105
[Train] epoch 432 Batch 2 Loss 0.20417869091033936
[Train] epoch 432 Batch 3 Loss 0.2681732475757599
[Train] epoch 432 Batch 4 Loss 0.1684493124485016
[Train] epoch 432 Batch 5 Loss 0.1338609755039215
[Train] epoch 432 Batch 6 Loss 0.26721662282943726
[Train] epoch 432 Batch 7 Loss 0.1338915228843689
[Train] epoch 432 Batch 8 Loss 0.20163920521736145
[Train] epoch 432 Batch 9 Loss 0.2022992968559265
[Train] epoch 432 Batch 10 Loss 0.2684336006641388
[Train] epoch 432 Batch 11 Loss 0.06840431690216064
[Train] epoch 432 Batch 12 Loss 0.33509036898612976
[Train] epoch 432 Batch 13 Loss 0.30145320296287537
[Train] epoch 432 Batch 14 Loss 0.10027502477169037
[Train] epoch 432 Batch 15 Loss 0.10330845415592194
[Train] epoch 432 Batch 16 Loss 0.1681896448135376
[Train] epoch 432 Batch 17 Loss 0.23481687903404236
[Train] epoch 432 Batch 18 Loss 0.10149133205413818
[Train] epoch 432 Batch 19 Loss 0.135248601436615
[Train] epoch 432 Batch 20 Loss 0.13399049639701843
[Train] epoch 432 Batch 21 Loss 0.13575974106788635
[Train] epoch 432 Batch 22 Loss 0.13449792563915253
[Train] epoch 432 Batch 23 Loss 0.16694514453411102
[Train] epoch 432 Batch 24 Loss 0.06798222661018372
[Train] epoch 432 Batch 25 Loss 0.20055687427520752
[Train] epoch 432 Batch 26 Loss 0.2006572186946869
[Train] epoch 432 Batch 27 Loss 0.2690945267677307
[Train] epoch 432 Batch 28 Loss 0.034220140427351
[Train] epoch 432 Batch 29 Loss 0.2343151867389679
[Train] epoch 432 Batch 30 Loss 0.1344495415687561
[Train] epoch 432 Batch 31 Loss 0.10153590142726898
[Train] epoch 432 Batch 32 Loss 0.2012074589729309
[Train] epoch 432 Batch 33 Loss 0.16815033555030823
[Train] epoch 432 Batch 34 Loss 0.13574187457561493
[Train] epoch 432 Batch 35 Loss 0.06722598522901535
[Train] epoch 432 Batch 36 Loss 0.13388904929161072
[Train] epoch 432 Batch 37 Loss 0.13627934455871582
[Train] epoch 432 Batch 38 Loss 0.2678651213645935
[Train] epoch 432 Batch 39 Loss 0.13507699966430664
[Train] epoch 432 Batch 40 Loss 0.16867920756340027
[Train] epoch 432 Batch 41 Loss 0.13448107242584229
[Train] epoch 432 Batch 42 Loss 0.1350296288728714
[Train] epoch 432 Batch 43 Loss 0.16805492341518402
[Train] epoch 432 Batch 44 Loss 0.20121031999588013
[Train] epoch 432 Batch 45 Loss 0.1350877285003662
[Train] epoch 432 Batch 46 Loss 0.3014928698539734
[Train] epoch 432 Batch 47 Loss 0.2342214435338974
[Train] epoch 433 Batch 0 Loss 0.06721291691064835
[Train] epoch 433 Batch 1 Loss 0.133334219455719
[Train] epoch 433 Batch 2 Loss 0.16809025406837463
[Train] epoch 433 Batch 3 Loss 0.23417149484157562
[Train] epoch 433 Batch 4 Loss 0.13389240205287933
[Train] epoch 433 Batch 5 Loss 0.1675816923379898
[Train] epoch 433 Batch 6 Loss 0.16807051002979279
[Train] epoch 433 Batch 7 Loss 0.23416030406951904
[Train] epoch 433 Batch 8 Loss 0.3014296591281891
[Train] epoch 433 Batch 9 Loss 0.2011430561542511
[Train] epoch 433 Batch 10 Loss 0.13447394967079163
[Train] epoch 433 Batch 11 Loss 0.0012002626899629831
[Train] epoch 433 Batch 12 Loss 0.26895684003829956
[Train] epoch 433 Batch 13 Loss 0.1680566817522049
[Train] epoch 433 Batch 14 Loss 0.33509647846221924
[Train] epoch 433 Batch 15 Loss 0.13444334268569946
[Train] epoch 433 Batch 16 Loss 0.06725651025772095
[Train] epoch 433 Batch 17 Loss 0.16863875091075897
[Train] epoch 433 Batch 18 Loss 0.06778471171855927
[Train] epoch 433 Batch 19 Loss 0.26835358142852783
[Train] epoch 433 Batch 20 Loss 0.16748875379562378
[Train] epoch 433 Batch 21 Loss 0.30084797739982605
[Train] epoch 433 Batch 22 Loss 0.1674758791923523
[Train] epoch 433 Batch 23 Loss 0.10141298919916153
[Train] epoch 433 Batch 24 Loss 0.20220595598220825
[Train] epoch 433 Batch 25 Loss 0.13555662333965302
[Train] epoch 433 Batch 26 Loss 0.13495197892189026
[Train] epoch 433 Batch 27 Loss 0.06942795217037201
[Train] epoch 433 Batch 28 Loss 0.4016866385936737
[Train] epoch 433 Batch 29 Loss 0.1360112577676773
[Train] epoch 433 Batch 30 Loss 0.3008386790752411
[Train] epoch 433 Batch 31 Loss 0.1696391999721527
[Train] epoch 433 Batch 32 Loss 0.1344507932662964
[Train] epoch 433 Batch 33 Loss 0.0677805244922638
[Train] epoch 433 Batch 34 Loss 0.16798549890518188
[Train] epoch 433 Batch 35 Loss 0.2357206642627716
[Train] epoch 433 Batch 36 Loss 0.13388749957084656
[Train] epoch 433 Batch 37 Loss 0.30134841799736023
[Train] epoch 433 Batch 38 Loss 0.23470214009284973
[Train] epoch 433 Batch 39 Loss 0.13385051488876343
[Train] epoch 433 Batch 40 Loss 0.16748875379562378
[Train] epoch 433 Batch 41 Loss 0.13549461960792542
[Train] epoch 433 Batch 42 Loss 0.20261713862419128
[Train] epoch 433 Batch 43 Loss 0.06815078854560852
[Train] epoch 433 Batch 44 Loss 0.20050451159477234
[Train] epoch 433 Batch 45 Loss 0.2677338719367981
[Train] epoch 433 Batch 46 Loss 0.10081137716770172
[Train] epoch 433 Batch 47 Loss 0.1002781018614769
[Train] epoch 434 Batch 0 Loss 1.0728851975727594e-06
[Train] epoch 434 Batch 1 Loss 0.3013859987258911
[Train] epoch 434 Batch 2 Loss 0.2341071367263794
[Train] epoch 434 Batch 3 Loss 0.1012999564409256
[Train] epoch 434 Batch 4 Loss 0.1343999207019806
[Train] epoch 434 Batch 5 Loss 0.1344268023967743
[Train] epoch 434 Batch 6 Loss 0.1684039831161499
[Train] epoch 434 Batch 7 Loss 0.13440991938114166
[Train] epoch 434 Batch 8 Loss 0.20102818310260773
[Train] epoch 434 Batch 9 Loss 0.13483427464962006
[Train] epoch 434 Batch 10 Loss 0.10174182802438736
[Train] epoch 434 Batch 11 Loss 0.13487453758716583
[Train] epoch 434 Batch 12 Loss 0.13385091722011566
[Train] epoch 434 Batch 13 Loss 0.133334219455719
[Train] epoch 434 Batch 14 Loss 0.3017891049385071
[Train] epoch 434 Batch 15 Loss 0.16839125752449036
[Train] epoch 434 Batch 16 Loss 0.2676502466201782
[Train] epoch 434 Batch 17 Loss 0.13434551656246185
[Train] epoch 434 Batch 18 Loss 0.13482260704040527
[Train] epoch 434 Batch 19 Loss 0.1012023538351059
[Train] epoch 434 Batch 20 Loss 0.23461559414863586
[Train] epoch 434 Batch 21 Loss 0.10173232853412628
[Train] epoch 434 Batch 22 Loss 0.0676746517419815
[Train] epoch 434 Batch 23 Loss 0.23458033800125122
[Train] epoch 434 Batch 24 Loss 0.03358474373817444
[Train] epoch 434 Batch 25 Loss 0.13435927033424377
[Train] epoch 434 Batch 26 Loss 0.20149317383766174
[Train] epoch 434 Batch 27 Loss 0.1679908186197281
[Train] epoch 434 Batch 28 Loss 0.10170626640319824
[Train] epoch 434 Batch 29 Loss 0.23553021252155304
[Train] epoch 434 Batch 30 Loss 0.13597999513149261
[Train] epoch 434 Batch 31 Loss 0.3013184666633606
[Train] epoch 434 Batch 32 Loss 0.16892704367637634
[Train] epoch 434 Batch 33 Loss 0.20156626403331757
[Train] epoch 434 Batch 34 Loss 0.10026827454566956
[Train] epoch 434 Batch 35 Loss 0.13489998877048492
[Train] epoch 434 Batch 36 Loss 0.3684907555580139
[Train] epoch 434 Batch 37 Loss 0.20155715942382812
[Train] epoch 434 Batch 38 Loss 0.20052212476730347
[Train] epoch 434 Batch 39 Loss 0.3674498200416565
[Train] epoch 434 Batch 40 Loss 0.06824399530887604
[Train] epoch 434 Batch 41 Loss 0.20105043053627014
[Train] epoch 434 Batch 42 Loss 0.3343820571899414
[Train] epoch 434 Batch 43 Loss 0.1674482524394989
[Train] epoch 434 Batch 44 Loss 0.13385064899921417
[Train] epoch 434 Batch 45 Loss 0.10078465938568115
[Train] epoch 434 Batch 46 Loss 0.23412612080574036
[Train] epoch 434 Batch 47 Loss 0.26876208186149597
[Train] epoch 435 Batch 0 Loss 0.06720401346683502
[Train] epoch 435 Batch 1 Loss 0.16850948333740234
[Train] epoch 435 Batch 2 Loss 0.2021026313304901
[Train] epoch 435 Batch 3 Loss 0.20157046616077423
[Train] epoch 435 Batch 4 Loss 0.26821351051330566
[Train] epoch 435 Batch 5 Loss 0.33436334133148193
[Train] epoch 435 Batch 6 Loss 0.16800552606582642
[Train] epoch 435 Batch 7 Loss 0.268207311630249
[Train] epoch 435 Batch 8 Loss 0.300764799118042
[Train] epoch 435 Batch 9 Loss 0.10182510316371918
[Train] epoch 435 Batch 10 Loss 0.13489578664302826
[Train] epoch 435 Batch 11 Loss 0.16848091781139374
[Train] epoch 435 Batch 12 Loss 0.2015574872493744
[Train] epoch 435 Batch 13 Loss 0.10079099982976913
[Train] epoch 435 Batch 14 Loss 0.13598206639289856
[Train] epoch 435 Batch 15 Loss 0.16748130321502686
[Train] epoch 435 Batch 16 Loss 0.10025450587272644
[Train] epoch 435 Batch 17 Loss 0.2682894468307495
[Train] epoch 435 Batch 18 Loss 0.33439329266548157
[Train] epoch 435 Batch 19 Loss 0.1017882376909256
[Train] epoch 435 Batch 20 Loss 0.06820104271173477
[Train] epoch 435 Batch 21 Loss 0.06767276674509048
[Train] epoch 435 Batch 22 Loss 0.10024967789649963
[Train] epoch 435 Batch 23 Loss 0.13385653495788574
[Train] epoch 435 Batch 24 Loss 0.16844230890274048
[Train] epoch 435 Batch 25 Loss 0.23513957858085632
[Train] epoch 435 Batch 26 Loss 0.10077858716249466
[Train] epoch 435 Batch 27 Loss 0.10129441320896149
[Train] epoch 435 Batch 28 Loss 0.2350970208644867
[Train] epoch 435 Batch 29 Loss 0.3348158597946167
[Train] epoch 435 Batch 30 Loss 0.4005219340324402
[Train] epoch 435 Batch 31 Loss 0.20101679861545563
[Train] epoch 435 Batch 32 Loss 0.06715214997529984
[Train] epoch 435 Batch 33 Loss 0.1012415736913681
[Train] epoch 435 Batch 34 Loss 0.06766820698976517
[Train] epoch 435 Batch 35 Loss 0.20098653435707092
[Train] epoch 435 Batch 36 Loss 0.10077014565467834
[Train] epoch 435 Batch 37 Loss 0.06715939193964005
[Train] epoch 435 Batch 38 Loss 0.23554784059524536
[Train] epoch 435 Batch 39 Loss 0.26768386363983154
[Train] epoch 435 Batch 40 Loss 0.13384848833084106
[Train] epoch 435 Batch 41 Loss 0.06763201951980591
[Train] epoch 435 Batch 42 Loss 0.06861720979213715
[Train] epoch 435 Batch 43 Loss 0.06763706356287003
[Train] epoch 435 Batch 44 Loss 0.10076414048671722
[Train] epoch 435 Batch 45 Loss 0.4015018343925476
[Train] epoch 435 Batch 46 Loss 0.1679222285747528
[Train] epoch 435 Batch 47 Loss 0.3012300431728363
[Train] epoch 436 Batch 0 Loss 0.0676436647772789
[Train] epoch 436 Batch 1 Loss 0.16791163384914398
[Train] epoch 436 Batch 2 Loss 0.1679147183895111
[Train] epoch 436 Batch 3 Loss 0.1026853621006012
[Train] epoch 436 Batch 4 Loss 0.10121817141771317
[Train] epoch 436 Batch 5 Loss 0.367885559797287
[Train] epoch 436 Batch 6 Loss 0.10075440257787704
[Train] epoch 436 Batch 7 Loss 0.10025200247764587
[Train] epoch 436 Batch 8 Loss 0.2000008225440979
[Train] epoch 436 Batch 9 Loss 0.06856716424226761
[Train] epoch 436 Batch 10 Loss 0.16737574338912964
[Train] epoch 436 Batch 11 Loss 0.1688556671142578
[Train] epoch 436 Batch 12 Loss 0.06716787815093994
[Train] epoch 436 Batch 13 Loss 0.034514233469963074
[Train] epoch 436 Batch 14 Loss 0.2671447992324829
[Train] epoch 436 Batch 15 Loss 0.2671201229095459
[Train] epoch 436 Batch 16 Loss 0.16691800951957703
[Train] epoch 436 Batch 17 Loss 0.13470855355262756
[Train] epoch 436 Batch 18 Loss 0.16788995265960693
[Train] epoch 436 Batch 19 Loss 0.16741859912872314
[Train] epoch 436 Batch 20 Loss 0.10117436945438385
[Train] epoch 436 Batch 21 Loss 0.034480053931474686
[Train] epoch 436 Batch 22 Loss 0.30169254541397095
[Train] epoch 436 Batch 23 Loss 0.03403051942586899
[Train] epoch 436 Batch 24 Loss 0.20143276453018188
[Train] epoch 436 Batch 25 Loss 0.30211061239242554
[Train] epoch 436 Batch 26 Loss 0.23406833410263062
[Train] epoch 436 Batch 27 Loss 0.1682652235031128
[Train] epoch 436 Batch 28 Loss 0.2009621262550354
[Train] epoch 436 Batch 29 Loss 0.16740736365318298
[Train] epoch 436 Batch 30 Loss 0.06848602741956711
[Train] epoch 436 Batch 31 Loss 0.2013368010520935
[Train] epoch 436 Batch 32 Loss 0.33425986766815186
[Train] epoch 436 Batch 33 Loss 0.2676539719104767
[Train] epoch 436 Batch 34 Loss 0.3673720359802246
[Train] epoch 436 Batch 35 Loss 0.13380104303359985
[Train] epoch 436 Batch 36 Loss 0.1673702597618103
[Train] epoch 436 Batch 37 Loss 0.10120133310556412
[Train] epoch 436 Batch 38 Loss 0.1678008735179901
[Train] epoch 436 Batch 39 Loss 0.06801484525203705
[Train] epoch 436 Batch 40 Loss 0.2349281907081604
[Train] epoch 436 Batch 41 Loss 0.20092879235744476
[Train] epoch 436 Batch 42 Loss 0.06759461015462875
[Train] epoch 436 Batch 43 Loss 0.13426321744918823
[Train] epoch 436 Batch 44 Loss 0.1682523787021637
[Train] epoch 436 Batch 45 Loss 0.3020808696746826
[Train] epoch 436 Batch 46 Loss 0.30163681507110596
[Train] epoch 436 Batch 47 Loss 0.2680148184299469
[Train] epoch 437 Batch 0 Loss 0.20094019174575806
[Train] epoch 437 Batch 1 Loss 0.13375702500343323
[Train] epoch 437 Batch 2 Loss 0.2013973593711853
[Train] epoch 437 Batch 3 Loss 0.13423240184783936
[Train] epoch 437 Batch 4 Loss 0.20097404718399048
[Train] epoch 437 Batch 5 Loss 0.13422967493534088
[Train] epoch 437 Batch 6 Loss 0.16739118099212646
[Train] epoch 437 Batch 7 Loss 0.1010814905166626
[Train] epoch 437 Batch 8 Loss 0.13424748182296753
[Train] epoch 437 Batch 9 Loss 0.10204721242189407
[Train] epoch 437 Batch 10 Loss 0.03486435487866402
[Train] epoch 437 Batch 11 Loss 0.03399695083498955
[Train] epoch 437 Batch 12 Loss 0.3019859194755554
[Train] epoch 437 Batch 13 Loss 0.26759329438209534
[Train] epoch 437 Batch 14 Loss 0.10156840831041336
[Train] epoch 437 Batch 15 Loss 0.20133593678474426
[Train] epoch 437 Batch 16 Loss 0.1350700557231903
[Train] epoch 437 Batch 17 Loss 0.10157090425491333
[Train] epoch 437 Batch 18 Loss 0.2000008225440979
[Train] epoch 437 Batch 19 Loss 0.13466133177280426
[Train] epoch 437 Batch 20 Loss 0.3682026267051697
[Train] epoch 437 Batch 21 Loss 0.16772691905498505
[Train] epoch 437 Batch 22 Loss 0.30024781823158264
[Train] epoch 437 Batch 23 Loss 0.13467010855674744
[Train] epoch 437 Batch 24 Loss 0.1674085259437561
[Train] epoch 437 Batch 25 Loss 0.13423094153404236
[Train] epoch 437 Batch 26 Loss 0.1677350103855133
[Train] epoch 437 Batch 27 Loss 0.10071147978305817
[Train] epoch 437 Batch 28 Loss 0.3333339989185333
[Train] epoch 437 Batch 29 Loss 0.2676540017127991
[Train] epoch 437 Batch 30 Loss 0.16728313267230988
[Train] epoch 437 Batch 31 Loss 0.2675286829471588
[Train] epoch 437 Batch 32 Loss 0.1006459891796112
[Train] epoch 437 Batch 33 Loss 0.1682659536600113
[Train] epoch 437 Batch 34 Loss 0.1673114001750946
[Train] epoch 437 Batch 35 Loss 0.13423949480056763
[Train] epoch 437 Batch 36 Loss 0.20049302279949188
[Train] epoch 437 Batch 37 Loss 0.06745973974466324
[Train] epoch 437 Batch 38 Loss 0.3019891381263733
[Train] epoch 437 Batch 39 Loss 0.10139919817447662
[Train] epoch 437 Batch 40 Loss 0.13423584401607513
[Train] epoch 437 Batch 41 Loss 0.1677476167678833
[Train] epoch 437 Batch 42 Loss 0.20140767097473145
[Train] epoch 437 Batch 43 Loss 0.1346077024936676
[Train] epoch 437 Batch 44 Loss 0.3010607957839966
[Train] epoch 437 Batch 45 Loss 0.034343041479587555
[Train] epoch 437 Batch 46 Loss 0.26824474334716797
[Train] epoch 437 Batch 47 Loss 0.267987996339798
[Train] epoch 438 Batch 0 Loss 0.10059952735900879
[Train] epoch 438 Batch 1 Loss 0.034371115267276764
[Train] epoch 438 Batch 2 Loss 0.134614497423172
[Train] epoch 438 Batch 3 Loss 0.10148783028125763
[Train] epoch 438 Batch 4 Loss 0.2344701737165451
[Train] epoch 438 Batch 5 Loss 0.20085321366786957
[Train] epoch 438 Batch 6 Loss 0.06743662804365158
[Train] epoch 438 Batch 7 Loss 0.2682994306087494
[Train] epoch 438 Batch 8 Loss 0.033540427684783936
[Train] epoch 438 Batch 9 Loss 0.23434346914291382
[Train] epoch 438 Batch 10 Loss 0.33498266339302063
[Train] epoch 438 Batch 11 Loss 0.10073520243167877
[Train] epoch 438 Batch 12 Loss 0.16730666160583496
[Train] epoch 438 Batch 13 Loss 0.16725096106529236
[Train] epoch 438 Batch 14 Loss 0.13447070121765137
[Train] epoch 438 Batch 15 Loss 0.2683606743812561
[Train] epoch 438 Batch 16 Loss 0.03397050127387047
[Train] epoch 438 Batch 17 Loss 0.16807043552398682
[Train] epoch 438 Batch 18 Loss 0.03391243517398834
[Train] epoch 438 Batch 19 Loss 0.03357876464724541
[Train] epoch 438 Batch 20 Loss 0.20164158940315247
[Train] epoch 438 Batch 21 Loss 0.20044609904289246
[Train] epoch 438 Batch 22 Loss 0.1352865993976593
[Train] epoch 438 Batch 23 Loss 0.10061787068843842
[Train] epoch 438 Batch 24 Loss 0.23357832431793213
[Train] epoch 438 Batch 25 Loss 0.26802927255630493
[Train] epoch 438 Batch 26 Loss 0.40082842111587524
[Train] epoch 438 Batch 27 Loss 0.20048893988132477
[Train] epoch 438 Batch 28 Loss 0.30117517709732056
[Train] epoch 438 Batch 29 Loss 0.26752448081970215
[Train] epoch 438 Batch 30 Loss 0.2016543745994568
[Train] epoch 438 Batch 31 Loss 0.23476943373680115
[Train] epoch 438 Batch 32 Loss 0.26747623085975647
[Train] epoch 438 Batch 33 Loss 0.20134247839450836
[Train] epoch 438 Batch 34 Loss 0.16773149371147156
[Train] epoch 438 Batch 35 Loss 0.03357774764299393
[Train] epoch 438 Batch 36 Loss 0.23396995663642883
[Train] epoch 438 Batch 37 Loss 0.1007305458188057
[Train] epoch 438 Batch 38 Loss 0.033577464520931244
[Train] epoch 438 Batch 39 Loss 0.2351970672607422
[Train] epoch 438 Batch 40 Loss 0.20118090510368347
[Train] epoch 438 Batch 41 Loss 0.16728731989860535
[Train] epoch 438 Batch 42 Loss 0.16849908232688904
[Train] epoch 438 Batch 43 Loss 0.23469164967536926
[Train] epoch 438 Batch 44 Loss 0.13505524396896362
[Train] epoch 438 Batch 45 Loss 0.2343132495880127
[Train] epoch 438 Batch 46 Loss 0.23480966687202454
[Train] epoch 438 Batch 47 Loss 0.1002432256937027
[Train] epoch 439 Batch 0 Loss 0.06784884631633759
[Train] epoch 439 Batch 1 Loss 0.10097521543502808
[Train] epoch 439 Batch 2 Loss 0.10139556974172592
[Train] epoch 439 Batch 3 Loss 0.10098537057638168
[Train] epoch 439 Batch 4 Loss 0.16763801872730255
[Train] epoch 439 Batch 5 Loss 0.10144134610891342
[Train] epoch 439 Batch 6 Loss 0.2674061059951782
[Train] epoch 439 Batch 7 Loss 0.10091658681631088
[Train] epoch 439 Batch 8 Loss 0.30066177248954773
[Train] epoch 439 Batch 9 Loss 0.1002425029873848
[Train] epoch 439 Batch 10 Loss 0.2678077220916748
[Train] epoch 439 Batch 11 Loss 0.2348310351371765
[Train] epoch 439 Batch 12 Loss 0.13375239074230194
[Train] epoch 439 Batch 13 Loss 0.33453497290611267
[Train] epoch 439 Batch 14 Loss 0.23405781388282776
[Train] epoch 439 Batch 15 Loss 0.2679312229156494
[Train] epoch 439 Batch 16 Loss 0.3341267704963684
[Train] epoch 439 Batch 17 Loss 0.20125070214271545
[Train] epoch 439 Batch 18 Loss 0.06786320358514786
[Train] epoch 439 Batch 19 Loss 0.26701784133911133
[Train] epoch 439 Batch 20 Loss 0.16810157895088196
[Train] epoch 439 Batch 21 Loss 0.13500772416591644
[Train] epoch 439 Batch 22 Loss 0.2004818320274353
[Train] epoch 439 Batch 23 Loss 0.2347765564918518
[Train] epoch 439 Batch 24 Loss 0.06701589375734329
[Train] epoch 439 Batch 25 Loss 0.10137471556663513
[Train] epoch 439 Batch 26 Loss 0.10065487027168274
[Train] epoch 439 Batch 27 Loss 0.16837388277053833
[Train] epoch 439 Batch 28 Loss 0.30017393827438354
[Train] epoch 439 Batch 29 Loss 0.033932048827409744
[Train] epoch 439 Batch 30 Loss 0.0335189551115036
[Train] epoch 439 Batch 31 Loss 0.2335737943649292
[Train] epoch 439 Batch 32 Loss 0.2007257640361786
[Train] epoch 439 Batch 33 Loss 0.13411399722099304
[Train] epoch 439 Batch 34 Loss 0.20077982544898987
[Train] epoch 439 Batch 35 Loss 0.1668509989976883
[Train] epoch 439 Batch 36 Loss 0.10133831202983856
[Train] epoch 439 Batch 37 Loss 0.23392802476882935
[Train] epoch 439 Batch 38 Loss 0.13457760214805603
[Train] epoch 439 Batch 39 Loss 0.1340983808040619
[Train] epoch 439 Batch 40 Loss 0.13480421900749207
[Train] epoch 439 Batch 41 Loss 0.23550841212272644
[Train] epoch 439 Batch 42 Loss 0.20095710456371307
[Train] epoch 439 Batch 43 Loss 0.20077311992645264
[Train] epoch 439 Batch 44 Loss 0.2682454586029053
[Train] epoch 439 Batch 45 Loss 0.23391252756118774
[Train] epoch 439 Batch 46 Loss 0.134162038564682
[Train] epoch 439 Batch 47 Loss 0.10162791609764099
[Train] epoch 440 Batch 0 Loss 0.23385260999202728
[Train] epoch 440 Batch 1 Loss 0.0006766158621758223
[Train] epoch 440 Batch 2 Loss 0.1676613688468933
[Train] epoch 440 Batch 3 Loss 0.10126073658466339
[Train] epoch 440 Batch 4 Loss 0.26708483695983887
[Train] epoch 440 Batch 5 Loss 0.1340276598930359
[Train] epoch 440 Batch 6 Loss 0.20088320970535278
[Train] epoch 440 Batch 7 Loss 0.06701342016458511
[Train] epoch 440 Batch 8 Loss 0.10092960298061371
[Train] epoch 440 Batch 9 Loss 0.3677866458892822
[Train] epoch 440 Batch 10 Loss 0.16738158464431763
[Train] epoch 440 Batch 11 Loss 0.1340935379266739
[Train] epoch 440 Batch 12 Loss 0.13402144610881805
[Train] epoch 440 Batch 13 Loss 0.3011181652545929
[Train] epoch 440 Batch 14 Loss 0.2004762589931488
[Train] epoch 440 Batch 15 Loss 0.23391422629356384
[Train] epoch 440 Batch 16 Loss 0.10050886869430542
[Train] epoch 440 Batch 17 Loss 0.20107705891132355
[Train] epoch 440 Batch 18 Loss 0.2017589807510376
[Train] epoch 440 Batch 19 Loss 0.2689296305179596
[Train] epoch 440 Batch 20 Loss 0.033901654183864594
[Train] epoch 440 Batch 21 Loss 0.23430287837982178
[Train] epoch 440 Batch 22 Loss 0.0669967532157898
[Train] epoch 440 Batch 23 Loss 0.10164608806371689
[Train] epoch 440 Batch 24 Loss 0.20080307126045227
[Train] epoch 440 Batch 25 Loss 0.2345644235610962
[Train] epoch 440 Batch 26 Loss 0.3348098397254944
[Train] epoch 440 Batch 27 Loss 0.23430806398391724
[Train] epoch 440 Batch 28 Loss 0.16812437772750854
[Train] epoch 440 Batch 29 Loss 0.20047429203987122
[Train] epoch 440 Batch 30 Loss 0.2341776192188263
[Train] epoch 440 Batch 31 Loss 0.16731317341327667
[Train] epoch 440 Batch 32 Loss 0.06773523986339569
[Train] epoch 440 Batch 33 Loss 0.16682952642440796
[Train] epoch 440 Batch 34 Loss 0.13452868163585663
[Train] epoch 440 Batch 35 Loss 0.1673116683959961
[Train] epoch 440 Batch 36 Loss 0.0677206963300705
[Train] epoch 440 Batch 37 Loss 0.1010318174958229
[Train] epoch 440 Batch 38 Loss 0.1341383010149002
[Train] epoch 440 Batch 39 Loss 0.10088025033473969
[Train] epoch 440 Batch 40 Loss 0.2007383108139038
[Train] epoch 440 Batch 41 Loss 0.2685932517051697
[Train] epoch 440 Batch 42 Loss 0.20113292336463928
[Train] epoch 440 Batch 43 Loss 0.23429539799690247
[Train] epoch 440 Batch 44 Loss 0.2000008225440979
[Train] epoch 440 Batch 45 Loss 0.13451983034610748
[Train] epoch 440 Batch 46 Loss 0.23475432395935059
[Train] epoch 440 Batch 47 Loss 0.1340571939945221
[Train] epoch 441 Batch 0 Loss 0.06739960610866547
[Train] epoch 441 Batch 1 Loss 0.0009838179685175419
[Train] epoch 441 Batch 2 Loss 0.40158557891845703
[Train] epoch 441 Batch 3 Loss 0.06733065098524094
[Train] epoch 441 Batch 4 Loss 0.2011137306690216
[Train] epoch 441 Batch 5 Loss 0.10015915334224701
[Train] epoch 441 Batch 6 Loss 0.10049386322498322
[Train] epoch 441 Batch 7 Loss 0.30102992057800293
[Train] epoch 441 Batch 8 Loss 0.10127723217010498
[Train] epoch 441 Batch 9 Loss 0.06729748100042343
[Train] epoch 441 Batch 10 Loss 0.13436433672904968
[Train] epoch 441 Batch 11 Loss 0.034206341952085495
[Train] epoch 441 Batch 12 Loss 0.06698136031627655
[Train] epoch 441 Batch 13 Loss 0.3345162868499756
[Train] epoch 441 Batch 14 Loss 0.2678489089012146
[Train] epoch 441 Batch 15 Loss 0.4007036089897156
[Train] epoch 441 Batch 16 Loss 0.0680818036198616
[Train] epoch 441 Batch 17 Loss 0.10063420981168747
[Train] epoch 441 Batch 18 Loss 0.3007027506828308
[Train] epoch 441 Batch 19 Loss 0.3010227084159851
[Train] epoch 441 Batch 20 Loss 0.10015632212162018
[Train] epoch 441 Batch 21 Loss 0.06698726862668991
[Train] epoch 441 Batch 22 Loss 0.03356805816292763
[Train] epoch 441 Batch 23 Loss 0.13428223133087158
[Train] epoch 441 Batch 24 Loss 0.1344297230243683
[Train] epoch 441 Batch 25 Loss 0.23387691378593445
[Train] epoch 441 Batch 26 Loss 0.13428841531276703
[Train] epoch 441 Batch 27 Loss 0.06761178374290466
[Train] epoch 441 Batch 28 Loss 0.2673811912536621
[Train] epoch 441 Batch 29 Loss 0.16753466427326202
[Train] epoch 441 Batch 30 Loss 0.23427096009254456
[Train] epoch 441 Batch 31 Loss 0.234577476978302
[Train] epoch 441 Batch 32 Loss 0.1671455204486847
[Train] epoch 441 Batch 33 Loss 0.13483616709709167
[Train] epoch 441 Batch 34 Loss 0.23466089367866516
[Train] epoch 441 Batch 35 Loss 0.10023040324449539
[Train] epoch 441 Batch 36 Loss 0.26793372631073
[Train] epoch 441 Batch 37 Loss 0.033561091870069504
[Train] epoch 441 Batch 38 Loss 0.2004520446062088
[Train] epoch 441 Batch 39 Loss 0.3020783066749573
[Train] epoch 441 Batch 40 Loss 0.1683485507965088
[Train] epoch 441 Batch 41 Loss 0.16733664274215698
[Train] epoch 441 Batch 42 Loss 0.3685106635093689
[Train] epoch 441 Batch 43 Loss 0.16792047023773193
[Train] epoch 441 Batch 44 Loss 0.20095594227313995
[Train] epoch 441 Batch 45 Loss 0.2009640485048294
[Train] epoch 441 Batch 46 Loss 0.1688084602355957
[Train] epoch 441 Batch 47 Loss 0.23580442368984222
[Train] epoch 442 Batch 0 Loss 0.16760388016700745
[Train] epoch 442 Batch 1 Loss 0.20279447734355927
[Train] epoch 442 Batch 2 Loss 0.1680348515510559
[Train] epoch 442 Batch 3 Loss 0.2111445665359497
[Train] epoch 442 Batch 4 Loss 0.23403549194335938
[Train] epoch 442 Batch 5 Loss 0.267167329788208
[Train] epoch 442 Batch 6 Loss 0.13420750200748444
[Train] epoch 442 Batch 7 Loss 0.034222155809402466
[Train] epoch 442 Batch 8 Loss 0.06758502125740051
[Train] epoch 442 Batch 9 Loss 0.13450020551681519
[Train] epoch 442 Batch 10 Loss 0.4443873167037964
[Train] epoch 442 Batch 11 Loss 0.33448415994644165
[Train] epoch 442 Batch 12 Loss 0.27859270572662354
[Train] epoch 442 Batch 13 Loss 0.20090235769748688
[Train] epoch 442 Batch 14 Loss 0.17219692468643188
[Train] epoch 442 Batch 15 Loss 0.10075564682483673
[Train] epoch 442 Batch 16 Loss 0.16798672080039978
[Train] epoch 442 Batch 17 Loss 0.26930320262908936
[Train] epoch 442 Batch 18 Loss 0.133334219455719
[Train] epoch 442 Batch 19 Loss 0.20158225297927856
[Train] epoch 442 Batch 20 Loss 0.24921394884586334
[Train] epoch 442 Batch 21 Loss 0.16855517029762268
[Train] epoch 442 Batch 22 Loss 0.0004895501188002527
[Train] epoch 442 Batch 23 Loss 0.1002579927444458
[Train] epoch 442 Batch 24 Loss 0.3349229693412781
[Train] epoch 442 Batch 25 Loss 0.16802272200584412
[Train] epoch 442 Batch 26 Loss 0.20109295845031738
[Train] epoch 442 Batch 27 Loss 0.30299946665763855
[Train] epoch 442 Batch 28 Loss 0.3013615608215332
[Train] epoch 442 Batch 29 Loss 0.2346864640712738
[Train] epoch 442 Batch 30 Loss 0.10173963010311127
[Train] epoch 442 Batch 31 Loss 0.13389110565185547
[Train] epoch 442 Batch 32 Loss 0.03466455265879631
[Train] epoch 442 Batch 33 Loss 0.13479608297348022
[Train] epoch 442 Batch 34 Loss 0.26726725697517395
[Train] epoch 442 Batch 35 Loss 0.034004807472229004
[Train] epoch 442 Batch 36 Loss 0.20193615555763245
[Train] epoch 442 Batch 37 Loss 0.03409362956881523
[Train] epoch 442 Batch 38 Loss 0.10770402103662491
[Train] epoch 442 Batch 39 Loss 0.4006476104259491
[Train] epoch 442 Batch 40 Loss 0.16802677512168884
[Train] epoch 442 Batch 41 Loss 0.06808845698833466
[Train] epoch 442 Batch 42 Loss 0.10132444649934769
[Train] epoch 442 Batch 43 Loss 0.16741843521595
[Train] epoch 442 Batch 44 Loss 0.16889938712120056
[Train] epoch 442 Batch 45 Loss 0.13438770174980164
[Train] epoch 442 Batch 46 Loss 0.1343439817428589
[Train] epoch 442 Batch 47 Loss 0.30128732323646545
[Train] epoch 443 Batch 0 Loss 0.10076810419559479
[Train] epoch 443 Batch 1 Loss 0.13434460759162903
[Train] epoch 443 Batch 2 Loss 0.23408368229866028
[Train] epoch 443 Batch 3 Loss 0.20153306424617767
[Train] epoch 443 Batch 4 Loss 0.20100367069244385
[Train] epoch 443 Batch 5 Loss 0.16848894953727722
[Train] epoch 443 Batch 6 Loss 0.2005135416984558
[Train] epoch 443 Batch 7 Loss 0.16791442036628723
[Train] epoch 443 Batch 8 Loss 0.16756761074066162
[Train] epoch 443 Batch 9 Loss 0.09403209388256073
[Train] epoch 443 Batch 10 Loss 0.20052829384803772
[Train] epoch 443 Batch 11 Loss 0.1687850058078766
[Train] epoch 443 Batch 12 Loss 0.23446722328662872
[Train] epoch 443 Batch 13 Loss 0.06741182506084442
[Train] epoch 443 Batch 14 Loss 0.0689927190542221
[Train] epoch 443 Batch 15 Loss 0.1344277560710907
[Train] epoch 443 Batch 16 Loss 0.06834514439105988
[Train] epoch 443 Batch 17 Loss 0.30146127939224243
[Train] epoch 443 Batch 18 Loss 0.2674127519130707
[Train] epoch 443 Batch 19 Loss 0.1347580850124359
[Train] epoch 443 Batch 20 Loss 0.1343688666820526
[Train] epoch 443 Batch 21 Loss 0.20139726996421814
[Train] epoch 443 Batch 22 Loss 0.16723063588142395
[Train] epoch 443 Batch 23 Loss 0.13420596718788147
[Train] epoch 443 Batch 24 Loss 0.23451416194438934
[Train] epoch 443 Batch 25 Loss 0.16697189211845398
[Train] epoch 443 Batch 26 Loss 0.13507510721683502
[Train] epoch 443 Batch 27 Loss 0.30115556716918945
[Train] epoch 443 Batch 28 Loss 0.16734105348587036
[Train] epoch 443 Batch 29 Loss 0.1678241789340973
[Train] epoch 443 Batch 30 Loss 0.16723696887493134
[Train] epoch 443 Batch 31 Loss 0.13484370708465576
[Train] epoch 443 Batch 32 Loss 0.26810818910598755
[Train] epoch 443 Batch 33 Loss 0.10056917369365692
[Train] epoch 443 Batch 34 Loss 0.2351405769586563
[Train] epoch 443 Batch 35 Loss 0.033988308161497116
[Train] epoch 443 Batch 36 Loss 0.16685178875923157
[Train] epoch 443 Batch 37 Loss 0.2676016688346863
[Train] epoch 443 Batch 38 Loss 0.16778357326984406
[Train] epoch 443 Batch 39 Loss 0.10111485421657562
[Train] epoch 443 Batch 40 Loss 0.2681649923324585
[Train] epoch 443 Batch 41 Loss 0.13500797748565674
[Train] epoch 443 Batch 42 Loss 0.20056025683879852
[Train] epoch 443 Batch 43 Loss 0.20140816271305084
[Train] epoch 443 Batch 44 Loss 0.2012135088443756
[Train] epoch 443 Batch 45 Loss 0.13425493240356445
[Train] epoch 443 Batch 46 Loss 0.26712703704833984
[Train] epoch 443 Batch 47 Loss 0.20157203078269958
[Train] epoch 444 Batch 0 Loss 0.13544240593910217
[Train] epoch 444 Batch 1 Loss 0.10063974559307098
[Train] epoch 444 Batch 2 Loss 0.033610809594392776
[Train] epoch 444 Batch 3 Loss 0.33443862199783325
[Train] epoch 444 Batch 4 Loss 0.1341656893491745
[Train] epoch 444 Batch 5 Loss 0.10145948082208633
[Train] epoch 444 Batch 6 Loss 0.4688766300678253
[Train] epoch 444 Batch 7 Loss 0.1676676869392395
[Train] epoch 444 Batch 8 Loss 0.13379564881324768
[Train] epoch 444 Batch 9 Loss 0.16813328862190247
[Train] epoch 444 Batch 10 Loss 0.13460463285446167
[Train] epoch 444 Batch 11 Loss 0.1673056185245514
[Train] epoch 444 Batch 12 Loss 0.26793453097343445
[Train] epoch 444 Batch 13 Loss 0.133704274892807
[Train] epoch 444 Batch 14 Loss 0.23496830463409424
[Train] epoch 444 Batch 15 Loss 0.13414627313613892
[Train] epoch 444 Batch 16 Loss 0.20126193761825562
[Train] epoch 444 Batch 17 Loss 0.13413679599761963
[Train] epoch 444 Batch 18 Loss 0.20145413279533386
[Train] epoch 444 Batch 19 Loss 0.03360731899738312
[Train] epoch 444 Batch 20 Loss 0.10072948038578033
[Train] epoch 444 Batch 21 Loss 0.10098195821046829
[Train] epoch 444 Batch 22 Loss 0.13424399495124817
[Train] epoch 444 Batch 23 Loss 0.133334219455719
[Train] epoch 444 Batch 24 Loss 0.20134136080741882
[Train] epoch 444 Batch 25 Loss 0.13378795981407166
[Train] epoch 444 Batch 26 Loss 0.33528441190719604
[Train] epoch 444 Batch 27 Loss 0.10107328742742538
[Train] epoch 444 Batch 28 Loss 0.13423210382461548
[Train] epoch 444 Batch 29 Loss 0.4349549412727356
[Train] epoch 444 Batch 30 Loss 0.13442108035087585
[Train] epoch 444 Batch 31 Loss 0.20103661715984344
[Train] epoch 444 Batch 32 Loss 0.10115984827280045
[Train] epoch 444 Batch 33 Loss 0.26745501160621643
[Train] epoch 444 Batch 34 Loss 0.0675535649061203
[Train] epoch 444 Batch 35 Loss 0.06746773421764374
[Train] epoch 444 Batch 36 Loss 0.10017944127321243
[Train] epoch 444 Batch 37 Loss 0.13368366658687592
[Train] epoch 444 Batch 38 Loss 0.10130427777767181
[Train] epoch 444 Batch 39 Loss 0.13524776697158813
[Train] epoch 444 Batch 40 Loss 0.23428598046302795
[Train] epoch 444 Batch 41 Loss 0.13490235805511475
[Train] epoch 444 Batch 42 Loss 0.1337813138961792
[Train] epoch 444 Batch 43 Loss 0.4670202136039734
[Train] epoch 444 Batch 44 Loss 0.2678912281990051
[Train] epoch 444 Batch 45 Loss 0.2675451338291168
[Train] epoch 444 Batch 46 Loss 0.03428556025028229
[Train] epoch 444 Batch 47 Loss 0.2678802013397217
[Train] epoch 445 Batch 0 Loss 0.26711219549179077
[Train] epoch 445 Batch 1 Loss 0.16762211918830872
[Train] epoch 445 Batch 2 Loss 0.10096143186092377
[Train] epoch 445 Batch 3 Loss 0.2007788121700287
[Train] epoch 445 Batch 4 Loss 0.26720643043518066
[Train] epoch 445 Batch 5 Loss 0.1016101986169815
[Train] epoch 445 Batch 6 Loss 0.03393634781241417
[Train] epoch 445 Batch 7 Loss 0.13464725017547607
[Train] epoch 445 Batch 8 Loss 0.30060142278671265
[Train] epoch 445 Batch 9 Loss 0.2679853141307831
[Train] epoch 445 Batch 10 Loss 0.20119976997375488
[Train] epoch 445 Batch 11 Loss 0.1344420313835144
[Train] epoch 445 Batch 12 Loss 0.16813984513282776
[Train] epoch 445 Batch 13 Loss 0.2342744767665863
[Train] epoch 445 Batch 14 Loss 0.16791321337223053
[Train] epoch 445 Batch 15 Loss 0.20086556673049927
[Train] epoch 445 Batch 16 Loss 0.13419824838638306
[Train] epoch 445 Batch 17 Loss 0.06753093004226685
[Train] epoch 445 Batch 18 Loss 0.06785658001899719
[Train] epoch 445 Batch 19 Loss 0.10115557909011841
[Train] epoch 445 Batch 20 Loss 0.20086881518363953
[Train] epoch 445 Batch 21 Loss 0.36813414096832275
[Train] epoch 445 Batch 22 Loss 1.0728851975727594e-06
[Train] epoch 445 Batch 23 Loss 0.20076808333396912
[Train] epoch 445 Batch 24 Loss 0.16779997944831848
[Train] epoch 445 Batch 25 Loss 0.2676374912261963
[Train] epoch 445 Batch 26 Loss 0.168667271733284
[Train] epoch 445 Batch 27 Loss 0.10026788711547852
[Train] epoch 445 Batch 28 Loss 0.234463170170784
[Train] epoch 445 Batch 29 Loss 0.20108449459075928
[Train] epoch 445 Batch 30 Loss 0.3008096218109131
[Train] epoch 445 Batch 31 Loss 0.13474243879318237
[Train] epoch 445 Batch 32 Loss 0.10016080737113953
[Train] epoch 445 Batch 33 Loss 0.06752622872591019
[Train] epoch 445 Batch 34 Loss 0.2008587121963501
[Train] epoch 445 Batch 35 Loss 0.06709284335374832
[Train] epoch 445 Batch 36 Loss 0.30104440450668335
[Train] epoch 445 Batch 37 Loss 0.20122280716896057
[Train] epoch 445 Batch 38 Loss 0.16729901731014252
[Train] epoch 445 Batch 39 Loss 0.20160993933677673
[Train] epoch 445 Batch 40 Loss 0.16738906502723694
[Train] epoch 445 Batch 41 Loss 0.16788813471794128
[Train] epoch 445 Batch 42 Loss 0.23544225096702576
[Train] epoch 445 Batch 43 Loss 0.1007283478975296
[Train] epoch 445 Batch 44 Loss 0.20329521596431732
[Train] epoch 445 Batch 45 Loss 0.10173986107110977
[Train] epoch 445 Batch 46 Loss 0.26769256591796875
[Train] epoch 445 Batch 47 Loss 0.13484567403793335
[Train] epoch 446 Batch 0 Loss 0.16742151975631714
[Train] epoch 446 Batch 1 Loss 0.23410263657569885
[Train] epoch 446 Batch 2 Loss 0.03361784294247627
[Train] epoch 446 Batch 3 Loss 0.06716117262840271
[Train] epoch 446 Batch 4 Loss 0.10081562399864197
[Train] epoch 446 Batch 5 Loss 0.2016478180885315
[Train] epoch 446 Batch 6 Loss 0.23469054698944092
[Train] epoch 446 Batch 7 Loss 0.1679096817970276
[Train] epoch 446 Batch 8 Loss 0.2689151167869568
[Train] epoch 446 Batch 9 Loss 0.23514306545257568
[Train] epoch 446 Batch 10 Loss 0.10076101124286652
[Train] epoch 446 Batch 11 Loss 0.3343973755836487
[Train] epoch 446 Batch 12 Loss 0.20051421225070953
[Train] epoch 446 Batch 13 Loss 0.10032519698143005
[Train] epoch 446 Batch 14 Loss 0.10098051279783249
[Train] epoch 446 Batch 15 Loss 0.13441389799118042
[Train] epoch 446 Batch 16 Loss 0.16747933626174927
[Train] epoch 446 Batch 17 Loss 0.23587685823440552
[Train] epoch 446 Batch 18 Loss 0.10423019528388977
[Train] epoch 446 Batch 19 Loss 0.23476415872573853
[Train] epoch 446 Batch 20 Loss 0.06725364923477173
[Train] epoch 446 Batch 21 Loss 0.23623985052108765
[Train] epoch 446 Batch 22 Loss 0.133334219455719
[Train] epoch 446 Batch 23 Loss 0.22646838426589966
[Train] epoch 446 Batch 24 Loss 0.2023286521434784
[Train] epoch 446 Batch 25 Loss 0.20268619060516357
[Train] epoch 446 Batch 26 Loss 0.2691015899181366
[Train] epoch 446 Batch 27 Loss 0.13449043035507202
[Train] epoch 446 Batch 28 Loss 0.10279586911201477
[Train] epoch 446 Batch 29 Loss 0.1686381995677948
[Train] epoch 446 Batch 30 Loss 0.2674201726913452
[Train] epoch 446 Batch 31 Loss 0.20283301174640656
[Train] epoch 446 Batch 32 Loss 0.16817137598991394
[Train] epoch 446 Batch 33 Loss 0.2686087191104889
[Train] epoch 446 Batch 34 Loss 0.16881580650806427
[Train] epoch 446 Batch 35 Loss 0.23415423929691315
[Train] epoch 446 Batch 36 Loss 0.267856240272522
[Train] epoch 446 Batch 37 Loss 0.20117583870887756
[Train] epoch 446 Batch 38 Loss 0.23577319085597992
[Train] epoch 446 Batch 39 Loss 0.2013237476348877
[Train] epoch 446 Batch 40 Loss 0.13447478413581848
[Train] epoch 446 Batch 41 Loss 0.13571330904960632
[Train] epoch 446 Batch 42 Loss 0.26896440982818604
[Train] epoch 446 Batch 43 Loss 0.0012397939572110772
[Train] epoch 446 Batch 44 Loss 0.10146812349557877
[Train] epoch 446 Batch 45 Loss 0.201138436794281
[Train] epoch 446 Batch 46 Loss 0.06950308382511139
[Train] epoch 446 Batch 47 Loss 0.1014433354139328
[Train] epoch 447 Batch 0 Loss 0.20103347301483154
[Train] epoch 447 Batch 1 Loss 0.1685808300971985
[Train] epoch 447 Batch 2 Loss 0.06775279343128204
[Train] epoch 447 Batch 3 Loss 0.20049798488616943
[Train] epoch 447 Batch 4 Loss 0.16858306527137756
[Train] epoch 447 Batch 5 Loss 0.10183236747980118
[Train] epoch 447 Batch 6 Loss 0.23459327220916748
[Train] epoch 447 Batch 7 Loss 0.23512041568756104
[Train] epoch 447 Batch 8 Loss 0.1343640685081482
[Train] epoch 447 Batch 9 Loss 0.16741538047790527
[Train] epoch 447 Batch 10 Loss 0.16795076429843903
[Train] epoch 447 Batch 11 Loss 0.10025031864643097
[Train] epoch 447 Batch 12 Loss 0.10025912523269653
[Train] epoch 447 Batch 13 Loss 0.16691696643829346
[Train] epoch 447 Batch 14 Loss 0.4020141363143921
[Train] epoch 447 Batch 15 Loss 0.3684147000312805
[Train] epoch 447 Batch 16 Loss 0.13432800769805908
[Train] epoch 447 Batch 17 Loss 0.06866494566202164
[Train] epoch 447 Batch 18 Loss 0.3338332772254944
[Train] epoch 447 Batch 19 Loss 0.1343289315700531
[Train] epoch 447 Batch 20 Loss 0.03407030925154686
[Train] epoch 447 Batch 21 Loss 0.16839027404785156
[Train] epoch 447 Batch 22 Loss 0.3007495403289795
[Train] epoch 447 Batch 23 Loss 0.13431984186172485
[Train] epoch 447 Batch 24 Loss 0.06811036169528961
[Train] epoch 447 Batch 25 Loss 0.13477852940559387
[Train] epoch 447 Batch 26 Loss 0.10073520243167877
[Train] epoch 447 Batch 27 Loss 0.1338064968585968
[Train] epoch 447 Batch 28 Loss 0.16930150985717773
[Train] epoch 447 Batch 29 Loss 0.06811128556728363
[Train] epoch 447 Batch 30 Loss 0.23451021313667297
[Train] epoch 447 Batch 31 Loss 0.03449394553899765
[Train] epoch 447 Batch 32 Loss 0.16830304265022278
[Train] epoch 447 Batch 33 Loss 0.16832235455513
[Train] epoch 447 Batch 34 Loss 0.23451891541481018
[Train] epoch 447 Batch 35 Loss 0.2681196630001068
[Train] epoch 447 Batch 36 Loss 0.10117869079113007
[Train] epoch 447 Batch 37 Loss 0.10160796344280243
[Train] epoch 447 Batch 38 Loss 0.2009219229221344
[Train] epoch 447 Batch 39 Loss 0.20144769549369812
[Train] epoch 447 Batch 40 Loss 0.333806574344635
[Train] epoch 447 Batch 41 Loss 0.168244868516922
[Train] epoch 447 Batch 42 Loss 0.33514803647994995
[Train] epoch 447 Batch 43 Loss 0.26710349321365356
[Train] epoch 447 Batch 44 Loss 0.03398716822266579
[Train] epoch 447 Batch 45 Loss 0.1668820083141327
[Train] epoch 447 Batch 46 Loss 0.13426411151885986
[Train] epoch 447 Batch 47 Loss 0.23447829484939575
[Train] epoch 448 Batch 0 Loss 0.3351210653781891
[Train] epoch 448 Batch 1 Loss 0.1342620849609375
[Train] epoch 448 Batch 2 Loss 0.3007497191429138
[Train] epoch 448 Batch 3 Loss 0.3006756007671356
[Train] epoch 448 Batch 4 Loss 0.06755302846431732
[Train] epoch 448 Batch 5 Loss 0.13379502296447754
[Train] epoch 448 Batch 6 Loss 0.1006687730550766
[Train] epoch 448 Batch 7 Loss 0.16687466204166412
[Train] epoch 448 Batch 8 Loss 0.23533570766448975
[Train] epoch 448 Batch 9 Loss 0.30112284421920776
[Train] epoch 448 Batch 10 Loss 0.1342049539089203
[Train] epoch 448 Batch 11 Loss 0.03399842977523804
[Train] epoch 448 Batch 12 Loss 0.1010771095752716
[Train] epoch 448 Batch 13 Loss 0.2675781846046448
[Train] epoch 448 Batch 14 Loss 0.1681443303823471
[Train] epoch 448 Batch 15 Loss 0.03476255014538765
[Train] epoch 448 Batch 16 Loss 0.13468924164772034
[Train] epoch 448 Batch 17 Loss 0.16808536648750305
[Train] epoch 448 Batch 18 Loss 0.23358339071273804
[Train] epoch 448 Batch 19 Loss 0.2348863184452057
[Train] epoch 448 Batch 20 Loss 0.13498136401176453
[Train] epoch 448 Batch 21 Loss 0.1681646704673767
[Train] epoch 448 Batch 22 Loss 0.13383269309997559
[Train] epoch 448 Batch 23 Loss 0.20099765062332153
[Train] epoch 448 Batch 24 Loss 0.10064615309238434
[Train] epoch 448 Batch 25 Loss 0.13383246958255768
[Train] epoch 448 Batch 26 Loss 0.4340289235115051
[Train] epoch 448 Batch 27 Loss 0.16780732572078705
[Train] epoch 448 Batch 28 Loss 0.23597924411296844
[Train] epoch 448 Batch 29 Loss 0.16774922609329224
[Train] epoch 448 Batch 30 Loss 0.2340245544910431
[Train] epoch 448 Batch 31 Loss 0.16691631078720093
[Train] epoch 448 Batch 32 Loss 0.20082849264144897
[Train] epoch 448 Batch 33 Loss 0.30201277136802673
[Train] epoch 448 Batch 34 Loss 0.06666764616966248
[Train] epoch 448 Batch 35 Loss 0.235166996717453
[Train] epoch 448 Batch 36 Loss 0.13486135005950928
[Train] epoch 448 Batch 37 Loss 0.16735363006591797
[Train] epoch 448 Batch 38 Loss 0.06704668700695038
[Train] epoch 448 Batch 39 Loss 0.16723361611366272
[Train] epoch 448 Batch 40 Loss 0.10150155425071716
[Train] epoch 448 Batch 41 Loss 0.13377133011817932
[Train] epoch 448 Batch 42 Loss 0.1357085108757019
[Train] epoch 448 Batch 43 Loss 0.20087090134620667
[Train] epoch 448 Batch 44 Loss 0.035011328756809235
[Train] epoch 448 Batch 45 Loss 0.16741202771663666
[Train] epoch 448 Batch 46 Loss 0.23451244831085205
[Train] epoch 448 Batch 47 Loss 0.1337047815322876
[Train] epoch 449 Batch 0 Loss 0.10111299157142639
[Train] epoch 449 Batch 1 Loss 0.367345929145813
[Train] epoch 449 Batch 2 Loss 0.10055087506771088
[Train] epoch 449 Batch 3 Loss 0.13486425578594208
[Train] epoch 449 Batch 4 Loss 0.23401111364364624
[Train] epoch 449 Batch 5 Loss 0.10183706879615784
[Train] epoch 449 Batch 6 Loss 0.20151859521865845
[Train] epoch 449 Batch 7 Loss 0.1349143385887146
[Train] epoch 449 Batch 8 Loss 0.16763636469841003
[Train] epoch 449 Batch 9 Loss 0.13382947444915771
[Train] epoch 449 Batch 10 Loss 0.23400743305683136
[Train] epoch 449 Batch 11 Loss 0.16734172403812408
[Train] epoch 449 Batch 12 Loss 0.16720357537269592
[Train] epoch 449 Batch 13 Loss 0.301591694355011
[Train] epoch 449 Batch 14 Loss 0.10109873116016388
[Train] epoch 449 Batch 15 Loss 0.10024823248386383
[Train] epoch 449 Batch 16 Loss 0.10088113695383072
[Train] epoch 449 Batch 17 Loss 0.06786873191595078
[Train] epoch 449 Batch 18 Loss 0.06737148761749268
[Train] epoch 449 Batch 19 Loss 0.3348119854927063
[Train] epoch 449 Batch 20 Loss 0.10109268128871918
[Train] epoch 449 Batch 21 Loss 0.10129732638597488
[Train] epoch 449 Batch 22 Loss 0.2339286208152771
[Train] epoch 449 Batch 23 Loss 0.20091532170772552
[Train] epoch 449 Batch 24 Loss 0.16810086369514465
[Train] epoch 449 Batch 25 Loss 0.1349366307258606
[Train] epoch 449 Batch 26 Loss 0.13417291641235352
[Train] epoch 449 Batch 27 Loss 0.13466410338878632
[Train] epoch 449 Batch 28 Loss 0.36725640296936035
[Train] epoch 449 Batch 29 Loss 0.06666764616966248
[Train] epoch 449 Batch 30 Loss 0.16793745756149292
[Train] epoch 449 Batch 31 Loss 0.30100545287132263
[Train] epoch 449 Batch 32 Loss 0.16732938587665558
[Train] epoch 449 Batch 33 Loss 0.20041696727275848
[Train] epoch 449 Batch 34 Loss 0.10134035348892212
[Train] epoch 449 Batch 35 Loss 0.13442572951316833
[Train] epoch 449 Batch 36 Loss 0.16766437888145447
[Train] epoch 449 Batch 37 Loss 0.13416226208209991
[Train] epoch 449 Batch 38 Loss 0.1668347716331482
[Train] epoch 449 Batch 39 Loss 0.2674158215522766
[Train] epoch 449 Batch 40 Loss 0.16716912388801575
[Train] epoch 449 Batch 41 Loss 0.3009133040904999
[Train] epoch 449 Batch 42 Loss 0.3341572880744934
[Train] epoch 449 Batch 43 Loss 0.06700059026479721
[Train] epoch 449 Batch 44 Loss 0.03391145169734955
[Train] epoch 449 Batch 45 Loss 0.2678999900817871
[Train] epoch 449 Batch 46 Loss 0.10189929604530334
[Train] epoch 449 Batch 47 Loss 0.3013157546520233
[Train] epoch 450 Batch 0 Loss 0.10057506710290909
[Train] epoch 450 Batch 1 Loss 0.2346450239419937
[Train] epoch 450 Batch 2 Loss 0.2350514829158783
[Train] epoch 450 Batch 3 Loss 0.23431451618671417
[Train] epoch 450 Batch 4 Loss 0.13415101170539856
[Train] epoch 450 Batch 5 Loss 0.135615274310112
[Train] epoch 450 Batch 6 Loss 0.16845877468585968
[Train] epoch 450 Batch 7 Loss 0.16723626852035522
[Train] epoch 450 Batch 8 Loss 0.100161612033844
[Train] epoch 450 Batch 9 Loss 0.13423018157482147
[Train] epoch 450 Batch 10 Loss 0.0335792675614357
[Train] epoch 450 Batch 11 Loss 0.23503001034259796
[Train] epoch 450 Batch 12 Loss 0.23421746492385864
[Train] epoch 450 Batch 13 Loss 0.2007237672805786
[Train] epoch 450 Batch 14 Loss 0.16754934191703796
[Train] epoch 450 Batch 15 Loss 0.33405405282974243
[Train] epoch 450 Batch 16 Loss 0.13422639667987823
[Train] epoch 450 Batch 17 Loss 0.20094919204711914
[Train] epoch 450 Batch 18 Loss 0.06770041584968567
[Train] epoch 450 Batch 19 Loss 0.3673129379749298
[Train] epoch 450 Batch 20 Loss 0.16762784123420715
[Train] epoch 450 Batch 21 Loss 0.20102843642234802
[Train] epoch 450 Batch 22 Loss 0.06715604662895203
[Train] epoch 450 Batch 23 Loss 0.33444613218307495
[Train] epoch 450 Batch 24 Loss 0.10046766698360443
[Train] epoch 450 Batch 25 Loss 0.2011992633342743
[Train] epoch 450 Batch 26 Loss 0.06737703830003738
[Train] epoch 450 Batch 27 Loss 0.267155259847641
[Train] epoch 450 Batch 28 Loss 0.30230873823165894
[Train] epoch 450 Batch 29 Loss 0.2674909830093384
[Train] epoch 450 Batch 30 Loss 0.30018675327301025
[Train] epoch 450 Batch 31 Loss 0.23478136956691742
[Train] epoch 450 Batch 32 Loss 0.10069425404071808
[Train] epoch 450 Batch 33 Loss 0.10165076702833176
[Train] epoch 450 Batch 34 Loss 0.2340453565120697
[Train] epoch 450 Batch 35 Loss 0.1343384087085724
[Train] epoch 450 Batch 36 Loss 0.10188326984643936
[Train] epoch 450 Batch 37 Loss 0.06847226619720459
[Train] epoch 450 Batch 38 Loss 0.10201974958181381
[Train] epoch 450 Batch 39 Loss 0.3345462381839752
[Train] epoch 450 Batch 40 Loss 0.13459619879722595
[Train] epoch 450 Batch 41 Loss 0.26841968297958374
[Train] epoch 450 Batch 42 Loss 0.13463756442070007
[Train] epoch 450 Batch 43 Loss 0.3021891415119171
[Train] epoch 450 Batch 44 Loss 0.035086508840322495
[Train] epoch 450 Batch 45 Loss 1.0728851975727594e-06
[Train] epoch 450 Batch 46 Loss 0.06884659826755524
[Train] epoch 450 Batch 47 Loss 0.10259145498275757
[Train] epoch 451 Batch 0 Loss 0.2351410835981369
[Train] epoch 451 Batch 1 Loss 0.2356107234954834
[Train] epoch 451 Batch 2 Loss 0.13411757349967957
[Train] epoch 451 Batch 3 Loss 0.03530343994498253
[Train] epoch 451 Batch 4 Loss 0.035150736570358276
[Train] epoch 451 Batch 5 Loss 0.30164623260498047
[Train] epoch 451 Batch 6 Loss 0.27090001106262207
[Train] epoch 451 Batch 7 Loss 0.2362106442451477
[Train] epoch 451 Batch 8 Loss 0.03528914973139763
[Train] epoch 451 Batch 9 Loss 0.20092730224132538
[Train] epoch 451 Batch 10 Loss 0.2686707675457001
[Train] epoch 451 Batch 11 Loss 0.1681043803691864
[Train] epoch 451 Batch 12 Loss 0.26803505420684814
[Train] epoch 451 Batch 13 Loss 0.06726562976837158
[Train] epoch 451 Batch 14 Loss 0.10097545385360718
[Train] epoch 451 Batch 15 Loss 0.1017378494143486
[Train] epoch 451 Batch 16 Loss 0.06666764616966248
[Train] epoch 451 Batch 17 Loss 0.1682315319776535
[Train] epoch 451 Batch 18 Loss 0.033690132200717926
[Train] epoch 451 Batch 19 Loss 0.20058616995811462
[Train] epoch 451 Batch 20 Loss 0.10239722579717636
[Train] epoch 451 Batch 21 Loss 0.13478565216064453
[Train] epoch 451 Batch 22 Loss 0.20234301686286926
[Train] epoch 451 Batch 23 Loss 0.06877743452787399
[Train] epoch 451 Batch 24 Loss 0.10232633352279663
[Train] epoch 451 Batch 25 Loss 0.20172792673110962
[Train] epoch 451 Batch 26 Loss 0.16771526634693146
[Train] epoch 451 Batch 27 Loss 0.3006954789161682
[Train] epoch 451 Batch 28 Loss 0.3007965087890625
[Train] epoch 451 Batch 29 Loss 0.10091602802276611
[Train] epoch 451 Batch 30 Loss 0.30099737644195557
[Train] epoch 451 Batch 31 Loss 0.10101325064897537
[Train] epoch 451 Batch 32 Loss 0.13533513247966766
[Train] epoch 451 Batch 33 Loss 0.2000008225440979
[Train] epoch 451 Batch 34 Loss 0.26880794763565063
[Train] epoch 451 Batch 35 Loss 0.20232951641082764
[Train] epoch 451 Batch 36 Loss 0.26832228899002075
[Train] epoch 451 Batch 37 Loss 0.13554896414279938
[Train] epoch 451 Batch 38 Loss 0.200464129447937
[Train] epoch 451 Batch 39 Loss 0.2341083288192749
[Train] epoch 451 Batch 40 Loss 0.2672083377838135
[Train] epoch 451 Batch 41 Loss 0.13506543636322021
[Train] epoch 451 Batch 42 Loss 0.20179998874664307
[Train] epoch 451 Batch 43 Loss 0.36915212869644165
[Train] epoch 451 Batch 44 Loss 0.03542660176753998
[Train] epoch 451 Batch 45 Loss 0.1344163566827774
[Train] epoch 451 Batch 46 Loss 0.16751417517662048
[Train] epoch 451 Batch 47 Loss 0.1680315136909485
[Train] epoch 452 Batch 0 Loss 0.20167149603366852
[Train] epoch 452 Batch 1 Loss 0.2000008225440979
[Train] epoch 452 Batch 2 Loss 0.03415919095277786
[Train] epoch 452 Batch 3 Loss 0.20158451795578003
[Train] epoch 452 Batch 4 Loss 0.20158010721206665
[Train] epoch 452 Batch 5 Loss 0.2009836733341217
[Train] epoch 452 Batch 6 Loss 0.3348974585533142
[Train] epoch 452 Batch 7 Loss 0.30087319016456604
[Train] epoch 452 Batch 8 Loss 0.23414206504821777
[Train] epoch 452 Batch 9 Loss 0.10023221373558044
[Train] epoch 452 Batch 10 Loss 0.23471584916114807
[Train] epoch 452 Batch 11 Loss 0.13436616957187653
[Train] epoch 452 Batch 12 Loss 0.20103701949119568
[Train] epoch 452 Batch 13 Loss 0.20098009705543518
[Train] epoch 452 Batch 14 Loss 0.13379648327827454
[Train] epoch 452 Batch 15 Loss 0.13379640877246857
[Train] epoch 452 Batch 16 Loss 0.20051471889019012
[Train] epoch 452 Batch 17 Loss 0.13593165576457977
[Train] epoch 452 Batch 18 Loss 0.20101866126060486
[Train] epoch 452 Batch 19 Loss 0.10083511471748352
[Train] epoch 452 Batch 20 Loss 0.3018520474433899
[Train] epoch 452 Batch 21 Loss 0.16689833998680115
[Train] epoch 452 Batch 22 Loss 0.06666764616966248
[Train] epoch 452 Batch 23 Loss 0.303944855928421
[Train] epoch 452 Batch 24 Loss 0.13383999466896057
[Train] epoch 452 Batch 25 Loss 0.16803139448165894
[Train] epoch 452 Batch 26 Loss 0.2346080243587494
[Train] epoch 452 Batch 27 Loss 0.20053276419639587
[Train] epoch 452 Batch 28 Loss 0.3018084466457367
[Train] epoch 452 Batch 29 Loss 0.20309391617774963
[Train] epoch 452 Batch 30 Loss 0.16689813137054443
[Train] epoch 452 Batch 31 Loss 0.034656599164009094
[Train] epoch 452 Batch 32 Loss 0.0015925912884995341
[Train] epoch 452 Batch 33 Loss 0.20151247084140778
[Train] epoch 452 Batch 34 Loss 0.10180151462554932
[Train] epoch 452 Batch 35 Loss 0.0677071064710617
[Train] epoch 452 Batch 36 Loss 0.2686769962310791
[Train] epoch 452 Batch 37 Loss 0.23451000452041626
[Train] epoch 452 Batch 38 Loss 0.23456132411956787
[Train] epoch 452 Batch 39 Loss 0.10119936615228653
[Train] epoch 452 Batch 40 Loss 0.06767202913761139
[Train] epoch 452 Batch 41 Loss 0.10171924531459808
[Train] epoch 452 Batch 42 Loss 0.10223859548568726
[Train] epoch 452 Batch 43 Loss 0.13480952382087708
[Train] epoch 452 Batch 44 Loss 0.13433139026165009
[Train] epoch 452 Batch 45 Loss 0.13430863618850708
[Train] epoch 452 Batch 46 Loss 0.16735899448394775
[Train] epoch 452 Batch 47 Loss 0.3352304697036743
[Train] epoch 453 Batch 0 Loss 0.23594921827316284
[Train] epoch 453 Batch 1 Loss 0.06666764616966248
[Train] epoch 453 Batch 2 Loss 0.20191141963005066
[Train] epoch 453 Batch 3 Loss 0.06810393184423447
[Train] epoch 453 Batch 4 Loss 0.1678544133901596
[Train] epoch 453 Batch 5 Loss 0.3361816108226776
[Train] epoch 453 Batch 6 Loss 0.20188015699386597
[Train] epoch 453 Batch 7 Loss 0.16784292459487915
[Train] epoch 453 Batch 8 Loss 0.133334219455719
[Train] epoch 453 Batch 9 Loss 0.10162466019392014
[Train] epoch 453 Batch 10 Loss 0.06666764616966248
[Train] epoch 453 Batch 11 Loss 0.26805180311203003
[Train] epoch 453 Batch 12 Loss 0.23494720458984375
[Train] epoch 453 Batch 13 Loss 0.10114490985870361
[Train] epoch 453 Batch 14 Loss 0.23356428742408752
[Train] epoch 453 Batch 15 Loss 0.16780677437782288
[Train] epoch 453 Batch 16 Loss 0.06803344935178757
[Train] epoch 453 Batch 17 Loss 0.30068716406822205
[Train] epoch 453 Batch 18 Loss 0.10069120675325394
[Train] epoch 453 Batch 19 Loss 0.0671171247959137
[Train] epoch 453 Batch 20 Loss 0.2027023881673813
[Train] epoch 453 Batch 21 Loss 0.16777890920639038
[Train] epoch 453 Batch 22 Loss 0.26755988597869873
[Train] epoch 453 Batch 23 Loss 0.30067384243011475
[Train] epoch 453 Batch 24 Loss 0.0675668865442276
[Train] epoch 453 Batch 25 Loss 0.10113085806369781
[Train] epoch 453 Batch 26 Loss 0.40088438987731934
[Train] epoch 453 Batch 27 Loss 0.2004493772983551
[Train] epoch 453 Batch 28 Loss 0.20090621709823608
[Train] epoch 453 Batch 29 Loss 0.16733235120773315
[Train] epoch 453 Batch 30 Loss 0.26712682843208313
[Train] epoch 453 Batch 31 Loss 0.16735652089118958
[Train] epoch 453 Batch 32 Loss 0.20175230503082275
[Train] epoch 453 Batch 33 Loss 0.1346815675497055
[Train] epoch 453 Batch 34 Loss 0.20043081045150757
[Train] epoch 453 Batch 35 Loss 0.2349066436290741
[Train] epoch 453 Batch 36 Loss 0.16819283366203308
[Train] epoch 453 Batch 37 Loss 0.10023027658462524
[Train] epoch 453 Batch 38 Loss 0.13506382703781128
[Train] epoch 453 Batch 39 Loss 0.13503465056419373
[Train] epoch 453 Batch 40 Loss 0.03396831825375557
[Train] epoch 453 Batch 41 Loss 0.03440697863698006
[Train] epoch 453 Batch 42 Loss 0.16689662635326385
[Train] epoch 453 Batch 43 Loss 0.16689659655094147
[Train] epoch 453 Batch 44 Loss 0.1346045583486557
[Train] epoch 453 Batch 45 Loss 0.4017295837402344
[Train] epoch 453 Batch 46 Loss 0.20128777623176575
[Train] epoch 453 Batch 47 Loss 0.10066511482000351
[Train] epoch 454 Batch 0 Loss 0.16772110760211945
[Train] epoch 454 Batch 1 Loss 0.2679052948951721
[Train] epoch 454 Batch 2 Loss 0.06707853823900223
[Train] epoch 454 Batch 3 Loss 0.20130282640457153
[Train] epoch 454 Batch 4 Loss 0.20043477416038513
[Train] epoch 454 Batch 5 Loss 0.1345587521791458
[Train] epoch 454 Batch 6 Loss 0.10145082324743271
[Train] epoch 454 Batch 7 Loss 0.20127058029174805
[Train] epoch 454 Batch 8 Loss 0.033968791365623474
[Train] epoch 454 Batch 9 Loss 0.2675541639328003
[Train] epoch 454 Batch 10 Loss 0.1018688976764679
[Train] epoch 454 Batch 11 Loss 0.13419383764266968
[Train] epoch 454 Batch 12 Loss 0.30060088634490967
[Train] epoch 454 Batch 13 Loss 0.1673247367143631
[Train] epoch 454 Batch 14 Loss 0.2017422467470169
[Train] epoch 454 Batch 15 Loss 0.2013423889875412
[Train] epoch 454 Batch 16 Loss 0.16817551851272583
[Train] epoch 454 Batch 17 Loss 0.20124563574790955
[Train] epoch 454 Batch 18 Loss 0.23353171348571777
[Train] epoch 454 Batch 19 Loss 0.06748606264591217
[Train] epoch 454 Batch 20 Loss 0.16889193654060364
[Train] epoch 454 Batch 21 Loss 0.23483392596244812
[Train] epoch 454 Batch 22 Loss 0.26790499687194824
[Train] epoch 454 Batch 23 Loss 0.0003901057643815875
[Train] epoch 454 Batch 24 Loss 0.13531041145324707
[Train] epoch 454 Batch 25 Loss 0.16773942112922668
[Train] epoch 454 Batch 26 Loss 0.20084239542484283
[Train] epoch 454 Batch 27 Loss 0.1337178349494934
[Train] epoch 454 Batch 28 Loss 0.13375452160835266
[Train] epoch 454 Batch 29 Loss 0.0674358382821083
[Train] epoch 454 Batch 30 Loss 0.06708577275276184
[Train] epoch 454 Batch 31 Loss 0.1337142288684845
[Train] epoch 454 Batch 32 Loss 0.16807524859905243
[Train] epoch 454 Batch 33 Loss 0.1340942531824112
[Train] epoch 454 Batch 34 Loss 0.3010242283344269
[Train] epoch 454 Batch 35 Loss 0.3341274857521057
[Train] epoch 454 Batch 36 Loss 0.06787846982479095
[Train] epoch 454 Batch 37 Loss 0.23393750190734863
[Train] epoch 454 Batch 38 Loss 0.10135571658611298
[Train] epoch 454 Batch 39 Loss 0.10060352087020874
[Train] epoch 454 Batch 40 Loss 0.2670809030532837
[Train] epoch 454 Batch 41 Loss 0.26794931292533875
[Train] epoch 454 Batch 42 Loss 0.03467768803238869
[Train] epoch 454 Batch 43 Loss 0.30105340480804443
[Train] epoch 454 Batch 44 Loss 0.03388895466923714
[Train] epoch 454 Batch 45 Loss 0.4347969889640808
[Train] epoch 454 Batch 46 Loss 0.30100810527801514
[Train] epoch 454 Batch 47 Loss 0.13378846645355225
[Train] epoch 455 Batch 0 Loss 0.30104878544807434
[Train] epoch 455 Batch 1 Loss 0.10091882944107056
[Train] epoch 455 Batch 2 Loss 0.23392659425735474
[Train] epoch 455 Batch 3 Loss 0.1673482358455658
[Train] epoch 455 Batch 4 Loss 0.2022780478000641
[Train] epoch 455 Batch 5 Loss 0.10140977054834366
[Train] epoch 455 Batch 6 Loss 0.3337424099445343
[Train] epoch 455 Batch 7 Loss 0.23469240963459015
[Train] epoch 455 Batch 8 Loss 0.2008608728647232
[Train] epoch 455 Batch 9 Loss 0.23437336087226868
[Train] epoch 455 Batch 10 Loss 0.06738751381635666
[Train] epoch 455 Batch 11 Loss 0.1672535240650177
[Train] epoch 455 Batch 12 Loss 0.1341458410024643
[Train] epoch 455 Batch 13 Loss 0.20162110030651093
[Train] epoch 455 Batch 14 Loss 0.1352633535861969
[Train] epoch 455 Batch 15 Loss 0.2674764394760132
[Train] epoch 455 Batch 16 Loss 0.13414175808429718
[Train] epoch 455 Batch 17 Loss 0.16760195791721344
[Train] epoch 455 Batch 18 Loss 0.3344941735267639
[Train] epoch 455 Batch 19 Loss 0.1675509512424469
[Train] epoch 455 Batch 20 Loss 0.26792389154434204
[Train] epoch 455 Batch 21 Loss 0.1673450917005539
[Train] epoch 455 Batch 22 Loss 0.20035164058208466
[Train] epoch 455 Batch 23 Loss 0.16794434189796448
[Train] epoch 455 Batch 24 Loss 0.1677446961402893
[Train] epoch 455 Batch 25 Loss 0.16759073734283447
[Train] epoch 455 Batch 26 Loss 0.06741562485694885
[Train] epoch 455 Batch 27 Loss 0.26741382479667664
[Train] epoch 455 Batch 28 Loss 0.133334219455719
[Train] epoch 455 Batch 29 Loss 0.1668929159641266
[Train] epoch 455 Batch 30 Loss 0.06666764616966248
[Train] epoch 455 Batch 31 Loss 0.06810134649276733
[Train] epoch 455 Batch 32 Loss 0.33447322249412537
[Train] epoch 455 Batch 33 Loss 0.10062362253665924
[Train] epoch 455 Batch 34 Loss 0.2006871998310089
[Train] epoch 455 Batch 35 Loss 0.134073868393898
[Train] epoch 455 Batch 36 Loss 0.33441585302352905
[Train] epoch 455 Batch 37 Loss 0.100226029753685
[Train] epoch 455 Batch 38 Loss 0.06814167648553848
[Train] epoch 455 Batch 39 Loss 0.03458136320114136
[Train] epoch 455 Batch 40 Loss 0.06740234792232513
[Train] epoch 455 Batch 41 Loss 0.20112907886505127
[Train] epoch 455 Batch 42 Loss 0.16796374320983887
[Train] epoch 455 Batch 43 Loss 0.33445847034454346
[Train] epoch 455 Batch 44 Loss 0.10095570981502533
[Train] epoch 455 Batch 45 Loss 0.06706072390079498
[Train] epoch 455 Batch 46 Loss 0.06733857095241547
[Train] epoch 455 Batch 47 Loss 0.23467868566513062
[Train] epoch 456 Batch 0 Loss 0.16795310378074646
[Train] epoch 456 Batch 1 Loss 0.06705884635448456
[Train] epoch 456 Batch 2 Loss 0.23350030183792114
[Train] epoch 456 Batch 3 Loss 0.23389117419719696
[Train] epoch 456 Batch 4 Loss 0.20033270120620728
[Train] epoch 456 Batch 5 Loss 0.13366521894931793
[Train] epoch 456 Batch 6 Loss 0.03521135821938515
[Train] epoch 456 Batch 7 Loss 0.033558838069438934
[Train] epoch 456 Batch 8 Loss 0.23382797837257385
[Train] epoch 456 Batch 9 Loss 0.16793814301490784
[Train] epoch 456 Batch 10 Loss 0.10022535920143127
[Train] epoch 456 Batch 11 Loss 0.16754679381847382
[Train] epoch 456 Batch 12 Loss 0.13476337492465973
[Train] epoch 456 Batch 13 Loss 0.16754409670829773
[Train] epoch 456 Batch 14 Loss 0.13404664397239685
[Train] epoch 456 Batch 15 Loss 0.16721683740615845
[Train] epoch 456 Batch 16 Loss 0.3002249598503113
[Train] epoch 456 Batch 17 Loss 0.2340068221092224
[Train] epoch 456 Batch 18 Loss 0.20115825533866882
[Train] epoch 456 Batch 19 Loss 0.16721436381340027
[Train] epoch 456 Batch 20 Loss 0.16689163446426392
[Train] epoch 456 Batch 21 Loss 0.20038586854934692
[Train] epoch 456 Batch 22 Loss 0.16721314191818237
[Train] epoch 456 Batch 23 Loss 0.36868661642074585
[Train] epoch 456 Batch 24 Loss 0.23413550853729248
[Train] epoch 456 Batch 25 Loss 0.20217680931091309
[Train] epoch 456 Batch 26 Loss 0.03419717401266098
[Train] epoch 456 Batch 27 Loss 0.10092679411172867
[Train] epoch 456 Batch 28 Loss 0.201532244682312
[Train] epoch 456 Batch 29 Loss 0.1675262749195099
[Train] epoch 456 Batch 30 Loss 0.10117567330598831
[Train] epoch 456 Batch 31 Loss 0.2015828788280487
[Train] epoch 456 Batch 32 Loss 0.10060587525367737
[Train] epoch 456 Batch 33 Loss 0.3019970655441284
[Train] epoch 456 Batch 34 Loss 0.1344759315252304
[Train] epoch 456 Batch 35 Loss 0.16803136467933655
[Train] epoch 456 Batch 36 Loss 0.20038047432899475
[Train] epoch 456 Batch 37 Loss 0.23462817072868347
[Train] epoch 456 Batch 38 Loss 0.10122603178024292
[Train] epoch 456 Batch 39 Loss 0.26742446422576904
[Train] epoch 456 Batch 40 Loss 0.2008930891752243
[Train] epoch 456 Batch 41 Loss 0.13395355641841888
[Train] epoch 456 Batch 42 Loss 0.0671134889125824
[Train] epoch 456 Batch 43 Loss 0.1005324199795723
[Train] epoch 456 Batch 44 Loss 0.16682159900665283
[Train] epoch 456 Batch 45 Loss 0.3675742447376251
[Train] epoch 456 Batch 46 Loss 0.16733551025390625
[Train] epoch 456 Batch 47 Loss 0.20167334377765656
[Train] epoch 457 Batch 0 Loss 0.20098921656608582
[Train] epoch 457 Batch 1 Loss 0.13422414660453796
[Train] epoch 457 Batch 2 Loss 0.13377904891967773
[Train] epoch 457 Batch 3 Loss 0.30097270011901855
[Train] epoch 457 Batch 4 Loss 0.1004578098654747
[Train] epoch 457 Batch 5 Loss 0.13401271402835846
[Train] epoch 457 Batch 6 Loss 0.20105265080928802
[Train] epoch 457 Batch 7 Loss 0.10150669515132904
[Train] epoch 457 Batch 8 Loss 0.20097985863685608
[Train] epoch 457 Batch 9 Loss 0.3672623336315155
[Train] epoch 457 Batch 10 Loss 0.033485252410173416
[Train] epoch 457 Batch 11 Loss 0.03355620428919792
[Train] epoch 457 Batch 12 Loss 0.13453809916973114
[Train] epoch 457 Batch 13 Loss 0.13445031642913818
[Train] epoch 457 Batch 14 Loss 0.03348442167043686
[Train] epoch 457 Batch 15 Loss 0.03438279777765274
[Train] epoch 457 Batch 16 Loss 0.36748695373535156
[Train] epoch 457 Batch 17 Loss 0.033483680337667465
[Train] epoch 457 Batch 18 Loss 0.03385394811630249
[Train] epoch 457 Batch 19 Loss 0.2348913997411728
[Train] epoch 457 Batch 20 Loss 0.10111364722251892
[Train] epoch 457 Batch 21 Loss 0.3010347783565521
[Train] epoch 457 Batch 22 Loss 0.1343691498041153
[Train] epoch 457 Batch 23 Loss 0.16711100935935974
[Train] epoch 457 Batch 24 Loss 0.16770033538341522
[Train] epoch 457 Batch 25 Loss 0.267993688583374
[Train] epoch 457 Batch 26 Loss 0.10044197738170624
[Train] epoch 457 Batch 27 Loss 0.3341444134712219
[Train] epoch 457 Batch 28 Loss 0.134069561958313
[Train] epoch 457 Batch 29 Loss 0.16710665822029114
[Train] epoch 457 Batch 30 Loss 0.10043922066688538
[Train] epoch 457 Batch 31 Loss 0.20139354467391968
[Train] epoch 457 Batch 32 Loss 0.167913556098938
[Train] epoch 457 Batch 33 Loss 0.16710419952869415
[Train] epoch 457 Batch 34 Loss 0.13435685634613037
[Train] epoch 457 Batch 35 Loss 0.1676199734210968
[Train] epoch 457 Batch 36 Loss 0.4349410831928253
[Train] epoch 457 Batch 37 Loss 0.16688817739486694
[Train] epoch 457 Batch 38 Loss 0.10168249905109406
[Train] epoch 457 Batch 39 Loss 0.3009732961654663
[Train] epoch 457 Batch 40 Loss 0.10064821690320969
[Train] epoch 457 Batch 41 Loss 0.10081666707992554
[Train] epoch 457 Batch 42 Loss 0.2679980397224426
[Train] epoch 457 Batch 43 Loss 0.1470029354095459
[Train] epoch 457 Batch 44 Loss 0.13547825813293457
[Train] epoch 457 Batch 45 Loss 0.3356502950191498
[Train] epoch 457 Batch 46 Loss 0.30208832025527954
[Train] epoch 457 Batch 47 Loss 0.20053036510944366
[Train] epoch 458 Batch 0 Loss 0.13389167189598083
[Train] epoch 458 Batch 1 Loss 0.26876574754714966
[Train] epoch 458 Batch 2 Loss 0.26768746972084045
[Train] epoch 458 Batch 3 Loss 0.2676473557949066
[Train] epoch 458 Batch 4 Loss 0.30170130729675293
[Train] epoch 458 Batch 5 Loss 0.23404955863952637
[Train] epoch 458 Batch 6 Loss 0.06719086319208145
[Train] epoch 458 Batch 7 Loss 0.10069607198238373
[Train] epoch 458 Batch 8 Loss 0.2345028668642044
[Train] epoch 458 Batch 9 Loss 0.20142796635627747
[Train] epoch 458 Batch 10 Loss 0.23482510447502136
[Train] epoch 458 Batch 11 Loss 0.06714163720607758
[Train] epoch 458 Batch 12 Loss 0.13380581140518188
[Train] epoch 458 Batch 13 Loss 0.23408223688602448
[Train] epoch 458 Batch 14 Loss 0.3345721960067749
[Train] epoch 458 Batch 15 Loss 0.3342738747596741
[Train] epoch 458 Batch 16 Loss 0.2010335922241211
[Train] epoch 458 Batch 17 Loss 0.1015947163105011
[Train] epoch 458 Batch 18 Loss 0.20083841681480408
[Train] epoch 458 Batch 19 Loss 0.06703469157218933
[Train] epoch 458 Batch 20 Loss 0.10111866891384125
[Train] epoch 458 Batch 21 Loss 0.20072650909423828
[Train] epoch 458 Batch 22 Loss 0.06811098009347916
[Train] epoch 458 Batch 23 Loss 0.16731320321559906
[Train] epoch 458 Batch 24 Loss 0.20139950513839722
[Train] epoch 458 Batch 25 Loss 0.16848859190940857
[Train] epoch 458 Batch 26 Loss 0.20057803392410278
[Train] epoch 458 Batch 27 Loss 0.13508200645446777
[Train] epoch 458 Batch 28 Loss 0.10110676288604736
[Train] epoch 458 Batch 29 Loss 0.1681210994720459
[Train] epoch 458 Batch 30 Loss 0.13379794359207153
[Train] epoch 458 Batch 31 Loss 0.1339140683412552
[Train] epoch 458 Batch 32 Loss 0.10202553123235703
[Train] epoch 458 Batch 33 Loss 0.06701374799013138
[Train] epoch 458 Batch 34 Loss 0.10075415670871735
[Train] epoch 458 Batch 35 Loss 0.10087219625711441
[Train] epoch 458 Batch 36 Loss 0.13482630252838135
[Train] epoch 458 Batch 37 Loss 0.23396740853786469
[Train] epoch 458 Batch 38 Loss 0.16856452822685242
[Train] epoch 458 Batch 39 Loss 0.46770912408828735
[Train] epoch 458 Batch 40 Loss 0.13379473984241486
[Train] epoch 458 Batch 41 Loss 0.1350552886724472
[Train] epoch 458 Batch 42 Loss 0.1675388365983963
[Train] epoch 458 Batch 43 Loss 0.23384223878383636
[Train] epoch 458 Batch 44 Loss 0.10062968730926514
[Train] epoch 458 Batch 45 Loss 0.20137768983840942
[Train] epoch 458 Batch 46 Loss 0.16830694675445557
[Train] epoch 458 Batch 47 Loss 0.06825797259807587
[Train] epoch 459 Batch 0 Loss 0.06746221333742142
[Train] epoch 459 Batch 1 Loss 0.20067253708839417
[Train] epoch 459 Batch 2 Loss 0.2007932960987091
[Train] epoch 459 Batch 3 Loss 0.16796070337295532
[Train] epoch 459 Batch 4 Loss 0.23383508622646332
[Train] epoch 459 Batch 5 Loss 0.23441357910633087
[Train] epoch 459 Batch 6 Loss 0.20136898756027222
[Train] epoch 459 Batch 7 Loss 0.3014112114906311
[Train] epoch 459 Batch 8 Loss 0.0672464668750763
[Train] epoch 459 Batch 9 Loss 0.4014891982078552
[Train] epoch 459 Batch 10 Loss 0.20078638195991516
[Train] epoch 459 Batch 11 Loss 0.06757630407810211
[Train] epoch 459 Batch 12 Loss 0.13502666354179382
[Train] epoch 459 Batch 13 Loss 0.1672862470149994
[Train] epoch 459 Batch 14 Loss 0.13391146063804626
[Train] epoch 459 Batch 15 Loss 0.06757364422082901
[Train] epoch 459 Batch 16 Loss 0.2007821798324585
[Train] epoch 459 Batch 17 Loss 0.06744851171970367
[Train] epoch 459 Batch 18 Loss 0.100740946829319
[Train] epoch 459 Batch 19 Loss 0.10119247436523438
[Train] epoch 459 Batch 20 Loss 0.26777398586273193
[Train] epoch 459 Batch 21 Loss 0.1345636248588562
[Train] epoch 459 Batch 22 Loss 0.13411179184913635
[Train] epoch 459 Batch 23 Loss 0.034601327031850815
[Train] epoch 459 Batch 24 Loss 0.10028809309005737
[Train] epoch 459 Batch 25 Loss 0.23427262902259827
[Train] epoch 459 Batch 26 Loss 0.133334219455719
[Train] epoch 459 Batch 27 Loss 0.1008613258600235
[Train] epoch 459 Batch 28 Loss 0.13443288207054138
[Train] epoch 459 Batch 29 Loss 0.2680138051509857
[Train] epoch 459 Batch 30 Loss 0.36727797985076904
[Train] epoch 459 Batch 31 Loss 0.16817423701286316
[Train] epoch 459 Batch 32 Loss 0.3001624345779419
[Train] epoch 459 Batch 33 Loss 0.23362010717391968
[Train] epoch 459 Batch 34 Loss 0.20121856033802032
[Train] epoch 459 Batch 35 Loss 0.13455137610435486
[Train] epoch 459 Batch 36 Loss 0.20101889967918396
[Train] epoch 459 Batch 37 Loss 0.10125302523374557
[Train] epoch 459 Batch 38 Loss 0.3008054792881012
[Train] epoch 459 Batch 39 Loss 0.16804182529449463
[Train] epoch 459 Batch 40 Loss 0.20165906846523285
[Train] epoch 459 Batch 41 Loss 0.06775453686714172
[Train] epoch 459 Batch 42 Loss 0.16835838556289673
[Train] epoch 459 Batch 43 Loss 0.2676815092563629
[Train] epoch 459 Batch 44 Loss 0.16823017597198486
[Train] epoch 459 Batch 45 Loss 0.23425662517547607
[Train] epoch 459 Batch 46 Loss 0.20113824307918549
[Train] epoch 459 Batch 47 Loss 0.000955651281401515
[Train] epoch 460 Batch 0 Loss 0.10199902951717377
[Train] epoch 460 Batch 1 Loss 0.23475399613380432
[Train] epoch 460 Batch 2 Loss 0.3010435104370117
[Train] epoch 460 Batch 3 Loss 0.334850549697876
[Train] epoch 460 Batch 4 Loss 0.2679917812347412
[Train] epoch 460 Batch 5 Loss 0.10047423839569092
[Train] epoch 460 Batch 6 Loss 0.10015851259231567
[Train] epoch 460 Batch 7 Loss 0.2672334909439087
[Train] epoch 460 Batch 8 Loss 0.3338997960090637
[Train] epoch 460 Batch 9 Loss 0.1671386957168579
[Train] epoch 460 Batch 10 Loss 0.2340562343597412
[Train] epoch 460 Batch 11 Loss 0.20056578516960144
[Train] epoch 460 Batch 12 Loss 0.13483870029449463
[Train] epoch 460 Batch 13 Loss 0.13389861583709717
[Train] epoch 460 Batch 14 Loss 0.20075197517871857
[Train] epoch 460 Batch 15 Loss 0.06848128885030746
[Train] epoch 460 Batch 16 Loss 0.20043863356113434
[Train] epoch 460 Batch 17 Loss 0.30240488052368164
[Train] epoch 460 Batch 18 Loss 0.10059386491775513
[Train] epoch 460 Batch 19 Loss 0.20149683952331543
[Train] epoch 460 Batch 20 Loss 0.26759958267211914
[Train] epoch 460 Batch 21 Loss 0.13408082723617554
[Train] epoch 460 Batch 22 Loss 0.13439005613327026
[Train] epoch 460 Batch 23 Loss 0.13376986980438232
[Train] epoch 460 Batch 24 Loss 0.20087164640426636
[Train] epoch 460 Batch 25 Loss 0.16787442564964294
[Train] epoch 460 Batch 26 Loss 0.06753731518983841
[Train] epoch 460 Batch 27 Loss 0.16750918328762054
[Train] epoch 460 Batch 28 Loss 0.13389509916305542
[Train] epoch 460 Batch 29 Loss 0.1678156554698944
[Train] epoch 460 Batch 30 Loss 0.1346890926361084
[Train] epoch 460 Batch 31 Loss 0.16781416535377502
[Train] epoch 460 Batch 32 Loss 0.13432712852954865
[Train] epoch 460 Batch 33 Loss 0.06753308326005936
[Train] epoch 460 Batch 34 Loss 0.2010452151298523
[Train] epoch 460 Batch 35 Loss 0.20043310523033142
[Train] epoch 460 Batch 36 Loss 0.16712558269500732
[Train] epoch 460 Batch 37 Loss 0.13437609374523163
[Train] epoch 460 Batch 38 Loss 1.0728851975727594e-06
[Train] epoch 460 Batch 39 Loss 0.20073683559894562
[Train] epoch 460 Batch 40 Loss 0.16768157482147217
[Train] epoch 460 Batch 41 Loss 0.2343471348285675
[Train] epoch 460 Batch 42 Loss 0.2008616179227829
[Train] epoch 460 Batch 43 Loss 0.30204954743385315
[Train] epoch 460 Batch 44 Loss 0.03391582518815994
[Train] epoch 460 Batch 45 Loss 0.23378854990005493
[Train] epoch 460 Batch 46 Loss 0.03452000021934509
[Train] epoch 460 Batch 47 Loss 0.16797876358032227
[Train] epoch 461 Batch 0 Loss 0.16737404465675354
[Train] epoch 461 Batch 1 Loss 0.1673738807439804
[Train] epoch 461 Batch 2 Loss 0.3005797863006592
[Train] epoch 461 Batch 3 Loss 0.20060282945632935
[Train] epoch 461 Batch 4 Loss 0.10148059576749802
[Train] epoch 461 Batch 5 Loss 0.1680997610092163
[Train] epoch 461 Batch 6 Loss 0.40085500478744507
[Train] epoch 461 Batch 7 Loss 0.10100455582141876
[Train] epoch 461 Batch 8 Loss 0.13448689877986908
[Train] epoch 461 Batch 9 Loss 0.10015054792165756
[Train] epoch 461 Batch 10 Loss 0.26751959323883057
[Train] epoch 461 Batch 11 Loss 0.23463311791419983
[Train] epoch 461 Batch 12 Loss 0.26794397830963135
[Train] epoch 461 Batch 13 Loss 0.20042622089385986
[Train] epoch 461 Batch 14 Loss 0.167835995554924
[Train] epoch 461 Batch 15 Loss 0.33503302931785583
[Train] epoch 461 Batch 16 Loss 0.20110487937927246
[Train] epoch 461 Batch 17 Loss 0.1337585151195526
[Train] epoch 461 Batch 18 Loss 0.06751541793346405
[Train] epoch 461 Batch 19 Loss 0.16736674308776855
[Train] epoch 461 Batch 20 Loss 0.23449712991714478
[Train] epoch 461 Batch 21 Loss 0.10082650184631348
[Train] epoch 461 Batch 22 Loss 0.1674061268568039
[Train] epoch 461 Batch 23 Loss 0.20084600150585175
[Train] epoch 461 Batch 24 Loss 0.10111992061138153
[Train] epoch 461 Batch 25 Loss 0.23407095670700073
[Train] epoch 461 Batch 26 Loss 0.1011587381362915
[Train] epoch 461 Batch 27 Loss 0.2672554552555084
[Train] epoch 461 Batch 28 Loss 0.2013913094997406
[Train] epoch 461 Batch 29 Loss 0.0002945122541859746
[Train] epoch 461 Batch 30 Loss 0.1350163072347641
[Train] epoch 461 Batch 31 Loss 0.10056762397289276
[Train] epoch 461 Batch 32 Loss 0.10157240182161331
[Train] epoch 461 Batch 33 Loss 0.13375413417816162
[Train] epoch 461 Batch 34 Loss 0.20071247220039368
[Train] epoch 461 Batch 35 Loss 0.1677790880203247
[Train] epoch 461 Batch 36 Loss 0.06779685616493225
[Train] epoch 461 Batch 37 Loss 0.300983726978302
[Train] epoch 461 Batch 38 Loss 0.10101994127035141
[Train] epoch 461 Batch 39 Loss 0.1340428590774536
[Train] epoch 461 Batch 40 Loss 0.26766663789749146
[Train] epoch 461 Batch 41 Loss 0.03447737172245979
[Train] epoch 461 Batch 42 Loss 0.03405928984284401
[Train] epoch 461 Batch 43 Loss 0.1343299299478531
[Train] epoch 461 Batch 44 Loss 0.3005625009536743
[Train] epoch 461 Batch 45 Loss 0.26750096678733826
[Train] epoch 461 Batch 46 Loss 0.16748395562171936
[Train] epoch 461 Batch 47 Loss 0.2007046490907669
[Train] epoch 462 Batch 0 Loss 0.23389361798763275
[Train] epoch 462 Batch 1 Loss 0.16837725043296814
[Train] epoch 462 Batch 2 Loss 0.06666764616966248
[Train] epoch 462 Batch 3 Loss 0.26721078157424927
[Train] epoch 462 Batch 4 Loss 0.16792725026607513
[Train] epoch 462 Batch 5 Loss 0.16693902015686035
[Train] epoch 462 Batch 6 Loss 0.13444867730140686
[Train] epoch 462 Batch 7 Loss 0.23417721688747406
[Train] epoch 462 Batch 8 Loss 0.1350177824497223
[Train] epoch 462 Batch 9 Loss 0.20041440427303314
[Train] epoch 462 Batch 10 Loss 0.13374795019626617
[Train] epoch 462 Batch 11 Loss 0.06695238500833511
[Train] epoch 462 Batch 12 Loss 0.23401787877082825
[Train] epoch 462 Batch 13 Loss 0.33485639095306396
[Train] epoch 462 Batch 14 Loss 0.20069687068462372
[Train] epoch 462 Batch 15 Loss 0.2008252739906311
[Train] epoch 462 Batch 16 Loss 0.0002845653798431158
[Train] epoch 462 Batch 17 Loss 0.06751658022403717
[Train] epoch 462 Batch 18 Loss 1.0728851975727594e-06
[Train] epoch 462 Batch 19 Loss 0.1341569721698761
[Train] epoch 462 Batch 20 Loss 0.033475399017333984
[Train] epoch 462 Batch 21 Loss 0.13374567031860352
[Train] epoch 462 Batch 22 Loss 0.1679125279188156
[Train] epoch 462 Batch 23 Loss 0.10109208524227142
[Train] epoch 462 Batch 24 Loss 0.26777034997940063
[Train] epoch 462 Batch 25 Loss 0.10070481151342392
[Train] epoch 462 Batch 26 Loss 0.23429489135742188
[Train] epoch 462 Batch 27 Loss 0.1340254545211792
[Train] epoch 462 Batch 28 Loss 0.10111252218484879
[Train] epoch 462 Batch 29 Loss 0.36872607469558716
[Train] epoch 462 Batch 30 Loss 0.334562212228775
[Train] epoch 462 Batch 31 Loss 0.1341518759727478
[Train] epoch 462 Batch 32 Loss 0.16775411367416382
[Train] epoch 462 Batch 33 Loss 0.067763552069664
[Train] epoch 462 Batch 34 Loss 0.13457897305488586
[Train] epoch 462 Batch 35 Loss 0.2349756956100464
[Train] epoch 462 Batch 36 Loss 0.20111322402954102
[Train] epoch 462 Batch 37 Loss 0.13401997089385986
[Train] epoch 462 Batch 38 Loss 0.1338707059621811
[Train] epoch 462 Batch 39 Loss 0.3338702321052551
[Train] epoch 462 Batch 40 Loss 0.06720363348722458
[Train] epoch 462 Batch 41 Loss 0.23441511392593384
[Train] epoch 462 Batch 42 Loss 0.2678854167461395
[Train] epoch 462 Batch 43 Loss 0.23402519524097443
[Train] epoch 462 Batch 44 Loss 0.434559166431427
[Train] epoch 462 Batch 45 Loss 0.16802094876766205
[Train] epoch 462 Batch 46 Loss 0.16787372529506683
[Train] epoch 462 Batch 47 Loss 0.10094797611236572
[Train] epoch 463 Batch 0 Loss 0.10081793367862701
[Train] epoch 463 Batch 1 Loss 0.23455485701560974
[Train] epoch 463 Batch 2 Loss 0.13386718928813934
[Train] epoch 463 Batch 3 Loss 0.16748210787773132
[Train] epoch 463 Batch 4 Loss 0.3018953204154968
[Train] epoch 463 Batch 5 Loss 0.16707843542099
[Train] epoch 463 Batch 6 Loss 0.23347076773643494
[Train] epoch 463 Batch 7 Loss 0.2008054554462433
[Train] epoch 463 Batch 8 Loss 0.16773782670497894
[Train] epoch 463 Batch 9 Loss 0.10026644170284271
[Train] epoch 463 Batch 10 Loss 0.20106232166290283
[Train] epoch 463 Batch 11 Loss 0.20063796639442444
[Train] epoch 463 Batch 12 Loss 0.10095545649528503
[Train] epoch 463 Batch 13 Loss 0.3012678623199463
[Train] epoch 463 Batch 14 Loss 0.10129396617412567
[Train] epoch 463 Batch 15 Loss 0.134395033121109
[Train] epoch 463 Batch 16 Loss 0.1344204694032669
[Train] epoch 463 Batch 17 Loss 0.30136537551879883
[Train] epoch 463 Batch 18 Loss 0.2340162992477417
[Train] epoch 463 Batch 19 Loss 0.06702838838100433
[Train] epoch 463 Batch 20 Loss 0.13470835983753204
[Train] epoch 463 Batch 21 Loss 0.13421215116977692
[Train] epoch 463 Batch 22 Loss 0.2012079656124115
[Train] epoch 463 Batch 23 Loss 0.3349442183971405
[Train] epoch 463 Batch 24 Loss 0.3677583336830139
[Train] epoch 463 Batch 25 Loss 0.20084792375564575
[Train] epoch 463 Batch 26 Loss 0.06716304272413254
[Train] epoch 463 Batch 27 Loss 0.30106502771377563
[Train] epoch 463 Batch 28 Loss 0.13428175449371338
[Train] epoch 463 Batch 29 Loss 0.06795572489500046
[Train] epoch 463 Batch 30 Loss 0.03441940248012543
[Train] epoch 463 Batch 31 Loss 0.23403555154800415
[Train] epoch 463 Batch 32 Loss 0.16786257922649384
[Train] epoch 463 Batch 33 Loss 0.13425222039222717
[Train] epoch 463 Batch 34 Loss 0.1682610958814621
[Train] epoch 463 Batch 35 Loss 0.0017218792345374823
[Train] epoch 463 Batch 36 Loss 0.13379287719726562
[Train] epoch 463 Batch 37 Loss 0.2012951374053955
[Train] epoch 463 Batch 38 Loss 0.3015393018722534
[Train] epoch 463 Batch 39 Loss 0.13425636291503906
[Train] epoch 463 Batch 40 Loss 0.23401212692260742
[Train] epoch 463 Batch 41 Loss 0.10154150426387787
[Train] epoch 463 Batch 42 Loss 0.06799274682998657
[Train] epoch 463 Batch 43 Loss 0.16739900410175323
[Train] epoch 463 Batch 44 Loss 0.10110801458358765
[Train] epoch 463 Batch 45 Loss 0.23490259051322937
[Train] epoch 463 Batch 46 Loss 0.20091700553894043
[Train] epoch 463 Batch 47 Loss 0.20043116807937622
[Train] epoch 464 Batch 0 Loss 0.10153385996818542
[Train] epoch 464 Batch 1 Loss 0.2349524199962616
[Train] epoch 464 Batch 2 Loss 0.06801497936248779
[Train] epoch 464 Batch 3 Loss 0.30024397373199463
[Train] epoch 464 Batch 4 Loss 0.10110004991292953
[Train] epoch 464 Batch 5 Loss 0.13467493653297424
[Train] epoch 464 Batch 6 Loss 0.0671539157629013
[Train] epoch 464 Batch 7 Loss 0.13421529531478882
[Train] epoch 464 Batch 8 Loss 0.20045670866966248
[Train] epoch 464 Batch 9 Loss 0.20172792673110962
[Train] epoch 464 Batch 10 Loss 0.06712093949317932
[Train] epoch 464 Batch 11 Loss 0.4009063243865967
[Train] epoch 464 Batch 12 Loss 0.0016894813161343336
[Train] epoch 464 Batch 13 Loss 0.20048648118972778
[Train] epoch 464 Batch 14 Loss 0.20087289810180664
[Train] epoch 464 Batch 15 Loss 0.06799101829528809
[Train] epoch 464 Batch 16 Loss 0.26757001876831055
[Train] epoch 464 Batch 17 Loss 0.26753532886505127
[Train] epoch 464 Batch 18 Loss 0.2675681412220001
[Train] epoch 464 Batch 19 Loss 0.20131522417068481
[Train] epoch 464 Batch 20 Loss 0.2004145085811615
[Train] epoch 464 Batch 21 Loss 0.16780956089496613
[Train] epoch 464 Batch 22 Loss 0.1337447464466095
[Train] epoch 464 Batch 23 Loss 0.2675289213657379
[Train] epoch 464 Batch 24 Loss 0.33467617630958557
[Train] epoch 464 Batch 25 Loss 0.2671153247356415
[Train] epoch 464 Batch 26 Loss 0.03480610251426697
[Train] epoch 464 Batch 27 Loss 0.1672816276550293
[Train] epoch 464 Batch 28 Loss 0.20129965245723724
[Train] epoch 464 Batch 29 Loss 0.03439045324921608
[Train] epoch 464 Batch 30 Loss 0.20129863917827606
[Train] epoch 464 Batch 31 Loss 0.1006869301199913
[Train] epoch 464 Batch 32 Loss 0.06755691766738892
[Train] epoch 464 Batch 33 Loss 0.2012503445148468
[Train] epoch 464 Batch 34 Loss 0.13422031700611115
[Train] epoch 464 Batch 35 Loss 0.06706731766462326
[Train] epoch 464 Batch 36 Loss 0.3685950040817261
[Train] epoch 464 Batch 37 Loss 0.20128323137760162
[Train] epoch 464 Batch 38 Loss 0.23445841670036316
[Train] epoch 464 Batch 39 Loss 0.16730812191963196
[Train] epoch 464 Batch 40 Loss 0.1010814756155014
[Train] epoch 464 Batch 41 Loss 0.30121007561683655
[Train] epoch 464 Batch 42 Loss 0.23564083874225616
[Train] epoch 464 Batch 43 Loss 0.0674559697508812
[Train] epoch 464 Batch 44 Loss 0.20170947909355164
[Train] epoch 464 Batch 45 Loss 0.13499659299850464
[Train] epoch 464 Batch 46 Loss 0.10063491761684418
[Train] epoch 464 Batch 47 Loss 0.16768983006477356
[Train] epoch 465 Batch 0 Loss 0.20165206491947174
[Train] epoch 465 Batch 1 Loss 0.2675396800041199
[Train] epoch 465 Batch 2 Loss 0.06748967617750168
[Train] epoch 465 Batch 3 Loss 0.20125854015350342
[Train] epoch 465 Batch 4 Loss 0.16816148161888123
[Train] epoch 465 Batch 5 Loss 0.16777577996253967
[Train] epoch 465 Batch 6 Loss 0.06748398393392563
[Train] epoch 465 Batch 7 Loss 0.4009147584438324
[Train] epoch 465 Batch 8 Loss 0.23395825922489166
[Train] epoch 465 Batch 9 Loss 0.10105541348457336
[Train] epoch 465 Batch 10 Loss 0.20119382441043854
[Train] epoch 465 Batch 11 Loss 0.2012431025505066
[Train] epoch 465 Batch 12 Loss 0.10024167597293854
[Train] epoch 465 Batch 13 Loss 0.20129087567329407
[Train] epoch 465 Batch 14 Loss 0.10099688172340393
[Train] epoch 465 Batch 15 Loss 0.3007223308086395
[Train] epoch 465 Batch 16 Loss 0.16771240532398224
[Train] epoch 465 Batch 17 Loss 0.2340552806854248
[Train] epoch 465 Batch 18 Loss 0.2674174904823303
[Train] epoch 465 Batch 19 Loss 0.13376212120056152
[Train] epoch 465 Batch 20 Loss 0.16802924871444702
[Train] epoch 465 Batch 21 Loss 0.0677872896194458
[Train] epoch 465 Batch 22 Loss 0.167601078748703
[Train] epoch 465 Batch 23 Loss 0.13498491048812866
[Train] epoch 465 Batch 24 Loss 0.3348734676837921
[Train] epoch 465 Batch 25 Loss 0.10098180174827576
[Train] epoch 465 Batch 26 Loss 0.26746147871017456
[Train] epoch 465 Batch 27 Loss 0.03394344076514244
[Train] epoch 465 Batch 28 Loss 0.3018244802951813
[Train] epoch 465 Batch 29 Loss 0.13375696539878845
[Train] epoch 465 Batch 30 Loss 0.10024077445268631
[Train] epoch 465 Batch 31 Loss 0.20084631443023682
[Train] epoch 465 Batch 32 Loss 0.23532046377658844
[Train] epoch 465 Batch 33 Loss 0.2000008225440979
[Train] epoch 465 Batch 34 Loss 0.10091084986925125
[Train] epoch 465 Batch 35 Loss 0.134481281042099
[Train] epoch 465 Batch 36 Loss 0.16738605499267578
[Train] epoch 465 Batch 37 Loss 0.16805073618888855
[Train] epoch 465 Batch 38 Loss 0.13489636778831482
[Train] epoch 465 Batch 39 Loss 0.06780660152435303
[Train] epoch 465 Batch 40 Loss 0.3010184168815613
[Train] epoch 465 Batch 41 Loss 0.06780407577753067
[Train] epoch 465 Batch 42 Loss 0.367622047662735
[Train] epoch 465 Batch 43 Loss 0.13410867750644684
[Train] epoch 465 Batch 44 Loss 0.033512771129608154
[Train] epoch 465 Batch 45 Loss 0.13381241261959076
[Train] epoch 465 Batch 46 Loss 0.1009499728679657
[Train] epoch 465 Batch 47 Loss 0.2012501358985901
[Train] epoch 466 Batch 0 Loss 0.10088606178760529
[Train] epoch 466 Batch 1 Loss 0.16767480969429016
[Train] epoch 466 Batch 2 Loss 0.10177542269229889
[Train] epoch 466 Batch 3 Loss 0.20130792260169983
[Train] epoch 466 Batch 4 Loss 0.16837430000305176
[Train] epoch 466 Batch 5 Loss 0.16814863681793213
[Train] epoch 466 Batch 6 Loss 0.06743109226226807
[Train] epoch 466 Batch 7 Loss 0.2346845269203186
[Train] epoch 466 Batch 8 Loss 0.1341596245765686
[Train] epoch 466 Batch 9 Loss 0.2678396701812744
[Train] epoch 466 Batch 10 Loss 0.2678389549255371
[Train] epoch 466 Batch 11 Loss 0.30093175172805786
[Train] epoch 466 Batch 12 Loss 0.23432964086532593
[Train] epoch 466 Batch 13 Loss 0.23439396917819977
[Train] epoch 466 Batch 14 Loss 0.1675948202610016
[Train] epoch 466 Batch 15 Loss 0.13415436446666718
[Train] epoch 466 Batch 16 Loss 0.23357203602790833
[Train] epoch 466 Batch 17 Loss 0.1681334674358368
[Train] epoch 466 Batch 18 Loss 0.1675902009010315
[Train] epoch 466 Batch 19 Loss 0.1676551103591919
[Train] epoch 466 Batch 20 Loss 0.13408365845680237
[Train] epoch 466 Batch 21 Loss 0.1676534116268158
[Train] epoch 466 Batch 22 Loss 0.13414925336837769
[Train] epoch 466 Batch 23 Loss 0.3012571334838867
[Train] epoch 466 Batch 24 Loss 0.16758301854133606
[Train] epoch 466 Batch 25 Loss 0.06700591742992401
[Train] epoch 466 Batch 26 Loss 0.13367195427417755
[Train] epoch 466 Batch 27 Loss 0.20121857523918152
[Train] epoch 466 Batch 28 Loss 0.10118015110492706
[Train] epoch 466 Batch 29 Loss 0.13454988598823547
[Train] epoch 466 Batch 30 Loss 0.23512166738510132
[Train] epoch 466 Batch 31 Loss 0.3005031943321228
[Train] epoch 466 Batch 32 Loss 0.20114359259605408
[Train] epoch 466 Batch 33 Loss 0.13440591096878052
[Train] epoch 466 Batch 34 Loss 0.30104440450668335
[Train] epoch 466 Batch 35 Loss 0.1340699940919876
[Train] epoch 466 Batch 36 Loss 0.13413982093334198
[Train] epoch 466 Batch 37 Loss 0.10064005106687546
[Train] epoch 466 Batch 38 Loss 0.06666764616966248
[Train] epoch 466 Batch 39 Loss 0.13413794338703156
[Train] epoch 466 Batch 40 Loss 0.1002373993396759
[Train] epoch 466 Batch 41 Loss 0.06765709817409515
[Train] epoch 466 Batch 42 Loss 0.1340646594762802
[Train] epoch 466 Batch 43 Loss 0.33406370878219604
[Train] epoch 466 Batch 44 Loss 0.20040133595466614
[Train] epoch 466 Batch 45 Loss 0.0006572105921804905
[Train] epoch 466 Batch 46 Loss 0.2007284164428711
[Train] epoch 466 Batch 47 Loss 0.33413344621658325
[Train] epoch 467 Batch 0 Loss 0.10089054703712463
[Train] epoch 467 Batch 1 Loss 0.13453185558319092
[Train] epoch 467 Batch 2 Loss 0.20079869031906128
[Train] epoch 467 Batch 3 Loss 0.33431029319763184
[Train] epoch 467 Batch 4 Loss 0.10081326216459274
[Train] epoch 467 Batch 5 Loss 0.13405677676200867
[Train] epoch 467 Batch 6 Loss 0.1673012375831604
[Train] epoch 467 Batch 7 Loss 0.10095779597759247
[Train] epoch 467 Batch 8 Loss 0.16787227988243103
[Train] epoch 467 Batch 9 Loss 0.10070822387933731
[Train] epoch 467 Batch 10 Loss 0.33444952964782715
[Train] epoch 467 Batch 11 Loss 0.20071882009506226
[Train] epoch 467 Batch 12 Loss 0.1009538546204567
[Train] epoch 467 Batch 13 Loss 0.36690282821655273
[Train] epoch 467 Batch 14 Loss 0.23436081409454346
[Train] epoch 467 Batch 15 Loss 0.2007160484790802
[Train] epoch 467 Batch 16 Loss 0.2669869065284729
[Train] epoch 467 Batch 17 Loss 0.06770071387290955
[Train] epoch 467 Batch 18 Loss 0.200395405292511
[Train] epoch 467 Batch 19 Loss 0.23403970897197723
[Train] epoch 467 Batch 20 Loss 0.23482774198055267
[Train] epoch 467 Batch 21 Loss 0.16714397072792053
[Train] epoch 467 Batch 22 Loss 0.06801317632198334
[Train] epoch 467 Batch 23 Loss 0.13475468754768372
[Train] epoch 467 Batch 24 Loss 0.2678465247154236
[Train] epoch 467 Batch 25 Loss 0.16768783330917358
[Train] epoch 467 Batch 26 Loss 0.20039325952529907
[Train] epoch 467 Batch 27 Loss 0.16682514548301697
[Train] epoch 467 Batch 28 Loss 0.26847273111343384
[Train] epoch 467 Batch 29 Loss 0.13380315899848938
[Train] epoch 467 Batch 30 Loss 0.16729335486888885
[Train] epoch 467 Batch 31 Loss 0.1672155261039734
[Train] epoch 467 Batch 32 Loss 0.10054843127727509
[Train] epoch 467 Batch 33 Loss 0.20172128081321716
[Train] epoch 467 Batch 34 Loss 0.13450543582439423
[Train] epoch 467 Batch 35 Loss 0.16713592410087585
[Train] epoch 467 Batch 36 Loss 0.13458164036273956
[Train] epoch 467 Batch 37 Loss 0.16713450849056244
[Train] epoch 467 Batch 38 Loss 0.13465628027915955
[Train] epoch 467 Batch 39 Loss 0.20038989186286926
[Train] epoch 467 Batch 40 Loss 0.16814160346984863
[Train] epoch 467 Batch 41 Loss 0.16721081733703613
[Train] epoch 467 Batch 42 Loss 0.13464978337287903
[Train] epoch 467 Batch 43 Loss 0.06744343042373657
[Train] epoch 467 Batch 44 Loss 0.20069658756256104
[Train] epoch 467 Batch 45 Loss 0.201083242893219
[Train] epoch 467 Batch 46 Loss 0.1679026484489441
[Train] epoch 467 Batch 47 Loss 0.10100746899843216
[Train] epoch 468 Batch 0 Loss 0.30070042610168457
[Train] epoch 468 Batch 1 Loss 0.16789862513542175
[Train] epoch 468 Batch 2 Loss 0.1008448600769043
[Train] epoch 468 Batch 3 Loss 0.1008441373705864
[Train] epoch 468 Batch 4 Loss 0.10061906278133392
[Train] epoch 468 Batch 5 Loss 0.1336382031440735
[Train] epoch 468 Batch 6 Loss 0.23433613777160645
[Train] epoch 468 Batch 7 Loss 0.3006178140640259
[Train] epoch 468 Batch 8 Loss 0.20046618580818176
[Train] epoch 468 Batch 9 Loss 0.33402037620544434
[Train] epoch 468 Batch 10 Loss 0.20107057690620422
[Train] epoch 468 Batch 11 Loss 0.13440346717834473
[Train] epoch 468 Batch 12 Loss 0.10091826319694519
[Train] epoch 468 Batch 13 Loss 0.2675151228904724
[Train] epoch 468 Batch 14 Loss 0.13423770666122437
[Train] epoch 468 Batch 15 Loss 0.13439977169036865
[Train] epoch 468 Batch 16 Loss 0.10113424062728882
[Train] epoch 468 Batch 17 Loss 0.1679631471633911
[Train] epoch 468 Batch 18 Loss 0.2340298593044281
[Train] epoch 468 Batch 19 Loss 0.1680135726928711
[Train] epoch 468 Batch 20 Loss 0.3006959855556488
[Train] epoch 468 Batch 21 Loss 0.13371527194976807
[Train] epoch 468 Batch 22 Loss 0.10158944129943848
[Train] epoch 468 Batch 23 Loss 0.20105873048305511
[Train] epoch 468 Batch 24 Loss 0.13439153134822845
[Train] epoch 468 Batch 25 Loss 0.10052910447120667
[Train] epoch 468 Batch 26 Loss 0.1337968111038208
[Train] epoch 468 Batch 27 Loss 0.13430540263652802
[Train] epoch 468 Batch 28 Loss 0.06734179705381393
[Train] epoch 468 Batch 29 Loss 1.0728851975727594e-06
[Train] epoch 468 Batch 30 Loss 0.43482810258865356
[Train] epoch 468 Batch 31 Loss 0.26750731468200684
[Train] epoch 468 Batch 32 Loss 0.1343841254711151
[Train] epoch 468 Batch 33 Loss 0.10119707882404327
[Train] epoch 468 Batch 34 Loss 0.16756902635097504
[Train] epoch 468 Batch 35 Loss 0.33400410413742065
[Train] epoch 468 Batch 36 Loss 0.03385733440518379
[Train] epoch 468 Batch 37 Loss 0.2674204111099243
[Train] epoch 468 Batch 38 Loss 0.26762744784355164
[Train] epoch 468 Batch 39 Loss 0.3005223870277405
[Train] epoch 468 Batch 40 Loss 0.13475294411182404
[Train] epoch 468 Batch 41 Loss 0.10072823613882065
[Train] epoch 468 Batch 42 Loss 0.13379456102848053
[Train] epoch 468 Batch 43 Loss 0.06762321293354034
[Train] epoch 468 Batch 44 Loss 0.10052087903022766
[Train] epoch 468 Batch 45 Loss 0.26799559593200684
[Train] epoch 468 Batch 46 Loss 0.16710104048252106
[Train] epoch 468 Batch 47 Loss 0.1342858374118805
[Train] epoch 469 Batch 0 Loss 0.2009201943874359
[Train] epoch 469 Batch 1 Loss 0.16709932684898376
[Train] epoch 469 Batch 2 Loss 0.13390867412090302
[Train] epoch 469 Batch 3 Loss 0.3008907437324524
[Train] epoch 469 Batch 4 Loss 0.234137162566185
[Train] epoch 469 Batch 5 Loss 0.4011189639568329
[Train] epoch 469 Batch 6 Loss 0.20103183388710022
[Train] epoch 469 Batch 7 Loss 0.10071536898612976
[Train] epoch 469 Batch 8 Loss 0.10060226917266846
[Train] epoch 469 Batch 9 Loss 0.10117176175117493
[Train] epoch 469 Batch 10 Loss 0.1343613713979721
[Train] epoch 469 Batch 11 Loss 0.2010270655155182
[Train] epoch 469 Batch 12 Loss 0.03404415026307106
[Train] epoch 469 Batch 13 Loss 0.16689665615558624
[Train] epoch 469 Batch 14 Loss 0.200654536485672
[Train] epoch 469 Batch 15 Loss 0.2015911042690277
[Train] epoch 469 Batch 16 Loss 0.16774296760559082
[Train] epoch 469 Batch 17 Loss 0.167548269033432
[Train] epoch 469 Batch 18 Loss 0.13435426354408264
[Train] epoch 469 Batch 19 Loss 0.10042200982570648
[Train] epoch 469 Batch 20 Loss 0.30059900879859924
[Train] epoch 469 Batch 21 Loss 0.1681947261095047
[Train] epoch 469 Batch 22 Loss 0.10070095211267471
[Train] epoch 469 Batch 23 Loss 0.16689616441726685
[Train] epoch 469 Batch 24 Loss 0.23476754128932953
[Train] epoch 469 Batch 25 Loss 0.16763213276863098
[Train] epoch 469 Batch 26 Loss 0.10096501559019089
[Train] epoch 469 Batch 27 Loss 0.16726380586624146
[Train] epoch 469 Batch 28 Loss 0.16717317700386047
[Train] epoch 469 Batch 29 Loss 0.0002780678914859891
[Train] epoch 469 Batch 30 Loss 0.23392948508262634
[Train] epoch 469 Batch 31 Loss 0.20073412358760834
[Train] epoch 469 Batch 32 Loss 0.2004569172859192
[Train] epoch 469 Batch 33 Loss 0.30050456523895264
[Train] epoch 469 Batch 34 Loss 0.16680537164211273
[Train] epoch 469 Batch 35 Loss 0.10087046772241592
[Train] epoch 469 Batch 36 Loss 0.16808903217315674
[Train] epoch 469 Batch 37 Loss 0.20128241181373596
[Train] epoch 469 Batch 38 Loss 0.30068355798721313
[Train] epoch 469 Batch 39 Loss 0.16808567941188812
[Train] epoch 469 Batch 40 Loss 0.03383592143654823
[Train] epoch 469 Batch 41 Loss 0.2341097593307495
[Train] epoch 469 Batch 42 Loss 0.300956130027771
[Train] epoch 469 Batch 43 Loss 0.2677602171897888
[Train] epoch 469 Batch 44 Loss 0.10050167888402939
[Train] epoch 469 Batch 45 Loss 0.10077530890703201
[Train] epoch 469 Batch 46 Loss 0.16753071546554565
[Train] epoch 469 Batch 47 Loss 0.06766695529222488
[Train] epoch 470 Batch 0 Loss 0.26748377084732056
[Train] epoch 470 Batch 1 Loss 0.10068047046661377
[Train] epoch 470 Batch 2 Loss 0.20099730789661407
[Train] epoch 470 Batch 3 Loss 1.0728851975727594e-06
[Train] epoch 470 Batch 4 Loss 0.23500780761241913
[Train] epoch 470 Batch 5 Loss 0.16743600368499756
[Train] epoch 470 Batch 6 Loss 0.06820125877857208
[Train] epoch 470 Batch 7 Loss 0.06693796068429947
[Train] epoch 470 Batch 8 Loss 0.10067547857761383
[Train] epoch 470 Batch 9 Loss 0.2006310671567917
[Train] epoch 470 Batch 10 Loss 0.03382911905646324
[Train] epoch 470 Batch 11 Loss 0.13396401703357697
[Train] epoch 470 Batch 12 Loss 0.16725438833236694
[Train] epoch 470 Batch 13 Loss 0.2677476406097412
[Train] epoch 470 Batch 14 Loss 0.16689354181289673
[Train] epoch 470 Batch 15 Loss 0.2673869729042053
[Train] epoch 470 Batch 16 Loss 0.10022683441638947
[Train] epoch 470 Batch 17 Loss 0.16716116666793823
[Train] epoch 470 Batch 18 Loss 0.20125314593315125
[Train] epoch 470 Batch 19 Loss 0.13431835174560547
[Train] epoch 470 Batch 20 Loss 0.10049235820770264
[Train] epoch 470 Batch 21 Loss 0.23471525311470032
[Train] epoch 470 Batch 22 Loss 0.20081061124801636
[Train] epoch 470 Batch 23 Loss 0.16787374019622803
[Train] epoch 470 Batch 24 Loss 0.13369256258010864
[Train] epoch 470 Batch 25 Loss 0.23444637656211853
[Train] epoch 470 Batch 26 Loss 0.26773983240127563
[Train] epoch 470 Batch 27 Loss 0.1337844431400299
[Train] epoch 470 Batch 28 Loss 0.2673817276954651
[Train] epoch 470 Batch 29 Loss 0.23479987680912018
[Train] epoch 470 Batch 30 Loss 0.2000008225440979
[Train] epoch 470 Batch 31 Loss 0.16769862174987793
[Train] epoch 470 Batch 32 Loss 0.13421636819839478
[Train] epoch 470 Batch 33 Loss 0.23391509056091309
[Train] epoch 470 Batch 34 Loss 0.0007879480253905058
[Train] epoch 470 Batch 35 Loss 0.3677717447280884
[Train] epoch 470 Batch 36 Loss 0.3009359836578369
[Train] epoch 470 Batch 37 Loss 0.1339520514011383
[Train] epoch 470 Batch 38 Loss 0.16784526407718658
[Train] epoch 470 Batch 39 Loss 0.06745254993438721
[Train] epoch 470 Batch 40 Loss 0.2340799868106842
[Train] epoch 470 Batch 41 Loss 0.13404236733913422
[Train] epoch 470 Batch 42 Loss 0.20044855773448944
[Train] epoch 470 Batch 43 Loss 0.20141607522964478
[Train] epoch 470 Batch 44 Loss 0.16731667518615723
[Train] epoch 470 Batch 45 Loss 0.26737523078918457
[Train] epoch 470 Batch 46 Loss 0.20089522004127502
[Train] epoch 470 Batch 47 Loss 0.1339462846517563
[Train] epoch 471 Batch 0 Loss 0.167408287525177
[Train] epoch 471 Batch 1 Loss 0.23426291346549988
[Train] epoch 471 Batch 2 Loss 0.10074052214622498
[Train] epoch 471 Batch 3 Loss 0.1681104153394699
[Train] epoch 471 Batch 4 Loss 0.2342606484889984
[Train] epoch 471 Batch 5 Loss 0.13410669565200806
[Train] epoch 471 Batch 6 Loss 0.3002236485481262
[Train] epoch 471 Batch 7 Loss 0.13377992808818817
[Train] epoch 471 Batch 8 Loss 0.06839661300182343
[Train] epoch 471 Batch 9 Loss 0.1335909217596054
[Train] epoch 471 Batch 10 Loss 0.30022329092025757
[Train] epoch 471 Batch 11 Loss 0.133334219455719
[Train] epoch 471 Batch 12 Loss 0.13377921283245087
[Train] epoch 471 Batch 13 Loss 0.10099060833454132
[Train] epoch 471 Batch 14 Loss 0.0676889717578888
[Train] epoch 471 Batch 15 Loss 0.10133623331785202
[Train] epoch 471 Batch 16 Loss 0.033461444079875946
[Train] epoch 471 Batch 17 Loss 0.10022316873073578
[Train] epoch 471 Batch 18 Loss 0.20095321536064148
[Train] epoch 471 Batch 19 Loss 0.10047644376754761
[Train] epoch 471 Batch 20 Loss 0.33526909351348877
[Train] epoch 471 Batch 21 Loss 0.1668895184993744
[Train] epoch 471 Batch 22 Loss 0.267713725566864
[Train] epoch 471 Batch 23 Loss 0.26771315932273865
[Train] epoch 471 Batch 24 Loss 0.10047571361064911
[Train] epoch 471 Batch 25 Loss 0.13478729128837585
[Train] epoch 471 Batch 26 Loss 0.06691945344209671
[Train] epoch 471 Batch 27 Loss 0.16739213466644287
[Train] epoch 471 Batch 28 Loss 0.2671101987361908
[Train] epoch 471 Batch 29 Loss 0.2672653794288635
[Train] epoch 471 Batch 30 Loss 0.16783545911312103
[Train] epoch 471 Batch 31 Loss 0.10047275573015213
[Train] epoch 471 Batch 32 Loss 0.06710983067750931
[Train] epoch 471 Batch 33 Loss 0.23355510830879211
[Train] epoch 471 Batch 34 Loss 0.1672951579093933
[Train] epoch 471 Batch 35 Loss 0.1673300862312317
[Train] epoch 471 Batch 36 Loss 0.20146477222442627
[Train] epoch 471 Batch 37 Loss 0.20035749673843384
[Train] epoch 471 Batch 38 Loss 0.23453104496002197
[Train] epoch 471 Batch 39 Loss 0.24712863564491272
[Train] epoch 471 Batch 40 Loss 0.16763997077941895
[Train] epoch 471 Batch 41 Loss 0.2354709804058075
[Train] epoch 471 Batch 42 Loss 0.20123550295829773
[Train] epoch 471 Batch 43 Loss 0.2013159990310669
[Train] epoch 471 Batch 44 Loss 0.10067344456911087
[Train] epoch 471 Batch 45 Loss 0.26759135723114014
[Train] epoch 471 Batch 46 Loss 0.20142027735710144
[Train] epoch 471 Batch 47 Loss 0.20096594095230103
[Train] epoch 472 Batch 0 Loss 0.23406057059764862
[Train] epoch 472 Batch 1 Loss 0.23516978323459625
[Train] epoch 472 Batch 2 Loss 0.13588985800743103
[Train] epoch 472 Batch 3 Loss 0.13438409566879272
[Train] epoch 472 Batch 4 Loss 0.23414763808250427
[Train] epoch 472 Batch 5 Loss 0.23467503488063812
[Train] epoch 472 Batch 6 Loss 0.03413761034607887
[Train] epoch 472 Batch 7 Loss 0.1669265627861023
[Train] epoch 472 Batch 8 Loss 0.2352069616317749
[Train] epoch 472 Batch 9 Loss 0.20054876804351807
[Train] epoch 472 Batch 10 Loss 0.2021859735250473
[Train] epoch 472 Batch 11 Loss 0.06829695403575897
[Train] epoch 472 Batch 12 Loss 0.1685718595981598
[Train] epoch 472 Batch 13 Loss 0.13441963493824005
[Train] epoch 472 Batch 14 Loss 0.26828938722610474
[Train] epoch 472 Batch 15 Loss 0.03414415568113327
[Train] epoch 472 Batch 16 Loss 0.30190563201904297
[Train] epoch 472 Batch 17 Loss 0.101380355656147
[Train] epoch 472 Batch 18 Loss 0.1354784369468689
[Train] epoch 472 Batch 19 Loss 0.20114317536354065
[Train] epoch 472 Batch 20 Loss 0.20163442194461823
[Train] epoch 472 Batch 21 Loss 0.26776236295700073
[Train] epoch 472 Batch 22 Loss 0.33553752303123474
[Train] epoch 472 Batch 23 Loss 0.03411661088466644
[Train] epoch 472 Batch 24 Loss 0.2677081227302551
[Train] epoch 472 Batch 25 Loss 0.30310335755348206
[Train] epoch 472 Batch 26 Loss 0.16858069598674774
[Train] epoch 472 Batch 27 Loss 0.2341434359550476
[Train] epoch 472 Batch 28 Loss 0.06666764616966248
[Train] epoch 472 Batch 29 Loss 0.13494792580604553
[Train] epoch 472 Batch 30 Loss 0.26882803440093994
[Train] epoch 472 Batch 31 Loss 0.10079747438430786
[Train] epoch 472 Batch 32 Loss 0.13501939177513123
[Train] epoch 472 Batch 33 Loss 0.13387846946716309
[Train] epoch 472 Batch 34 Loss 0.13392317295074463
[Train] epoch 472 Batch 35 Loss 0.23467999696731567
[Train] epoch 472 Batch 36 Loss 0.1689647138118744
[Train] epoch 472 Batch 37 Loss 0.13496753573417664
[Train] epoch 472 Batch 38 Loss 0.06725732982158661
[Train] epoch 472 Batch 39 Loss 0.2004995495080948
[Train] epoch 472 Batch 40 Loss 0.20054122805595398
[Train] epoch 472 Batch 41 Loss 0.20103371143341064
[Train] epoch 472 Batch 42 Loss 0.13540276885032654
[Train] epoch 472 Batch 43 Loss 0.2000008225440979
[Train] epoch 472 Batch 44 Loss 0.10078515112400055
[Train] epoch 472 Batch 45 Loss 0.13485068082809448
[Train] epoch 472 Batch 46 Loss 0.20156726241111755
[Train] epoch 472 Batch 47 Loss 0.1344127506017685
[Train] epoch 473 Batch 0 Loss 0.2681797742843628
[Train] epoch 473 Batch 1 Loss 0.033629536628723145
[Train] epoch 473 Batch 2 Loss 0.13386864960193634
[Train] epoch 473 Batch 3 Loss 0.16755303740501404
[Train] epoch 473 Batch 4 Loss 0.1673903465270996
[Train] epoch 473 Batch 5 Loss 0.2340552806854248
[Train] epoch 473 Batch 6 Loss 0.06767956167459488
[Train] epoch 473 Batch 7 Loss 0.10172630846500397
[Train] epoch 473 Batch 8 Loss 0.2677296996116638
[Train] epoch 473 Batch 9 Loss 0.30124765634536743
[Train] epoch 473 Batch 10 Loss 0.06761445105075836
[Train] epoch 473 Batch 11 Loss 0.13392454385757446
[Train] epoch 473 Batch 12 Loss 0.06772994995117188
[Train] epoch 473 Batch 13 Loss 0.2681970000267029
[Train] epoch 473 Batch 14 Loss 0.034568753093481064
[Train] epoch 473 Batch 15 Loss 0.20052793622016907
[Train] epoch 473 Batch 16 Loss 0.3013509511947632
[Train] epoch 473 Batch 17 Loss 0.16842077672481537
[Train] epoch 473 Batch 18 Loss 0.23514467477798462
[Train] epoch 473 Batch 19 Loss 0.1016831248998642
[Train] epoch 473 Batch 20 Loss 0.20197570323944092
[Train] epoch 473 Batch 21 Loss 0.23467546701431274
[Train] epoch 473 Batch 22 Loss 0.13431648910045624
[Train] epoch 473 Batch 23 Loss 0.16748574376106262
[Train] epoch 473 Batch 24 Loss 0.2015022337436676
[Train] epoch 473 Batch 25 Loss 0.20117807388305664
[Train] epoch 473 Batch 26 Loss 0.03408171236515045
[Train] epoch 473 Batch 27 Loss 0.2677745223045349
[Train] epoch 473 Batch 28 Loss 0.20090526342391968
[Train] epoch 473 Batch 29 Loss 0.16779771447181702
[Train] epoch 473 Batch 30 Loss 0.13423305749893188
[Train] epoch 473 Batch 31 Loss 0.16754771769046783
[Train] epoch 473 Batch 32 Loss 0.06890740990638733
[Train] epoch 473 Batch 33 Loss 0.10074024647474289
[Train] epoch 473 Batch 34 Loss 0.26887303590774536
[Train] epoch 473 Batch 35 Loss 0.23488663136959076
[Train] epoch 473 Batch 36 Loss 0.20147323608398438
[Train] epoch 473 Batch 37 Loss 0.10029387474060059
[Train] epoch 473 Batch 38 Loss 0.3021276295185089
[Train] epoch 473 Batch 39 Loss 0.16791078448295593
[Train] epoch 473 Batch 40 Loss 0.13420966267585754
[Train] epoch 473 Batch 41 Loss 0.10029356181621552
[Train] epoch 473 Batch 42 Loss 0.23515674471855164
[Train] epoch 473 Batch 43 Loss 0.20153027772903442
[Train] epoch 473 Batch 44 Loss 0.16826249659061432
[Train] epoch 473 Batch 45 Loss 0.20144960284233093
[Train] epoch 473 Batch 46 Loss 0.20144712924957275
[Train] epoch 473 Batch 47 Loss 0.23456357419490814
[Train] epoch 474 Batch 0 Loss 0.06768011301755905
[Train] epoch 474 Batch 1 Loss 0.13419003784656525
[Train] epoch 474 Batch 2 Loss 0.1007205992937088
[Train] epoch 474 Batch 3 Loss 0.1019970253109932
[Train] epoch 474 Batch 4 Loss 0.3347647190093994
[Train] epoch 474 Batch 5 Loss 0.2009279727935791
[Train] epoch 474 Batch 6 Loss 0.23404639959335327
[Train] epoch 474 Batch 7 Loss 0.267589807510376
[Train] epoch 474 Batch 8 Loss 0.3012126088142395
[Train] epoch 474 Batch 9 Loss 0.06842771172523499
[Train] epoch 474 Batch 10 Loss 0.20141756534576416
[Train] epoch 474 Batch 11 Loss 0.10089156031608582
[Train] epoch 474 Batch 12 Loss 0.3012166917324066
[Train] epoch 474 Batch 13 Loss 0.30166468024253845
[Train] epoch 474 Batch 14 Loss 0.26875805854797363
[Train] epoch 474 Batch 15 Loss 0.2021142840385437
[Train] epoch 474 Batch 16 Loss 0.13386055827140808
[Train] epoch 474 Batch 17 Loss 0.10137228667736053
[Train] epoch 474 Batch 18 Loss 0.23463350534439087
[Train] epoch 474 Batch 19 Loss 0.2347089648246765
[Train] epoch 474 Batch 20 Loss 0.1007908284664154
[Train] epoch 474 Batch 21 Loss 0.20279058814048767
[Train] epoch 474 Batch 22 Loss 0.36860495805740356
[Train] epoch 474 Batch 23 Loss 0.03567377105355263
[Train] epoch 474 Batch 24 Loss 0.16789013147354126
[Train] epoch 474 Batch 25 Loss 0.13459175825119019
[Train] epoch 474 Batch 26 Loss 0.26784491539001465
[Train] epoch 474 Batch 27 Loss 0.2687302529811859
[Train] epoch 474 Batch 28 Loss 0.10137641429901123
[Train] epoch 474 Batch 29 Loss 0.23504111170768738
[Train] epoch 474 Batch 30 Loss 0.2340404987335205
[Train] epoch 474 Batch 31 Loss 0.06730115413665771
[Train] epoch 474 Batch 32 Loss 0.133334219455719
[Train] epoch 474 Batch 33 Loss 0.20137743651866913
[Train] epoch 474 Batch 34 Loss 0.10076936334371567
[Train] epoch 474 Batch 35 Loss 0.20158298313617706
[Train] epoch 474 Batch 36 Loss 0.10142560303211212
[Train] epoch 474 Batch 37 Loss 0.16730406880378723
[Train] epoch 474 Batch 38 Loss 0.1341840922832489
[Train] epoch 474 Batch 39 Loss 0.16790226101875305
[Train] epoch 474 Batch 40 Loss 0.06784310936927795
[Train] epoch 474 Batch 41 Loss 0.16794824600219727
[Train] epoch 474 Batch 42 Loss 0.2010560780763626
[Train] epoch 474 Batch 43 Loss 0.13438519835472107
[Train] epoch 474 Batch 44 Loss 0.168453648686409
[Train] epoch 474 Batch 45 Loss 0.16730868816375732
[Train] epoch 474 Batch 46 Loss 0.03406890481710434
[Train] epoch 474 Batch 47 Loss 0.13437029719352722
[Train] epoch 475 Batch 0 Loss 0.06821690499782562
[Train] epoch 475 Batch 1 Loss 0.2010304480791092
[Train] epoch 475 Batch 2 Loss 0.26811978220939636
[Train] epoch 475 Batch 3 Loss 0.2011910080909729
[Train] epoch 475 Batch 4 Loss 0.16844943165779114
[Train] epoch 475 Batch 5 Loss 0.13430668413639069
[Train] epoch 475 Batch 6 Loss 0.23354843258857727
[Train] epoch 475 Batch 7 Loss 0.13426421582698822
[Train] epoch 475 Batch 8 Loss 0.1675776243209839
[Train] epoch 475 Batch 9 Loss 0.30122119188308716
[Train] epoch 475 Batch 10 Loss 0.16737757623195648
[Train] epoch 475 Batch 11 Loss 0.10070924460887909
[Train] epoch 475 Batch 12 Loss 0.16791239380836487
[Train] epoch 475 Batch 13 Loss 0.20134933292865753
[Train] epoch 475 Batch 14 Loss 0.13468115031719208
[Train] epoch 475 Batch 15 Loss 0.16779832541942596
[Train] epoch 475 Batch 16 Loss 0.10064435005187988
[Train] epoch 475 Batch 17 Loss 0.301231324672699
[Train] epoch 475 Batch 18 Loss 0.16842612624168396
[Train] epoch 475 Batch 19 Loss 0.10135337710380554
[Train] epoch 475 Batch 20 Loss 0.23516157269477844
[Train] epoch 475 Batch 21 Loss 0.10083936154842377
[Train] epoch 475 Batch 22 Loss 0.13478827476501465
[Train] epoch 475 Batch 23 Loss 0.3684978485107422
[Train] epoch 475 Batch 24 Loss 0.3017534017562866
[Train] epoch 475 Batch 25 Loss 0.13580800592899323
[Train] epoch 475 Batch 26 Loss 0.267544686794281
[Train] epoch 475 Batch 27 Loss 0.10228848457336426
[Train] epoch 475 Batch 28 Loss 0.16847960650920868
[Train] epoch 475 Batch 29 Loss 0.2671802043914795
[Train] epoch 475 Batch 30 Loss 0.06666764616966248
[Train] epoch 475 Batch 31 Loss 0.13384369015693665
[Train] epoch 475 Batch 32 Loss 0.3347269296646118
[Train] epoch 475 Batch 33 Loss 0.06904399394989014
[Train] epoch 475 Batch 34 Loss 0.16879698634147644
[Train] epoch 475 Batch 35 Loss 0.1027231216430664
[Train] epoch 475 Batch 36 Loss 0.2004491090774536
[Train] epoch 475 Batch 37 Loss 0.13428033888339996
[Train] epoch 475 Batch 38 Loss 0.16731086373329163
[Train] epoch 475 Batch 39 Loss 0.10159701108932495
[Train] epoch 475 Batch 40 Loss 0.1006501168012619
[Train] epoch 475 Batch 41 Loss 0.10121381282806396
[Train] epoch 475 Batch 42 Loss 0.2675975561141968
[Train] epoch 475 Batch 43 Loss 0.23404020071029663
[Train] epoch 475 Batch 44 Loss 0.1337631791830063
[Train] epoch 475 Batch 45 Loss 0.13419800996780396
[Train] epoch 475 Batch 46 Loss 0.133334219455719
[Train] epoch 475 Batch 47 Loss 0.20048828423023224
[Train] epoch 476 Batch 0 Loss 0.06801286339759827
[Train] epoch 476 Batch 1 Loss 0.26886671781539917
[Train] epoch 476 Batch 2 Loss 0.13504575192928314
[Train] epoch 476 Batch 3 Loss 0.26752346754074097
[Train] epoch 476 Batch 4 Loss 0.23456409573554993
[Train] epoch 476 Batch 5 Loss 0.2013319581747055
[Train] epoch 476 Batch 6 Loss 0.30159884691238403
[Train] epoch 476 Batch 7 Loss 0.16825835406780243
[Train] epoch 476 Batch 8 Loss 0.16736066341400146
[Train] epoch 476 Batch 9 Loss 0.06666764616966248
[Train] epoch 476 Batch 10 Loss 0.10062648355960846
[Train] epoch 476 Batch 11 Loss 0.13417868316173553
[Train] epoch 476 Batch 12 Loss 0.10073745250701904
[Train] epoch 476 Batch 13 Loss 0.20046810805797577
[Train] epoch 476 Batch 14 Loss 0.10109409689903259
[Train] epoch 476 Batch 15 Loss 0.03488989546895027
[Train] epoch 476 Batch 16 Loss 0.20139949023723602
[Train] epoch 476 Batch 17 Loss 0.0670960396528244
[Train] epoch 476 Batch 18 Loss 0.13503991067409515
[Train] epoch 476 Batch 19 Loss 0.13457722961902618
[Train] epoch 476 Batch 20 Loss 0.26755326986312866
[Train] epoch 476 Batch 21 Loss 0.16780561208724976
[Train] epoch 476 Batch 22 Loss 0.2004169523715973
[Train] epoch 476 Batch 23 Loss 0.20127293467521667
[Train] epoch 476 Batch 24 Loss 0.10108233243227005
[Train] epoch 476 Batch 25 Loss 0.2679610252380371
[Train] epoch 476 Batch 26 Loss 0.10101468116044998
[Train] epoch 476 Batch 27 Loss 0.133762389421463
[Train] epoch 476 Batch 28 Loss 0.20180457830429077
[Train] epoch 476 Batch 29 Loss 0.1346226930618286
[Train] epoch 476 Batch 30 Loss 0.13374608755111694
[Train] epoch 476 Batch 31 Loss 0.23438580334186554
[Train] epoch 476 Batch 32 Loss 0.1337759792804718
[Train] epoch 476 Batch 33 Loss 0.03394092991948128
[Train] epoch 476 Batch 34 Loss 0.23478877544403076
[Train] epoch 476 Batch 35 Loss 0.367728590965271
[Train] epoch 476 Batch 36 Loss 0.20091289281845093
[Train] epoch 476 Batch 37 Loss 0.368635892868042
[Train] epoch 476 Batch 38 Loss 0.10185883939266205
[Train] epoch 476 Batch 39 Loss 0.13422083854675293
[Train] epoch 476 Batch 40 Loss 0.13419732451438904
[Train] epoch 476 Batch 41 Loss 0.16773748397827148
[Train] epoch 476 Batch 42 Loss 0.23352572321891785
[Train] epoch 476 Batch 43 Loss 0.3677823543548584
[Train] epoch 476 Batch 44 Loss 0.10064269602298737
[Train] epoch 476 Batch 45 Loss 0.16685789823532104
[Train] epoch 476 Batch 46 Loss 0.13454575836658478
[Train] epoch 476 Batch 47 Loss 0.2343064844608307
[Train] epoch 477 Batch 0 Loss 0.13420921564102173
[Train] epoch 477 Batch 1 Loss 0.101392462849617
[Train] epoch 477 Batch 2 Loss 0.2017357498407364
[Train] epoch 477 Batch 3 Loss 0.2671130299568176
[Train] epoch 477 Batch 4 Loss 0.30145376920700073
[Train] epoch 477 Batch 5 Loss 0.23475822806358337
[Train] epoch 477 Batch 6 Loss 0.13408143818378448
[Train] epoch 477 Batch 7 Loss 0.06666764616966248
[Train] epoch 477 Batch 8 Loss 0.10148610919713974
[Train] epoch 477 Batch 9 Loss 0.30101218819618225
[Train] epoch 477 Batch 10 Loss 0.20158059895038605
[Train] epoch 477 Batch 11 Loss 0.06747718900442123
[Train] epoch 477 Batch 12 Loss 0.13376116752624512
[Train] epoch 477 Batch 13 Loss 0.13450844585895538
[Train] epoch 477 Batch 14 Loss 0.2343411147594452
[Train] epoch 477 Batch 15 Loss 0.30104830861091614
[Train] epoch 477 Batch 16 Loss 0.16721537709236145
[Train] epoch 477 Batch 17 Loss 0.20087432861328125
[Train] epoch 477 Batch 18 Loss 0.13453903794288635
[Train] epoch 477 Batch 19 Loss 0.3015025854110718
[Train] epoch 477 Batch 20 Loss 0.2016276717185974
[Train] epoch 477 Batch 21 Loss 0.06702925264835358
[Train] epoch 477 Batch 22 Loss 0.1346033215522766
[Train] epoch 477 Batch 23 Loss 0.3014332950115204
[Train] epoch 477 Batch 24 Loss 0.10054008662700653
[Train] epoch 477 Batch 25 Loss 0.13412514328956604
[Train] epoch 477 Batch 26 Loss 0.3006054759025574
[Train] epoch 477 Batch 27 Loss 0.1672431230545044
[Train] epoch 477 Batch 28 Loss 0.10104045271873474
[Train] epoch 477 Batch 29 Loss 0.16727110743522644
[Train] epoch 477 Batch 30 Loss 0.26748740673065186
[Train] epoch 477 Batch 31 Loss 0.10174623876810074
[Train] epoch 477 Batch 32 Loss 0.13439670205116272
[Train] epoch 477 Batch 33 Loss 0.1341128647327423
[Train] epoch 477 Batch 34 Loss 0.2339356392621994
[Train] epoch 477 Batch 35 Loss 0.13418443500995636
[Train] epoch 477 Batch 36 Loss 0.16726984083652496
[Train] epoch 477 Batch 37 Loss 0.2000008225440979
[Train] epoch 477 Batch 38 Loss 0.06666764616966248
[Train] epoch 477 Batch 39 Loss 0.1352723240852356
[Train] epoch 477 Batch 40 Loss 0.23474636673927307
[Train] epoch 477 Batch 41 Loss 0.16730426251888275
[Train] epoch 477 Batch 42 Loss 0.16730426251888275
[Train] epoch 477 Batch 43 Loss 0.10125625133514404
[Train] epoch 477 Batch 44 Loss 0.2346998155117035
[Train] epoch 477 Batch 45 Loss 0.23431363701820374
[Train] epoch 477 Batch 46 Loss 0.13371708989143372
[Train] epoch 477 Batch 47 Loss 0.10159343481063843
[Train] epoch 478 Batch 0 Loss 0.06735638529062271
[Train] epoch 478 Batch 1 Loss 0.3341383934020996
[Train] epoch 478 Batch 2 Loss 0.20152674615383148
[Train] epoch 478 Batch 3 Loss 0.06781245768070221
[Train] epoch 478 Batch 4 Loss 0.06704530864953995
[Train] epoch 478 Batch 5 Loss 0.36687374114990234
[Train] epoch 478 Batch 6 Loss 0.13371020555496216
[Train] epoch 478 Batch 7 Loss 0.13515141606330872
[Train] epoch 478 Batch 8 Loss 0.26788270473480225
[Train] epoch 478 Batch 9 Loss 0.16725297272205353
[Train] epoch 478 Batch 10 Loss 0.067428819835186
[Train] epoch 478 Batch 11 Loss 0.06704790145158768
[Train] epoch 478 Batch 12 Loss 0.23438496887683868
[Train] epoch 478 Batch 13 Loss 0.23467573523521423
[Train] epoch 478 Batch 14 Loss 0.30016815662384033
[Train] epoch 478 Batch 15 Loss 0.1337578445672989
[Train] epoch 478 Batch 16 Loss 0.06816243380308151
[Train] epoch 478 Batch 17 Loss 0.13445907831192017
[Train] epoch 478 Batch 18 Loss 0.0003684553084895015
[Train] epoch 478 Batch 19 Loss 0.16808143258094788
[Train] epoch 478 Batch 20 Loss 0.13375741243362427
[Train] epoch 478 Batch 21 Loss 0.06807305663824081
[Train] epoch 478 Batch 22 Loss 0.23501719534397125
[Train] epoch 478 Batch 23 Loss 0.2674204409122467
[Train] epoch 478 Batch 24 Loss 0.26820603013038635
[Train] epoch 478 Batch 25 Loss 0.1680009365081787
[Train] epoch 478 Batch 26 Loss 0.1004934161901474
[Train] epoch 478 Batch 27 Loss 0.034234512597322464
[Train] epoch 478 Batch 28 Loss 0.26746463775634766
[Train] epoch 478 Batch 29 Loss 0.23423144221305847
[Train] epoch 478 Batch 30 Loss 0.26894810795783997
[Train] epoch 478 Batch 31 Loss 0.03387065231800079
[Train] epoch 478 Batch 32 Loss 0.16759349405765533
[Train] epoch 478 Batch 33 Loss 0.26739704608917236
[Train] epoch 478 Batch 34 Loss 0.16757361590862274
[Train] epoch 478 Batch 35 Loss 0.2007453441619873
[Train] epoch 478 Batch 36 Loss 0.10083827376365662
[Train] epoch 478 Batch 37 Loss 0.20116585493087769
[Train] epoch 478 Batch 38 Loss 0.2342691421508789
[Train] epoch 478 Batch 39 Loss 0.20084424316883087
[Train] epoch 478 Batch 40 Loss 0.0673898309469223
[Train] epoch 478 Batch 41 Loss 0.06773985922336578
[Train] epoch 478 Batch 42 Loss 0.3668779730796814
[Train] epoch 478 Batch 43 Loss 0.03421284258365631
[Train] epoch 478 Batch 44 Loss 0.23429478704929352
[Train] epoch 478 Batch 45 Loss 0.2003699243068695
[Train] epoch 478 Batch 46 Loss 0.33408215641975403
[Train] epoch 478 Batch 47 Loss 0.20105406641960144
[Train] epoch 479 Batch 0 Loss 0.23425966501235962
[Train] epoch 479 Batch 1 Loss 0.06698283553123474
[Train] epoch 479 Batch 2 Loss 0.16685588657855988
[Train] epoch 479 Batch 3 Loss 0.2343326210975647
[Train] epoch 479 Batch 4 Loss 0.06732629239559174
[Train] epoch 479 Batch 5 Loss 0.16753551363945007
[Train] epoch 479 Batch 6 Loss 0.10118100047111511
[Train] epoch 479 Batch 7 Loss 0.10018781572580338
[Train] epoch 479 Batch 8 Loss 0.16761013865470886
[Train] epoch 479 Batch 9 Loss 0.06740617752075195
[Train] epoch 479 Batch 10 Loss 0.16769394278526306
[Train] epoch 479 Batch 11 Loss 0.23383063077926636
[Train] epoch 479 Batch 12 Loss 0.20141811668872833
[Train] epoch 479 Batch 13 Loss 0.10117083787918091
[Train] epoch 479 Batch 14 Loss 0.03351907059550285
[Train] epoch 479 Batch 15 Loss 0.1343463957309723
[Train] epoch 479 Batch 16 Loss 0.1015559509396553
[Train] epoch 479 Batch 17 Loss 0.13400939106941223
[Train] epoch 479 Batch 18 Loss 0.3341468870639801
[Train] epoch 479 Batch 19 Loss 0.26739391684532166
[Train] epoch 479 Batch 20 Loss 0.23482587933540344
[Train] epoch 479 Batch 21 Loss 0.13406141102313995
[Train] epoch 479 Batch 22 Loss 0.16729679703712463
[Train] epoch 479 Batch 23 Loss 0.23426908254623413
[Train] epoch 479 Batch 24 Loss 0.26775363087654114
[Train] epoch 479 Batch 25 Loss 0.2670866549015045
[Train] epoch 479 Batch 26 Loss 0.10178568959236145
[Train] epoch 479 Batch 27 Loss 0.20033259689807892
[Train] epoch 479 Batch 28 Loss 0.23387479782104492
[Train] epoch 479 Batch 29 Loss 0.13402533531188965
[Train] epoch 479 Batch 30 Loss 0.10090065002441406
[Train] epoch 479 Batch 31 Loss 0.30101731419563293
[Train] epoch 479 Batch 32 Loss 0.3005390763282776
[Train] epoch 479 Batch 33 Loss 0.06798435747623444
[Train] epoch 479 Batch 34 Loss 0.23396191000938416
[Train] epoch 479 Batch 35 Loss 0.13405199348926544
[Train] epoch 479 Batch 36 Loss 0.16762202978134155
[Train] epoch 479 Batch 37 Loss 0.2007455825805664
[Train] epoch 479 Batch 38 Loss 0.16758882999420166
[Train] epoch 479 Batch 39 Loss 0.16747215390205383
[Train] epoch 479 Batch 40 Loss 0.2676432132720947
[Train] epoch 479 Batch 41 Loss 0.10079899430274963
[Train] epoch 479 Batch 42 Loss 0.334432989358902
[Train] epoch 479 Batch 43 Loss 0.0673481822013855
[Train] epoch 479 Batch 44 Loss 0.13404738903045654
[Train] epoch 479 Batch 45 Loss 0.20109717547893524
[Train] epoch 479 Batch 46 Loss 0.2018357813358307
[Train] epoch 479 Batch 47 Loss 0.13398440182209015
[Train] epoch 480 Batch 0 Loss 0.10124162584543228
[Train] epoch 480 Batch 1 Loss 0.13404467701911926
[Train] epoch 480 Batch 2 Loss 0.16748923063278198
[Train] epoch 480 Batch 3 Loss 0.30152279138565063
[Train] epoch 480 Batch 4 Loss 0.1677442342042923
[Train] epoch 480 Batch 5 Loss 0.1339445412158966
[Train] epoch 480 Batch 6 Loss 0.03415170684456825
[Train] epoch 480 Batch 7 Loss 0.1668756604194641
[Train] epoch 480 Batch 8 Loss 0.30090540647506714
[Train] epoch 480 Batch 9 Loss 0.13404016196727753
[Train] epoch 480 Batch 10 Loss 0.03385818004608154
[Train] epoch 480 Batch 11 Loss 0.2006949484348297
[Train] epoch 480 Batch 12 Loss 0.2676229774951935
[Train] epoch 480 Batch 13 Loss 0.06704583764076233
[Train] epoch 480 Batch 14 Loss 0.2014077752828598
[Train] epoch 480 Batch 15 Loss 0.20071783661842346
[Train] epoch 480 Batch 16 Loss 0.2006649672985077
[Train] epoch 480 Batch 17 Loss 0.10178357362747192
[Train] epoch 480 Batch 18 Loss 0.233892560005188
[Train] epoch 480 Batch 19 Loss 0.16757619380950928
[Train] epoch 480 Batch 20 Loss 0.1340211182832718
[Train] epoch 480 Batch 21 Loss 0.13396906852722168
[Train] epoch 480 Batch 22 Loss 0.13462817668914795
[Train] epoch 480 Batch 23 Loss 0.13374920189380646
[Train] epoch 480 Batch 24 Loss 0.2679586112499237
[Train] epoch 480 Batch 25 Loss 0.167815700173378
[Train] epoch 480 Batch 26 Loss 0.10106664150953293
[Train] epoch 480 Batch 27 Loss 0.20076388120651245
[Train] epoch 480 Batch 28 Loss 0.20034900307655334
[Train] epoch 480 Batch 29 Loss 0.06906148791313171
[Train] epoch 480 Batch 30 Loss 0.26780202984809875
[Train] epoch 480 Batch 31 Loss 0.167527437210083
[Train] epoch 480 Batch 32 Loss 0.2000008225440979
[Train] epoch 480 Batch 33 Loss 0.26775747537612915
[Train] epoch 480 Batch 34 Loss 0.3340339660644531
[Train] epoch 480 Batch 35 Loss 0.20082855224609375
[Train] epoch 480 Batch 36 Loss 0.2010635882616043
[Train] epoch 480 Batch 37 Loss 0.06724825501441956
[Train] epoch 480 Batch 38 Loss 0.2673585116863251
[Train] epoch 480 Batch 39 Loss 0.13400569558143616
[Train] epoch 480 Batch 40 Loss 0.2673575282096863
[Train] epoch 480 Batch 41 Loss 0.06666764616966248
[Train] epoch 480 Batch 42 Loss 0.3671743869781494
[Train] epoch 480 Batch 43 Loss 0.200758159160614
[Train] epoch 480 Batch 44 Loss 0.10020732879638672
[Train] epoch 480 Batch 45 Loss 0.1675417423248291
[Train] epoch 480 Batch 46 Loss 0.16724178194999695
[Train] epoch 480 Batch 47 Loss 0.03411473333835602
[Train] epoch 481 Batch 0 Loss 0.1340453028678894
[Train] epoch 481 Batch 1 Loss 0.16687357425689697
[Train] epoch 481 Batch 2 Loss 0.30123913288116455
[Train] epoch 481 Batch 3 Loss 0.2344312071800232
[Train] epoch 481 Batch 4 Loss 0.233494833111763
[Train] epoch 481 Batch 5 Loss 0.1343405842781067
[Train] epoch 481 Batch 6 Loss 0.13399741053581238
[Train] epoch 481 Batch 7 Loss 0.13390398025512695
[Train] epoch 481 Batch 8 Loss 0.10116339474916458
[Train] epoch 481 Batch 9 Loss 0.2673052251338959
[Train] epoch 481 Batch 10 Loss 0.10091325640678406
[Train] epoch 481 Batch 11 Loss 0.301300048828125
[Train] epoch 481 Batch 12 Loss 0.10040830075740814
[Train] epoch 481 Batch 13 Loss 0.1672835797071457
[Train] epoch 481 Batch 14 Loss 0.20082193613052368
[Train] epoch 481 Batch 15 Loss 0.3680722415447235
[Train] epoch 481 Batch 16 Loss 0.2009521722793579
[Train] epoch 481 Batch 17 Loss 0.13399116694927216
[Train] epoch 481 Batch 18 Loss 0.20146718621253967
[Train] epoch 481 Batch 19 Loss 0.20131275057792664
[Train] epoch 481 Batch 20 Loss 0.2002931833267212
[Train] epoch 481 Batch 21 Loss 0.16781969368457794
[Train] epoch 481 Batch 22 Loss 0.133334219455719
[Train] epoch 481 Batch 23 Loss 0.20094500482082367
[Train] epoch 481 Batch 24 Loss 0.03353894129395485
[Train] epoch 481 Batch 25 Loss 0.13410449028015137
[Train] epoch 481 Batch 26 Loss 0.16687199473381042
[Train] epoch 481 Batch 27 Loss 0.23445624113082886
[Train] epoch 481 Batch 28 Loss 0.10076171159744263
[Train] epoch 481 Batch 29 Loss 0.0672234445810318
[Train] epoch 481 Batch 30 Loss 0.1002051904797554
[Train] epoch 481 Batch 31 Loss 0.2014697790145874
[Train] epoch 481 Batch 32 Loss 0.20033779740333557
[Train] epoch 481 Batch 33 Loss 0.10075823962688446
[Train] epoch 481 Batch 34 Loss 0.13386426866054535
[Train] epoch 481 Batch 35 Loss 0.13436585664749146
[Train] epoch 481 Batch 36 Loss 0.1336209625005722
[Train] epoch 481 Batch 37 Loss 0.03382473438978195
[Train] epoch 481 Batch 38 Loss 0.16715751588344574
[Train] epoch 481 Batch 39 Loss 0.10073184221982956
[Train] epoch 481 Batch 40 Loss 0.16749227046966553
[Train] epoch 481 Batch 41 Loss 0.16751384735107422
[Train] epoch 481 Batch 42 Loss 0.10103672742843628
[Train] epoch 481 Batch 43 Loss 0.20131194591522217
[Train] epoch 481 Batch 44 Loss 0.20090332627296448
[Train] epoch 481 Batch 45 Loss 0.3009682893753052
[Train] epoch 481 Batch 46 Loss 0.3011779189109802
[Train] epoch 481 Batch 47 Loss 0.33423352241516113
[Train] epoch 482 Batch 0 Loss 0.33395013213157654
[Train] epoch 482 Batch 1 Loss 0.033819809556007385
[Train] epoch 482 Batch 2 Loss 0.16746434569358826
[Train] epoch 482 Batch 3 Loss 0.26756301522254944
[Train] epoch 482 Batch 4 Loss 0.23394420742988586
[Train] epoch 482 Batch 5 Loss 0.2008945345878601
[Train] epoch 482 Batch 6 Loss 0.1672772765159607
[Train] epoch 482 Batch 7 Loss 0.13402041792869568
[Train] epoch 482 Batch 8 Loss 0.03435460105538368
[Train] epoch 482 Batch 9 Loss 0.06812643259763718
[Train] epoch 482 Batch 10 Loss 0.20040684938430786
[Train] epoch 482 Batch 11 Loss 0.1336657702922821
[Train] epoch 482 Batch 12 Loss 0.13368675112724304
[Train] epoch 482 Batch 13 Loss 0.2672763466835022
[Train] epoch 482 Batch 14 Loss 0.23348337411880493
[Train] epoch 482 Batch 15 Loss 0.16742464900016785
[Train] epoch 482 Batch 16 Loss 0.03401609882712364
[Train] epoch 482 Batch 17 Loss 0.13434657454490662
[Train] epoch 482 Batch 18 Loss 0.06707289069890976
[Train] epoch 482 Batch 19 Loss 0.03406796604394913
[Train] epoch 482 Batch 20 Loss 0.10040401667356491
[Train] epoch 482 Batch 21 Loss 0.13423550128936768
[Train] epoch 482 Batch 22 Loss 0.23421648144721985
[Train] epoch 482 Batch 23 Loss 0.20116055011749268
[Train] epoch 482 Batch 24 Loss 0.1342877894639969
[Train] epoch 482 Batch 25 Loss 0.23429059982299805
[Train] epoch 482 Batch 26 Loss 0.233810156583786
[Train] epoch 482 Batch 27 Loss 0.20027439296245575
[Train] epoch 482 Batch 28 Loss 0.23439079523086548
[Train] epoch 482 Batch 29 Loss 0.1676681637763977
[Train] epoch 482 Batch 30 Loss 0.36739426851272583
[Train] epoch 482 Batch 31 Loss 0.20143312215805054
[Train] epoch 482 Batch 32 Loss 0.1677967607975006
[Train] epoch 482 Batch 33 Loss 0.2669948637485504
[Train] epoch 482 Batch 34 Loss 0.16714055836200714
[Train] epoch 482 Batch 35 Loss 0.13358505070209503
[Train] epoch 482 Batch 36 Loss 0.13412612676620483
[Train] epoch 482 Batch 37 Loss 0.20096471905708313
[Train] epoch 482 Batch 38 Loss 0.10062576830387115
[Train] epoch 482 Batch 39 Loss 0.16713865101337433
[Train] epoch 482 Batch 40 Loss 0.3012574315071106
[Train] epoch 482 Batch 41 Loss 0.0673394650220871
[Train] epoch 482 Batch 42 Loss 0.2338811159133911
[Train] epoch 482 Batch 43 Loss 0.23399507999420166
[Train] epoch 482 Batch 44 Loss 0.1347297728061676
[Train] epoch 482 Batch 45 Loss 0.20099613070487976
[Train] epoch 482 Batch 46 Loss 0.16755808889865875
[Train] epoch 482 Batch 47 Loss 0.16768810153007507
[Train] epoch 483 Batch 0 Loss 0.23429593443870544
[Train] epoch 483 Batch 1 Loss 0.20116259157657623
[Train] epoch 483 Batch 2 Loss 0.26750391721725464
[Train] epoch 483 Batch 3 Loss 0.16764560341835022
[Train] epoch 483 Batch 4 Loss 0.20138518512248993
[Train] epoch 483 Batch 5 Loss 0.10046644508838654
[Train] epoch 483 Batch 6 Loss 0.20136184990406036
[Train] epoch 483 Batch 7 Loss 0.23410232365131378
[Train] epoch 483 Batch 8 Loss 0.16754119098186493
[Train] epoch 483 Batch 9 Loss 0.1336759477853775
[Train] epoch 483 Batch 10 Loss 0.20141367614269257
[Train] epoch 483 Batch 11 Loss 0.13439872860908508
[Train] epoch 483 Batch 12 Loss 0.13405723869800568
[Train] epoch 483 Batch 13 Loss 0.16751126945018768
[Train] epoch 483 Batch 14 Loss 0.06757128983736038
[Train] epoch 483 Batch 15 Loss 0.16760879755020142
[Train] epoch 483 Batch 16 Loss 0.23413440585136414
[Train] epoch 483 Batch 17 Loss 0.2678285539150238
[Train] epoch 483 Batch 18 Loss 0.16726800799369812
[Train] epoch 483 Batch 19 Loss 0.10020102560520172
[Train] epoch 483 Batch 20 Loss 0.0672466903924942
[Train] epoch 483 Batch 21 Loss 0.2002594769001007
[Train] epoch 483 Batch 22 Loss 0.30076003074645996
[Train] epoch 483 Batch 23 Loss 0.13399197161197662
[Train] epoch 483 Batch 24 Loss 0.20049799978733063
[Train] epoch 483 Batch 25 Loss 0.166867196559906
[Train] epoch 483 Batch 26 Loss 0.2678202986717224
[Train] epoch 483 Batch 27 Loss 0.16686707735061646
[Train] epoch 483 Batch 28 Loss 0.23410922288894653
[Train] epoch 483 Batch 29 Loss 0.13413198292255402
[Train] epoch 483 Batch 30 Loss 0.16776013374328613
[Train] epoch 483 Batch 31 Loss 0.16712307929992676
[Train] epoch 483 Batch 32 Loss 0.06692371517419815
[Train] epoch 483 Batch 33 Loss 0.10069344192743301
[Train] epoch 483 Batch 34 Loss 0.2006729543209076
[Train] epoch 483 Batch 35 Loss 0.2338690161705017
[Train] epoch 483 Batch 36 Loss 0.23418620228767395
[Train] epoch 483 Batch 37 Loss 0.06723994016647339
[Train] epoch 483 Batch 38 Loss 0.03402458131313324
[Train] epoch 483 Batch 39 Loss 0.10077182948589325
[Train] epoch 483 Batch 40 Loss 0.06698907911777496
[Train] epoch 483 Batch 41 Loss 0.23425175249576569
[Train] epoch 483 Batch 42 Loss 0.23430553078651428
[Train] epoch 483 Batch 43 Loss 0.2015681266784668
[Train] epoch 483 Batch 44 Loss 0.2671462893486023
[Train] epoch 483 Batch 45 Loss 0.23410040140151978
[Train] epoch 483 Batch 46 Loss 0.16850176453590393
[Train] epoch 483 Batch 47 Loss 0.15644918382167816
[Train] epoch 484 Batch 0 Loss 0.26804324984550476
[Train] epoch 484 Batch 1 Loss 0.13375619053840637
[Train] epoch 484 Batch 2 Loss 0.16734063625335693
[Train] epoch 484 Batch 3 Loss 0.20201414823532104
[Train] epoch 484 Batch 4 Loss 1.2819515466690063
[Train] epoch 484 Batch 5 Loss 0.13372328877449036
[Train] epoch 484 Batch 6 Loss 0.20079255104064941
[Train] epoch 484 Batch 7 Loss 0.0874709039926529
[Train] epoch 484 Batch 8 Loss 0.2343277931213379
[Train] epoch 484 Batch 9 Loss 0.3716638684272766
[Train] epoch 484 Batch 10 Loss 0.42161667346954346
[Train] epoch 484 Batch 11 Loss 0.2592252194881439
[Train] epoch 484 Batch 12 Loss 0.25772735476493835
[Train] epoch 484 Batch 13 Loss 0.1634209305047989
[Train] epoch 484 Batch 14 Loss 0.17560705542564392
[Train] epoch 484 Batch 15 Loss 0.13594889640808105
[Train] epoch 484 Batch 16 Loss 0.30069658160209656
[Train] epoch 484 Batch 17 Loss 0.17334598302841187
[Train] epoch 484 Batch 18 Loss 0.3007640242576599
[Train] epoch 484 Batch 19 Loss 0.1338120996952057
[Train] epoch 484 Batch 20 Loss 0.1677020788192749
[Train] epoch 484 Batch 21 Loss 0.13409480452537537
[Train] epoch 484 Batch 22 Loss 0.06717012077569962
[Train] epoch 484 Batch 23 Loss 0.33442988991737366
[Train] epoch 484 Batch 24 Loss 0.43659278750419617
[Train] epoch 484 Batch 25 Loss 0.26974841952323914
[Train] epoch 484 Batch 26 Loss 0.19955161213874817
[Train] epoch 484 Batch 27 Loss 0.13561156392097473
[Train] epoch 484 Batch 28 Loss 0.13435713946819305
[Train] epoch 484 Batch 29 Loss 0.11668108403682709
[Train] epoch 484 Batch 30 Loss 0.16829413175582886
[Train] epoch 484 Batch 31 Loss 0.20861101150512695
[Train] epoch 484 Batch 32 Loss 0.08241358399391174
[Train] epoch 484 Batch 33 Loss 0.19992446899414062
[Train] epoch 484 Batch 34 Loss 0.06803415715694427
[Train] epoch 484 Batch 35 Loss 0.06716851890087128
[Train] epoch 484 Batch 36 Loss 0.10079845786094666
[Train] epoch 484 Batch 37 Loss 0.3014506697654724
[Train] epoch 484 Batch 38 Loss 0.23543816804885864
[Train] epoch 484 Batch 39 Loss 0.3339453935623169
[Train] epoch 484 Batch 40 Loss 0.06923206150531769
[Train] epoch 484 Batch 41 Loss 0.16768629848957062
[Train] epoch 484 Batch 42 Loss 1.0728851975727594e-06
[Train] epoch 484 Batch 43 Loss 0.23714369535446167
[Train] epoch 484 Batch 44 Loss 0.23499959707260132
[Train] epoch 484 Batch 45 Loss 0.13540911674499512
[Train] epoch 484 Batch 46 Loss 0.07096442580223083
[Train] epoch 484 Batch 47 Loss 0.20785287022590637
[Train] epoch 485 Batch 0 Loss 0.10097086429595947
[Train] epoch 485 Batch 1 Loss 0.16930831968784332
[Train] epoch 485 Batch 2 Loss 0.20153731107711792
[Train] epoch 485 Batch 3 Loss 0.2680436670780182
[Train] epoch 485 Batch 4 Loss 0.16979150474071503
[Train] epoch 485 Batch 5 Loss 0.1353904753923416
[Train] epoch 485 Batch 6 Loss 0.16904078423976898
[Train] epoch 485 Batch 7 Loss 0.1690172553062439
[Train] epoch 485 Batch 8 Loss 0.2026917189359665
[Train] epoch 485 Batch 9 Loss 0.3340427279472351
[Train] epoch 485 Batch 10 Loss 0.06801017373800278
[Train] epoch 485 Batch 11 Loss 0.16766083240509033
[Train] epoch 485 Batch 12 Loss 0.20067861676216125
[Train] epoch 485 Batch 13 Loss 0.13528960943222046
[Train] epoch 485 Batch 14 Loss 0.1015738695859909
[Train] epoch 485 Batch 15 Loss 1.0728851975727594e-06
[Train] epoch 485 Batch 16 Loss 0.1346876323223114
[Train] epoch 485 Batch 17 Loss 0.13468824326992035
[Train] epoch 485 Batch 18 Loss 0.10174411535263062
[Train] epoch 485 Batch 19 Loss 0.13642188906669617
[Train] epoch 485 Batch 20 Loss 0.03419414907693863
[Train] epoch 485 Batch 21 Loss 0.30085524916648865
[Train] epoch 485 Batch 22 Loss 0.20113477110862732
[Train] epoch 485 Batch 23 Loss 0.1352524757385254
[Train] epoch 485 Batch 24 Loss 0.23553085327148438
[Train] epoch 485 Batch 25 Loss 0.10095714032649994
[Train] epoch 485 Batch 26 Loss 0.06833261996507645
[Train] epoch 485 Batch 27 Loss 0.4350924789905548
[Train] epoch 485 Batch 28 Loss 0.16817787289619446
[Train] epoch 485 Batch 29 Loss 0.16927199065685272
[Train] epoch 485 Batch 30 Loss 0.23428340256214142
[Train] epoch 485 Batch 31 Loss 0.23522824048995972
[Train] epoch 485 Batch 32 Loss 0.13400840759277344
[Train] epoch 485 Batch 33 Loss 0.46869969367980957
[Train] epoch 485 Batch 34 Loss 0.26748356223106384
[Train] epoch 485 Batch 35 Loss 0.16761639714241028
[Train] epoch 485 Batch 36 Loss 0.06719561666250229
[Train] epoch 485 Batch 37 Loss 0.10094796121120453
[Train] epoch 485 Batch 38 Loss 0.20174677670001984
[Train] epoch 485 Batch 39 Loss 0.16896693408489227
[Train] epoch 485 Batch 40 Loss 0.201637864112854
[Train] epoch 485 Batch 41 Loss 0.06748602539300919
[Train] epoch 485 Batch 42 Loss 0.23682467639446259
[Train] epoch 485 Batch 43 Loss 0.13520464301109314
[Train] epoch 485 Batch 44 Loss 0.1014726459980011
[Train] epoch 485 Batch 45 Loss 0.1354450285434723
[Train] epoch 485 Batch 46 Loss 0.23440954089164734
[Train] epoch 485 Batch 47 Loss 0.2671898603439331
[Train] epoch 486 Batch 0 Loss 0.16789166629314423
[Train] epoch 486 Batch 1 Loss 0.20252907276153564
[Train] epoch 486 Batch 2 Loss 0.1345246434211731
[Train] epoch 486 Batch 3 Loss 0.1016029566526413
[Train] epoch 486 Batch 4 Loss 0.16810506582260132
[Train] epoch 486 Batch 5 Loss 0.23544995486736298
[Train] epoch 486 Batch 6 Loss 0.13503479957580566
[Train] epoch 486 Batch 7 Loss 0.20169883966445923
[Train] epoch 486 Batch 8 Loss 0.2679886817932129
[Train] epoch 486 Batch 9 Loss 0.10158640891313553
[Train] epoch 486 Batch 10 Loss 0.13414627313613892
[Train] epoch 486 Batch 11 Loss 0.3015827238559723
[Train] epoch 486 Batch 12 Loss 0.36758363246917725
[Train] epoch 486 Batch 13 Loss 0.20132727921009064
[Train] epoch 486 Batch 14 Loss 0.2357890009880066
[Train] epoch 486 Batch 15 Loss 0.13414359092712402
[Train] epoch 486 Batch 16 Loss 0.2337384670972824
[Train] epoch 486 Batch 17 Loss 0.1341424435377121
[Train] epoch 486 Batch 18 Loss 0.1674308180809021
[Train] epoch 486 Batch 19 Loss 0.13465331494808197
[Train] epoch 486 Batch 20 Loss 0.2014659345149994
[Train] epoch 486 Batch 21 Loss 0.13515612483024597
[Train] epoch 486 Batch 22 Loss 0.1687488853931427
[Train] epoch 486 Batch 23 Loss 0.33500540256500244
[Train] epoch 486 Batch 24 Loss 0.06783345341682434
[Train] epoch 486 Batch 25 Loss 0.13448721170425415
[Train] epoch 486 Batch 26 Loss 0.23555345833301544
[Train] epoch 486 Batch 27 Loss 0.270075261592865
[Train] epoch 486 Batch 28 Loss 0.20214684307575226
[Train] epoch 486 Batch 29 Loss 0.20165473222732544
[Train] epoch 486 Batch 30 Loss 0.23422780632972717
[Train] epoch 486 Batch 31 Loss 0.10090474784374237
[Train] epoch 486 Batch 32 Loss 0.10075071454048157
[Train] epoch 486 Batch 33 Loss 0.06766767054796219
[Train] epoch 486 Batch 34 Loss 0.06716959178447723
[Train] epoch 486 Batch 35 Loss 0.16805720329284668
[Train] epoch 486 Batch 36 Loss 0.10203754901885986
[Train] epoch 486 Batch 37 Loss 0.06795850396156311
[Train] epoch 486 Batch 38 Loss 0.20143979787826538
[Train] epoch 486 Batch 39 Loss 0.16756337881088257
[Train] epoch 486 Batch 40 Loss 0.1018843948841095
[Train] epoch 486 Batch 41 Loss 0.16982333362102509
[Train] epoch 486 Batch 42 Loss 0.23551739752292633
[Train] epoch 486 Batch 43 Loss 0.16740930080413818
[Train] epoch 486 Batch 44 Loss 0.26779404282569885
[Train] epoch 486 Batch 45 Loss 0.23452521860599518
[Train] epoch 486 Batch 46 Loss 0.03471527621150017
[Train] epoch 486 Batch 47 Loss 0.16754993796348572
[Train] epoch 487 Batch 0 Loss 0.1675490438938141
[Train] epoch 487 Batch 1 Loss 0.10088154673576355
[Train] epoch 487 Batch 2 Loss 0.3684897720813751
[Train] epoch 487 Batch 3 Loss 0.06730752438306808
[Train] epoch 487 Batch 4 Loss 0.10167472064495087
[Train] epoch 487 Batch 5 Loss 0.13382214307785034
[Train] epoch 487 Batch 6 Loss 0.033728744834661484
[Train] epoch 487 Batch 7 Loss 0.20208901166915894
[Train] epoch 487 Batch 8 Loss 0.30135685205459595
[Train] epoch 487 Batch 9 Loss 0.10166724026203156
[Train] epoch 487 Batch 10 Loss 0.20160773396492004
[Train] epoch 487 Batch 11 Loss 0.1343040019273758
[Train] epoch 487 Batch 12 Loss 0.2009691596031189
[Train] epoch 487 Batch 13 Loss 0.23435592651367188
[Train] epoch 487 Batch 14 Loss 0.13445091247558594
[Train] epoch 487 Batch 15 Loss 0.16865237057209015
[Train] epoch 487 Batch 16 Loss 0.23516058921813965
[Train] epoch 487 Batch 17 Loss 0.20237910747528076
[Train] epoch 487 Batch 18 Loss 0.26855796575546265
[Train] epoch 487 Batch 19 Loss 0.3345966041088104
[Train] epoch 487 Batch 20 Loss 0.16816291213035583
[Train] epoch 487 Batch 21 Loss 0.26808106899261475
[Train] epoch 487 Batch 22 Loss 0.16848260164260864
[Train] epoch 487 Batch 23 Loss 0.10070429742336273
[Train] epoch 487 Batch 24 Loss 0.13474082946777344
[Train] epoch 487 Batch 25 Loss 0.13458558917045593
[Train] epoch 487 Batch 26 Loss 0.20156532526016235
[Train] epoch 487 Batch 27 Loss 0.06666764616966248
[Train] epoch 487 Batch 28 Loss 0.10148029029369354
[Train] epoch 487 Batch 29 Loss 0.2034376710653305
[Train] epoch 487 Batch 30 Loss 0.30086129903793335
[Train] epoch 487 Batch 31 Loss 0.16814708709716797
[Train] epoch 487 Batch 32 Loss 0.06775649636983871
[Train] epoch 487 Batch 33 Loss 0.3006993532180786
[Train] epoch 487 Batch 34 Loss 0.16814285516738892
[Train] epoch 487 Batch 35 Loss 0.03419060632586479
[Train] epoch 487 Batch 36 Loss 0.13395147025585175
[Train] epoch 487 Batch 37 Loss 0.20217010378837585
[Train] epoch 487 Batch 38 Loss 0.16876310110092163
[Train] epoch 487 Batch 39 Loss 0.16705477237701416
[Train] epoch 487 Batch 40 Loss 0.20108139514923096
[Train] epoch 487 Batch 41 Loss 0.06713288277387619
[Train] epoch 487 Batch 42 Loss 0.20184706151485443
[Train] epoch 487 Batch 43 Loss 0.26989173889160156
[Train] epoch 487 Batch 44 Loss 0.23479148745536804
[Train] epoch 487 Batch 45 Loss 0.1020679771900177
[Train] epoch 487 Batch 46 Loss 0.13410383462905884
[Train] epoch 487 Batch 47 Loss 0.2024587243795395
[Train] epoch 488 Batch 0 Loss 0.33487048745155334
[Train] epoch 488 Batch 1 Loss 0.2027566134929657
[Train] epoch 488 Batch 2 Loss 0.234634131193161
[Train] epoch 488 Batch 3 Loss 0.20167303085327148
[Train] epoch 488 Batch 4 Loss 0.06789229810237885
[Train] epoch 488 Batch 5 Loss 0.16826815903186798
[Train] epoch 488 Batch 6 Loss 0.13378843665122986
[Train] epoch 488 Batch 7 Loss 0.23371514678001404
[Train] epoch 488 Batch 8 Loss 0.1668919026851654
[Train] epoch 488 Batch 9 Loss 0.13484960794448853
[Train] epoch 488 Batch 10 Loss 0.2692483365535736
[Train] epoch 488 Batch 11 Loss 0.13485164940357208
[Train] epoch 488 Batch 12 Loss 0.1017405316233635
[Train] epoch 488 Batch 13 Loss 0.1003795862197876
[Train] epoch 488 Batch 14 Loss 0.2018146514892578
[Train] epoch 488 Batch 15 Loss 0.1678008735179901
[Train] epoch 488 Batch 16 Loss 0.0671176016330719
[Train] epoch 488 Batch 17 Loss 0.00045042706187814474
[Train] epoch 488 Batch 18 Loss 0.10098238289356232
[Train] epoch 488 Batch 19 Loss 0.1337779015302658
[Train] epoch 488 Batch 20 Loss 0.10157110542058945
[Train] epoch 488 Batch 21 Loss 0.16793900728225708
[Train] epoch 488 Batch 22 Loss 0.13453924655914307
[Train] epoch 488 Batch 23 Loss 0.23431293666362762
[Train] epoch 488 Batch 24 Loss 0.13453763723373413
[Train] epoch 488 Batch 25 Loss 0.10037726163864136
[Train] epoch 488 Batch 26 Loss 0.16838262975215912
[Train] epoch 488 Batch 27 Loss 0.13482312858104706
[Train] epoch 488 Batch 28 Loss 0.16868694126605988
[Train] epoch 488 Batch 29 Loss 0.23475241661071777
[Train] epoch 488 Batch 30 Loss 0.2000008225440979
[Train] epoch 488 Batch 31 Loss 0.06771329045295715
[Train] epoch 488 Batch 32 Loss 0.1343696117401123
[Train] epoch 488 Batch 33 Loss 0.3018606901168823
[Train] epoch 488 Batch 34 Loss 0.40163618326187134
[Train] epoch 488 Batch 35 Loss 0.201335608959198
[Train] epoch 488 Batch 36 Loss 0.1349668949842453
[Train] epoch 488 Batch 37 Loss 0.16791987419128418
[Train] epoch 488 Batch 38 Loss 0.30318665504455566
[Train] epoch 488 Batch 39 Loss 0.1674792468547821
[Train] epoch 488 Batch 40 Loss 0.23445549607276917
[Train] epoch 488 Batch 41 Loss 0.20162135362625122
[Train] epoch 488 Batch 42 Loss 0.23576700687408447
[Train] epoch 488 Batch 43 Loss 0.10081405192613602
[Train] epoch 488 Batch 44 Loss 0.10155364125967026
[Train] epoch 488 Batch 45 Loss 0.20206362009048462
[Train] epoch 488 Batch 46 Loss 0.16806519031524658
[Train] epoch 488 Batch 47 Loss 0.3013969659805298
[Train] epoch 489 Batch 0 Loss 0.10095769166946411
[Train] epoch 489 Batch 1 Loss 0.23472736775875092
[Train] epoch 489 Batch 2 Loss 0.26784515380859375
[Train] epoch 489 Batch 3 Loss 0.06725156307220459
[Train] epoch 489 Batch 4 Loss 0.10095834732055664
[Train] epoch 489 Batch 5 Loss 0.1008063554763794
[Train] epoch 489 Batch 6 Loss 0.201605886220932
[Train] epoch 489 Batch 7 Loss 0.10021436214447021
[Train] epoch 489 Batch 8 Loss 0.23589441180229187
[Train] epoch 489 Batch 9 Loss 0.3674699068069458
[Train] epoch 489 Batch 10 Loss 0.20247003436088562
[Train] epoch 489 Batch 11 Loss 0.1355123221874237
[Train] epoch 489 Batch 12 Loss 0.13449272513389587
[Train] epoch 489 Batch 13 Loss 0.2342832088470459
[Train] epoch 489 Batch 14 Loss 0.10267274081707001
[Train] epoch 489 Batch 15 Loss 0.13406531512737274
[Train] epoch 489 Batch 16 Loss 0.13492459058761597
[Train] epoch 489 Batch 17 Loss 0.20129583775997162
[Train] epoch 489 Batch 18 Loss 0.13461926579475403
[Train] epoch 489 Batch 19 Loss 0.20100682973861694
[Train] epoch 489 Batch 20 Loss 0.26855018734931946
[Train] epoch 489 Batch 21 Loss 0.06752227246761322
[Train] epoch 489 Batch 22 Loss 0.23485013842582703
[Train] epoch 489 Batch 23 Loss 0.00042533487430773675
[Train] epoch 489 Batch 24 Loss 0.03482772037386894
[Train] epoch 489 Batch 25 Loss 0.16845384240150452
[Train] epoch 489 Batch 26 Loss 0.2682386636734009
[Train] epoch 489 Batch 27 Loss 0.16787448525428772
[Train] epoch 489 Batch 28 Loss 0.16760578751564026
[Train] epoch 489 Batch 29 Loss 0.20057187974452972
[Train] epoch 489 Batch 30 Loss 0.03438328951597214
[Train] epoch 489 Batch 31 Loss 0.1690141260623932
[Train] epoch 489 Batch 32 Loss 0.23453879356384277
[Train] epoch 489 Batch 33 Loss 0.1684441864490509
[Train] epoch 489 Batch 34 Loss 0.03453637287020683
[Train] epoch 489 Batch 35 Loss 0.2349562644958496
[Train] epoch 489 Batch 36 Loss 0.10020741820335388
[Train] epoch 489 Batch 37 Loss 0.23540303111076355
[Train] epoch 489 Batch 38 Loss 0.23426678776741028
[Train] epoch 489 Batch 39 Loss 0.20170548558235168
[Train] epoch 489 Batch 40 Loss 0.10176567733287811
[Train] epoch 489 Batch 41 Loss 0.23452728986740112
[Train] epoch 489 Batch 42 Loss 0.30108219385147095
[Train] epoch 489 Batch 43 Loss 0.26764586567878723
[Train] epoch 489 Batch 44 Loss 0.2009822279214859
[Train] epoch 489 Batch 45 Loss 0.20056486129760742
[Train] epoch 489 Batch 46 Loss 0.23425710201263428
[Train] epoch 489 Batch 47 Loss 0.2007189393043518
[Train] epoch 490 Batch 0 Loss 0.0012403612490743399
[Train] epoch 490 Batch 1 Loss 0.16846027970314026
[Train] epoch 490 Batch 2 Loss 0.16908958554267883
[Train] epoch 490 Batch 3 Loss 0.1354002058506012
[Train] epoch 490 Batch 4 Loss 0.13445991277694702
[Train] epoch 490 Batch 5 Loss 0.23410522937774658
[Train] epoch 490 Batch 6 Loss 0.20071542263031006
[Train] epoch 490 Batch 7 Loss 0.03451311215758324
[Train] epoch 490 Batch 8 Loss 0.2676388621330261
[Train] epoch 490 Batch 9 Loss 0.06738094985485077
[Train] epoch 490 Batch 10 Loss 0.1685560643672943
[Train] epoch 490 Batch 11 Loss 0.23409375548362732
[Train] epoch 490 Batch 12 Loss 0.0672251358628273
[Train] epoch 490 Batch 13 Loss 0.3014781177043915
[Train] epoch 490 Batch 14 Loss 0.13445134460926056
[Train] epoch 490 Batch 15 Loss 0.20137709379196167
[Train] epoch 490 Batch 16 Loss 0.10188446938991547
[Train] epoch 490 Batch 17 Loss 0.13414552807807922
[Train] epoch 490 Batch 18 Loss 0.23505741357803345
[Train] epoch 490 Batch 19 Loss 0.10076351463794708
[Train] epoch 490 Batch 20 Loss 0.23480325937271118
[Train] epoch 490 Batch 21 Loss 0.20162159204483032
[Train] epoch 490 Batch 22 Loss 0.16702064871788025
[Train] epoch 490 Batch 23 Loss 0.30076074600219727
[Train] epoch 490 Batch 24 Loss 0.20096367597579956
[Train] epoch 490 Batch 25 Loss 0.10267660766839981
[Train] epoch 490 Batch 26 Loss 0.20165929198265076
[Train] epoch 490 Batch 27 Loss 0.30105701088905334
[Train] epoch 490 Batch 28 Loss 0.23464179039001465
[Train] epoch 490 Batch 29 Loss 0.133334219455719
[Train] epoch 490 Batch 30 Loss 0.2012530118227005
[Train] epoch 490 Batch 31 Loss 0.10115690529346466
[Train] epoch 490 Batch 32 Loss 0.13468775153160095
[Train] epoch 490 Batch 33 Loss 0.30115121603012085
[Train] epoch 490 Batch 34 Loss 0.16742101311683655
[Train] epoch 490 Batch 35 Loss 0.06776674836874008
[Train] epoch 490 Batch 36 Loss 0.36906516551971436
[Train] epoch 490 Batch 37 Loss 0.1678180694580078
[Train] epoch 490 Batch 38 Loss 0.13453686237335205
[Train] epoch 490 Batch 39 Loss 0.16701635718345642
[Train] epoch 490 Batch 40 Loss 0.2684561014175415
[Train] epoch 490 Batch 41 Loss 0.16781428456306458
[Train] epoch 490 Batch 42 Loss 0.16795383393764496
[Train] epoch 490 Batch 43 Loss 0.13427895307540894
[Train] epoch 490 Batch 44 Loss 0.20039722323417664
[Train] epoch 490 Batch 45 Loss 0.1674109697341919
[Train] epoch 490 Batch 46 Loss 0.10129071772098541
[Train] epoch 490 Batch 47 Loss 0.1685028076171875
[Train] epoch 491 Batch 0 Loss 0.1683468520641327
[Train] epoch 491 Batch 1 Loss 0.20188164710998535
[Train] epoch 491 Batch 2 Loss 0.1340266615152359
[Train] epoch 491 Batch 3 Loss 0.16835008561611176
[Train] epoch 491 Batch 4 Loss 0.26705747842788696
[Train] epoch 491 Batch 5 Loss 0.23531150817871094
[Train] epoch 491 Batch 6 Loss 0.300595760345459
[Train] epoch 491 Batch 7 Loss 0.10143211483955383
[Train] epoch 491 Batch 8 Loss 0.13441962003707886
[Train] epoch 491 Batch 9 Loss 0.06760203093290329
[Train] epoch 491 Batch 10 Loss 0.20131900906562805
[Train] epoch 491 Batch 11 Loss 0.16740290820598602
[Train] epoch 491 Batch 12 Loss 0.1344127357006073
[Train] epoch 491 Batch 13 Loss 0.13387125730514526
[Train] epoch 491 Batch 14 Loss 0.23583459854125977
[Train] epoch 491 Batch 15 Loss 0.0670580342411995
[Train] epoch 491 Batch 16 Loss 0.03446095064282417
[Train] epoch 491 Batch 17 Loss 0.2336764931678772
[Train] epoch 491 Batch 18 Loss 0.20200327038764954
[Train] epoch 491 Batch 19 Loss 0.201314315199852
[Train] epoch 491 Batch 20 Loss 0.2011752724647522
[Train] epoch 491 Batch 21 Loss 0.16754287481307983
[Train] epoch 491 Batch 22 Loss 0.06705601513385773
[Train] epoch 491 Batch 23 Loss 0.034067071974277496
[Train] epoch 491 Batch 24 Loss 0.06720051169395447
[Train] epoch 491 Batch 25 Loss 0.23406589031219482
[Train] epoch 491 Batch 26 Loss 0.06744576245546341
[Train] epoch 491 Batch 27 Loss 0.2689513564109802
[Train] epoch 491 Batch 28 Loss 0.23367419838905334
[Train] epoch 491 Batch 29 Loss 0.10126207768917084
[Train] epoch 491 Batch 30 Loss 0.1675417423248291
[Train] epoch 491 Batch 31 Loss 0.2685111165046692
[Train] epoch 491 Batch 32 Loss 0.16792243719100952
[Train] epoch 491 Batch 33 Loss 0.16778071224689484
[Train] epoch 491 Batch 34 Loss 0.06773370504379272
[Train] epoch 491 Batch 35 Loss 0.3349282145500183
[Train] epoch 491 Batch 36 Loss 0.23497705161571503
[Train] epoch 491 Batch 37 Loss 0.2016923725605011
[Train] epoch 491 Batch 38 Loss 0.23405921459197998
[Train] epoch 491 Batch 39 Loss 0.33501553535461426
[Train] epoch 491 Batch 40 Loss 0.26666736602783203
[Train] epoch 491 Batch 41 Loss 0.06734206527471542
[Train] epoch 491 Batch 42 Loss 0.20182907581329346
[Train] epoch 491 Batch 43 Loss 0.16829803586006165
[Train] epoch 491 Batch 44 Loss 0.2686402499675751
[Train] epoch 491 Batch 45 Loss 0.06772174686193466
[Train] epoch 491 Batch 46 Loss 0.1677655279636383
[Train] epoch 491 Batch 47 Loss 0.13514775037765503
[Train] epoch 492 Batch 0 Loss 0.36753058433532715
[Train] epoch 492 Batch 1 Loss 0.10148616135120392
[Train] epoch 492 Batch 2 Loss 0.2673381567001343
[Train] epoch 492 Batch 3 Loss 0.13385719060897827
[Train] epoch 492 Batch 4 Loss 0.23509642481803894
[Train] epoch 492 Batch 5 Loss 0.1673806756734848
[Train] epoch 492 Batch 6 Loss 0.23443171381950378
[Train] epoch 492 Batch 7 Loss 0.16828572750091553
[Train] epoch 492 Batch 8 Loss 0.16723543405532837
[Train] epoch 492 Batch 9 Loss 0.2006685435771942
[Train] epoch 492 Batch 10 Loss 0.06847215443849564
[Train] epoch 492 Batch 11 Loss 0.26719075441360474
[Train] epoch 492 Batch 12 Loss 0.20193952322006226
[Train] epoch 492 Batch 13 Loss 0.26756590604782104
[Train] epoch 492 Batch 14 Loss 0.10070935636758804
[Train] epoch 492 Batch 15 Loss 0.06718629598617554
[Train] epoch 492 Batch 16 Loss 0.06794246286153793
[Train] epoch 492 Batch 17 Loss 0.16841375827789307
[Train] epoch 492 Batch 18 Loss 0.1672338992357254
[Train] epoch 492 Batch 19 Loss 0.23351946473121643
[Train] epoch 492 Batch 20 Loss 0.10122674703598022
[Train] epoch 492 Batch 21 Loss 0.1669992059469223
[Train] epoch 492 Batch 22 Loss 0.2675602436065674
[Train] epoch 492 Batch 23 Loss 0.1678943932056427
[Train] epoch 492 Batch 24 Loss 0.16803693771362305
[Train] epoch 492 Batch 25 Loss 0.20117828249931335
[Train] epoch 492 Batch 26 Loss 0.20244669914245605
[Train] epoch 492 Batch 27 Loss 0.16737310588359833
[Train] epoch 492 Batch 28 Loss 0.2358146458864212
[Train] epoch 492 Batch 29 Loss 0.13399392366409302
[Train] epoch 492 Batch 30 Loss 0.06844377517700195
[Train] epoch 492 Batch 31 Loss 0.23454435169696808
[Train] epoch 492 Batch 32 Loss 0.1675092577934265
[Train] epoch 492 Batch 33 Loss 0.16722485423088074
[Train] epoch 492 Batch 34 Loss 0.2015463262796402
[Train] epoch 492 Batch 35 Loss 0.20102399587631226
[Train] epoch 492 Batch 36 Loss 0.034260377287864685
[Train] epoch 492 Batch 37 Loss 0.034404121339321136
[Train] epoch 492 Batch 38 Loss 0.2021966278553009
[Train] epoch 492 Batch 39 Loss 0.1343606412410736
[Train] epoch 492 Batch 40 Loss 0.0674082338809967
[Train] epoch 492 Batch 41 Loss 0.30157655477523804
[Train] epoch 492 Batch 42 Loss 0.40065333247184753
[Train] epoch 492 Batch 43 Loss 0.2671758830547333
[Train] epoch 492 Batch 44 Loss 0.03476962819695473
[Train] epoch 492 Batch 45 Loss 0.13420942425727844
[Train] epoch 492 Batch 46 Loss 0.1015743613243103
[Train] epoch 492 Batch 47 Loss 0.1355348378419876
[Train] epoch 493 Batch 0 Loss 0.2343951314687729
[Train] epoch 493 Batch 1 Loss 0.16823410987854004
[Train] epoch 493 Batch 2 Loss 0.3017066717147827
[Train] epoch 493 Batch 3 Loss 0.10018497705459595
[Train] epoch 493 Batch 4 Loss 0.23388242721557617
[Train] epoch 493 Batch 5 Loss 0.2681891918182373
[Train] epoch 493 Batch 6 Loss 0.23481589555740356
[Train] epoch 493 Batch 7 Loss 0.13370069861412048
[Train] epoch 493 Batch 8 Loss 0.13420450687408447
[Train] epoch 493 Batch 9 Loss 0.06790617108345032
[Train] epoch 493 Batch 10 Loss 0.06840246915817261
[Train] epoch 493 Batch 11 Loss 0.1341993808746338
[Train] epoch 493 Batch 12 Loss 0.10155375301837921
[Train] epoch 493 Batch 13 Loss 0.16785785555839539
[Train] epoch 493 Batch 14 Loss 0.20165503025054932
[Train] epoch 493 Batch 15 Loss 0.13419969379901886
[Train] epoch 493 Batch 16 Loss 0.16785836219787598
[Train] epoch 493 Batch 17 Loss 0.13441695272922516
[Train] epoch 493 Batch 18 Loss 0.30262142419815063
[Train] epoch 493 Batch 19 Loss 0.4020083546638489
[Train] epoch 493 Batch 20 Loss 0.20064477622509003
[Train] epoch 493 Batch 21 Loss 0.20085608959197998
[Train] epoch 493 Batch 22 Loss 0.1344161033630371
[Train] epoch 493 Batch 23 Loss 0.10104165226221085
[Train] epoch 493 Batch 24 Loss 0.1338355839252472
[Train] epoch 493 Batch 25 Loss 0.10067927837371826
[Train] epoch 493 Batch 26 Loss 0.300678551197052
[Train] epoch 493 Batch 27 Loss 0.10017801821231842
[Train] epoch 493 Batch 28 Loss 0.16720449924468994
[Train] epoch 493 Batch 29 Loss 0.20100033283233643
[Train] epoch 493 Batch 30 Loss 0.10032068192958832
[Train] epoch 493 Batch 31 Loss 0.03401019051671028
[Train] epoch 493 Batch 32 Loss 0.13454222679138184
[Train] epoch 493 Batch 33 Loss 0.16769836843013763
[Train] epoch 493 Batch 34 Loss 0.33482322096824646
[Train] epoch 493 Batch 35 Loss 0.33468878269195557
[Train] epoch 493 Batch 36 Loss 0.2009965479373932
[Train] epoch 493 Batch 37 Loss 0.06738027185201645
[Train] epoch 493 Batch 38 Loss 0.13432270288467407
[Train] epoch 493 Batch 39 Loss 0.20234315097332
[Train] epoch 493 Batch 40 Loss 0.10067614912986755
[Train] epoch 493 Batch 41 Loss 0.13489489257335663
[Train] epoch 493 Batch 42 Loss 0.20085333287715912
[Train] epoch 493 Batch 43 Loss 0.13488927483558655
[Train] epoch 493 Batch 44 Loss 0.16783320903778076
[Train] epoch 493 Batch 45 Loss 0.3346765637397766
[Train] epoch 493 Batch 46 Loss 0.06751748919487
[Train] epoch 493 Batch 47 Loss 0.16761891543865204
[Train] epoch 494 Batch 0 Loss 0.16768726706504822
[Train] epoch 494 Batch 1 Loss 0.16797196865081787
[Train] epoch 494 Batch 2 Loss 0.23449203372001648
[Train] epoch 494 Batch 3 Loss 0.13396693766117096
[Train] epoch 494 Batch 4 Loss 0.20035123825073242
[Train] epoch 494 Batch 5 Loss 0.5001770257949829
[Train] epoch 494 Batch 6 Loss 0.13452935218811035
[Train] epoch 494 Batch 7 Loss 0.13368692994117737
[Train] epoch 494 Batch 8 Loss 0.06785832345485687
[Train] epoch 494 Batch 9 Loss 0.10157977044582367
[Train] epoch 494 Batch 10 Loss 0.2347683310508728
[Train] epoch 494 Batch 11 Loss 0.2011859118938446
[Train] epoch 494 Batch 12 Loss 0.10136650502681732
[Train] epoch 494 Batch 13 Loss 0.1678236722946167
[Train] epoch 494 Batch 14 Loss 0.1355646550655365
[Train] epoch 494 Batch 15 Loss 0.1345152109861374
[Train] epoch 494 Batch 16 Loss 0.2684133052825928
[Train] epoch 494 Batch 17 Loss 0.0010453120339661837
[Train] epoch 494 Batch 18 Loss 0.2676423192024231
[Train] epoch 494 Batch 19 Loss 0.2011154741048813
[Train] epoch 494 Batch 20 Loss 0.13479897379875183
[Train] epoch 494 Batch 21 Loss 0.06805817037820816
[Train] epoch 494 Batch 22 Loss 0.23364806175231934
[Train] epoch 494 Batch 23 Loss 0.033992260694503784
[Train] epoch 494 Batch 24 Loss 0.13430532813072205
[Train] epoch 494 Batch 25 Loss 0.13382086157798767
[Train] epoch 494 Batch 26 Loss 0.3023218810558319
[Train] epoch 494 Batch 27 Loss 0.16683757305145264
[Train] epoch 494 Batch 28 Loss 0.2009667158126831
[Train] epoch 494 Batch 29 Loss 0.06729338318109512
[Train] epoch 494 Batch 30 Loss 0.2676376700401306
[Train] epoch 494 Batch 31 Loss 0.16760492324829102
[Train] epoch 494 Batch 32 Loss 0.2682553231716156
[Train] epoch 494 Batch 33 Loss 0.2344745695590973
[Train] epoch 494 Batch 34 Loss 0.035017650574445724
[Train] epoch 494 Batch 35 Loss 0.20096489787101746
[Train] epoch 494 Batch 36 Loss 0.16862711310386658
[Train] epoch 494 Batch 37 Loss 0.06763307750225067
[Train] epoch 494 Batch 38 Loss 0.16752342879772186
[Train] epoch 494 Batch 39 Loss 0.20115840435028076
[Train] epoch 494 Batch 40 Loss 0.10079015791416168
[Train] epoch 494 Batch 41 Loss 0.13381560146808624
[Train] epoch 494 Batch 42 Loss 0.20124006271362305
[Train] epoch 494 Batch 43 Loss 0.10065008699893951
[Train] epoch 494 Batch 44 Loss 0.43446028232574463
[Train] epoch 494 Batch 45 Loss 0.20150423049926758
[Train] epoch 494 Batch 46 Loss 0.2671443819999695
[Train] epoch 494 Batch 47 Loss 0.10065115988254547
[Train] epoch 495 Batch 0 Loss 0.2009563446044922
[Train] epoch 495 Batch 1 Loss 0.2009584903717041
[Train] epoch 495 Batch 2 Loss 0.16751474142074585
[Train] epoch 495 Batch 3 Loss 0.2341175079345703
[Train] epoch 495 Batch 4 Loss 0.13367486000061035
[Train] epoch 495 Batch 5 Loss 0.10126391053199768
[Train] epoch 495 Batch 6 Loss 0.06762253493070602
[Train] epoch 495 Batch 7 Loss 0.03350171074271202
[Train] epoch 495 Batch 8 Loss 0.1340114027261734
[Train] epoch 495 Batch 9 Loss 0.1683279275894165
[Train] epoch 495 Batch 10 Loss 0.03431464731693268
[Train] epoch 495 Batch 11 Loss 0.2009531557559967
[Train] epoch 495 Batch 12 Loss 0.23506300151348114
[Train] epoch 495 Batch 13 Loss 0.10064329206943512
[Train] epoch 495 Batch 14 Loss 0.3019319474697113
[Train] epoch 495 Batch 15 Loss 0.2674807012081146
[Train] epoch 495 Batch 16 Loss 0.10064470022916794
[Train] epoch 495 Batch 17 Loss 0.13481667637825012
[Train] epoch 495 Batch 18 Loss 0.2004750370979309
[Train] epoch 495 Batch 19 Loss 0.36730462312698364
[Train] epoch 495 Batch 20 Loss 0.16750468313694
[Train] epoch 495 Batch 21 Loss 0.23430734872817993
[Train] epoch 495 Batch 22 Loss 0.1682528555393219
[Train] epoch 495 Batch 23 Loss 0.23525451123714447
[Train] epoch 495 Batch 24 Loss 0.06727730482816696
[Train] epoch 495 Batch 25 Loss 0.2008034884929657
[Train] epoch 495 Batch 26 Loss 0.2680785655975342
[Train] epoch 495 Batch 27 Loss 0.23458200693130493
[Train] epoch 495 Batch 28 Loss 0.06780345737934113
[Train] epoch 495 Batch 29 Loss 0.03430474177002907
[Train] epoch 495 Batch 30 Loss 0.13400015234947205
[Train] epoch 495 Batch 31 Loss 0.10096995532512665
[Train] epoch 495 Batch 32 Loss 0.267799973487854
[Train] epoch 495 Batch 33 Loss 0.23443585634231567
[Train] epoch 495 Batch 34 Loss 0.16777372360229492
[Train] epoch 495 Batch 35 Loss 0.30096423625946045
[Train] epoch 495 Batch 36 Loss 0.20093682408332825
[Train] epoch 495 Batch 37 Loss 0.20140531659126282
[Train] epoch 495 Batch 38 Loss 0.20140434801578522
[Train] epoch 495 Batch 39 Loss 0.2007983922958374
[Train] epoch 495 Batch 40 Loss 0.26787692308425903
[Train] epoch 495 Batch 41 Loss 0.06713543832302094
[Train] epoch 495 Batch 42 Loss 0.2683984637260437
[Train] epoch 495 Batch 43 Loss 0.3009592294692993
[Train] epoch 495 Batch 44 Loss 0.16776405274868011
[Train] epoch 495 Batch 45 Loss 0.03429426625370979
[Train] epoch 495 Batch 46 Loss 0.06713136285543442
[Train] epoch 495 Batch 47 Loss 0.10156133770942688
[Train] epoch 496 Batch 0 Loss 0.10095897316932678
[Train] epoch 496 Batch 1 Loss 0.20112314820289612
[Train] epoch 496 Batch 2 Loss 0.20139582455158234
[Train] epoch 496 Batch 3 Loss 0.3012275695800781
[Train] epoch 496 Batch 4 Loss 0.13412268459796906
[Train] epoch 496 Batch 5 Loss 0.33472365140914917
[Train] epoch 496 Batch 6 Loss 0.2681936025619507
[Train] epoch 496 Batch 7 Loss 0.10089822113513947
[Train] epoch 496 Batch 8 Loss 0.2674563527107239
[Train] epoch 496 Batch 9 Loss 0.1009535863995552
[Train] epoch 496 Batch 10 Loss 0.16814164817333221
[Train] epoch 496 Batch 11 Loss 0.033495835959911346
[Train] epoch 496 Batch 12 Loss 0.16775482892990112
[Train] epoch 496 Batch 13 Loss 0.10048957169055939
[Train] epoch 496 Batch 14 Loss 0.16820982098579407
[Train] epoch 496 Batch 15 Loss 0.40137606859207153
[Train] epoch 496 Batch 16 Loss 0.20118992030620575
[Train] epoch 496 Batch 17 Loss 0.10108240693807602
[Train] epoch 496 Batch 18 Loss 0.3018653392791748
[Train] epoch 496 Batch 19 Loss 0.23481683433055878
[Train] epoch 496 Batch 20 Loss 0.20046010613441467
[Train] epoch 496 Batch 21 Loss 0.13411426544189453
[Train] epoch 496 Batch 22 Loss 0.10094347596168518
[Train] epoch 496 Batch 23 Loss 0.20091743767261505
[Train] epoch 496 Batch 24 Loss 0.16761384904384613
[Train] epoch 496 Batch 25 Loss 0.23395445942878723
[Train] epoch 496 Batch 26 Loss 0.20091556012630463
[Train] epoch 496 Batch 27 Loss 0.13424354791641235
[Train] epoch 496 Batch 28 Loss 0.13392286002635956
[Train] epoch 496 Batch 29 Loss 0.16779956221580505
[Train] epoch 496 Batch 30 Loss 0.13443247973918915
[Train] epoch 496 Batch 31 Loss 0.16714930534362793
[Train] epoch 496 Batch 32 Loss 0.23472709953784943
[Train] epoch 496 Batch 33 Loss 0.13411125540733337
[Train] epoch 496 Batch 34 Loss 0.20077739655971527
[Train] epoch 496 Batch 35 Loss 0.2013634592294693
[Train] epoch 496 Batch 36 Loss 0.20109966397285461
[Train] epoch 496 Batch 37 Loss 0.16760408878326416
[Train] epoch 496 Batch 38 Loss 0.23439911007881165
[Train] epoch 496 Batch 39 Loss 0.10125866532325745
[Train] epoch 496 Batch 40 Loss 0.23459331691265106
[Train] epoch 496 Batch 41 Loss 0.1336536854505539
[Train] epoch 496 Batch 42 Loss 0.06712096184492111
[Train] epoch 496 Batch 43 Loss 0.30177953839302063
[Train] epoch 496 Batch 44 Loss 0.10029324889183044
[Train] epoch 496 Batch 45 Loss 0.06730451434850693
[Train] epoch 496 Batch 46 Loss 0.03413349762558937
[Train] epoch 496 Batch 47 Loss 0.06775566935539246
[Train] epoch 497 Batch 0 Loss 0.3678629398345947
[Train] epoch 497 Batch 1 Loss 0.10048064589500427
[Train] epoch 497 Batch 2 Loss 0.23349151015281677
[Train] epoch 497 Batch 3 Loss 0.16746343672275543
[Train] epoch 497 Batch 4 Loss 0.23502914607524872
[Train] epoch 497 Batch 5 Loss 0.2014031857252121
[Train] epoch 497 Batch 6 Loss 0.26859793066978455
[Train] epoch 497 Batch 7 Loss 0.10092616081237793
[Train] epoch 497 Batch 8 Loss 0.10060767829418182
[Train] epoch 497 Batch 9 Loss 0.26801255345344543
[Train] epoch 497 Batch 10 Loss 0.2003156989812851
[Train] epoch 497 Batch 11 Loss 0.1672731339931488
[Train] epoch 497 Batch 12 Loss 0.23420673608779907
[Train] epoch 497 Batch 13 Loss 0.23407378792762756
[Train] epoch 497 Batch 14 Loss 0.16759073734283447
[Train] epoch 497 Batch 15 Loss 0.10150223225355148
[Train] epoch 497 Batch 16 Loss 0.0674295648932457
[Train] epoch 497 Batch 17 Loss 0.30163025856018066
[Train] epoch 497 Batch 18 Loss 0.1674051582813263
[Train] epoch 497 Batch 19 Loss 0.30105096101760864
[Train] epoch 497 Batch 20 Loss 0.16758301854133606
[Train] epoch 497 Batch 21 Loss 0.13472408056259155
[Train] epoch 497 Batch 22 Loss 0.20089401304721832
[Train] epoch 497 Batch 23 Loss 0.13422465324401855
[Train] epoch 497 Batch 24 Loss 0.13377806544303894
[Train] epoch 497 Batch 25 Loss 0.26786667108535767
[Train] epoch 497 Batch 26 Loss 0.13480226695537567
[Train] epoch 497 Batch 27 Loss 0.2677406668663025
[Train] epoch 497 Batch 28 Loss 0.23442789912223816
[Train] epoch 497 Batch 29 Loss 0.16852103173732758
[Train] epoch 497 Batch 30 Loss 0.13453426957130432
[Train] epoch 497 Batch 31 Loss 0.10059943795204163
[Train] epoch 497 Batch 32 Loss 0.10179963707923889
[Train] epoch 497 Batch 33 Loss 0.06755504012107849
[Train] epoch 497 Batch 34 Loss 0.134263813495636
[Train] epoch 497 Batch 35 Loss 0.2674179673194885
[Train] epoch 497 Batch 36 Loss 0.1339549571275711
[Train] epoch 497 Batch 37 Loss 0.1002880185842514
[Train] epoch 497 Batch 38 Loss 0.3008617162704468
[Train] epoch 497 Batch 39 Loss 0.10117221623659134
[Train] epoch 497 Batch 40 Loss 0.06728207319974899
[Train] epoch 497 Batch 41 Loss 0.10059772431850433
[Train] epoch 497 Batch 42 Loss 0.10046375542879105
[Train] epoch 497 Batch 43 Loss 0.13509730994701385
[Train] epoch 497 Batch 44 Loss 0.16796530783176422
[Train] epoch 497 Batch 45 Loss 0.10046075284481049
[Train] epoch 497 Batch 46 Loss 0.23449687659740448
[Train] epoch 497 Batch 47 Loss 0.16681991517543793
[Train] epoch 498 Batch 0 Loss 0.167262002825737
[Train] epoch 498 Batch 1 Loss 0.1673927903175354
[Train] epoch 498 Batch 2 Loss 0.23423230648040771
[Train] epoch 498 Batch 3 Loss 0.1345192790031433
[Train] epoch 498 Batch 4 Loss 0.26771461963653564
[Train] epoch 498 Batch 5 Loss 0.10059390962123871
[Train] epoch 498 Batch 6 Loss 0.2340574562549591
[Train] epoch 498 Batch 7 Loss 0.36826077103614807
[Train] epoch 498 Batch 8 Loss 0.2351016104221344
[Train] epoch 498 Batch 9 Loss 0.1685665398836136
[Train] epoch 498 Batch 10 Loss 0.10146540403366089
[Train] epoch 498 Batch 11 Loss 0.10076459497213364
[Train] epoch 498 Batch 12 Loss 0.23453649878501892
[Train] epoch 498 Batch 13 Loss 0.16751763224601746
[Train] epoch 498 Batch 14 Loss 0.1673871874809265
[Train] epoch 498 Batch 15 Loss 0.1676909327507019
[Train] epoch 498 Batch 16 Loss 0.1675606667995453
[Train] epoch 498 Batch 17 Loss 0.20143507421016693
[Train] epoch 498 Batch 18 Loss 0.10058926045894623
[Train] epoch 498 Batch 19 Loss 0.10045740753412247
[Train] epoch 498 Batch 20 Loss 0.20087039470672607
[Train] epoch 498 Batch 21 Loss 0.13407203555107117
[Train] epoch 498 Batch 22 Loss 0.23448210954666138
[Train] epoch 498 Batch 23 Loss 0.2672303020954132
[Train] epoch 498 Batch 24 Loss 0.20086616277694702
[Train] epoch 498 Batch 25 Loss 0.03409237787127495
[Train] epoch 498 Batch 26 Loss 0.10058664530515671
[Train] epoch 498 Batch 27 Loss 0.06697233766317368
[Train] epoch 498 Batch 28 Loss 0.16811607778072357
[Train] epoch 498 Batch 29 Loss 0.13389508426189423
[Train] epoch 498 Batch 30 Loss 0.16694778203964233
[Train] epoch 498 Batch 31 Loss 0.2670973539352417
[Train] epoch 498 Batch 32 Loss 0.06770546734333038
[Train] epoch 498 Batch 33 Loss 0.16725122928619385
[Train] epoch 498 Batch 34 Loss 0.1678520143032074
[Train] epoch 498 Batch 35 Loss 0.20129480957984924
[Train] epoch 498 Batch 36 Loss 0.2003020942211151
[Train] epoch 498 Batch 37 Loss 0.13535690307617188
[Train] epoch 498 Batch 38 Loss 0.2672256529331207
[Train] epoch 498 Batch 39 Loss 0.20060677826404572
[Train] epoch 498 Batch 40 Loss 0.10161624848842621
[Train] epoch 498 Batch 41 Loss 0.16712141036987305
[Train] epoch 498 Batch 42 Loss 0.1342371106147766
[Train] epoch 498 Batch 43 Loss 0.20141705870628357
[Train] epoch 498 Batch 44 Loss 0.034212302416563034
[Train] epoch 498 Batch 45 Loss 0.3008780777454376
[Train] epoch 498 Batch 46 Loss 0.23391374945640564
[Train] epoch 498 Batch 47 Loss 0.2019270658493042
[Train] epoch 499 Batch 0 Loss 0.2337854504585266
[Train] epoch 499 Batch 1 Loss 0.000600178842432797
[Train] epoch 499 Batch 2 Loss 0.26722344756126404
[Train] epoch 499 Batch 3 Loss 0.20145264267921448
[Train] epoch 499 Batch 4 Loss 0.16839823126792908
[Train] epoch 499 Batch 5 Loss 0.20140942931175232
[Train] epoch 499 Batch 6 Loss 0.06739409267902374
[Train] epoch 499 Batch 7 Loss 0.13465596735477448
[Train] epoch 499 Batch 8 Loss 0.2676834166049957
[Train] epoch 499 Batch 9 Loss 0.167239248752594
[Train] epoch 499 Batch 10 Loss 0.1337585747241974
[Train] epoch 499 Batch 11 Loss 0.2676871716976166
[Train] epoch 499 Batch 12 Loss 0.10014770925045013
[Train] epoch 499 Batch 13 Loss 0.13392680883407593
[Train] epoch 499 Batch 14 Loss 0.13503649830818176
[Train] epoch 499 Batch 15 Loss 0.3001471161842346
[Train] epoch 499 Batch 16 Loss 0.10057437419891357
[Train] epoch 499 Batch 17 Loss 0.10070273280143738
[Train] epoch 499 Batch 18 Loss 0.2680685222148895
[Train] epoch 499 Batch 19 Loss 0.06666764616966248
[Train] epoch 499 Batch 20 Loss 0.16766420006752014
[Train] epoch 499 Batch 21 Loss 0.1343477964401245
[Train] epoch 499 Batch 22 Loss 0.2344929575920105
[Train] epoch 499 Batch 23 Loss 0.06780855357646942
[Train] epoch 499 Batch 24 Loss 0.30128660798072815
[Train] epoch 499 Batch 25 Loss 0.2673817276954651
[Train] epoch 499 Batch 26 Loss 0.06709079444408417
[Train] epoch 499 Batch 27 Loss 0.16752827167510986
[Train] epoch 499 Batch 28 Loss 0.23461708426475525
[Train] epoch 499 Batch 29 Loss 0.26822710037231445
[Train] epoch 499 Batch 30 Loss 0.267801970243454
[Train] epoch 499 Batch 31 Loss 0.06767500936985016
[Train] epoch 499 Batch 32 Loss 0.23503398895263672
[Train] epoch 499 Batch 33 Loss 0.06738238036632538
[Train] epoch 499 Batch 34 Loss 0.1672353446483612
[Train] epoch 499 Batch 35 Loss 0.06666764616966248
[Train] epoch 499 Batch 36 Loss 0.10127778351306915
[Train] epoch 499 Batch 37 Loss 0.16836431622505188
[Train] epoch 499 Batch 38 Loss 0.2349986732006073
[Train] epoch 499 Batch 39 Loss 0.233900249004364
[Train] epoch 499 Batch 40 Loss 0.1344641000032425
[Train] epoch 499 Batch 41 Loss 0.3008539080619812
[Train] epoch 499 Batch 42 Loss 0.23360806703567505
[Train] epoch 499 Batch 43 Loss 0.2344447672367096
[Train] epoch 499 Batch 44 Loss 0.20138441026210785
[Train] epoch 499 Batch 45 Loss 0.20112359523773193
[Train] epoch 499 Batch 46 Loss 0.06708429753780365
[Train] epoch 499 Batch 47 Loss 0.13375243544578552
